{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgOhk8U4Rpl"
      },
      "source": [
        "# Quickstart: Querying PDF With Chroma and LangChain\n",
        "\n",
        "### A question-answering demo using Chroma DB and LangChain, powered by Vector Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqfJKgRM4Rpo"
      },
      "source": [
        "#### Pre-requisites:\n",
        "\n",
        "You need a chroma Db and Ollama hosted llama3.2 to generate embeddings.\n",
        "\n",
        "#### What you will do:\n",
        "\n",
        "- Setup: import dependencies, provide secrets, create the LangChain vector store;\n",
        "- Run a Question-Answering loop retrieving the relevant headlines and having an LLM construct the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_FeN-Ep4Rpp"
      },
      "source": [
        "Install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Uk0qUhJUQrkO"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install PyPDF2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQQN-L2J4Rpq"
      },
      "source": [
        "Import the packages you'll need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "V4qBIihE4Rpq"
      },
      "outputs": [],
      "source": [
        "# LangChain components to use\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "\n",
        "\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# To read PDF files\n",
        "from PyPDF2 import PdfReader\n",
        "from typing_extensions import Concatenate\n",
        "\n",
        "# Load env file\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "attachments": {
        "image-2.png": {
          "image/png": "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"
        },
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAG Pipeline\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n",
        "\n",
        "\n",
        "## Data loading process\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2UauiC4Rpr"
      },
      "source": [
        "### Data Loading Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "42BKuFRO6meP"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('data/Amazon SageMaker.pdf')\n",
        "\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "vR41Iq-4ZHnG",
        "outputId": "861bc27a-fd4d-47f9-f722-8e365a6fd030"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Amazon SageMaker\\nDeveloper Guide\\nAmazon SageMaker Developer Guide\\nAmazon SageMaker: Developer Guide\\nCopyright © 2019 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\\nAmazon\\'s trademarks and trade dress may not be used in connection with any product or service that is not\\nAmazon\\'s, in any manner that is likely to cause confusion among customers, or in any manner that disparages or\\ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may\\nor may not be aﬃliated with, connected to, or sponsored by Amazon.Amazon SageMaker Developer Guide\\nTable of Contents\\nWhat Is Amazon SageMaker?...............................................................................................................1\\nAre You a First-time User of Amazon SageMaker?..........................................................................1\\nHow It Works....................................................................................................................................2\\nMachine Learning with Amazon SageMaker...................................................................................2\\nHow It Works: Next Topic...................................................................................................3\\nExplore and Preprocess Data.......................................................................................................4\\nHow It Works: Next Topic...................................................................................................4\\nModel Training...........................................................................................................................4\\nHow It Works: Next Topic....................................................................................................7\\nModel Deployment.....................................................................................................................7\\nHosting Services................................................................................................................7\\nBatch Transform...............................................................................................................10\\nValidating Models.............................................................................................................11\\nProgramming Model.........................................................................................................12\\nSet Up Amazon SageMaker...............................................................................................................14\\nStep 1: Create an AWS Account..................................................................................................14\\nStep 2: Create an IAM Administrator User and Group....................................................................14\\nGet Started.....................................................................................................................................16\\nStep 1: Create an Amazon S3 Bucket..........................................................................................17\\nNext Step........................................................................................................................17\\nStep 2: Create an Amazon SageMaker Notebook Instance..............................................................17\\nNext Step........................................................................................................................18\\nStep 3: Create a Jupyter Notebook.............................................................................................18\\n......................................................................................................................................19\\nStep 4: Download, Explore, and Transform Data...........................................................................19\\nStep 4.1: Download the Dataset.........................................................................................19\\nStep 4.2: Explore the Dataset............................................................................................20\\nStep 4.3: Transform Dataset and Upload to S3.....................................................................21\\nStep 5: Train a Model...............................................................................................................21\\nChoose the Training Algorithm...........................................................................................22\\nCreate and Run a Training Job (Amazon SageMaker Python SDK)............................................22\\nCreate and Run a Training Job (AWS SDK for Python (Boto 3))...............................................23\\nStep 6: Deploy the Model..........................................................................................................26\\nStep 6.1: Hosting Services.................................................................................................26\\nStep 6.2: Batch Transform.................................................................................................28\\nStep 7: Validate the Model........................................................................................................30\\nStep 7.1: Validate a Model Deployed to Amazon SageMaker Hosting Services...........................30\\nStep 7.2: Validate a Model Deployed with Batch Transform....................................................33\\nStep 8: Clean Up ......................................................................................................................35\\nStep 9: Integrating Amazon SageMaker Endpoints into Internet-facing Applications..........................35\\nUsing Notebook Instances.................................................................................................................36\\nCreate a Notebook Instance.......................................................................................................36\\nAccess Notebook Instances........................................................................................................39\\nControl Root Access to a Notebook Instance........................................................................40\\nCustomize a Notebook Instance.................................................................................................40\\nLifecycle Conﬁguration Best Practices.................................................................................41\\nUse Example Notebooks ............................................................................................................42\\nUse or View Example Notebooks in Jupyter Classic...............................................................42\\nUse or View Example Notebooks in Jupyterlab.....................................................................43\\nNotebook Instance Software Updates.........................................................................................44\\nSet the Notebook Kernel...........................................................................................................44\\nInstall External Libraries and Kernels in Notebook Instances...........................................................45\\nMaintain a Sandboxed Python Environment.........................................................................45\\nAssociate Git Repositories with Amazon SageMaker Notebook Instances..........................................46\\niiiAmazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account.....................................................47\\nCreate a Notebook Instance with an Associated Git Repository...............................................49\\nAssociate a CodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance.........51\\nUse Git Repositories in a Notebook Instance........................................................................52\\nGet Notebook Instance Metadata...............................................................................................54\\nMonitor Jupyter Logs in Amazon CloudWatch Logs.......................................................................54\\nBuild a Model ..................................................................................................................................56\\nUse Built-in Algorithms.............................................................................................................56\\nCommon Information .......................................................................................................58\\nBlazingText......................................................................................................................74\\nDeepAR Forecasting..........................................................................................................83\\nFactorization Machines......................................................................................................98\\nImage Classiﬁcation Algorithm .........................................................................................108\\nIP Insights .....................................................................................................................131\\nK-Means Algorithm.........................................................................................................141\\nK-Nearest Neighbors (k-NN) Algorithm..............................................................................148\\nLatent Dirichlet Allocation (LDA).......................................................................................157\\nLinear Learner Algorithm .................................................................................................162\\nNeural Topic Model (NTM) Algorithm................................................................................177\\nObject2Vec....................................................................................................................183\\nObject Detection Algorithm.............................................................................................199\\nPrincipal Component Analysis (PCA) Algorithm ...................................................................222\\nRandom Cut Forest (RCF) Algorithm..................................................................................226\\nSemantic Segmentation ..................................................................................................234\\nSequence to Sequence (seq2seq)......................................................................................242\\nXGBoost Algorithm.........................................................................................................255\\nTrain a Model.................................................................................................................................276\\nMonitor and Analyze Training Jobs Using Metrics.......................................................................276\\nSample Notebooks .........................................................................................................276\\nDeﬁning Training Metrics.................................................................................................277\\nMonitoring Training Job Metrics ( Console).........................................................................279\\nMonitoring Training Job Metrics (Amazon SageMaker Console).............................................279\\nExample: Viewing a Training and Validation Curve..............................................................281\\nIncremental Training...............................................................................................................282\\nPerform Incremental Training (Console).............................................................................283\\nPerform Incremental Training (API)...................................................................................285\\nManaged Spot Training...........................................................................................................287\\nUsing Managed Spot Training..........................................................................................287\\nManaged Spot Training Lifecycle......................................................................................288\\nUsing Checkpoints ..................................................................................................................288\\nAutomatic Model Tuning.........................................................................................................288\\nHow Hyperparameter Tuning Works..................................................................................289\\nDeﬁne Metrics ................................................................................................................290\\nDeﬁne Hyperparameter Ranges ........................................................................................292\\nExample: Hyperparameter Tuning Job...............................................................................293\\nStop Training Jobs Early..................................................................................................302\\nRun a Warm Start Hyperparameter Tuning Job..................................................................303\\nAutomatic Model Tuning Resource Limits...........................................................................307\\nBest Practices for Hyperparameter Tuning.........................................................................308\\nUsing Augmented Manifest Files ..............................................................................................308\\nAugmented Manifest File format ......................................................................................309\\nAugmented Manifest File format ......................................................................................310\\nUse an Augmented Manifest File (Console)........................................................................310\\nUse an Augmented Manifest File (API) ...............................................................................311\\nDeploy a Model..............................................................................................................................313\\nPrerequisites..........................................................................................................................313\\nWhat do you want to do?........................................................................................................313\\nivAmazon SageMaker Developer Guide\\nManage Model Deployments....................................................................................................313\\nDeploy Your Own Inference Code.............................................................................................314\\nGuide to Amazon SageMaker...................................................................................................314\\nInference Pipelines..................................................................................................................314\\nSample Notebooks .........................................................................................................315\\nProcess Features with Spark ML and Scikit-learn.................................................................315\\nCreate a Pipeline Model..................................................................................................316\\nReal-time Inference.........................................................................................................318\\nBatch Transform.............................................................................................................320\\nLogs and Metrics ............................................................................................................321\\nTroubleshooting.............................................................................................................326\\nCompile and Deploy Models with Neo.......................................................................................328\\nSample Notebooks .........................................................................................................329\\nCompile Models ..............................................................................................................329\\nDeploy Models...............................................................................................................334\\nRequest Inferences..........................................................................................................342\\nTroubleshoot Errors........................................................................................................342\\nBatch Transform.....................................................................................................................348\\nUse Batch Transform with Large Datasets..........................................................................349\\nSpeed Up a Batch Transform Job.....................................................................................350\\nUse Batch Transform to Test Production Variants................................................................350\\nBatch Transform Errors...................................................................................................350\\nSample Notebooks .........................................................................................................350\\nAssociate Prediction Results with Input.............................................................................351\\nElastic Inference.....................................................................................................................355\\nHow EI Works................................................................................................................356\\nChoose an EI Accelerator Type.........................................................................................356\\nUse EI in a Amazon SageMaker Notebook Instance.............................................................356\\nUse EI on a Hosted Endpoint ...........................................................................................357\\nFrameworks that Support EI............................................................................................357\\nUse EI with Amazon SageMaker Built-in Algorithms............................................................357\\nEI Sample Notebooks ......................................................................................................357\\nSet Up to Use EI ............................................................................................................358\\nAttaching EI to a Notebook Instance.................................................................................361\\nEndpoints with Elastic Inference.......................................................................................363\\nAutomatically Scale Amazon SageMaker Models.........................................................................365\\nAutomatic Scaling Components ........................................................................................366\\nBefore You Begin............................................................................................................368\\nRelated Topics................................................................................................................369\\nConﬁgure Automatic Scaling for a Production Variant.........................................................369\\nEdit a Scaling Policy.......................................................................................................375\\nDelete a Scaling Policy....................................................................................................375\\nUpdate Endpoints that Use Automatic Scaling ....................................................................377\\nLoad Testing..................................................................................................................377\\nAdditional Considerations................................................................................................378\\nTroubleshoot..........................................................................................................................380\\nCPU Detection Errors with a JVM......................................................................................380\\nBest Practices.........................................................................................................................381\\nDeploy Multiple Instances................................................................................................381\\nHosting Instance Storage Volumes............................................................................................381\\nUse Your Own Algorithms or Models................................................................................................384\\nScenarios and Guidance...........................................................................................................384\\nDocker Container Basics..........................................................................................................385\\nAmazon SageMaker Containers................................................................................................386\\nEnvironmental Variables - Entrypoints...............................................................................388\\nEnvironmental Variables - User Scripts..............................................................................389\\nEnvironmental Variable - Reference..................................................................................392\\nvAmazon SageMaker Developer Guide\\nGet Information for a Script ............................................................................................395\\nGet Started with Containers....................................................................................................396\\nPre-built Docker Images - Deep Learning...................................................................................398\\nPre-built Docker Images - Scikit-learn and Spark ML...................................................................401\\nExample Notebooks ................................................................................................................402\\nUse Your Own Training Algorithms...........................................................................................404\\nRun Your Training Image.................................................................................................404\\nProvide Training Information............................................................................................405\\nSignal Success or Failure.................................................................................................407\\nTraining Output..............................................................................................................408\\nUse Your Own Inference Code..................................................................................................408\\nWith Hosting Services.....................................................................................................408\\nWith Batch Transform.....................................................................................................411\\nCreate Algorithm and Model Package Resources.........................................................................413\\nCreate an Algorithm Resource..........................................................................................413\\nCreate a Model Package Resource.....................................................................................417\\nUse Algorithm and Model Package Resources.............................................................................419\\nUse an Algorithm to Run a Training Job............................................................................420\\nUse an Algorithm to Run a Hyperparameter Tuning Job......................................................423\\nUse a Model Package to Create a Model............................................................................425\\nAmazon SageMaker in AWS Marketplace...........................................................................................428\\nTopics...................................................................................................................................428\\nAmazon SageMaker Algorithms................................................................................................428\\nAmazon SageMaker Model Packages.........................................................................................428\\nSell Amazon SageMaker Algorithms and Model Packages............................................................429\\nTopics...........................................................................................................................429\\nDevelop Algorithms and Models in Amazon SageMaker.......................................................429\\nList Your Algorithm or Model Package on AWS Marketplace.................................................431\\nFind and Subscribe to Algorithms and Model Packages on AWS Marketplace..................................431\\nUse Algorithms and Model Packages.................................................................................432\\nManage ML Experiments with Amazon SageMaker Model Tracking Capability.........................................433\\nSample Notebooks .................................................................................................................433\\nUse Model Tracking to Find, Organize, and Evaluate Training Jobs (Console)...................................434\\nUse Tags to Track Training Jobs (Console).........................................................................434\\nFind Training Jobs (Console)...........................................................................................435\\nEvaluate Models Returned by a Search (Console)................................................................435\\nUse Model Tracking to Find and Evaluate Training Jobs (API)........................................................436\\nUse Search to Find Training Jobs Tagged with Speciﬁc Values (API).......................................436\\nEvaluate Models (API) .....................................................................................................436\\nGet Suggestions for a Search (API)...................................................................................437\\nVerify the Contents of Your Training Jobs..................................................................................438\\nTrace the Lineage of your Models.............................................................................................438\\nUse Single-click on the Amazon SageMaker Console to Trace the Lineage of Your Models\\n(Console).......................................................................................................................438\\nUse Code to Trace the Lineage of Your Models (API)...........................................................439\\nUse Machine Learning Frameworks with Amazon SageMaker................................................................440\\nUsing Apache Spark ................................................................................................................440\\nDownload the Amazon SageMaker Spark Library................................................................440\\nIntegrate Your Apache Spark Application with Amazon SageMaker........................................441\\nExample 1: Amazon SageMaker with Apache Spark.............................................................442\\nAdditional Examples: Amazon SageMaker with Apache Spark...............................................449\\nUsing TensorFlow...................................................................................................................449\\nUse TensorFlow Version 1.11 and Later.............................................................................449\\nUse TensorFlow Legacy Mode for Versions 1.11 and Earlier..................................................450\\nUsing Apache MXNet ..............................................................................................................450\\nWhat do you want to do?................................................................................................450\\nUsing Scikit-learn...................................................................................................................451\\nviAmazon SageMaker Developer Guide\\nWhat do you want to do?................................................................................................451\\nUsing PyTorch........................................................................................................................451\\nWhat do you want to do?................................................................................................451\\nUsing Chainer ........................................................................................................................452\\nWhat do you want to do?................................................................................................452\\nUse SparkML Serving..............................................................................................................453\\nReinforcement Learning with Amazon SageMaker RL..........................................................................454\\nWhy is Reinforcement Learning Important?................................................................................454\\nMarkov Decision Process (MDP)................................................................................................454\\nKey Features of Amazon SageMaker RL.....................................................................................455\\nSample RL Workﬂow Using Amazon SageMaker RL.....................................................................457\\nRL Environments in Amazon SageMaker....................................................................................458\\nUse OpenAI Gym Interface for Environments in Amazon SageMaker RL..................................459\\nUse Open Source Environments........................................................................................459\\nUse Commercial Environments.........................................................................................459\\nDistributed Training with Amazon SageMaker RL........................................................................459\\nHyperparameter Tuning with Amazon SageMaker RL...................................................................460\\nMonitoring .....................................................................................................................................461\\nMonitoring with CloudWatch....................................................................................................461\\nLogging with CloudWatch........................................................................................................466\\nLog Amazon SageMaker API Calls with AWS CloudTrail................................................................467\\nAmazon SageMaker Information in CloudTrail....................................................................468\\nOperations Performed by Automatic Model Tuning.............................................................468\\nUnderstanding Amazon SageMaker Log File Entries............................................................468\\nReact to Amazon SageMaker Job Status Changes with CloudWatch Events.....................................470\\nSecurity.........................................................................................................................................471\\nData Protection......................................................................................................................471\\nProtecting Data at Rest Using Encryption..........................................................................472\\nProtecting Data in Transit with Encryption.........................................................................473\\nKey Management............................................................................................................475\\nInternetwork Traﬃc Privacy.............................................................................................475\\nIdentity and Access Management..............................................................................................475\\nAudience.......................................................................................................................475\\nAuthenticating With Identities ..........................................................................................476\\nManaging Access Using Policies........................................................................................478\\nHow Amazon SageMaker Works with IAM..........................................................................479\\nIdentity-Based Policy Examples........................................................................................481\\nAmazon SageMaker Roles................................................................................................496\\nAWS Managed (Predeﬁned) Policies for Amazon SageMaker.................................................507\\nAmazon SageMaker API Permissions Reference...................................................................508\\nTroubleshooting.............................................................................................................512\\nLogging and Monitoring ..........................................................................................................514\\nCompliance Validation.............................................................................................................514\\nResilience..............................................................................................................................515\\nInfrastructure Security.............................................................................................................515\\nConnect a Notebook Instance to Resources in a VPC...........................................................516\\nTraining and Inference Containers Run in Internet-Free Mode...............................................516\\nAmazon SageMaker Scans AWS Marketplace Training and Inference Containers for Security\\nVulnerabilities................................................................................................................517\\nConnect to Amazon SageMaker Through a VPC Interface Endpoint.......................................517\\nGive Amazon SageMaker Training Jobs Access to Resources in Your Amazon VPC.....................522\\nGive Amazon SageMaker Hosted Endpoints Access to Resources in Your Amazon VPC...............525\\nGive Batch Transform Jobs Access to Resources in Your Amazon VPC.....................................529\\nAmazon SageMaker Ground Truth....................................................................................................532\\nAre You a First-time User of Ground Truth?...............................................................................532\\nGetting started.......................................................................................................................533\\nStep 1: Before You Begin.................................................................................................533\\nviiAmazon SageMaker Developer Guide\\nStep 2: Create a Labeling Job..........................................................................................534\\nStep 3: Select Workers....................................................................................................535\\nStep 4: Conﬁgure the Bounding Box Tool...........................................................................535\\nStep 5: Monitoring Your Labeling Job...............................................................................536\\nData Labeling .........................................................................................................................537\\nBatches for Labeling Tasks...............................................................................................537\\nAnnotation Consolidation ................................................................................................537\\nUsing Automated Data Labeling .......................................................................................539\\nChaining labeling jobs .....................................................................................................540\\nUsing Input and Output Data ...................................................................................................543\\nInput Data .....................................................................................................................543\\nOutput Data ..................................................................................................................545\\nCreating Instruction Pages.......................................................................................................549\\nShort Instructions...........................................................................................................550\\nFull Instructions.............................................................................................................551\\nAdd example images to your instructions..........................................................................551\\nManaging Your Workforce.......................................................................................................551\\nUsing the Amazon Mechanical Turk Workforce...................................................................552\\nManaging Vendor Workforces..........................................................................................553\\nManaging a Private Workforce.........................................................................................553\\nCreate and manage Amazon SNS topics for your work teams...............................................556\\nCreating Custom Labeling Workﬂows........................................................................................557\\nNext..............................................................................................................................557\\nStep 1: Setting up your workforce....................................................................................557\\nStep 2: Creating your custom labeling task template...........................................................558\\nDemo: Image Annotation with crowd-bounding-box ........................................................563\\nDemo: Text Intent with crowd-classifier .....................................................................567\\nStep 3: Processing with AWS Lambda...............................................................................574\\nCustom Workﬂows via the API.........................................................................................577\\nHTML Elements Reference...............................................................................................577\\nLimits and Supported Regions.........................................................................................................615\\nAPI Reference.................................................................................................................................616\\nActions..................................................................................................................................616\\nAmazon SageMaker Service.............................................................................................618\\nAmazon SageMaker Runtime............................................................................................852\\nData Types............................................................................................................................856\\nAmazon SageMaker Service.............................................................................................859\\nAmazon SageMaker Runtime..........................................................................................1041\\nCommon Errors....................................................................................................................1041\\nCommon Parameters.............................................................................................................1043\\nDocument History.........................................................................................................................1045\\nAWS Glossary...............................................................................................................................1047\\nviiiAmazon SageMaker Developer Guide\\nAre You a First-time User of Amazon SageMaker?\\nWhat Is Amazon SageMaker?\\nAmazon SageMaker is a fully managed machine learning service. With Amazon SageMaker, data\\nscientists and developers can quickly and easily build and train machine learning models, and then\\ndirectly deploy them into a production-ready hosted environment. It provides an integrated Jupyter\\nauthoring notebook instance for easy access to your data sources for exploration and analysis, so you\\ndon\\'t have to manage servers. It also provides common machine learning algorithms that are optimized\\nto run eﬃciently against extremely large data in a distributed environment. With native support for\\nbring-your-own-algorithms and frameworks, Amazon SageMaker oﬀers ﬂexible distributed training\\noptions that adjust to your speciﬁc workﬂows. Deploy a model into a secure and scalable environment by\\nlaunching it with a single click from the Amazon SageMaker console. Training and hosting are billed by\\nminutes of usage, with no minimum fees and no upfront commitments.\\nThis is a HIPAA Eligible Service. For more information about AWS, U.S. Health Insurance Portability and\\nAccountability Act of 1996 (HIPAA), and using AWS services to process, store, and transmit protected\\nhealth information (PHI), see HIPAA Overview.\\nAre You a First-time User of Amazon SageMaker?\\nIf you are a ﬁrst-time user of Amazon SageMaker, we recommend that you do the following:\\n1.Read How Amazon SageMaker Works (p. 2) – This section provides an overview of Amazon\\nSageMaker, explains key concepts, and describes the core components involved in building AI solutions\\nwith Amazon SageMaker. We recommend that you read this topic in the order presented.\\n2.Read Get Started (p. 16) – This section explains how to set up your account and create your ﬁrst\\nAmazon SageMaker notebook instance.\\n3.Try a model training exercise – This exercise walks you through training your ﬁrst model. You use\\ntraining algorithms provided by Amazon SageMaker. For more information, see Get Started (p. 16).\\n4.Explore other topics – Depending on your needs, do the following:\\n•Submit Python code to train with deep learning frameworks – In Amazon SageMaker, you can use\\nyour own training scripts to train models. For information, see Use Machine Learning Frameworks\\nwith Amazon SageMaker (p. 440).\\n•Use Amazon SageMaker directly from Apache Spark – For information, see Use Apache Spark with\\nAmazon SageMaker (p. 440).\\n•Use Amazon AI to train and/or deploy your own custom algorithms – Package your custom\\nalgorithms with Docker so you can train and/or deploy them in Amazon SageMaker. See Use Your\\nOwn Algorithms or Models with Amazon SageMaker  (p. 384) to learn how Amazon SageMaker\\ninteracts with Docker containers, and for the Amazon SageMaker requirements for Docker images.\\n5.See the API Reference (p. 616) – This section describes the Amazon SageMaker API operations.\\n1Amazon SageMaker Developer Guide\\nMachine Learning with Amazon SageMaker\\nHow Amazon SageMaker Works\\nAmazon SageMaker is a fully managed service that enables you to quickly and easily integrate machine\\nlearning-based models into your applications. This section provides an overview of machine learning\\nand explains how Amazon SageMaker works. If you are a ﬁrst-time user of Amazon SageMaker, we\\nrecommend that you read the following sections in order:\\nTopics\\n•Machine Learning with Amazon SageMaker (p. 2)\\n•Explore and Preprocess Data (p. 4)\\n•Train a Model with Amazon SageMaker  (p. 4)\\n•Deploy a Model in Amazon SageMaker (p. 7)\\nHow It Works: Next Topic\\nMachine Learning with Amazon SageMaker (p. 2)\\nMachine Learning with Amazon SageMaker\\nThis section describes a typical machine learning workﬂow and summarizes how you accomplish those\\ntasks with Amazon SageMaker.\\nIn machine learning, you \"teach\" a computer to make predictions, or inferences. First, you use an\\nalgorithm and example data to train a model. Then you integrate your model into your application to\\ngenerate inferences in real time and at scale. In a production environment, a model typically learns from\\nmillions of example data items and produces inferences in hundreds to less than 20 milliseconds.\\nThe following diagram illustrates the typical workﬂow for creating a machine learning model:\\nAs the diagram illustrates, you typically perform the following activities:\\n1.Generate example data—To train a model, you need example data. The type of data that you need\\ndepends on the business problem that you want the model to solve (the inferences that you want\\n2Amazon SageMaker Developer Guide\\nHow It Works: Next Topic\\nthe model to generate). For example, suppose that you want to create a model to predict a number\\ngiven an input image of a handwritten digit. To train such a model, you need example images of\\nhandwritten numbers.\\nData scientists often spend a lot of time exploring and preprocessing, or \"wrangling,\" example data\\nbefore using it for model training. To preprocess data, you typically do the following:\\na.Fetch the data— You might have in-house example data repositories, or you might use datasets\\nthat are publicly available. Typically, you pull the dataset or datasets into a single repository.\\nb.Clean the data—To improve model training, inspect the data and clean it as needed. For example, if\\nyour data has a country name  attribute with values United States  and US, you might want to\\nedit the data to be consistent.\\nc.Prepare or transform the data —To improve performance, you might perform additional data\\ntransformations. For example, you might choose to combine attributes. If your model predicts the\\nconditions that require de-icing an aircraft, instead of using temperature and humidity attributes\\nseparately, you might combine those attributes into a new attribute to get a better model.\\nIn Amazon SageMaker, you preprocess example data in a Jupyter notebook on your notebook\\ninstance. You use your notebook to fetch your dataset, explore it, and prepare it for model training.\\nFor more information, see Explore and Preprocess Data (p. 4). For more information about\\npreparing data in AWS Marketplace, see data preparation.\\n2.Train a model—Model training includes both training and evaluating the model, as follows:\\n•Training the model— To train a model, you need an algorithm. The algorithm you choose depends\\non a number of factors. For a quick, out-of-the-box solution, you might be able to use one of\\nthe algorithms that Amazon SageMaker provides. For a list of algorithms provided by Amazon\\nSageMaker and related considerations, see Use Amazon SageMaker Built-in Algorithms  (p. 56).\\n\\xa0\\nYou also need compute resources for training. Depending on the size of your training dataset and\\nhow quickly you need the results, you can use resources ranging from a single general-purpose\\ninstance to a distributed cluster of GPU instances. For more information, see Train a Model with\\nAmazon SageMaker  (p. 4).\\n\\xa0\\n•Evaluating the model —After you\\'ve trained your model, you evaluate it to determine whether the\\naccuracy of the inferences is acceptable. In Amazon SageMaker, you use either the AWS SDK for\\nPython (Boto) or the high-level Python library that Amazon SageMaker provides to send requests to\\nthe model for inferences.\\nYou use a Jupyter notebook in your Amazon SageMaker notebook instance to train and evaluate\\nyour model.\\n3.Deploy the model— You traditionally re-engineer a model before you integrate it with your\\napplication and deploy it. With Amazon SageMaker hosting services, you can deploy your model\\nindependently, decoupling it from your application code. For more information, see Deploy a Model on\\nAmazon SageMaker Hosting Services (p. 7).\\nMachine learning is a continuous cycle. After deploying a model, you monitor the inferences, collect\\n\"ground truth,\" and evaluate the model to identify drift. You then increase the accuracy of your\\ninferences by updating your training data to include the newly collected ground truth. You do this by\\nretraining the model with the new dataset. As more and more example data becomes available, you\\ncontinue retraining your model to increase accuracy.\\nHow It Works: Next Topic\\nExplore and Preprocess Data (p. 4)\\n3Amazon SageMaker Developer Guide\\nExplore and Preprocess Data\\nExplore and Preprocess Data\\nBefore using a dataset to train a model, data scientists typically explore and preprocess it. For example,\\nin one of the exercises in this guide, you use the MNIST dataset, a commonly available dataset of\\nhandwritten numbers, for model training. Before you begin training, you transform the data into a\\nformat that is more eﬃcient for training. For more information, see Step 4.3: Transform the Training\\nDataset and Upload It to Amazon S3 (p. 21).\\nTo preprocess data use one of the following methods:\\n•Use a Jupyter notebook on an Amazon SageMaker notebook instance. You can also use the notebook\\ninstance to do the following:\\n•Write code to create model training jobs\\n•Deploy models to Amazon SageMaker hosting\\n•Test or validate your models\\nFor more information, see Use Notebook Instances (p. 36)\\n•You can use a model to transform data by using Amazon SageMaker batch transform. For more\\ninformation, see Step 6.2: Deploy the Model with Batch Transform (p. 28).\\nHow It Works: Next Topic\\nTrain a Model with Amazon SageMaker  (p. 4)\\nTrain a Model with Amazon SageMaker\\nThe following diagram shows how you train and deploy a model with Amazon SageMaker:\\n4Amazon SageMaker Developer Guide\\nModel Training\\nThe area labeled Amazon SageMaker highlights the two components of Amazon SageMaker: model\\ntraining and model deployment.\\nTo train a model in Amazon SageMaker, you create a training job. The training job includes the following\\ninformation:\\n•The URL of the Amazon Simple Storage Service (Amazon S3) bucket where you\\'ve stored the training\\ndata.\\n•The compute resources that you want Amazon SageMaker to use for model training. Compute\\nresources are ML compute instances that are managed by Amazon SageMaker.\\n•The URL of the S3 bucket where you want to store the output of the job.\\n•The Amazon Elastic Container Registry path where the training code is stored. For more information,\\nsee Common Parameters for Built-In Algorithms  (p. 58).\\nYou have the following options for a training algorithm:\\n•Use an algorithm provided by Amazon SageMaker—Amazon SageMaker provides training\\nalgorithms. If one of these meets your needs, it\\'s a great out-of-the-box solution for quick model\\n5Amazon SageMaker Developer Guide\\nModel Training\\ntraining. For a list of algorithms provided by Amazon SageMaker, see Use Amazon SageMaker Built-in\\nAlgorithms  (p. 56). To try an exercise that uses an algorithm provided by Amazon SageMaker, see\\nGet Started (p. 16).\\n•Use Apache Spark with Amazon SageMaker—Amazon SageMaker provides a library that you can\\nuse in Apache Spark to train models with Amazon SageMaker. Using the library provided by Amazon\\nSageMaker is similar to using Apache Spark MLLib. For more information, see Use Apache Spark with\\nAmazon SageMaker (p. 440).\\n•Submit custom code to train with deep learning frameworks—You can submit custom Python code\\nthat uses TensorFlow or Apache MXNet for model training. For more information, see Use TensorFlow\\nwith Amazon SageMaker (p. 449) and Use Apache MXNet with Amazon SageMaker (p. 450).\\n•Use your own custom algorithms—Put your code together as a Docker image and specify the registry\\npath of the image in an Amazon SageMaker CreateTrainingJob  API call. For more information, see\\nUse Your Own Algorithms or Models with Amazon SageMaker  (p. 384).\\n•Use an algorithm that you subscribe to from AWS Marketplace—For information, see Find and\\nSubscribe to Algorithms and Model Packages on AWS Marketplace (p. 431).\\nAfter you create the training job, Amazon SageMaker launches the ML compute instances and uses the\\ntraining code and the training dataset to train the model. It saves the resulting model artifacts and other\\noutput in the S3 bucket you speciﬁed for that purpose.\\nYou can create a training job with the Amazon SageMaker console or the API. For information about\\ncreating a training job with the API, see the CreateTrainingJob (p. 667) API.\\nWhen you create a training job with the API, Amazon SageMaker replicates the entire dataset on ML\\ncompute instances by default. To make Amazon SageMaker replicate a subset of the data on each\\nML compute instance, you must set the S3DataDistributionType  ﬁeld to ShardedByS3Key . You\\ncan set this ﬁeld using the low-level SDK. For more information, see S3DataDistributionType  in\\nS3DataSource (p. 994).\\nImportant\\nTo prevent your algorithm container from contending for memory, you should reserve some\\nmemory for Amazon SageMaker critical system processes on your ML compute instances. If the\\nalgorithm container is allowed to use memory needed for system processes, it can trigger a\\nsystem failure.\\n6Amazon SageMaker Developer Guide\\nHow It Works: Next Topic\\nHow It Works: Next Topic\\nDeploy a Model in Amazon SageMaker (p. 7)\\nDeploy a Model in Amazon SageMaker\\nAfter you train your model, you can deploy it to get predictions in one of two ways:\\n•To set up a persistent endpoint to get one prediction at a time, use Amazon SageMaker hosting\\nservices.\\n•To get predictions for an entire dataset, use Amazon SageMaker batch transform.\\nTopics\\n•Deploy a Model on Amazon SageMaker Hosting Services (p. 7)\\n•Get Inferences for an Entire Dataset with Batch Transform (p. 10)\\n•Validate a Machine Learning Model (p. 11)\\n•The Amazon SageMaker Programming Model  (p. 12)\\nDeploy a Model on Amazon SageMaker Hosting\\nServices\\nAmazon SageMaker also provides model hosting services for model deployment, as shown in the\\nfollowing diagram. Amazon SageMaker provides an HTTPS endpoint where your machine learning model\\nis available to provide inferences.\\n7Amazon SageMaker Developer Guide\\nHosting Services\\nDeploying a model using Amazon SageMaker hosting services is a three-step process:\\n1. Create a model in Amazon SageMaker—By creating a model, you tell Amazon SageMaker where it\\ncan ﬁnd the model components. This includes the S3 path where the model artifacts are stored and\\nthe Docker registry path for the image that contains the inference code. In subsequent deployment\\nsteps, you specify the model by name. For more information, see the CreateModel (p. 648) API.\\n2. Create an endpoint conﬁguration for an HTTPS endpoint—You specify the name of one or more\\nmodels in production variants and the ML compute instances that you want Amazon SageMaker to\\nlaunch to host each production variant.\\nWhen hosting models in production, you can conﬁgure the endpoint to elastically scale the\\ndeployed ML compute instances. For each production variant, you specify the number of\\nML compute instances that you want to deploy. When you specify two or more instances,\\nAmazon SageMaker launches them in multiple Availability Zones. This ensures continuous\\navailability. Amazon SageMaker manages deploying the instances. For more information, see the\\nCreateEndpointConﬁg (p. 635) API.\\n3. Create an HTTPS endpoint—Provide the endpoint conﬁguration to Amazon SageMaker. The\\nservice launches the ML compute instances and deploys the model or models as speciﬁed in the\\nconﬁguration. For more information, see the CreateEndpoint (p. 632) API. To get inferences from\\n8Amazon SageMaker Developer Guide\\nHosting Services\\nthe model, client applications send requests to the Amazon SageMaker Runtime HTTPS endpoint.\\nFor more information about the API, see the InvokeEndpoint (p. 853) API.\\nNote\\nWhen you create an endpoint, Amazon SageMaker attaches an Amazon EBS storage volume to\\neach ML compute instance that hosts the endpoint. The size of the storage volume depends on\\nthe instance type. For a list of instance types that Amazon SageMaker hosting service supports,\\nsee AWS Service Limits. For a list of the sizes of the storage volumes that Amazon SageMaker\\nattaches to each instance, see Hosting Instance Storage Volumes (p. 381).\\nTo increase a model\\'s accuracy, you might choose to save the user\\'s input data and ground truth, if\\navailable, as part of the training data. You can then retrain the model periodically with a larger, improved\\ntraining dataset.\\nBest Practices for Deploying Models on Amazon SageMaker\\nHosting Services\\nWhen hosting models using Amazon SageMaker hosting services, consider the following:\\n•Typically, a client application sends requests to the Amazon SageMaker HTTPS endpoint to obtain\\ninferences from a deployed model. You can also send requests to this endpoint from your Jupyter\\nnotebook during testing.\\n\\xa0\\n•You can deploy a model trained with Amazon SageMaker to your own deployment target. To do that,\\nyou need to know the algorithm-speciﬁc format of the model artifacts that were generated by model\\ntraining. For more information about output formats, see the section corresponding to the algorithm\\nyou are using in  Training Data Formats  (p. 65).\\n\\xa0\\n•You can deploy multiple variants of a model to the same Amazon SageMaker HTTPS endpoint.\\nThis is useful for testing variations of a model in production. For example, suppose that you\\'ve\\ndeployed a model into production. You want to test a variation of the model by directing a small\\namount of traﬃc, say 5%, to the new model. To do this, create an endpoint conﬁguration that\\ndescribes both variants of the model. You specify the ProductionVariant  in your request to the\\nCreateEndPointConfig . For more information, see ProductionVariant (p. 981).\\n\\xa0\\n•You can conﬁgure a ProductionVariant  to use Application Auto Scaling. For information about\\nconﬁguring automatic scaling, see Automatically Scale Amazon SageMaker Models (p. 365).\\n\\xa0\\n•You can modify an endpoint without taking models that are already deployed into production\\nout of service. For example, you can add new model variants, update the ML Compute instance\\nconﬁgurations of existing model variants, or change the distribution of traﬃc among model variants.\\nTo modify an endpoint, you provide a new endpoint conﬁguration. Amazon SageMaker implements\\nthe changes without any downtime. For more information see, UpdateEndpoint  (p. 840) and\\nUpdateEndpointWeightsAndCapacities (p. 842).\\n\\xa0\\n•Changing or deleting model artifacts or changing inference code after deploying a model produces\\nunpredictable results. If you need to change or delete model artifacts or change inference code,\\nmodify the endpoint by providing a new endpoint conﬁguration. Once you provide the new endpoint\\nconﬁguration, you can change or delete the model artifacts corresponding to the old endpoint\\nconﬁguration.\\n9Amazon SageMaker Developer Guide\\nBatch Transform\\n\\xa0\\n•If you want to get inferences on entire datasets, consider using batch transform as an alternative\\nto hosting services. For information, see Get Inferences for an Entire Dataset with Batch\\nTransform (p. 10)\\nHow It Works: Next Topic\\nValidate a Machine Learning Model (p. 11)\\nGet Inferences for an Entire Dataset with Batch\\nTransform\\nTo get inferences for an entire dataset, use batch transform. With batch transform, you create a batch\\ntransform job using a trained model and the dataset, which must be stored in Amazon S3. Amazon\\nSageMaker saves the inferences in an S3 bucket that you specify when you create the batch transform\\njob. Batch transform manages all of the compute resources required to get inferences. This includes\\nlaunching instances and deleting them after the batch transform job has completed. Batch transform\\nmanages interactions between the data and the model with an object within the instance node called an\\nagent.\\nUse batch transform when you:\\n•Want to get inferences for an entire dataset and index them to serve inferences in real time\\n•Don\\'t need a persistent endpoint that applications (for example, web or mobile apps) can call to get\\ninferences\\n•Don\\'t need the subsecond latency that Amazon SageMaker hosted endpoints provide\\nYou can also use batch transform to preprocess your data before using it to train a new model or\\ngenerate inferences.\\nThe following diagram shows the workﬂow of a batch transform job:\\nTo perform a batch transform, create a batch transform job using either the Amazon SageMaker console\\nor the API. Provide the following:\\n•The path to the S3 bucket where you\\'ve stored the data that you want to transform.\\n•The compute resources that you want Amazon SageMaker to use for the transform job. Compute\\nresources  are machine learning (ML) compute instances that are managed by Amazon SageMaker.\\n10Amazon SageMaker Developer Guide\\nValidating Models\\n•The path to the S3 bucket where you want to store the output of the job.\\n•The name of the Amazon SageMaker model that you want to use to create inferences. You must use a\\nmodel that you have already created either with the CreateModel (p. 648) operation or the console.\\nThe following is an example of what a dataset ﬁle might look like.\\nAn example of input file content:\\n                Record1-Attribute1, Record1-Attribute2, Record1-Attribute3, ..., Record1-\\nAttributeM\\n                Record2-Attribute1, Record2-Attribute2, Record2-Attribute3, ..., Record2-\\nAttributeM\\n                Record3-Attribute1, Record3-Attribute2, Record3-Attribute3, ..., Record3-\\nAttributeM\\n                ...\\n                RecordN-Attribute1, RecordN-Attribute2, RecordN-Attribute3, ..., RecordN-\\nAttributeM\\n            \\nA record is a single input data unit, for information on how to delimit records for batch transform jobs,\\nsee SplitType  in TransformInput (p. 1024 ).\\nFor an example of how to use batch transform, see Step 6.2: Deploy the Model with Batch\\nTransform (p. 28).\\nHow It Works: Next Topic\\nValidate a Machine Learning Model (p. 11)\\nValidate a Machine Learning Model\\nAfter training a model, evaluate it to determine whether its performance and accuracy allow you to\\nachieve your business goals. You might generate multiple models using diﬀerent methods and evaluate\\neach. For example, you could apply diﬀerent business rules for each model, and then apply various\\nmeasures to determine each model\\'s suitability. You might consider whether your model needs to be\\nmore sensitive than speciﬁc (or vice versa).\\nYou can evaluate your model using historical data (oﬄine) or live data:\\n•Oﬄine testing —Use historical, not live, data to send requests to the model for inferences.\\n\\xa0\\nDeploy your trained model to an alpha endpoint, and use historical data to send inference requests to\\nit. To send the requests, use a Jupyter notebook in your Amazon SageMaker notebook instance and\\neither the AWS SDK for Python (Boto) or the high-level Python library provided by Amazon SageMaker.\\n\\xa0\\n•Online testing with live data—Amazon SageMaker supports deploying multiple models (called\\nproduction variants) to a single Amazon SageMaker endpoint. You conﬁgure the production variants\\nso that a small portion of the live traﬃc goes to the model that you want to validate. For example, you\\nmight choose to send 10% of the traﬃc to a model variant for evaluation. After you are satisﬁed with\\nthe model\\'s performance, you can route 100% traﬃc to the updated model.\\nFor more information, see articles and books about how to evaluate models, for example, Evaluating\\nMachine Learning Models .\\nOptions for oﬄine model evaluation include:\\n11Amazon SageMaker Developer Guide\\nProgramming Model \\n•Validating using a \"holdout set\"—Machine learning practitioners often set aside a part of the data as\\na \"holdout set.\" They don’t use this data for model training.\\nWith this approach, you evaluate how well your model provides inferences on the holdout set. You\\nthen assess how eﬀectively the model generalizes what it learned in the initial training, as opposed to\\nusing model \"memory.\" This approach to validation gives you an idea of how often the model is able to\\ninfer the correct answer.\\n\\xa0\\nIn some ways, this approach is similar to teaching elementary school students. First, you provide them\\nwith a set of examples to learn, and then test their ability to generalize from their learning. With\\nhomework and tests, you pose problems that were not included in the initial learning and determine\\nwhether they are able to generalize eﬀectively. Students with perfect memories could memorize the\\nproblems, instead of learning the rules.\\n\\xa0\\nTypically, the holdout dataset is of 20-30% of the training data.\\n\\xa0\\n•k-fold validation—In this validation approach, you split the example dataset into k parts. You treat\\neach of these parts as a holdout set for k training runs, and use the other k-1 parts as the training set\\nfor that run. You produce k models using a similar process, and aggregate the models to generate your\\nﬁnal model. The value k is typically in the range of 5-10.\\nHow It Works: Next Topic\\nThe Amazon SageMaker Programming Model  (p. 12)\\nThe Amazon SageMaker Programming Model\\nAmazon SageMaker provides APIs that you can use to create and manage notebook instances and train\\nand deploy models. For more information, see API Reference (p. 616).\\nMaking API calls directly from code is cumbersome, and requires you to write code to authenticate your\\nrequests. Amazon SageMaker provides the following alternatives:\\n•Use the Amazon SageMaker console—With the console, you don\\'t write any code. You use the console\\nUI to start model training or deploy a model. The console works well for simple jobs, where you use a\\nbuilt-in training algorithm and you don\\'t need to preprocess training data.\\n\\xa0\\n•Modify the example Jupyter notebooks—Amazon SageMaker provides several Jupyter notebooks\\nthat train and deploy models using speciﬁc algorithms and datasets. Start with a notebook that has a\\nsuitable algorithm and modify it to accommodate your data source and speciﬁc needs.\\n\\xa0\\n•Write model training and inference code from scratch—Amazon SageMaker provides both an AWS\\nSDK and a high-level Python library that you can use in your code to start model training jobs and\\ndeploy the resulting models.\\n\\xa0\\n•The high-level Python library—The Python library simpliﬁes model training and deployment. In\\naddition to authenticating your requests, the library abstracts platform speciﬁcs by providing simple\\nmethods and default parameters. For example:\\n12Amazon SageMaker Developer Guide\\nProgramming Model \\n\\xa0\\n•To deploy your model, you call only the deploy()  method. The method creates an Amazon\\nSageMaker model, an endpoint conﬁguration, and an endpoint.\\n\\xa0\\n•If you use a custom framework script for model training, you call the fit()  method. The method\\ncreates a .gzip ﬁle of your script, uploads it to an Amazon S3 location, and then runs it for model\\ntraining, and other tasks. For more information, see Use Machine Learning Frameworks with\\nAmazon SageMaker (p. 440).\\n\\xa0\\n•The AWS SDK —The SDKs provide methods that correspond to the Amazon SageMaker API (see\\nActions (p. 616)). Use the SDKs to programmatically start a model training job and host the model\\nin Amazon SageMaker. SDK clients authenticate your requests by using your access keys, so you\\ndon\\'t need to write authentication code. They are available in multiple languages and platforms. For\\nmore information, see SDKs .\\n\\xa0\\nIn Get Started (p. 16), you train and deploy a model using an algorithm provided by Amazon\\nSageMaker. That exercise shows how to use both of these libraries. For more information, see Get\\nStarted (p. 16).\\n\\xa0\\n•Integrate Amazon SageMaker into your Apache Spark workﬂow—Amazon SageMaker provides\\na library for calling its APIs from Apache Spark. With it, you can use Amazon SageMaker-based\\nestimators in an Apache Spark pipeline. For more information, see Use Apache Spark with Amazon\\nSageMaker (p. 440).\\nHow It Works: Next Topic\\nGet Started (p. 16)\\n13Amazon SageMaker Developer Guide\\nStep 1: Create an AWS Account\\nSet Up Amazon SageMaker\\nIn this section, you sign up for an AWS account and then create an IAM user, a security group, and create\\nan Amazon S3 bucket.\\nIf you\\'re new to Amazon SageMaker, we recommend that you read How Amazon SageMaker Works (p. 2).\\nTopics\\n•Step 1: Create an AWS Account (p. 14)\\n•Step 2: Create an IAM Administrator User and Group  (p. 14)\\nStep 1: Create an AWS Account\\nIn this section, you sign up for an AWS account. If you already have an AWS account, skip this step.\\nWhen you sign up for Amazon Web Services (AWS), your AWS account is automatically signed up for all\\nAWS services, including Amazon SageMaker. You are charged only for the services that you use.\\nTo create an AWS account\\n1. Open https://portal.aws.amazon.com/billing/signup.\\n2. Follow the online instructions.\\nPart of the sign-up procedure involves receiving a phone call and entering a veriﬁcation code on the\\nphone keypad.\\nWrite down your AWS account ID because you\\'ll need it for the next task.\\nStep 2: Create an IAM Administrator User and\\nGroup\\nWhen you create an AWS account, you get a single sign-in identity that has complete access to all of the\\nAWS services and resources in the account. This identity is called the AWS account root user . Signing in\\nto the AWS console using the email address and password that you used to create the account gives you\\ncomplete access to all of the AWS resources in your account.\\nWe strongly recommend that you not use the root user for everyday tasks, even the administrative\\nones. Instead, adhere to the Create Individual IAM Users, an AWS Identity and Access Management (IAM)\\nadministrator user. Then securely lock away the root user credentials and use them to perform only a few\\naccount and service management tasks.\\nTo create an administrator user and sign in to the console\\n1. Create an administrator user in your AWS account. For instructions, see Creating Your First IAM User\\nand Administrators Group in the IAM User Guide .\\nNote\\nWe assume that you use administrator user credentials for the exercises and procedures\\nin this guide. If you choose to create and use another IAM user, grant that user minimum\\npermissions. For more information, see Authenticating With Identities  (p. 476).\\n14Amazon SageMaker Developer Guide\\nStep 2: Create an IAM Administrator User and Group \\n2. Sign in to the AWS Management Console.\\nTo sign in to the AWS console as a IAM user, you must use a special URL. For more information, see\\nHow Users Sign In to Your Account in the IAM User Guide .\\nNext Step\\nStep 1: Create an Amazon S3 Bucket (p. 17)\\n15Amazon SageMaker Developer Guide\\nGet Started\\nThe best way to learn how to use Amazon SageMaker is to create, train, and deploy a simple machine\\nlearning model. To do this, you need the following:\\n•A dataset. You use the MNIST (Modiﬁed National Institute of Standards and Technology database)\\ndataset of images of handwritten, single digit numbers. This dataset provides a training set of 50,000\\nexample images of handwritten single-digit numbers, a validation set of 10,000 images, and a test\\ndataset of 10,000 images. You provide this dataset to the algorithm for model training. For more\\ninformation about the MNIST dataset, see MNIST Dataset .\\n•An algorithm. You use the XGBoost algorithm provided by Amazon SageMaker to train the model\\nusing the MNIST dataset. During model training, the algorithm assigns example data of handwritten\\nnumbers into 10 clusters: one for each number, 0 through 9. For more information about the\\nalgorithm, see XGBoost Algorithm (p. 255).\\nYou also need a few resources for storing your data and running the code in this exercise:\\n•An Amazon Simple Storage Service (Amazon S3) bucket to store the training data and the model\\nartifacts that Amazon SageMaker creates when it trains the model.\\n•An Amazon SageMaker notebook instance to prepare and process data and to train and deploy a\\nmachine learning model.\\n•A Jupyter notebook to use with the notebook instance to prepare your training data and train and\\ndeploy the model.\\nIn this exercise, you learn how to create all of the resources that you need to create, train, and deploy a\\nmodel.\\nImportant\\nFor model training, deployment, and validation, you can use either of the following:\\n•The high-level Amazon SageMaker Python SDK\\n•The AWS SDK for Python (Boto 3)\\nThe Amazon SageMaker Python SDK abstracts several implementation details, and is easy\\nto use. This exercise provides code examples for both libraries. If you\\'re a ﬁrst-time Amazon\\nSageMaker user, we recommend that you use the Amazon SageMaker Python SDK. For more\\ninformation, see https://sagemaker.readthedocs.io/en/stable/overview.html.\\nIf you\\'re new to Amazon SageMaker, we recommend that you read How Amazon SageMaker Works (p. 2)\\nbefore starting this exercise.\\nTopics\\n•Step 1: Create an Amazon S3 Bucket (p. 17)\\n•Step 2: Create an Amazon SageMaker Notebook Instance (p. 17)\\n•Step 3: Create a Jupyter Notebook (p. 18)\\n•Step 4: Download, Explore, and Transform the Training Data (p. 19)\\n•Step 5: Train a Model (p. 21)\\n•Step 6: Deploy the Model to Amazon SageMaker (p. 26)\\n•Step 7: Validate the Model (p. 30)\\n16Amazon SageMaker Developer Guide\\nStep 1: Create an Amazon S3 Bucket\\n•Step 8: Clean Up  (p. 35)\\n•Step 9: Integrating Amazon SageMaker Endpoints into Internet-facing Applications (p. 35)\\nStep 1: Create an Amazon S3 Bucket\\nTraining a model produces the following\\n•The model training data\\n•Model artifacts, which Amazon SageMaker generates during model training\\nYou save these in an Amazon Simple Storage Service (Amazon S3) bucket: You can store datasets that\\nyou use as your training data and model artifacts that are the output of a training job in a single bucket\\nor in two separate buckets. For this exercise and others in this guide, one bucket is suﬃcient. If you\\nalready have S3 buckets, you can use them, or you can create new ones.\\nTo create a bucket, follow the instructions in Create a Bucket in the Amazon Simple Storage Service\\nConsole User Guide . Include sagemaker  in the bucket name. For example, sagemaker- datetime .\\nNote\\nAmazon SageMaker needs permission to access these buckets. You grant permission with an\\nIAM role, which you create in the next step when you create an Amazon SageMaker notebook\\ninstance. This IAM role automatically gets permissions to access any bucket that has sagemaker\\nin the name. It gets these permissions through the AmazonSageMakerFullAccess  policy,\\nwhich Amazon SageMaker attaches to the role. If you add a policy to the role that grants the\\nSageMaker service principal S3FullAccess  permission, the name of the bucket does not need\\nto contain sagemaker .\\nNext Step\\nStep 2: Create an Amazon SageMaker Notebook Instance (p. 17)\\nStep 2: Create an Amazon SageMaker Notebook\\nInstance\\nAn Amazon SageMaker notebook instance is a fully managed machine learning (ML) Amazon Elastic\\nCompute Cloud (Amazon EC2) compute instance that runs the Jupyter Notebook App. You use the\\nnotebook instance to create and manage Jupyter notebooks that you can use to prepare and process\\ndata and to train and deploy machine learning models. For more information, see Explore and Preprocess\\nData  (p. 4).\\nNote\\nIf necessary, you can change the notebook instance settings, including the ML compute instance\\ntype, later.\\nTo create an Amazon SageMaker notebook instance\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances, then choose Create notebook instance.\\n3. On the Create notebook instance page, provide the following information (if a ﬁeld is not\\nmentioned, leave the default values):\\n17Amazon SageMaker Developer Guide\\nNext Step\\na. For Notebook instance name, type a name for your notebook instance.\\nb. For Instance type, choose ml.t2.medium . This is the least expensive instance type that\\nnotebook instances support, and it suﬃces for this exercise.\\nc. For IAM role, choose Create a new role, then choose Create role.\\nd. Choose Create notebook instance.\\nIn a few minutes, Amazon SageMaker launches an ML compute instance—in this case, a\\nnotebook instance—and attaches an ML storage volume to it. The notebook instance has a\\npreconﬁgured Jupyter notebook server and a set of Anaconda libraries.\\nNext Step\\nStep 3: Create a Jupyter Notebook (p. 18).\\nStep 3: Create a Jupyter Notebook\\nCreate a Jupyter notebook in the notebook instance you created in Step 2: Create an Amazon SageMaker\\nNotebook Instance (p. 17), and create a cell that gets the IAM role that your notebook needs to run\\nAmazon SageMaker APIs and speciﬁes the name of the Amazon S3 bucket that you will use to store the\\ndatasets that you use for your training data and the model artifacts that a Amazon SageMaker training\\njob outputs.\\nTo create a Jupyter notebook\\n1. Open the notebook instance.\\na. Sign in to the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\nb. Open the notebook instance, by choosing either Open Jupyter for classic Juypter view or\\nOpen JupyterLab for JupyterLab view next to the name of the notebook instance. The Jupyter\\nnotebook server page appears:\\n2. Create a notebook.\\na. If you opened the notebook in Jupyter classic view, on the Files tab, choose New , and\\nconda_python3. This preinstalled environment includes the default Anaconda installation and\\nPython 3.\\nb. If you opened the notebook in JupyterLab view, on the File menu, choose New , and then choose\\nNotebook. . For Select Kernel, choose conda_python3. This preinstalled environment includes\\nthe default Anaconda installation and Python 3.\\n3. In the Jupyter notebook, choose File and Save as, and name the notebook.\\n4. Copy the following Python code and paste it into the ﬁrst cell in your notebook. Add the name\\nof the S3 bucket that you created in Set Up Amazon SageMaker (p. 14), and run the code. The\\nget_execution_role  function retrieves the IAM role you created when you created your notebook\\ninstance.\\nimport os\\nimport boto3\\nimport re\\nimport copy\\nimport time\\nfrom time import gmtime, strftime\\nfrom sagemaker import get_execution_role\\n18Amazon SageMaker Developer Guide\\nStep 4: Download, Explore, and Transform Data\\nrole = get_execution_role()\\nregion = boto3.Session().region_name\\nbucket=\\' bucket-name \\' # Replace with your s3 bucket name\\nprefix = \\'sagemaker/xgboost-mnist\\' # Used as part of the path in the bucket where you\\n store data\\nbucket_path = \\'https://s3-{}.amazonaws.com/{}\\'.format(region,bucket) # The URL to\\n access the bucket\\nNext Step\\nStep 4: Download, Explore, and Transform the Training Data (p. 19)\\nStep 4: Download, Explore, and Transform the\\nTraining Data\\nDownload the MNIST dataset to your notebook instance, review the data, transform it, and upload it to\\nyour S3 bucket.\\nYou transform the data by changing its format from numpy.array  to comma-separated values (CSV).\\nThe XGBoost Algorithm (p. 255) expects input in either the LIBSVM or CSV format. LIBSVM is an open\\nsource machine learning library. In this exercise , you use CSV format because it\\'s simpler.\\nTopics\\n•Step 4.1: Download the MNIST Dataset  (p. 19)\\n•Step 4.2: Explore the Training Dataset (p. 20)\\n•Step 4.3: Transform the Training Dataset and Upload It to Amazon S3 (p. 21)\\nStep 4.1: Download the MNIST Dataset\\nTo download the MNIST dataset, copy and paste the following code into the notebook and run it:.\\n%%time \\nimport pickle, gzip, urllib.request, json\\nimport numpy as np\\n# Load the dataset\\nurllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\",\\n \"mnist.pkl.gz\")\\nwith gzip.open(\\'mnist.pkl.gz\\', \\'rb\\') as f:\\n    train_set, valid_set, test_set = pickle.load(f, encoding=\\'latin1\\')\\nprint(train_set[0].shape)\\nThe code does the following:\\n1.Downloads the MNIST dataset (mnist.pkl.gz ) from the MNIST Database website to your notebook.\\n2.Unzips the ﬁle and reads the following datasets into the notebook\\'s memory:\\n•train_set  – You use these images of handwritten numbers to train a model.\\n•valid_set  – The XGBoost Algorithm (p. 255) uses these images to evaluate the progress of the\\nmodel during training.\\n19Amazon SageMaker Developer Guide\\nStep 4.2: Explore the Dataset\\n•test_set  – You use this set to get inferences to test the deployed model.\\nNext Step\\nStep 4.2: Explore the Training Dataset (p. 20)\\nStep 4.2: Explore the Training Dataset\\nTypically, you explore training data to determine what you need to clean up and which transformations\\nto apply to improve model training. For this exercise, you don\\'t need to clean up the MNIST dataset.\\nTo explore the dataset\\n• Type the following code in a cell in your notebook and run the cell to display the ﬁrst 10 images in\\ntrain_set :.\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nplt.rcParams[\"figure.figsize\"] = (2,10)\\nfor i in range(0, 10):\\n    img = train_set[0][i]\\n    label = train_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')\\n    print(\\'This is a {}\\'.format(label))\\n    plt.show()\\ntrain_set  contains the following structures:\\n•train_set[0]  – Contains images.\\n•train_set[1]  – Contains labels.\\nThe code uses the matplotlib  library to get and display the ﬁrst 10 images from the training\\ndataset.\\nNext Step\\nStep 4.3: Transform the Training Dataset and Upload It to Amazon S3 (p. 21)\\n20Amazon SageMaker Developer Guide\\nStep 4.3: Transform Dataset and Upload to S3\\nStep 4.3: Transform the Training Dataset and Upload\\nIt to Amazon S3\\nThe XGBoost Algorithm (p. 255) expects comma-separated values (CSV) for its training input. The\\nformat of the training dataset is numpy.array. Transform the dataset from numpy.array format to the\\nCSV format. Then upload it to the Amazon S3 bucket that you created in Step 1: Create an Amazon S3\\nBucket (p. 17)\\nTo convert the dataset to CSV format and upload it\\n• Type the following code into a cell in your notebook and then run the cell.\\n%%time\\nimport struct\\nimport io\\nimport csv\\nimport boto3\\n        \\ndef convert_data():\\n    data_partitions = [(\\'train\\', train_set), (\\'validation\\', valid_set), (\\'test\\',\\n test_set)]\\n    for data_partition_name, data_partition in data_partitions:\\n        print(\\'{}: {} {}\\'.format(data_partition_name, data_partition[0].shape,\\n data_partition[1].shape))\\n        labels = [t.tolist() for t in data_partition[1]]\\n        features = [t.tolist() for t in data_partition[0]]\\n        \\n        if data_partition_name != \\'test\\':\\n            examples = np.insert(features, 0, labels, axis=1)\\n        else:\\n            examples = features\\n        #print(examples[50000,:])\\n        \\n        \\n        np.savetxt(\\'data.csv\\', examples, delimiter=\\',\\')\\n        \\n        \\n        \\n        key = \"{}/{}/examples\".format(prefix,data_partition_name)\\n        url = \\'s3://{}/{}\\'.format(bucket, key)\\n       \\n boto3.Session().resource(\\'s3\\').Bucket(bucket).Object(key).upload_file(\\'data.csv\\')\\n        print(\\'Done writing to {}\\'.format(url))\\n        \\nconvert_data()\\nAfter it converts the dataset to the CSV format, ,the code uploads the CSV ﬁle to the S3 bucket.\\nNext Step\\nStep 5: Train a Model (p. 21)\\nStep 5: Train a Model\\nTo train, deploy, and validate a model in Amazon SageMaker, you can use either the Amazon SageMaker\\nPython SDK or the AWS SDK for Python (Boto 3). (You can also use the console, but for this exercise,\\n21Amazon SageMaker Developer Guide\\nChoose the Training Algorithm\\nyou will use the notebook instance and one of the SDKs.) This exercise provides code examples for each\\nlibrary.\\nThe Amazon SageMaker Python SDK abstracts several implementation details, and is easy to use. If\\nyou\\'re a ﬁrst-time Amazon SageMaker user, we recommend that you use it to train, deploy, and validate\\nthe model. For more information, see https://sagemaker.readthedocs.io/en/stable/overview.html.\\nTopics\\n•Choose the Training Algorithm (p. 22)\\n•Create and Run a Training Job (Amazon SageMaker Python SDK) (p. 22)\\n•Create and Run a Training Job (AWS SDK for Python (Boto 3)) (p. 23)\\nChoose the Training Algorithm\\nTo choose the right algorithm for your model, you typically follow an evaluation process. For this\\nexercise, you use the XGBoost Algorithm (p. 255) provided by Amazon SageMaker, so no evaluation is\\nrequired. For information about choosing algorithms, see Use Amazon SageMaker Built-in Algorithms\\n (p. 56).\\nCreate and Run a Training Job (Amazon SageMaker\\nPython SDK)\\nThe Amazon SageMaker Python SDK includes the sagemaker.estimator.Estimator  estimator. You\\ncan use this class, in the sagemaker.estimator  module, with any algorithm. For more information, see\\nhttps://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.\\nTo run a model training job (Amazon SageMaker Python SDK)\\n1. Import the Amazon SageMaker Python SDK and get the XGBoost container.\\nimport sagemaker\\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\\ncontainer = get_image_uri(boto3.Session().region_name, \\'xgboost\\')\\n2. Download the training and validation data from the Amazon S3 location where you uploaded it in\\nStep 4.3: Transform the Training Dataset and Upload It to Amazon S3 (p. 21), and set the location\\nwhere you store the training output.\\ntrain_data = \\'s3://{}/{}/{}\\'.format(bucket, prefix, \\'train\\')\\nvalidation_data = \\'s3://{}/{}/{}\\'.format(bucket, prefix, \\'validation\\')\\ns3_output_location = \\'s3://{}/{}/{}\\'.format(bucket, prefix, \\'xgboost_model_sdk\\')\\nprint(train_data)\\n3. Create an instance of the sagemaker.estimator.Estimator  class.\\nxgb_model = sagemaker.estimator.Estimator(container,\\n                                         role, \\n                                         train_instance_count=1, \\n                                         train_instance_type=\\'ml.m4.xlarge\\',\\n                                         train_volume_size = 5,\\n                                         output_path=s3_output_location,\\n                                         sagemaker_session=sagemaker.Session())\\n22Amazon SageMaker Developer Guide\\nCreate and Run a Training Job\\n(AWS SDK for Python (Boto 3))\\nIn the constructor, you specify the following parameters:\\n•role – The AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume\\nto perform tasks on your behalf (for example, reading training results, called model artifacts, from\\nthe S3 bucket and writing training results to Amazon S3). This is the role that you got in Step 3:\\nCreate a Jupyter Notebook (p. 18).\\n•train_instance_count  and train_instance_type  – The type and number of ML compute\\ninstances to use for model training. For this exercise, you use only a single training instance.\\n•train_volume_size  – The size, in GB, of the Amazon Elastic Block Store (Amazon EBS) storage\\nvolume to attach to the training instance. This must be large enough to store training data if you\\nuse File  mode (File  mode is the default).\\n•output_path  – The path to the S3 bucket where Amazon SageMaker stores the training results.\\n•sagemaker_session  – The session object that manages interactions with Amazon SageMaker\\nAPIs and any other AWS service that the training job uses.\\n4. Set the hyperparameter values for the XGBoost training job by calling the set_hyperparameters\\nmethod of the estimator. For a description of XGBoost hyperparameters, see XGBoost\\nHyperparameters  (p. 258).\\nxgb_model.set_hyperparameters(max_depth = 5,\\n                              eta = .2,\\n                              gamma = 4,\\n                              min_child_weight = 6,\\n                              silent = 0,\\n                              objective = \"multi:softmax\",\\n                              num_class = 10,\\n                              num_round = 10)\\n5. Create the training channels to use for the training job. For this example, we use both train  and\\nvalidation  channels.\\ntrain_channel = sagemaker.session.s3_input(train_data, content_type=\\'text/csv\\')\\nvalid_channel = sagemaker.session.s3_input(validation_data, content_type=\\'text/csv\\')\\ndata_channels = {\\'train\\': train_channel, \\'validation\\': valid_channel}\\n6. To start model training, call the estimator\\'s fit method.\\nxgb_model.fit(inputs=data_channels,  logs=True)\\nThis is a synchronous operation. The method displays progress logs and waits until training\\ncompletes before returning. For more information about model training, see Train a Model with\\nAmazon SageMaker  (p. 4).\\nModel training for this exercise can take up to 15 minutes.\\nNext Step\\nStep 6: Deploy the Model to Amazon SageMaker (p. 26)\\nCreate and Run a Training Job (AWS SDK for Python\\n(Boto 3))\\nTo train a model, Amazon SageMaker uses the CreateTrainingJob (p. 667) API. The AWS SDK for Python\\n(Boto 3) provides the corresponding create_training_job  method.\\n23Amazon SageMaker Developer Guide\\nCreate and Run a Training Job\\n(AWS SDK for Python (Boto 3))\\nWhen using this method, you provide the following information:\\n•The training algorithm – Specify the registry path of the Docker image that contains the training code.\\nFor the registry paths for the algorithms provided by Amazon SageMaker, see Common Parameters for\\nBuilt-In Algorithms  (p. 58).\\n•Algorithm-speciﬁc hyperparameters – Specify algorithm-speciﬁc hyperparameters to inﬂuence the\\nﬁnal quality of the model. For information, see XGBoost Hyperparameters (p. 258).\\n•The input and output conﬁguration – Provide the S3 bucket where training data is stored and where\\nAmazon SageMaker saves the results of model training (the model artifacts).\\nTo run a model training job (AWS SDK for Python (Boto 3))\\n1. Import the get_image_url  utility function Amazon SageMaker Python SDK and get the location of\\nthe XGBoost container.\\nimport sagemaker\\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\\ncontainer = get_image_uri(boto3.Session().region_name, \\'xgboost\\')\\n2. Set up the training information for the job. You pass this information when you call\\ncreate_training_job . For more information about the information that you need to send to a\\ntraining job, see the section called “CreateTrainingJob” (p. 667).\\n#Ensure that the train and validation data folders generated above are reflected in the\\n \"InputDataConfig\" parameter below.\\ncommon_training_params = \\\\\\n{\\n    \"AlgorithmSpecification\": {\\n        \"TrainingImage\": container,\\n        \"TrainingInputMode\": \"File\"\\n    },\\n    \"RoleArn\": role,\\n    \"OutputDataConfig\": {\\n        \"S3OutputPath\": bucket_path + \"/\"+ prefix + \"/xgboost\"\\n    },\\n    \"ResourceConfig\": {\\n        \"InstanceCount\": 1,   \\n        \"InstanceType\": \"ml.m4.xlarge\",\\n        \"VolumeSizeInGB\": 5\\n    },\\n    \"HyperParameters\": {\\n        \"max_depth\":\"5\",\\n        \"eta\":\"0.2\",\\n        \"gamma\":\"4\",\\n        \"min_child_weight\":\"6\",\\n        \"silent\":\"0\",\\n        \"objective\": \"multi:softmax\",\\n        \"num_class\": \"10\",\\n        \"num_round\": \"10\"\\n    },\\n    \"StoppingCondition\": {\\n        \"MaxRuntimeInSeconds\": 86400\\n    },\\n    \"InputDataConfig\": [\\n        {\\n            \"ChannelName\": \"train\",\\n            \"DataSource\": {\\n                \"S3DataSource\": {\\n                    \"S3DataType\": \"S3Prefix\",\\n24Amazon SageMaker Developer Guide\\nCreate and Run a Training Job\\n(AWS SDK for Python (Boto 3))\\n                    \"S3Uri\": bucket_path + \"/\"+ prefix+ \\'/train/\\',\\n                    \"S3DataDistributionType\": \"FullyReplicated\" \\n                }\\n            },\\n            \"ContentType\": \"text/csv\",\\n            \"CompressionType\": \"None\"\\n        },\\n        {\\n            \"ChannelName\": \"validation\",\\n            \"DataSource\": {\\n                \"S3DataSource\": {\\n                    \"S3DataType\": \"S3Prefix\",\\n                    \"S3Uri\": bucket_path + \"/\"+ prefix+ \\'/validation/\\',\\n                    \"S3DataDistributionType\": \"FullyReplicated\"\\n                }\\n            },\\n            \"ContentType\": \"text/csv\",\\n            \"CompressionType\": \"None\"\\n        }\\n    ]\\n}\\n3. Name your training job, and ﬁnish conﬁguring the parameters that you send to it.\\n#training job params\\ntraining_job_name = \\'xgboost-mnist\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nprint(\"Job name is:\", training_job_name)\\ntraining_job_params = copy.deepcopy(common_training_params)\\ntraining_job_params[\\'TrainingJobName\\'] = training_job_name\\ntraining_job_params[\\'ResourceConfig\\'][\\'InstanceCount\\'] = 1\\n4. Call create_training_job  to start the training job, and wait for it to complete. If the training job\\nfails, print the reason that it failed.\\n%%time\\nregion = boto3.Session().region_name\\nsm = boto3.Session().client(\\'sagemaker\\')\\nsm.create_training_job(**training_job_params)\\nstatus = sm.describe_training_job(TrainingJobName=training_job_name)\\n[\\'TrainingJobStatus\\']\\nprint(status)\\nsm.get_waiter(\\'training_job_completed_or_stopped\\').wait(TrainingJobName=training_job_name)\\nstatus = sm.describe_training_job(TrainingJobName=training_job_name)\\n[\\'TrainingJobStatus\\']\\nprint(\"Training job ended with status: \" + status)\\nif status == \\'Failed\\':\\n    message = sm.describe_training_job(TrainingJobName=training_job_name)\\n[\\'FailureReason\\']\\n    print(\\'Training failed with the following error: {}\\'.format(message))\\n    raise Exception(\\'Training job failed\\')\\nYou now have a trained model. Amazon SageMaker stores the resulting artifacts in your S3 bucket.\\nNext Step\\nStep 6: Deploy the Model to Amazon SageMaker (p. 26)\\n25Amazon SageMaker Developer Guide\\nStep 6: Deploy the Model\\nStep 6: Deploy the Model to Amazon SageMaker\\nTo get predictions, deploy your model. The method you use depends on how you want to generate\\ninferences:\\n•To get one inference at a time in real time, set up a persistent endpoint using Amazon SageMaker\\nhosting services.\\n•To get inferences for an entire dataset, use Amazon SageMaker batch transform.\\nTopics\\n•Step 6.1: Deploy the Model to Amazon SageMaker Hosting Services  (p. 26)\\n•Step 6.2: Deploy the Model with Batch Transform (p. 28)\\nStep 6.1: Deploy the Model to Amazon SageMaker\\nHosting Services\\nTo deploy a model in Amazon SageMaker, hosting services, you can use either the Amazon SageMaker\\nPython SDK or the AWS SDK for Python (Boto 3). This exercise provides code examples for both libraries.\\nThe Amazon SageMaker Python SDK abstracts several implementation details, and is easy to use. If\\nyou\\'re a ﬁrst-time Amazon SageMaker user, we recommend that you use it. For more information, see\\nhttps://sagemaker.readthedocs.io/en/stable/overview.html.\\nTopics\\n•Deploy the Model to Amazon SageMaker Hosting Services (Amazon SageMaker Python\\nSDK)  (p. 26)\\n•Deploy the Model to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto 3).) (p. 27)\\nDeploy the Model to Amazon SageMaker Hosting Services\\n(Amazon SageMaker Python SDK)\\nDeploy the model that you trained in Create and Run a Training Job (Amazon SageMaker Python\\nSDK)  (p. 22) by calling the deploy  method of the sagemaker.estimator.Estimator  object. This\\nis the same object that you used to train the model. When you call the deploy method, specify the\\nnumber and type of ML instances that you want to use to host the endpoint.\\nxgb_predictor = xgb_model.deploy(initial_instance_count=1,\\n                                instance_type=\\'ml.m4.xlarge\\',\\n                                )\\nThe deploy method creates the deployable model, conﬁgures the Amazon SageMaker hosting\\nservices endpoint, and launches the endpoint to host the model. For more information, see https://\\nsagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.deploy.\\nIt also returns a sagemaker.predictor.RealTimePredictor  object, which you can use to\\nget inferences from the model. For information, see https://sagemaker.readthedocs.io/en/stable/\\npredictors.html#sagemaker.predictor.RealTimePredictor.\\nNext Step\\n26Amazon SageMaker Developer Guide\\nStep 6.1: Hosting Services\\nStep 7: Validate the Model (p. 30)\\nDeploy the Model to Amazon SageMaker Hosting Services (AWS\\nSDK for Python (Boto 3).)\\nDeploying a model using the AWS SDK for Python (Boto 3) is a three-step process:\\n1.Create a model in Amazon SageMaker – Send a CreateModel (p. 648) request to provide information\\nsuch as the location of the S3 bucket that contains your model artifacts and the registry path of the\\nimage that contains inference code.\\n2.Create an endpoint conﬁguration – Send a CreateEndpointConﬁg (p. 635) request to provide the\\nresource conﬁguration for hosting. This includes the type and number of ML compute instances to\\nlaunch to deploy the model.\\n3.Create an endpoint – Send a CreateEndpoint (p. 632) request to create an endpoint. Amazon\\nSageMaker launches the ML compute instances and deploys the model. Amazon SageMaker returns an\\nendpoint. Applications can send requests for inference to this endpoint.\\nTo deploy the model (AWS SDK for Python (Boto 3))\\nFor each of the following steps, paste the code in a cell in the Jupyter notebook you created in Step 3:\\nCreate a Jupyter Notebook (p. 18) and run the cell.\\n1. Create a deployable model by identifying the location of model artifacts and the Docker image that\\ncontains the inference code.\\nmodel_name = training_job_name + \\'-mod\\'\\ninfo = sm.describe_training_job(TrainingJobName=training_job_name)\\nmodel_data = info[\\'ModelArtifacts\\'][\\'S3ModelArtifacts\\']\\nprint(model_data)\\nprimary_container = {\\n    \\'Image\\': container,\\n    \\'ModelDataUrl\\': model_data\\n}\\ncreate_model_response = sm.create_model(\\n    ModelName = model_name,\\n    ExecutionRoleArn = role,\\n    PrimaryContainer = primary_container)\\nprint(create_model_response[\\'ModelArn\\'])\\n2. Create an Amazon SageMaker endpoint conﬁguration by specifying the ML compute instances that\\nyou want to deploy your model to.\\nendpoint_config_name = \\'DEMO-XGBoostEndpointConfig-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\",\\n gmtime())\\nprint(endpoint_config_name)\\ncreate_endpoint_config_response = sm.create_endpoint_config(\\n    EndpointConfigName = endpoint_config_name,\\n    ProductionVariants=[{\\n        \\'InstanceType\\':\\'ml.m4.xlarge\\',\\n        \\'InitialVariantWeight\\':1,\\n        \\'InitialInstanceCount\\':1,\\n        \\'ModelName\\':model_name,\\n        \\'VariantName\\':\\'AllTraffic\\'}])\\nprint(\"Endpoint Config Arn: \" + create_endpoint_config_response[\\'EndpointConfigArn\\'])\\n27Amazon SageMaker Developer Guide\\nStep 6.2: Batch Transform\\n3. Create an Amazon SageMaker endpoint.\\n%%time\\nimport time\\nendpoint_name = \\'DEMO-XGBoostEndpoint-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nprint(endpoint_name)\\ncreate_endpoint_response = sm.create_endpoint(\\n    EndpointName=endpoint_name,\\n    EndpointConfigName=endpoint_config_name)\\nprint(create_endpoint_response[\\'EndpointArn\\'])\\nresp = sm.describe_endpoint(EndpointName=endpoint_name)\\nstatus = resp[\\'EndpointStatus\\']\\nprint(\"Status: \" + status)\\nwhile status==\\'Creating\\':\\n    time.sleep(60)\\n    resp = sm.describe_endpoint(EndpointName=endpoint_name)\\n    status = resp[\\'EndpointStatus\\']\\n    print(\"Status: \" + status)\\nprint(\"Arn: \" + resp[\\'EndpointArn\\'])\\nprint(\"Status: \" + status)\\nThis code continuously calls the describe_endpoint  command in a while  loop until the endpoint\\neither fails or is in service, and then prints the status of the endpoint. When the status changes to\\nInService , the endpoint is ready to serve inference requests.\\nNext Step\\nStep 7: Validate the Model (p. 30)\\nStep 6.2: Deploy the Model with Batch Transform\\nTo get inference for an entire dataset, use batch transform. Amazon SageMaker stores the results in\\nAmazon S3.\\nFor information about batch transforms, see Get Inferences for an Entire Dataset with Batch\\nTransform (p. 10). For an example that uses batch transform, see the batch transform sample\\nnotebook at https://github.com/awslabs/amazon-sagemaker-examples/tree/master/\\nsagemaker_batch_transform/introduction_to_batch_transform.\\nTopics\\n•Deploy a Model with Batch Transform (Amazon SageMaker High-level Python Library) (p. 28)\\n•Deploy a Model with Batch Transform (SDK for Python (Boto 3)) (p. 29)\\nDeploy a Model with Batch Transform (Amazon SageMaker\\nHigh-level Python Library)\\nThe following code creates a sagemaker.transformer.Transformer  object from the model\\nthat you trained in Create and Run a Training Job (Amazon SageMaker Python SDK) (p. 22).\\nThen it calls that object\\'s transform  method to create a transform job. When you create the\\nsagemaker.transformer.Transformer  object, you specify the number and type of ML instances\\nto use to perform the batch transform job, and the location in Amazon S3 where you want to store the\\ninferences.\\n28Amazon SageMaker Developer Guide\\nStep 6.2: Batch Transform\\nPaste the following code in a cell in the Jupyter notebook you created in Step 3: Create a Jupyter\\nNotebook  (p. 18) and run the cell.\\nbatch_input =\\n                \\'s3://{}/{}/test/examples\\'.format(bucket, prefix) # The location of the\\n test dataset\\nbatch_output = \\'s3://{}/{}/batch-inference\\'.format(bucket, prefix) # The location to store\\n the\\nresults of the batch transform job\\ntransformer = xgb_model.transformer(instance_count=1, instance_type=\\'ml.m4.xlarge\\',\\n output_path=batch_output)\\ntransformer.transform(data=batch_input, data_type=\\'S3Prefix\\', content_type=\\'text/csv\\',\\n split_type=\\'Line\\')\\ntransformer.wait()\\nFor more information, see https://sagemaker.readthedocs.io/en/stable/transformer.html.\\nNext Step\\nStep 7: Validate the Model (p. 30)\\nDeploy a Model with Batch Transform (SDK for Python (Boto 3))\\nTo run a batch transform job, call the create_transform_job . method using the model that you\\ntrained in Create and Run a Training Job (AWS SDK for Python (Boto 3)) (p. 23).\\nTo create a batch transform job (SDK for Python (Boto 3))\\nFor each of the following steps, paste the code in a cell in the Jupyter notebook you created in Step 3:\\nCreate a Jupyter Notebook (p. 18) and run the cell.\\n1. Name the batch transform job and specify where the input data (the test dataset) is stored and\\nwhere to store the job\\'s output.\\nbatch_job_name = \\'xgboost-mnist-batch\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nbatch_input = \\'s3://{}/{}/test/examples\\'.format(bucket, prefix)\\nprint(batch_input)\\nbatch_output = \\'s3://{}/{}/batch-inference\\'.format(bucket, prefix)\\n2. Conﬁgure the parameters that you pass when you call the create_transform_job  method.\\nrequest = \\\\\\n{\\n    \"TransformJobName\": batch_job_name,\\n    \"ModelName\": model_name,\\n    \"BatchStrategy\": \"MultiRecord\",\\n    \"TransformOutput\": {\\n        \"S3OutputPath\": batch_output\\n    },\\n    \"TransformInput\": {\\n        \"DataSource\": {\\n            \"S3DataSource\": {\\n                \"S3DataType\": \"S3Prefix\",\\n                \"S3Uri\": batch_input \\n            }\\n        },\\n29Amazon SageMaker Developer Guide\\nStep 7: Validate the Model\\n        \"ContentType\": \"text/csv\",\\n        \"SplitType\": \"Line\",\\n        \"CompressionType\": \"None\"\\n    },\\n    \"TransformResources\": {\\n            \"InstanceType\": \"ml.m4.xlarge\",\\n            \"InstanceCount\": 1\\n    }\\n}\\nFor more information about the parameters, see the section called “CreateTransformJob” (p. 673).\\n3. Call the create_transform_job  method, passing in the parameters that you conﬁgured in the\\nprevious step. Then call the describe_transform_job  method in a loop until it completes.\\nPaste the following code in a cell in the Jupyter notebook you created in Step 3: Create a Jupyter\\nNotebook  (p. 18) and run the cell.\\nsm.create_transform_job(**request)\\n                            \\nwhile(True):\\n    response = sm.describe_transform_job(TransformJobName=batch_job_name)\\n    status = response[\\'TransformJobStatus\\']\\n    if  status == \\'Completed\\':\\n        print(\"Transform job ended with status: \" + status)\\n        break\\n    if status == \\'Failed\\':\\n        message = response[\\'FailureReason\\']\\n        print(\\'Transform failed with the following error: {}\\'.format(message))\\n        raise Exception(\\'Transform job failed\\') \\n    print(\"Transform job is still in status: \" + status)    \\n    time.sleep(30) \\nNext Step\\nStep 7: Validate the Model (p. 30)\\nStep 7: Validate the Model\\nNow that you have trained and deployed a model in Amazon SageMaker, validate it to ensure that it\\ngenerates accurate predictions on new data. That is, on data that is diﬀerent from the data that the\\nmodel was trained on. For this, use the test dataset that you created in Step 4: Download, Explore, and\\nTransform the Training Data (p. 19).\\nTopics\\n•Step 7.1: Validate a Model Deployed to Amazon SageMaker Hosting Services (p. 30)\\n•Step 7.2: Validate a Model Deployed with Batch Transform (p. 33)\\nStep 7.1: Validate a Model Deployed to Amazon\\nSageMaker Hosting Services\\nIf you deployed a model to Amazon SageMaker hosting services in Step 6.1: Deploy the Model to\\nAmazon SageMaker Hosting Services  (p. 26), you now have an endpoint that you can invoke to get\\ninferences in real time. To validate the model, invoke the endpoint with example images from the test\\ndataset and check whether the inferences you get match the actual labels of the images.\\n30Amazon SageMaker Developer Guide\\nStep 7.1: Validate a Model Deployed to\\nAmazon SageMaker Hosting Services\\nTopics\\n•Validate a Model Deployed to Amazon SageMaker Hosting Services (Amazon SageMaker Python\\nSDK)  (p. 31)\\n•Validate a Model Deployed to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto\\n3)) (p. 32)\\nValidate a Model Deployed to Amazon SageMaker Hosting\\nServices (Amazon SageMaker Python SDK)\\nTo validate the model by using the Amazon SageMaker Python SDK, use the\\nsagemaker.predictor.RealTimePredictor  object that you created in Deploy the Model to Amazon\\nSageMaker Hosting Services (Amazon SageMaker Python SDK) (p. 26). For information, see https://\\nsagemaker.readthedocs.io/en/stable/predictors.html#sagemaker.predictor.RealTimePredictor.\\nTo validate the model (Amazon SageMaker Python SDK)\\n1. Download the test data from Amazon S3.\\ns3 = boto3.resource(\\'s3\\')\\ntest_key = \"{}/test/examples\".format(prefix)\\ns3.Bucket(bucket).download_file(test_key, \\'test_data\\')\\n2. Plot the ﬁrst 10 images from the test dataset with their labels.\\n%matplotlib inline\\n                        \\nfor i in range (0, 10):\\n    img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')\\n    print(\\'This is a {}\\'.format(label))\\n    plt.show()\\n3. To get inferences for the ﬁrst 10 examples in the test dataset, call the predict  method of the\\nsagemaker.predictor.RealTimePredictor  object.\\n31Amazon SageMaker Developer Guide\\nStep 7.1: Validate a Model Deployed to\\nAmazon SageMaker Hosting Services\\nwith open(\\'test_data\\', \\'r\\') as f:\\n    for j in range(0,10):\\n        single_test = f.readline()\\n        result = xgb_predictor.predict(single_test)\\n        print(result)\\nTo see if the model is making accurate predictions, check the output from this step against the\\nnumbers that you plotted in the previous step.\\nYou have now trained, deployed, and validated your ﬁrst model in Amazon SageMaker.\\nNext Step\\nStep 8: Clean Up  (p. 35)\\nValidate a Model Deployed to Amazon SageMaker Hosting\\nServices (AWS SDK for Python (Boto 3))\\nTo use the AWS SDK for Python (Boto 3) to validate the model, call the invoke_endpoint  method. This\\nmethod corresponds to the InvokeEndpoint (p. 853) API provided by the Amazon SageMaker runtime.\\nTo validate the model (AWS SDK for Python (Boto 3))\\n1. Download the test data from Amazon S3.\\ns3 = boto3.resource(\\'s3\\')\\ntest_key = \"{}/test/examples\".format(prefix)\\ns3.Bucket(bucket).download_file(test_key, \\'test_data\\')\\n2. Plot the ﬁrst 10 images from the test dataset with their labels.\\n%matplotlib inline\\n                        \\nfor i in range (0, 10):\\n    img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')\\n    print(\\'This is a {}\\'.format(label))\\n    plt.show()\\n32Amazon SageMaker Developer Guide\\nStep 7.2: Validate a Model Deployed with Batch Transform\\n3. Get the Amazon SageMaker runtime client, which provides the invoke_endpoint  method.\\nruntime_client = boto3.client(\\'runtime.sagemaker\\')\\n4. Get inferences from the ﬁrst 10 examples in the test dataset by calling invoke_endpoint .\\nwith open(\\'test_data\\', \\'r\\') as f:\\n    \\n    for i in range(0,10):\\n        single_test = f.readline()\\n        response = runtime_client.invoke_endpoint(EndpointName = endpoint_name,\\n                                         ContentType = \\'text/csv\\',\\n                                         Body = single_test)\\n        result = response[\\'Body\\'].read().decode(\\'ascii\\')\\n        print(\\'Predicted label is {}.\\'.format(result))\\n5. To see if the model is making accurate predictions, check the output from this step against the\\nnumbers you plotted in the previous step.\\nYou have now trained, deployed, and validated your ﬁrst model in Amazon SageMaker.\\nNext Step\\nStep 8: Clean Up  (p. 35)\\nStep 7.2: Validate a Model Deployed with Batch\\nTransform\\nYou now have a ﬁle in Amazon S3 that contains inferences that you got by running a batch transform job\\nin Step 6.2: Deploy the Model with Batch Transform (p. 28). To validate the model, check a subset of\\nthe inferences from the ﬁle to see whether they match the actual numbers from the test dataset.\\nTo validate the batch transform inferences\\n1. Download the test data from Amazon S3.\\ns3 = boto3.resource(\\'s3\\')\\n33Amazon SageMaker Developer Guide\\nStep 7.2: Validate a Model Deployed with Batch Transform\\ntest_key = \"{}/test/examples\".format(prefix)\\ns3.Bucket(bucket).download_file(test_key, \\'test_data\\')\\n2. Plot the ﬁrst 10 images from the test dataset with their labels.\\n%matplotlib inline\\n                    \\nfor i in range (0, 10):\\n    img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')\\n    print(\\'This is a {}\\'.format(label))\\n    plt.show()\\n3. Download the output from the batch transform job from Amazon S3 to a local ﬁle.\\ns3.Bucket(bucket).download_file(prefix + \\'/batch-inference/examples.out\\', \\n \\'batch_results\\')\\n4. Get the ﬁrst 10 results from the batch transform job.\\nwith open(\\'batch_results\\') as f:\\n    results = f.readlines()\\nfor j in range (0, 10):\\n    print(results[j])\\n5. To see if the batch transform job made accurate predictions, check the output from this step against\\nthe numbers that you plotted from the test data.\\nYou have now trained, deployed, and validated your ﬁrst model in Amazon SageMaker.\\nNext Step\\nStep 8: Clean Up  (p. 35)\\n34Amazon SageMaker Developer Guide\\nStep 8: Clean Up\\nStep 8: Clean Up\\nTo avoid incurring unnecessary charges, use the AWS Management Console to delete the resources that\\nyou created for this exercise.\\nNote\\nIf you plan to explore other exercises in this guide, you might want to keep some of these\\nresources, such as your notebook instance, S3 bucket, and IAM role.\\n1.Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/ and delete the\\nfollowing resources:\\n•The endpoint. Deleting the endpoint also deletes the ML compute instance or instances that\\nsupport it.\\n•The endpoint conﬁguration.\\n•The model.\\n•The notebook instance. Before deleting the notebook instance, stop it.\\n2.Open the Amazon S3 console at https://console.aws.amazon.com/s3/ and delete the bucket that you\\ncreated for storing model artifacts and the training dataset.\\n3.Open the IAM console at https://console.aws.amazon.com/iam/ and delete the IAM role. If you\\ncreated permission policies, you can delete them, too.\\n4.Open the Amazon CloudWatch console at https://console.aws.amazon.com/cloudwatch/ and delete\\nall of the log groups that have names starting with /aws/sagemaker/ .\\nStep 9: Integrating Amazon SageMaker Endpoints\\ninto Internet-facing Applications\\nIn a production environment, you might have an internet-facing application sending requests to the\\nendpoint for inference. The following high-level example shows how to integrate your model endpoint\\ninto your application.\\n1. Create an IAM role that the AWS Lambda service principal can assume. Give the role permissions to\\ncall the Amazon SageMaker InvokeEndpoint  API.\\n2. Create a Lambda function that calls the Amazon SageMaker InvokeEndpoint  API.\\n3. Call the Lambda function from a mobile application. For an example of how to call a Lambda\\nfunction from a mobile application using Amazon Cognito for credentials, see Tutorial: Using AWS\\nLambda as Mobile Application Backend.\\n35Amazon SageMaker Developer Guide\\nCreate a Notebook Instance\\nUse Notebook Instances\\nAn Amazon SageMaker notebook instance  is a fully managed ML compute instance running the Jupyter\\nNotebook App. Amazon SageMaker manages creating the instance and related resources. Use Jupyter\\nnotebooks in your notebook instance to prepare and process data, write code to train models, deploy\\nmodels to Amazon SageMaker hosting, and test or validate your models.\\nTopics\\n•Create a Notebook Instance (p. 36)\\n•Access Notebook Instances  (p. 39)\\n•Customize a Notebook Instance  (p. 40)\\n•Use Example Notebooks  (p. 42)\\n•Notebook Instance Software Updates (p. 44)\\n•Set the Notebook Kernel (p. 44)\\n•Install External Libraries and Kernels in Notebook Instances (p. 45)\\n•Associate Git Repositories with Amazon SageMaker Notebook Instances (p. 46)\\n•Get Notebook Instance Metadata (p. 54)\\n•Monitor Jupyter Logs in Amazon CloudWatch Logs (p. 54)\\nCreate a Notebook Instance\\nTo create a notebook instance, use either the Amazon SageMaker console or the\\nCreateNotebookInstance (p. 656) API.\\nAfter receiving the request, Amazon SageMaker does the following:\\n•Creates a network interface—If you choose the optional VPC conﬁguration, it creates the network\\ninterface in your VPC. It uses the subnet ID that you provide in the request to determine which\\nAvailability Zone to create the subnet in. Amazon SageMaker associates the security group that you\\nprovide in the request with the subnet. For more information, see Connect a Notebook Instance to\\nResources in a VPC (p. 516).\\n•Launches an ML compute instance—Amazon SageMaker launches an ML compute instance in an\\nAmazon SageMaker VPC. Amazon SageMaker performs the conﬁguration tasks that allow it to manage\\nyour notebook instance, and if you speciﬁed your VPC, it enables traﬃc between your VPC and the\\nnotebook instance.\\n•Installs Anaconda packages and libraries for common deep learning platforms—Amazon\\nSageMaker installs all of the Anaconda packages that are included in the installer. For more\\ninformation, see Anaconda package list. In addition, Amazon SageMaker installs the TensorFlow and\\nApache MXNet deep learning libraries.\\n•Attaches an ML storage volume—Amazon SageMaker attaches an ML storage volume to the ML\\ncompute instance. You can use the volume to clean up the training dataset or to temporarily store\\nother data to work with. Choose any size between 5 GB and 16384 GB, in 1 GB increments, for\\nthe volume. The default is 5 GB. ML storage volumes are encrypted, so Amazon SageMaker can\\'t\\ndetermine the amount of available free space on the volume. Because of this, you can increase the\\nvolume size when you update a notebook instance, but you can\\'t decrease the volume size. If you want\\nto decrease the size of the ML storage volume in use, create a new notebook instance with the desired\\nsize.\\n36Amazon SageMaker Developer Guide\\nCreate a Notebook Instance\\nImportant\\nOnly ﬁles and data saved within the /home/ec2-user/SageMaker  folder persist between\\nnotebook instance sessions. Files and data that are saved outside this directory are\\noverwritten when the notebook instance stops and restarts.\\nNote\\nEach notebook instance\\'s /tmp directory provides a minimum of 10 GB of storage in an\\ninstant store. An instance store is temporary, block-level storage that isn\\'t persistent. When\\nthe instance is stopped or restarted, Amazon SageMaker deletes the directory\\'s contents. This\\ntemporary storage is part of the root volume of the notebook instance.\\n•Copies example Jupyter notebooks— These Python code examples illustrate model training and\\nhosting exercises using various algorithms and training datasets.\\nTo create a notebook instance:\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances, then choose Create notebook instance.\\n3. On the Create notebook instance page, provide the following information:\\na. For Notebook instance name, type a name for your notebook instance.\\nb. For Instance type, choose an instance type for your notebook instance. For a list of supported\\ninstance types, see Amazon SageMaker Limits.\\nc. For Elastic Inference, choose an inference accelerator type to associate with the notebook\\ninstance, or choose none . For information about elastic inference, see Amazon SageMaker\\nElastic Inference (EI)  (p. 355).\\nd. For IAM role, choose either an existing IAM role in your account that has the necessary\\npermissions to access Amazon SageMaker resources or Create a new role. If you choose Create\\na new role, for Create an IAM role:\\ni. If you want to use S3 buckets other than the one you created in Step 1: Create an Amazon\\nS3 Bucket (p. 17) to store your input data and output, choose them.\\nThe IAM role automatically has permissions to use any bucket that has sagemaker  as\\npart of its name. The AmazonSageMakerFullAccess  policy, which Amazon SageMaker\\nattaches to the role, gives the role those permissions.\\nTo give access to other S3 buckets from your notebook instance\\n•If you\\'re not concerned about users in your AWS account accessing your data, choose Any\\nS3 bucket.\\n•If your account has sensitive data (such as Human Resources information), restrict access\\nto certain buckets by choosing Speciﬁc S3 buckets. You can update the permissions\\npolicy attached to the role you are creating later.\\n•To explicitly control access, restrict access by choosing None . Use bucket and object\\nnames and tags as supported by the AmazonSageMakerFullAccess  policy. For more\\ninformation, see AmazonSageMakerFullAccess Policy (p. 506).\\nii. Choose Create role.\\nAmazon SageMaker creates an IAM role named AmazonSageMaker-\\nExecutionRole- YYYYMMDD THHmmSS. For example, AmazonSageMaker-\\nExecutionRole-20171125T090800 .\\nTo see the policies that are attached to the role, use the IAM console.\\nOpen the IAM console at https://console.aws.amazon.com/iam/.\\n37Amazon SageMaker Developer Guide\\nCreate a Notebook Instance\\nYou can see that the following policies are attached to the role:\\n•A trust policy that allows Amazon SageMaker to assume the role.\\n•The AmazonSageMakerFullAccess  AWS managed policy.\\n•If you gave access to additional S3 bucket(s) when creating this role, the customer\\nmanaged policy attached to the role. The name of the customer managed policy is\\nAmazonSageMaker-ExecutionPolicy- YYYYMMDD THHmmSS .\\nFor more information about creating your own IAM role, see Amazon SageMaker Roles\\n (p. 496).\\ne. For Root access, to enable root access for all notebook instance users,choose Enabled. To\\ndisable root access for users, choose Disabled.If you enable root access, all notebook instance\\nusers have administrator privileges and can access and edit all ﬁles on it.\\nNote\\nIf you disable root access, you will still be able to set up lifecycle conﬁgurations, as\\ndescribed later in this procedure.\\nf.(Optional) Allow access to resources in your Virtual Private Cloud (VPC).\\nTo access resources in your VPC from the notebook instance\\ni. Choose the VPC and a SubnetId .\\nii. For Security Group, choose your VPC\\'s default security group. For this exercise and others\\nin this guide) the inbound and outbound rules of the default security group are suﬃcient.\\niii. To allow connecting to a resource in your VPC, ensure that the resource resolves to a private\\nIP address in your VPC. For example, to ensure that an Amazon Redshift DNS name resolves\\nto a private IP address, do one of the following:\\n•Ensure that the Amazon Redshift cluster is not publicly accessible.\\n•If the Amazon Redshift cluster is publicly accessible, set the DNS resolution  and DNS\\nhostnames  VPC parameters to true. For more information, see Managing Clusters in an\\nAmazon Virtual Private Cloud (VPC)\\niv.By default, a notebook instance can\\'t connect to on-premises resources or to a peer\\nVPC. You can create a lifecycle conﬁguration that creates an entry in your route table\\nthat enables connection to on-premises resources or to a peer VPC. For information, see\\nUnderstanding Amazon SageMaker notebook instance networking conﬁgurations and\\nadvanced routing options.\\ng. If you allowed access to resources from your VPC, enable direct internet access. For Direct\\ninternet access, choose Enable. Without internet access, you can\\'t train or host models from\\nnotebooks on this notebook instance unless your VPC has a NAT gateway and your security\\ngroup allows outbound connections. For more information, see Connect a Notebook Instance to\\nResources in a VPC (p. 516).\\nh. (Optional) To use shell scripts that run when you create or start the instance, specify a lifecycle\\nconﬁguration. For information, see Customize a Notebook Instance  (p. 40)\\ni. (Optional) If you want Amazon SageMaker to use an AWS Key Management Service (AWS KMS)\\nkey to encrypt data in the ML storage volume attached to the notebook instance, specify the\\nkey.\\nj. Specify the size, in GB, of the ML storage volume that is attached to the notebook instance. You\\ncan choose a size between 5 GB and 16,384 GB, in 1 GB increments. You can use the volume to\\nclean up the training dataset when you no longer need it or to temporarily store other data to\\nwork with.\\n38Amazon SageMaker Developer Guide\\nAccess Notebook Instances \\nk. (Optional) To associate Git repositories with the notebook instance, choose a default repository\\nand up to three additional repositories. For more information, see Associate Git Repositories\\nwith Amazon SageMaker Notebook Instances (p. 46).\\nl. Choose Create notebook instance.\\nIn a few minutes, Amazon SageMaker launches an ML compute instance—in this case, a\\nnotebook instance—and attaches an ML storage volume to it. The notebook instance has a\\npreconﬁgured Jupyter notebook server and a set of Anaconda libraries. For more information,\\nsee the CreateNotebookInstance (p. 656) API.\\n4. When the status of the notebook instance is InService , choose Open Jupyter next to its name to\\nopen the classic Jupyter dashboard, or choose Open JupyterLab to open the JupyterLab dashboard.\\nFor more information, see Access Notebook Instances  (p. 39).\\nThe dashboard provides access to:\\n•Sample notebooks. Amazon SageMaker provides sample notebooks that contain complete code\\nwalkthroughs. These walkthroughs show how to use Amazon SageMaker to perform common\\nmachine learning tasks. For more information, see Use Example Notebooks  (p. 42).\\n•The kernels for Jupyter, including those that provide support for Python 2 and 3, Apache MXNet,\\nTensorFlow, PySpark, and R. To create a new notebook and choose a kernel for that notebook, use\\nthe New  menu.\\nFor more information about Jupyter notebooks, see The Jupyter notebook.\\nAccess Notebook Instances\\nTo access your Amazon SageMaker notebook instances, choose one of the following options:\\n•Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\nChoose Notebook instances. The console displays a list of notebook instances in your account. To\\nopen a notebook instance with a standard Jupyter interface, choose Open Jupyter for that instance.\\nTo open a notebook instance with a JupyterLab interface, choose Open JupyterLab for that instance.\\nThe console uses your sign-in credentials to send a CreatePresignedNotebookInstanceUrl (p. 665) API\\nrequest to Amazon SageMaker. Amazon SageMaker returns the URL for your notebook instance, and\\nthe console opens the URL in another browser tab and displays the Jupyter notebook dashboard.\\nNote\\nThe URL that you get from a call to CreatePresignedNotebookInstanceUrl (p. 665) is valid\\nonly for 5 minutes. If you try to use the URL after the 5-minute limit expires, you are directed\\nto the AWS Management Console sign-in page.\\n•Use the API.\\nTo get the URL for the notebook instance, call the CreatePresignedNotebookInstanceUrl (p. 665) API\\nand use the URL that the API returns to open the notebook instance.\\n39Amazon SageMaker Developer Guide\\nControl Root Access to a Notebook Instance\\nUse the Jupyter notebook dashboard to create and manage notebooks and to write code. For more\\ninformation about Jupyter notebooks, see http://jupyter.org/documentation.html.\\nControl Root Access to a Notebook Instance\\nBy default, when you create a notebook instance, users that log into that notebook instance have root\\naccess. Data science is an iterative process that might require the data scientist to test and use diﬀerent\\nsoftware tools and packages, so many notebook instance users need to have root access to be able to\\ninstall these tools and packages. Because users with root access have administrator privileges, users can\\naccess and edit all ﬁles on a notebook instance with root access enabled.\\nIf you don\\'t want users to have root access to a notebook instance, when you call\\nCreateNotebookInstance (p. 656) or UpdateNotebookInstance (p. 844) operations, set the\\nRootAccess  ﬁeld to Disabled . You can also disable root access for users when you create or update\\na notebook instance in the Amazon SageMaker console. For information, see Step 2: Create an Amazon\\nSageMaker Notebook Instance (p. 17).\\nNote\\nLifecycle conﬁgurations need root access to be able to set up a notebook instance. Because of\\nthis, lifecycle conﬁgurations associated with a notebook instance always run with root access\\neven if you disable root access for users.\\nCustomize a Notebook Instance\\nTo install packages or sample notebooks on your notebook instance, conﬁgure networking and security\\nfor it, or otherwise use a shell script to customize it, use a lifecycle conﬁguration. A lifecycle conﬁguration\\nprovides shell scripts that run only when you create the notebook instance or whenever you start one.\\nWhen you create a notebook instance, you can create a new lifecycle conﬁguration and the scripts it uses\\nor apply one that you already have.\\nThe Amazon SageMaker team maintains a public repository of notebook intance lifecycle conﬁgurations\\nthat address common use cases for customizing notebook instances at https://github.com/aws-samples/\\namazon-sagemaker-notebook-instance-lifecycle-conﬁguration-samples.\\nNote\\nEach script has a limit of 16384 characters.\\nThe value of the $PATH environment variable that is available to both scripts is /usr/local/\\nsbin:/usr/local/bin:/usr/bin:/usr/sbin:/sbin:/bin . The working directory, which\\nis the value of the $PWD environment variable, is /.\\nView CloudWatch Logs for notebook instance lifecycle conﬁgurations in log group /\\naws/sagemaker/NotebookInstances  in log stream [notebook-instance-name]/\\n[LifecycleConfigHook] .\\nScripts cannot run for longer than 5 minutes. If a script runs for longer than 5 minutes, it fails\\nand the notebook instance is not created or started. To help decrease the run time of scripts, try\\nthe following:\\n•Cut down on necessary steps. For example, limit which conda environments in which to install\\nlarge packages.\\n•Run tasks in parallel processes.\\n•Use the nohup command in your script.\\nTo create a lifecycle conﬁguration\\n1. For Lifecycle conﬁguration - Optional , choose Create a new lifecycle conﬁguration.\\n40Amazon SageMaker Developer Guide\\nLifecycle Conﬁguration Best Practices\\n2. For Name , type a name.\\n3. (Optional) To create a script that runs when you create the notebook and every time you start it,\\nchoose Start notebook.\\n4. In the Start notebook editor, type the script.\\n5. (Optional) To create a script that runs only once, when you create the notebook, choose Create\\nnotebook .\\n6. In the Create notebook  editor, type the script conﬁgure networking.\\n7. Choose Create conﬁguration.\\nYou can see a list of notebook instance lifecycle conﬁgurations you previously created by choosing\\nLifecycle conﬁguration in the Amazon SageMaker console. From there, you can view, edit, delete\\nexisting lifecycle conﬁgurations. You can create a new notebook instance lifecycle conﬁguration by\\nchoosing Create conﬁguration. These notebook instance lifecycle conﬁgurations are available when you\\ncreate a new notebook instance.\\nLifecycle Conﬁguration Best Practices\\nThe following are best practices for using lifecycle conﬁgurations:\\n•Lifecycle conﬁgurations run as the root user. If your script makes any changes within the /home/ec2-\\nuser/SageMaker  directory, (for example, installing a package with pip), use the command sudo -u\\nec2-user  command to run as the ec2-user  user. This is the same user that Amazon SageMaker runs\\nas.\\n•Amazon SageMaker notebook instances use conda environments to implement diﬀerent kernels for\\nJupyter notebooks. If you want to install packages that are available to one or more notebook kernels,\\nenclose the commands to install the packages with conda environment commands that activate the\\nconda environment that contains the kernel where you want to install the packages.\\nFor example, if you want to install a package only in for the python3 environment, use the following\\ncode:\\n#!/bin/bash\\nsudo -u ec2-user -i <<\\'EOF\\'\\n# This will affect only the Jupyter kernel called \"conda_python3\".\\nsource activate python3\\n# Replace myPackage  with the name of the package you want to install.\\npip install myPackage\\n# You can also perform \"conda install\" here as well.\\nsource deactivate\\nEOF\\nIf you want to install a package in all conda environments in the notebook instance, use the following\\ncode:\\n#!/bin/bash\\nsudo -u ec2-user -i <<\\'EOF\\'\\n# Note that \"base\" is special environment name, include it there as well.\\nfor env in base /home/ec2-user/anaconda3/envs/*; do\\n    source /home/ec2-user/anaconda3/bin/activate $(basename \"$env\")\\n    # Installing packages in the Jupyter system environment can affect stability of your\\n SageMaker\\n41Amazon SageMaker Developer Guide\\nUse Example Notebooks\\n    # Notebook Instance.  You can remove this check if you\\'d like to install Jupyter\\n extensions, etc.\\n    if [ $env = \\'JupyterSystemEnv\\' ]; then\\n      continue\\n    fi\\n    # Replace myPackage  with the name of the package you want to install.\\n    pip install --upgrade --quiet myPackage\\n    # You can also perform \"conda install\" here as well.\\n    source /home/ec2-user/anaconda3/bin/deactivate\\ndone\\nEOF\\nImportant\\nWhen you create or change a script ﬁle, we recommend you use Create notebook  editor or\\na text editor that allows for Unix style line breaks. Copying text from a non Linux operating\\nsystem might include incompatible line breaks and result in an unexpected error.\\nUse Example Notebooks\\nYour notebook instance contains example notebooks provided by Amazon SageMaker. The example\\nnotebooks contain code that shows how to apply machine learning solutions by using Amazon\\nSageMaker. Notebook instances use the nbexamples  Jupyter extension, which enables you to view a\\nread-only version of an example notebook or create a copy of it so that you can modify and run it. For\\nmore information about the nbexamples  extension, see https://github.com/danielballan/nbexamples.\\nNote\\nExample notebooks typically download datasets from the internet. If you disable Amazon\\nSageMaker-provided internet access when you create you notebook instance, example\\nnotebooks might not work. For more information, see Connect a Notebook Instance to\\nResources in a VPC (p. 516).\\nUse or View Example Notebooks in Jupyter Classic\\nTo view or use the example notebooks in the classic Jupyter view, choose the SageMaker Examples tab.\\nTo view a read-only version of an example notebook in the Jupyter classic view, on the SageMaker\\nExamples tab, choose Preview  for that notebook. To create a copy of an example notebook in the home\\ndirectory of your notebook instance, choose Use. In the dialog box, you can change the notebook\\'s name\\nbefore saving it.\\n42Amazon SageMaker Developer Guide\\nUse or View Example Notebooks in Jupyterlab\\nUse or View Example Notebooks in Jupyterlab\\nTo view or use the example notebooks in the Jupyterlab view, choose the examples icon in the left\\nnavigation panel.\\n43Amazon SageMaker Developer Guide\\nNotebook Instance Software Updates\\nTo view a read-only version of an example notebook, choose the name of the notebook. This opens the\\nnotebook as a tab in the main area. To create a copy of an example notebook in the home directory of\\nyour notebook instance, choose Create a Copy in the top banner. In the dialog box, type a name for the\\nnotebook and then choose CREATE COPY.\\nFor more information about the example notebooks, see the Amazon SageMaker examples GitHub\\nrepository.\\nNotebook Instance Software Updates\\nAmazon SageMaker periodically tests and releases software that is installed on notebook instances. This\\nincludes:\\n•Kernel updates\\n•Security patches\\n•AWS SDK updates\\n•Amazon SageMaker Python SDK updates\\n•Open source software updates\\nAmazon SageMaker does not automatically update software on a notebook instance when it is in service.\\nTo ensure that you have the most recent software updates, stop and restart your notebook instance,\\neither in the Amazon SageMaker console or by calling StopNotebookInstance (p. 832) followd by\\nStartNotebookInstance (p. 824).\\nYou can also manually update software installed on your notebook instance while it is running by using\\nupdate commands in a terminal or in a notebook.\\nNote\\nUpdating kernels and some packages might depend on whether root access is enabled\\nfor the notebook instance. For more information, see Control Root Access to a Notebook\\nInstance (p. 40).\\nNotebook instances do not notify you if you are running outdated software. You can check the Personal\\nHealth Dashboard or the security bulletin at https://aws.amazon.com/security/security-bulletins/  for\\nupdates.\\nSet the Notebook Kernel\\nAmazon SageMaker provides several kernels for Jupyter that provide support for Python 2 and 3, Apache\\nMXNet, TensorFlow, and PySpark. To set a kernel for a new notebook in the Jupyter notebook dashboard,\\nchoose New , and then choose the kernel from the list.\\n44Amazon SageMaker Developer Guide\\nInstall External Libraries and Kernels in Notebook Instances\\nInstall External Libraries and Kernels in Notebook\\nInstances\\nAmazon SageMaker notebook instances come with multiple environments already installed. These\\nenvironments contain Jupyter kernels and Python packages including: scikit, Pandas, NumPy,\\nTensorFlow, and MXNet. These environments, along with all ﬁles in the sample-notebooks  folder, are\\nrefreshed when you stop and start a notebook instance. You can also install your own environments\\nthat contain your choice of packages and kernels. This is typically done using conda install  or pip\\ninstall .\\nThe diﬀerent Jupyter kernels in Amazon SageMaker notebook instances are separate conda\\nenvironments. For information about conda environments, see Managing environments in the Conda\\ndocumentation. If you want to use an external library in a speciﬁc kernel, install the library in the\\nenvironment for that kernel. You can do this either in the terminal or in a notebook cell. The following\\nprocedures show how to install Theano so that you can use it in a notebook with a conda_mxnet_p36\\nkernel.\\nTo install Theano from a terminal\\n1. Open a notebook instance.\\n2. In the Jupyter dashboard, choose New , and then choose Terminal.\\n3. In the terminal, type the following commands:\\nconda install -n mxnet_p36 -c conda-forge theano\\n   python\\n   import theano\\nTo install Theano from a Jupyter notebook cell\\n1. Open a notebook instance.\\n2. In the Jupyter dashboard, choose New , and then choose conda_mxnet_p36.\\n3. In a cell in the new notebook, type the following command:\\n!pip install theano\\nMaintain a Sandboxed Python Environment\\nAmazon SageMaker periodically updates the Python and dependency versions in the environments\\ninstalled on a notebook instance when it is stopped and restarted. For more information, see Notebook\\nInstance Software Updates (p. 44). To maintain an isolated Python environment that does not change\\nversions, create a lifecycle conﬁguration that runs each time you start your notebook instance. For\\ninformation about creating lifecycle conﬁgurations, see Customize a Notebook Instance  (p. 40).\\nThe following example lifecycle conﬁguration script installs Miniconda on your notebook instance.\\nThis allows you to create environments in your notebook instance with speciﬁc versions of Python and\\ndependencies that Amazon SageMaker does not update:\\n#!/bin/bash\\nset -e\\nWORKING_DIR=/home/ec2-user/.myproject\\n45Amazon SageMaker Developer Guide\\nAssociate Git Repositories with Amazon\\nSageMaker Notebook Instances\\nmkdir -p \"$WORKING_DIR\"\\n# Install Miniconda to get a separate python and pip\\nwget https://repo.anaconda.com/miniconda/Miniconda3-4.5.12-Linux-x86_64.sh -O\\n \"$WORKING_DIR/miniconda.sh\"\\n# Install Miniconda into the working directory\\nbash \"$WORKING_DIR/miniconda.sh\" -b -u -p \"$WORKING_DIR/miniconda\"\\n# Install pinned versions of any dependencies\\nsource \"$WORKING_DIR/miniconda/bin/activate\"\\npip install boto3==1.9.86\\npip install requests==2.21.0\\n# Bootstrapping code\\n# Cleanup\\nsource \"$WORKING_DIR/miniconda/bin/deactivate\"\\nrm -rf \"$WORKING_DIR/miniconda.sh\"\\nYou can also add a sandboxed Python installation as a kernel that you can use in a Jupyter notebook by\\nincluding the following code to the above lifecycle conﬁguration:\\nsource \"$WORKING_DIR/miniconda/bin/activate\" \\n# If required, add this as a kernel\\npip install ipykernel \\npython -m ipykernel install --user --name MyProjectEnv --display-name \"Python\\n (myprojectenv)\"\\nsource \"$WORKING_DIR/miniconda/bin/deactivate\"\\nAssociate Git Repositories with Amazon SageMaker\\nNotebook Instances\\nAssociate Git repositories with your notebook instance to save your notebooks in a source control\\nenvironment that persists even if you stop or delete your notebook instance. You can associate one\\ndefault repository and up to three additional repositories with a notebook instance. The repositories can\\nbe hosted in AWS CodeCommit, GitHub or on any other Git server. Associating Git repositories with your\\nnotebook instance can be useful for:\\n•Persistence - Notebooks in a notebook instance are stored on durable Amazon EBS volumes, but they\\ndo not persist beyond the life of your notebook instance. Storing notebooks in a Git repository enables\\nyou to store and use notebooks even if you stop or delete your notebook instance.\\n•Collaboration - Peers on a team often work on machine learning projects together. Storing your\\nnotebooks in Git repositories allows peers working in diﬀerent notebook instances to share notebooks\\nand collaborate on them in a source-control environment.\\n•Learning - Many Jupyter notebooks that demonstrate machine learning techniques are available in\\npublicly hosted Git repositories, such as on GitHub. You can associate your notebook instance with a\\nrepository to easily load Jupyter notebooks contained in that repository.\\nThere are two ways to associate a Git repository with a notebook instance:\\n•Add a Git repository as a resource in your Amazon SageMaker account. Then, to access the repository,\\nyou can specify an AWS Secrets Manager secret that contains credentials. That way, you can access\\nrepositories that require authentication.\\n46Amazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account\\n•Associate a public Git repository that is not a resource in your account. If you do this, you cannot\\nspecify credentials to access the repository.\\nTopics\\n•Add a Git Repository to Your Amazon SageMaker Account (p. 47)\\n•Create a Notebook Instance with an Associated Git Repository (p. 49)\\n•Associate a CodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance (p. 51)\\n•Use Git Repositories in a Notebook Instance (p. 52)\\nAdd a Git Repository to Your Amazon SageMaker\\nAccount\\nTo manage your GitHub repositories, easily associate them with your notebook instances, and associate\\ncredentials for repositories that require authentication, add the repositories as resources in your Amazon\\nSageMaker account. You can view a list of repositories that are stored in your account and details about\\neach repository in the Amazon SageMaker console and by using the API.\\nYou can add Git repositories to your Amazon SageMaker account in the Amazon SageMaker console or by\\nusing the AWS CLI.\\nNote\\nYou can use the Amazon SageMaker API CreateCodeRepository (p. 627) to add Git repositories\\nto your Amazon SageMaker account, but step-by-step instructions are not provided here.\\nAdd a Git Repository to Your Amazon SageMaker Account\\n(Console)\\nTo add a Git repository as a resource in your Amazon SageMaker account\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Git repositories , then choose Add repository.\\n3. To add an CodeCommit repository, choose AWS CodeCommit.\\na. To use an existing CodeCommit repository:\\ni. Choose Use existing repository.\\nii. For Repository, choose a repository from the list.\\niii. Enter a name to use for the repository in Amazon SageMaker. The name must be 1 to 63\\ncharacters. Valid characters are a-z, A-Z, 0-9, and - (hyphen).\\niv.Choose Add repository.\\nb. To create a new CodeCommit repository:\\ni. Choose Create new repository.\\nii. Enter a name for the repository that you can use in both CodeCommit and Amazon\\nSageMaker. The name must be 1 to 63 characters. Valid characters are a-z, A-Z, 0-9, and -\\n(hyphen).\\niii. Choose Create repository.\\n4. To add a Git repository hosted somewhere other than CodeCommit :\\na. Choose GitHub/Other Git-based repo.\\nb. Enter a name to use for the repository in Amazon SageMaker. The name must be 1 to 63\\ncharacters. Valid characters are a-z, A-Z, 0-9, and - (hyphen).\\n47Amazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account\\nc. Enter the URL for the repository.\\nNote\\nDo not provide a user name in the URL. Add the username and password in AWS\\nSecrets Manager as described in the next step.\\nd. For Git credentials , choose the credentials to use to authenticate to the repository. This is\\nnecessary only if the Git repository is private.\\nNote\\nIf you have two-factor authentication enabled for your Git repository, use a personal\\naccess token generated by your Git service provider instead of a password.\\ni. To use an existing AWS Secrets Manager secret, choose Use existing secret , and then\\nchoose a secret from the list. For information about creating and storing a secret, see\\nCreating a Basic Secret in the AWS Secrets Manager User Guide. The name of the secret you\\nuse must contain the string sagemaker .\\nNote\\nThe secret must have a staging label of AWSCURRENT  and must be in the following\\nformat:\\n{\"username\": UserName , \"password\": Password }\\nFor GitHub repositories, we recommend using a personal access token instead of\\nyour account password. For information, see https://help.github.com/articles/\\ncreating-a-personal-access-token-for-the-command-line/.\\nii. To create a new AWS Secrets Manager secret, choose Create secret , enter a name for the\\nsecret, and then enter the username and password to use to authenticate to the repository.\\nThe name for the secret must contain the string sagemaker .\\nNote\\nThe IAM role you use to create the secret must have the\\nsecretsmanager:GetSecretValue  permission in its IAM policy.\\nThe secret must have a staging label of AWSCURRENT  and must be in the following\\nformat:\\n{\"username\": UserName , \"password\": Password }\\nFor GitHub repositories, we recommend using a personal access token instead of\\nyour account password.\\niii. To not use any credentials, choose No secret .\\ne. Choose Create secret .\\nAdd a Git Repository to Your Amazon SageMaker Account (CLI)\\nUse the create-code-repository  AWS CLI command. Specify a name for the repository as the value\\nof the code-repository-name  argument. The name must be 1 to 63 characters. Valid characters are a-\\nz, A-Z, 0-9, and - (hyphen). Also specify the following:\\n•The default branch\\n•The URL of the Git repository\\nNote\\nDo not provide a user name in the URL. Add the username and password in AWS Secrets\\nManager as described in the next step.\\n•The Amazon Resource Name (ARN) of an AWS Secrets Manager secret that contains the credentials to\\nuse to authenticate the repository as the value of the git-config  argument\\nFor information about creating and storing a secret, see Creating a Basic Secret in the AWS Secrets\\nManager User Guide . The following command creates a new repository named MyRespository  in\\n48Amazon SageMaker Developer Guide\\nCreate a Notebook Instance with\\nan Associated Git Repository\\nyour Amazon SageMaker account that points to a Git repository hosted at https://github.com/\\nmyprofile/my-repo\" .\\nFor Linux, OS X, or Unix:\\naws sagemaker create-code-repository \\\\\\n                    --code-repository-name \"MyRepository\" \\\\\\n                    --git-config \\'{\"Branch\":\"master\", \"RepositoryUrl\" :\\n                    \"https://github.com/myprofile/my-repo\", \"SecretArn\" :\\n \"arn:aws:secretsmanager:us-east-2:012345678901:secret:my-secret-ABc0DE\"}\\'\\nFor Windows:\\naws sagemaker create-code-repository ^\\n                    --code-repository-name \"MyRepository\" ^\\n                    --git-config \"{\\\\\"Branch\\\\\":\\\\\"master\\\\\", \\\\\"RepositoryUrl\\\\\" :\\n                    \\\\\"https://github.com/myprofile/my-repo\\\\\", \\\\\"SecretArn\\\\\" :\\n \\\\\"arn:aws:secretsmanager:us-east-2:012345678901:secret:my-secret-ABc0DE\\\\\"}\"\\nNote\\nThe secret must have a staging label of AWSCURRENT  and must be in the following format:\\n{\"username\": UserName , \"password\": Password }\\nFor GitHub repositories, we recommend using a personal access token instead of your account\\npassword.\\nCreate a Notebook Instance with an Associated Git\\nRepository\\nYou can associate Git repositories with a notebook instance when you create the notebook instance by\\nusing the AWS Management Console, or the AWS CLI.\\nNote\\nYou can use the Amazon SageMaker API CreateNotebookInstance (p. 656) to associate Git\\nrepositories with a notebook instance, but step-by-step instructions are not provided here.\\nNote\\nIf you want to use a CodeCommit repository that is in a diﬀerent AWS than the notebook\\ninstance,set up cross-account access for the repository. For information, see Associate a\\nCodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance (p. 51).\\nTopics\\n•Create a Notebook Instance with an Associated Git Repository (Console) (p. 49)\\n•Create a Notebook Instance with an Associated Git Repository (CLI) (p. 50)\\nCreate a Notebook Instance with an Associated Git Repository\\n(Console)\\nTo create a notebook instance and associate Git repositories in the AWS Management\\nConsole\\n1. Follow the instructions at Step 2: Create an Amazon SageMaker Notebook Instance (p. 17).\\n2. For Git repositories , choose Git repositories to associate with the notebook instance.\\na. For Default repository, choose a repository that you want to use as your default repository.\\nAmazon SageMaker clones this repository as a subdirectory in the Jupyter startup directory\\n49Amazon SageMaker Developer Guide\\nCreate a Notebook Instance with\\nan Associated Git Repository\\nat /home/ec2-user/SageMaker . When you open your notebook instance, it opens in this\\nrepository. To choose a repository that is stored as a resource in your account, choose its\\nname from the list. To add a new repository as a resource in your account, choose Add a\\nrepository to Amazon SageMaker (opens the Add repository ﬂow in a new window) and\\nthen follow the instructions at Create a Notebook Instance with an Associated Git Repository\\n(Console) (p. 49). To clone a public repository that is not stored in your account, choose\\nClone a public Git repository to this notebook instance only, and then specify the URL for that\\nrepository.\\nb. For Additional repository 1, choose a repository that you want to add as an additional\\ndirectory. Amazon SageMaker clones this repository as a subdirectory in the Jupyter startup\\ndirectory at /home/ec2-user/SageMaker . To choose a repository that is stored as a resource\\nin your account, choose its name from the list. To add a new repository as a resource in your\\naccount, choose Add a repository to Amazon SageMaker (opens the Add repository ﬂow\\nin a new window) and then follow the instructions at Create a Notebook Instance with an\\nAssociated Git Repository (Console) (p. 49). To clone a repository that is not stored in your\\naccount, choose Clone a public Git repository to this notebook instance only, and then specify\\nthe URL for that repository.\\nRepeat this step up to three times to add up to three additional repositories to your notebook\\ninstance.\\nCreate a Notebook Instance with an Associated Git Repository\\n(CLI)\\nTo create a notebook instance and associate Git repositories by using the AWS CLI, use the create-\\nnotebook-instance  command as follows:\\n•Specify the repository that you want to use as your default repository as the value of the default-\\ncode-repository  argument. Amazon SageMaker clones this repository as a subdirectory in the\\nJupyter startup directory at /home/ec2-user/SageMaker . When you open your notebook instance,\\nit opens in this repository. To use a repository that is stored as a resource in your Amazon SageMaker\\naccount, specify the name of the repository as the value of the default-code-repository\\nargument. To use a repository that is not stored in your account, specify the URL of the repository as\\nthe value of the default-code-repository  argument.\\n•Specify up to three additional repositories as the value of the additional-code-repositories\\nargument. Amazon SageMaker clones this repository as a subdirectory in the Jupyter startup directory\\nat /home/ec2-user/SageMaker , and the repository is excluded from the default repository by\\nadding it to the .git/info/exclude  directory of the default repository. To use repositories that\\nare stored as resources in your Amazon SageMaker account, specify the names of the repositories\\nas the value of the additional-code-repositories  argument. To use repositories that are not\\nstored in your account, specify the URLs of the repositories as the value of the additional-code-\\nrepositories  argument.\\nFor example, the following command creates a notebook instance that has a repository named\\nMyGitRepo , that is stored as a resource in your Amazon SageMaker account, as a default repository, and\\nan additional repository that is hosted on GitHub:\\naws sagemaker create-notebook-instance \\\\\\n                    --notebook-instance-name \"MyNotebookInstance\" \\\\\\n                    --instance-type \"ml.t2.medium\" \\\\\\n                    --role-arn \"arn:aws:iam::012345678901:role/service-role/\\nAmazonSageMaker-ExecutionRole-20181129T121390\" \\\\\\n                    --default-code-repository \"MyGitRepo\" \\\\\\n                    --additional-code-repositories \"https://github.com/myprofile/my-other-\\nrepo\"\\n50Amazon SageMaker Developer Guide\\nAssociate a CodeCommit Repository in a\\nDiﬀerent AWS Account with a Notebook Instance\\nNote\\nIf you use an AWS CodeCommit repository that does not contain \"SageMaker\" in its name, add\\nthe codecommit:GitPull  and codecommit:GitPush  permissions to the role that you pass\\nas the role-arn  argument to the create-notebook-instance  command. For information\\nabout how to add permissions to a role, see Adding and Removing IAM Policies in the AWS\\nIdentity and Access Management User Guide .\\nAssociate a CodeCommit Repository in a Diﬀerent\\nAWS Account with a Notebook Instance\\nTo associate a CodeCommit repository in a diﬀerent AWS account with your notebook instance, set up\\ncross-account access for the CodeCommit repository.\\nTo set up cross-account access for a CodeCommit repository and associate it with a notebook\\ninstance:\\n1. In the AWS account that contains the CodeCommit repository, create an IAM policy that allows\\naccess to the repository from users in the account that contains your notebook instance. For\\ninformation, see Step 1: Create a Policy for Repository Access in AccountA in the CodeCommit User\\nGuide .\\n2. In the AWS account that contains the CodeCommit repository, create an IAM role, and attach the\\npolicy that you created in the previous step to that role. For information, see Step 2: Create a Role\\nfor Repository Access in AccountA in the CodeCommit User Guide .\\n3. Create a proﬁle in the notebook instance that uses the role that you created in the previous step:\\na. Open the notebook instance.\\nb. Open a terminal in the notebook instance.\\nc. Edit a new proﬁle by typing the following in the terminal:\\nvi /home/ec2-user/.aws/config\\nd. Edit the ﬁle with the following proﬁle information:\\n[profile CrossAccountAccessProfile ]\\nregion = us-west-2\\nrole_arn =\\n arn:aws:iam:: CodeCommitAccount :role/CrossAccountRepositoryContributorRole\\ncredential_source=Ec2InstanceMetadata\\noutput = json\\nWhere CodeCommitAccount  is the account that contains the CodeCommit\\nrepository, CrossAccountAccessProfile  is the name of the new proﬁle, and\\nCrossAccountRepositoryContributorRole  is the name of the role you created in the\\nprevious step.\\n4. On the notebook instance, conﬁgure git to use the proﬁle you created in the previous step:\\na. Open the notebook instance.\\nb. Open a terminal in the notebook instance.\\nc. Edit the Git conﬁguration ﬁle typing the following in the terminal:\\nvi /home/ec2-user/.gitconfig\\nd. Edit the ﬁle with the following proﬁle information:\\n51Amazon SageMaker Developer Guide\\nUse Git Repositories in a Notebook Instance\\n[credential]\\n        helper = !aws codecommit credential-helper --\\nprofile CrossAccountAccessProfile  $@\\n        UseHttpPath = true\\nWhere CrossAccountAccessProfile  is the name of the proﬁle that you created in the\\nprevious step.\\nUse Git Repositories in a Notebook Instance\\nWhen you open a notebook instance that has Git repositories associated with it, it opens in the default\\nrepository, which is installed in your notebook instance directly under /home/ec2-user/SageMaker .\\nYou can open and create notebooks, and you can manually run Git commands in a notebook cell. For\\nexample:\\n!git pull origin master\\nTo open any of the additional repositories, navigate up one folder. The additional repositories are also\\ninstalled as directories under /home/ec2-user/SageMaker .\\nIf you open the notebook instance with a JupyterLab interface, the jupyter-git extension is installed and\\navailable to use. For information about the jupyter-git extension for JupyterLab, see https://github.com/\\njupyterlab/jupyterlab-git.\\nWhen you open a notebook instance in JupyterLab, you see the git repositories associated with it on the\\nleft menu:\\n52Amazon SageMaker Developer Guide\\nUse Git Repositories in a Notebook Instance\\nYou can use the jupyter-git extension to manage git visually, instead of using the command line:\\n53Amazon SageMaker Developer Guide\\nGet Notebook Instance Metadata\\nGet Notebook Instance Metadata\\nWhen you create a notebook instance, Amazon SageMaker creates a JSON ﬁle on the instance at the\\nlocation /opt/ml/metadata/resource-metadata.json  that contains the ResourceName  and\\nResourceArn  of the notebook instance. You can access this metadata from anywhere within the\\nnotebook instance, including in lifecycle conﬁgurations. For information about notebook instance\\nlifecycle conﬁgurations, see Customize a Notebook Instance  (p. 40).\\nThe resource-metadata.json  ﬁle has the following structure:\\n{\\n    \"ResourceArn\": \" NotebookInstanceArn \",\\n    \"ResourceName\": \" NotebookInstanceName \"\\n}\\nYou can use this metadata from within the notebook instance to get other information about the\\nnotebook instance. For example, the following commands get the tags associated with the notebook\\ninstance:\\nNOTEBOOK_ARN=$(jq \\'.ResourceArn\\'\\n            /opt/ml/metadata/resource-metadata.json --raw-output)\\naws sagemaker list-tags --resource-arn $NOTEBOOK_ARN\\nThe out put looks like the following:\\n{\\n    \"Tags\": [\\n        {\\n            \"Key\": \"test\",\\n            \"Value\": \"true\"\\n        }\\n    ]\\n}\\nMonitor Jupyter Logs in Amazon CloudWatch Logs\\nJupyter logs include important information such as events, metrics, and health information that provide\\nactionable insights when running Amazon SageMaker notebooks. By importing Jupyter logs into\\nCloudWatch Logs, customers can use CloudWatch Logs to detect anomalous behaviors, set alarms, and\\ndiscover insights to keep the Amazon SageMaker notebooks running more smoothly. You can access the\\nlogs even when the Amazon EC2 instance that hosts the notebook is unresponsive, and use the logs to\\ntroubleshoot the unresponsive notebook. Sensitive information such as AWS account IDs, secret keys,\\nand authentication tokens in presigned URLs are removed so that customers can share logs without\\nleaking private information.\\nTo view Jupyter logs for a notebook instance:\\n1. Sign in to the AWS Management Console and open the Amazon SageMaker console at https://\\nconsole.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances.\\n3. In the list of notebook instances, choose the notebook instance for which you want to view Jupyter\\nlogs.\\n4. Under Monitor  on the notebook instance details page, choose View logs.\\n54Amazon SageMaker Developer Guide\\nMonitor Jupyter Logs in Amazon CloudWatch Logs\\n5. In the CloudWatch console, choose the log stream for your notebook intance. Its name is in the form\\nNotebookInstanceName /jupyter.log .\\nFor more information about monitoring CloudWatch logs for Amazon SageMaker, see Log Amazon\\nSageMaker Events with Amazon CloudWatch (p. 466).\\n55Amazon SageMaker Developer Guide\\nUse Built-in Algorithms\\nBuild a Model\\nTo build a machine learning model in Amazon SageMaker, you have the following options:\\n•Use one of the built-in algorithims. Amazon SageMaker provides several built-in machine learning\\nalgorithms that you can use for a variety of problem types. For more information, see Use Amazon\\nSageMaker Built-in Algorithms  (p. 56).\\n•Write a custom training script in a machine learning framework that Amazon SageMaker supports, and\\nuse one of the pre-built framework containers to run it in Amazon SageMaker. For information, see Use\\nMachine Learning Frameworks with Amazon SageMaker (p. 440).\\n•Bring your own algorithm or model to train or host in Amazon SageMaker. For information, see Use\\nYour Own Algorithms or Models with Amazon SageMaker  (p. 384).\\n•Use an algorithm that you subscribe to from AWS Marketplace. For information, see Amazon\\nSageMaker Resources in AWS Marketplace (p. 428).\\nTopics\\n•Use Amazon SageMaker Built-in Algorithms  (p. 56)\\nUse Amazon SageMaker Built-in Algorithms\\nA machine learning algorithm uses example data to create a generalized solution (a model ) that\\naddresses the business question you are trying to answer. After you create a model using example data,\\nyou can use it to answer the same business question for a new set of data. This is also referred to as\\nobtaining inferences.\\nAmazon SageMaker provides several built-in machine learning algorithms that you can use for a variety\\nof problem types.\\nBecause you create a model to address a business question, your ﬁrst step is to understand the problem\\nthat you want to solve. Speciﬁcally, the format of the answer that you are looking for inﬂuences the\\nalgorithm that you choose. For example, suppose that you are a bank marketing manager, and that\\nyou want to conduct a direct mail campaign to attract new customers. Consider the potential types of\\nanswers that you\\'re looking for:\\n•Answers that ﬁt into discrete categories—For example, answers to these questions:\\n\\xa0\\n•\"Based on past customer responses, should I mail this particular customer?\" Answers to this question\\nfall into two categories, \"yes\" or \"no.\" In this case, you use the answer to narrow the recipients of the\\nmail campaign.\\n\\xa0\\n•\"Based on past customer segmentation, which segment does this customer fall into?\" Answers might\\nfall into categories such as \"empty nester,\" \"suburban family,\" or \"urban professional.\" You could use\\nthese segments to decide who should receive the mailing.\\n\\xa0\\n56Amazon SageMaker Developer Guide\\nUse Built-in Algorithms\\nFor this type of discrete classiﬁcation problem, Amazon SageMaker provides two algorithms:\\nLinear Learner Algorithm  (p. 162) and the XGBoost Algorithm (p. 255). You set the following\\nhyperparameters to direct these algorithms to produce discrete results:\\n\\xa0\\n•For the Linear Learner algorithm, set the predictor_type  hyperparameter to\\nbinary_classifier .\\n\\xa0\\n•For the XGBoost algorithm, set the objective  hyperparameter to reg:logistic .\\n\\xa0\\n•Answers that are quantitative—Consider this question: \"Based on the return on investment (ROI)\\nfrom past mailings, what is the ROI for mailing this customer?” In this case, you use the ROI to target\\ncustomers for the mail campaign. For these quantitative analysis problems, you can also use the Linear\\nLearner Algorithm  (p. 162) or the XGBoost Algorithm (p. 255) algorithms. You set the following\\nhyperparameters to direct these algorithms to produce quantitative results:\\n\\xa0\\n•For the Linear Learner algorithm, set the predictor_type  hyperparameter to regressor .\\n\\xa0\\n•For the XGBoost algorithm, set the objective  hyperparameter to reg:linear .\\n\\xa0\\n•Answers in the form of discrete recommendations—Consider this question: \"Based on past responses\\nto mailings, what is the recommended content for each customer?\" In this case, you are looking for\\na recommendation on what to mail, not whether to mail, the customer. For this problem, Amazon\\nSageMaker provides the Factorization Machines Algorithm (p. 98) algorithm.\\n\\xa0\\nAll of the questions in the preceding examples rely on having example data that includes answers. There\\nare times that you don\\'t need, or can\\'t get, example data with answers. This is true for problems whose\\nanswers identify groups. For example:\\n•\"I want to group current and prospective customers into 10 groups based on their attributes. How\\nshould I group them? \" You might choose to send the mailing to customers in the group that has the\\nhighest percentage of current customers. That is, prospective customers that most resemble current\\ncustomers based on the same set of attributes. For this type of question, Amazon SageMaker provides\\nthe K-Means Algorithm (p. 141).\\n\\xa0\\n•\"What are the attributes that diﬀerentiate these customers, and what are the values for each customer\\nalong those dimensions.\" You use these answers to simplify the view of current and prospective\\ncustomers, and, maybe, to better understand these customer attributes. For this type of question,\\nAmazon SageMaker provides the Principal Component Analysis (PCA) Algorithm  (p. 222) algorithm.\\nIn addition to these general-purpose algorithms, Amazon SageMaker provides algorithms that are\\ntailored to speciﬁc use cases. These include:\\n•Image Classiﬁcation Algorithm  (p. 108)—Use this algorithm to classify images. It uses example data\\nwith answers (referred to as supervised algorithm).\\n\\xa0\\n57Amazon SageMaker Developer Guide\\nCommon Information\\n•Sequence-to-Sequence Algorithm (p. 242)—This supervised algorithm is commonly used for neural\\nmachine translation.\\n\\xa0\\n•Latent Dirichlet Allocation (LDA) Algorithm (p. 157)—This algorithm is suitable for determining\\ntopics in a set of documents. It is an unsupervised algorithm, which means that it doesn\\'t use example\\ndata with answers during training.\\n\\xa0\\n•Neural Topic Model (NTM) Algorithm (p. 177)—Another unsupervised technique for determining\\ntopics in a set of documents, using a neural network approach.\\nTopics\\n•Common Elements of Built-in Algorithms  (p. 58)\\n•BlazingText Algorithm (p. 74)\\n•DeepAR Forecasting Algorithm (p. 83)\\n•Factorization Machines Algorithm (p. 98)\\n•Image Classiﬁcation Algorithm  (p. 108)\\n•IP Insights Algorithm  (p. 131)\\n•K-Means Algorithm (p. 141)\\n•K-Nearest Neighbors (k-NN) Algorithm (p. 148)\\n•Latent Dirichlet Allocation (LDA) Algorithm (p. 157)\\n•Linear Learner Algorithm  (p. 162)\\n•Neural Topic Model (NTM) Algorithm (p. 177)\\n•Object2Vec Algorithm (p. 183)\\n•Object Detection Algorithm (p. 199)\\n•Principal Component Analysis (PCA) Algorithm  (p. 222)\\n•Random Cut Forest (RCF) Algorithm (p. 226)\\n•Semantic Segmentation Algorithm  (p. 234)\\n•Sequence-to-Sequence Algorithm (p. 242)\\n•XGBoost Algorithm (p. 255)\\nCommon Elements of Built-in Algorithms\\nThe following topics provide information common to all of the algorithms provided by Amazon\\nSageMaker.\\nTopics\\n•Common Parameters for Built-In Algorithms  (p. 58)\\n•Common Data Formats for Built-in Algorithms  (p. 64)\\n•Instance Types for Built-in Algorithms  (p. 72)\\n•Logs for Built-In Algorithms  (p. 73)\\nCommon Parameters for Built-In Algorithms\\nThe following table lists parameters for each of the algorithms provided by Amazon SageMaker.\\n58Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm\\nNameChannel\\nNameTraining Image and\\nInference Image Registry\\nPathTraining\\nInput\\nModeFile TypeInstance\\nClassParallelizable\\nBlazingTexttrain <ecr_path> /\\nblazingtext:<tag>File or\\nPipeText ﬁle\\n(one\\nsentence\\nper line\\nwith\\nspace-\\nseparated\\ntokens)GPU\\n(single\\ninstance\\nonly) or\\nCPUNo\\nDeepAR\\nForecastingtrain and\\n(optionally)\\ntest<ecr_path> /forecasting-\\ndeepar:<tag>FileJSON\\nLines or\\nParquetGPU or\\nCPUYes\\nFactorization\\nMachinestrain and\\n(optionally)\\ntest<ecr_path> /factorization-\\nmachines: <tag>File or\\nPiperecordIO-\\nprotobufCPU (GPU\\nfor dense\\ndata)Yes\\nImage\\nClassiﬁcationtrain and\\nvalidation,\\n(optionally)\\ntrain_lst,\\nvalidation_lst,\\nand\\nmodel<ecr_path> /image-\\nclassiﬁcation: <tag>File or\\nPiperecordIO\\nor image\\nﬁles (.jpg\\nor .png)GPUYes\\nIP\\nInsightstrain and\\n(optionally)\\nvalidation<ecr_path> /\\nipinsights: <tag>FileCSV CPU or\\nGPUYes\\nk-means train and\\n(optionally)\\ntest<ecr_path> /kmeans:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPUCommon\\n(single\\nGPU\\ndevice\\non one\\nor more\\ninstances)No\\nk-nearest-\\nneighbor\\n(k-NN)train and\\n(optionally)\\ntest<ecr_path> /knn:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPU\\n(single\\nGPU\\ndevice\\non one\\nor more\\ninstances)Yes\\nLDA train and\\n(optionally)\\ntest<ecr_path> /lda:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU\\n(single\\ninstance\\nonly)No\\n59Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm\\nNameChannel\\nNameTraining Image and\\nInference Image Registry\\nPathTraining\\nInput\\nModeFile TypeInstance\\nClassParallelizable\\nLinear\\nLearnertrain and\\n(optionally)\\nvalidation,\\ntest, or\\nboth<ecr_path> /linear-\\nlearner:<tag>File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPUYes\\nNeural\\nTopic\\nModeltrain and\\n(optionally)\\nvalidation,\\ntest, or\\nboth<ecr_path> /ntm:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVGPU or\\nCPUYes\\nObject2Vectrain and\\n(optionally)\\nvalidation,\\ntest, or\\nboth<ecr_path> /\\nobject2vec:<tag>FileJSON\\nLinesGPU\\nor CPU\\n(single\\ninstance\\nonly)No\\nObject\\nDetectiontrain and\\nvalidation,\\n(optionally)\\ntrain_annotation,\\nvalidation_annotation,\\nand\\nmodel<ecr_path> /object-\\ndetection:<tag>File or\\nPiperecordIO\\nor image\\nﬁles (.jpg\\nor .png)GPUYes\\nPCA train and\\n(optionally)\\ntest<ecr_path> /pca:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVGPU or\\nCPUYes\\nRandom\\nCut Foresttrain and\\n(optionally)\\ntest<ecr_path> /\\nrandomcutforest:<tag>File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPUYes\\nSemantic\\nSegmentationtrain and\\nvalidation,\\ntrain_annotation,\\nvalidation_annotation,\\nand\\n(optionally)\\nlabel_map\\nand\\nmodel<ecr_path> /semantic-\\nsegmentation: <tag>File or\\nPipeimage\\nﬁlesGPU\\n(single\\ninstance\\nonly)No\\nSeq2Seq\\nModelingtrain,\\nvalidation,\\nand\\nvocab<ecr_path> /seq2seq:<tag> FilerecordIO-\\nprotobufGPU\\n(single\\ninstance\\nonly)No\\nXGBoost train and\\n(optionally)\\nvalidation<ecr_path> /xgboost:<tag> FileCSV or\\nLibSVMCPUYes\\n60Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithms that are parallelizable  can be deployed on multiple compute instances for distributed\\ntraining. For the Training Image and Inference Image Registry Path column, use the :1 version tag\\nto ensure that you are using a stable version of the algorithm. You can reliably host a model trained\\nusing an image with the :1 tag on an inference image that has the :1 tag. Using the :latest  tag in the\\nregistry path provides you with the most up-to-date version of the algorithm, but might cause problems\\nwith backward compatibility. Avoid using the :latest tag for production purposes.\\nFor the Training Image and Inference Image Registry Path column, depending on algorithm and region\\nuse one of the following values for <ecr_path>.\\nAlgorithm Name AWS Region Training Image and Inference Image Registry Path\\nus-west-1 632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2 174872318107.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1 382416733822.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2 404615174143.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-east-1 286214385809.dkr.ecr.ap-east-1.amazonaws.com\\nap-northeast-1351501993468.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2835164637446.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1 991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2712309505854.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1 469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1 664544806723.dkr.ecr.eu-central-1.amazonaws.com\\neu-north-1 669576153137.dkr.ecr.eu-north-1.amazonaws.com\\neu-west-1 438346466558.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2 644912444149.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3 749696950732.dkr.ecr.eu-west-3.amazonaws.comFactorization Machines,\\nIP Insights, k-means, k-\\nnearest-neighbor, Linear\\nLearner, Object2Vec,\\nNeural Topic Model,PCA,\\nand Random Cut Forest\\nsa-east-1 855470959533.dkr.ecr.sa-east-1.amazonaws.com\\nus-west-1 632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2 266724342769.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1 766337827248.dkr.ecr.us-east-1.amazonaws.comLDA\\nus-east-2 999911452149.dkr.ecr.us-east-2.amazonaws.com\\n61Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-northeast-1258307448986.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2293181348795.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2297031611018.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1353608530281.dkr.ecr.eu-central-1.amazonaws.com\\neu-west-1999678624901.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com\\nus-west-1632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2433757028032.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1811284229777.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2825641698319.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-east-1286214385809.dkr.ecr.ap-east-1.amazonaws.com\\nap-northeast-1501404015308.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2306986355934.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2544295431143.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1813361260812.dkr.ecr.eu-central-1.amazonaws.com\\neu-north-1669576153137.dkr.ecr.eu-north-1.amazonaws.comBlazingText, Image\\nClassiﬁcation, Object\\nDetection, Semantic\\nSegmentation, Seq2Seq,\\nand XGBoost (0.72)\\neu-west-1685385470294.dkr.ecr.eu-west-1.amazonaws.com\\n62Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3749696950732.dkr.ecr.eu-west-3.amazonaws.com\\nsa-east-1855470959533.dkr.ecr.sa-east-1.amazonaws.com\\nus-west-1746614075791.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2246618743249.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1683313688378.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2257758044811.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1414596584902.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-northeast-1354813040037.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2366743142698.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-southeast-1121021644041.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2783357654285.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nap-south-1720646828776.dkr.ecr.ap-south-1.amazonaws.com\\nap-east-1651117190479.dkr.ecr.ap-east-1.amazonaws.com\\nca-central-1341280168497.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1492215442770.dkr.ecr.eu-central-1.amazonaws.com\\neu-north-1662702820516.dkr.ecr.eu-north-1.amazonaws.com\\neu-west-1141502667606.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2764974769150.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3659782779980.dkr.ecr.eu-west-3.amazonaws.comXGBoost (0.90)\\nsa-east-1737474898029.dkr.ecr.sa-east-1.amazonaws.com\\nus-west-1632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2156387875391.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1522234722520.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2566113047672.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.comDeepAR Forecasting\\nap-east-1286214385809.dkr.ecr.ap-east-1.amazonaws.com\\n63Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path\\nap-northeast-1633353088612.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2204372634319.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2514117268639.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-north-1669576153137.dkr.ecr.eu-north-1.amazonaws.com\\neu-central-1495149712605.dkr.ecr.eu-central-1.amazonaws.com\\neu-west-1224300973850.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3749696950732.dkr.ecr.eu-west-3.amazonaws.com\\nsa-east-1855470959533.dkr.ecr.sa-east-1.amazonaws.com\\nUse the paths and training input mode as follows:\\n•To create a training job (with a request to the CreateTrainingJob (p. 667) API), specify the Docker\\nRegistry path and the training input mode for the training image. You create a training job to train a\\nmodel using a speciﬁc dataset.\\n\\xa0\\n•To create a model (with a CreateModel (p. 648) request), specify the Docker Registry path for the\\ninference image. Amazon SageMaker launches machine learning compute instances that are based on\\nthe endpoint conﬁguration and deploys the model, which includes the artifacts (the result of model\\ntraining).\\nCommon Data Formats for Built-in Algorithms\\nThe following topics explain the data formats for the algorithms provided by Amazon SageMaker.\\nTopics\\n•Common Data Formats for Training  (p. 64)\\n•Common Data Formats for Inference  (p. 68)\\nCommon Data Formats for Training\\nTo prepare for training, you can preprocess your data using a variety of AWS services, including AWS\\nGlue, Amazon EMR, Amazon Redshift, Amazon Relational Database Service, and Amazon Athena. After\\npreprocessing, publish the data to an Amazon S3 bucket. For training, the data need to go through a\\nseries of conversions and transformations, including:\\n64Amazon SageMaker Developer Guide\\nCommon Information\\n•Training data serialization (handled by you)\\n•Training data deserialization (handled by the algorithm)\\n•Training model serialization (handled by the algorithm)\\n•Trained model deserialization (optional, handled by you)\\nWhen using Amazon SageMaker in the training portion of the algorithm, make sure to upload all data\\nat once. If more data is added to that location, a new training call would need to be made to construct a\\nbrand new model.\\nThe following table lists supported ContentType values:\\nContent Type Deﬁnition\\ntext/csv; label_size=n Comma-separated values, where n speciﬁes the number of starting\\ncolumns in a row that are labels. The default value for n is 1.\\napplication/x-recordio-\\nprotobufA protobuf message wrapped in a RecordIO record.\\nTraining Data Formats\\nMany Amazon SageMaker algorithms support training with data in CSV format. To use data in CSV\\nformat for training, in the input data channel speciﬁcation, specify text/csv  as the ContentType.\\nAmazon SageMaker requires that a CSV ﬁle doesn\\'t have a header record and that the target variable is\\nin the ﬁrst column. To run unsupervised learning algorithms that don\\'t have a target, specify the number\\nof label columns in the content type. For example, in this case \\'text/csv;label_size=0\\' .\\nMost Amazon SageMaker algorithms work best when you use the optimized protobuf recordIO format\\nfor the training data. Using this format allows you to take advantage of Pipe mode  when training\\nthe algorithms that support it. File mode  loads all of your data from Amazon Simple Storage Service\\n(Amazon S3) to the training instance volumes. In Pipe mode , your training job streams data directly\\nfrom Amazon S3. Streaming can provide faster start times for training jobs and better throughput.\\nWith Pipe mode, you also reduce the size of the Amazon Elastic Block Store volumes for your training\\ninstances. Pipe mode needs only enough disk space to store your ﬁnal model artifacts. File mode\\nneeds disk space to store both your ﬁnal model artifacts and your full training dataset. See the\\nAlgorithmSpeciﬁcation  (p. 863) for additional details on the training input mode. For a summary of the\\ndata formats supported by each algorithm, see the documentation for the individual algorithms or this\\ntable .\\nNote\\nFor an example that shows how to convert the commonly used numPy array into the\\nprotobuf recordIO format, see https://github.com/awslabs/amazon-sagemaker-examples/\\nblob/master/introduction_to_amazon_algorithms/factorization_machines_mnist/\\nfactorization_machines_mnist.ipynb. .\\nIn the protobuf recordIO format, Amazon SageMaker converts each observation in the dataset into\\na binary representation as a set of 4-byte ﬂoats and is then loads it to the protobuf values ﬁeld. If\\nyou are using Python for your data preparation, we strongly recommend that you use these existing\\ntransformations. However, if you are using another language, the protobuf deﬁnition ﬁle below provides\\nthe schema that you use to convert your data into Amazon SageMaker protobuf format.\\nsyntax = \"proto2\";\\n \\n package aialgs.data;\\n \\n option java_package = \"com.amazonaws.aialgorithms.proto\";\\n option java_outer_classname = \"RecordProtos\";\\n65Amazon SageMaker Developer Guide\\nCommon Information\\n \\n // A sparse or dense rank-R tensor that stores data as doubles (float64).\\n message Float32Tensor   {\\n     // Each value in the vector. If keys is empty, this is treated as a\\n     // dense vector.\\n     repeated float values = 1 [packed = true];\\n \\n     // If key is not empty, the vector is treated as sparse, with\\n     // each key specifying the location of the value in the sparse vector.\\n     repeated uint64 keys = 2 [packed = true];\\n \\n     // An optional shape that allows the vector to represent a matrix.\\n     // For example, if shape = [ 10, 20 ], floor(keys[i] / 10) gives the row,\\n     // and keys[i] % 20 gives the column.\\n     // This also supports n-dimensonal tensors.\\n     // Note: If the tensor is sparse, you must specify this value.\\n     repeated uint64 shape = 3 [packed = true];\\n }\\n \\n // A sparse or dense rank-R tensor that stores data as doubles (float64).\\n message Float64Tensor {\\n     // Each value in the vector. If keys is empty, this is treated as a\\n     // dense vector.\\n     repeated double values = 1 [packed = true];\\n \\n     // If this is not empty, the vector is treated as sparse, with\\n     // each key specifying the location of the value in the sparse vector.\\n     repeated uint64 keys = 2 [packed = true];\\n \\n     // An optional shape that allows the vector to represent a matrix.\\n     // For example, if shape = [ 10, 20 ], floor(keys[i] / 10) gives the row,\\n     // and keys[i] % 20 gives the column.\\n     // This also supports n-dimensonal tensors.\\n     // Note: If the tensor is sparse, you must specify this value.\\n     repeated uint64 shape = 3 [packed = true];\\n }\\n \\n // A sparse or dense rank-R tensor that stores data as 32-bit ints (int32).\\n message Int32Tensor {\\n     // Each value in the vector. If keys is empty, this is treated as a\\n     // dense vector.\\n     repeated int32 values = 1 [packed = true];\\n \\n     // If this is not empty, the vector is treated as sparse with\\n     // each key specifying the location of the value in the sparse vector.\\n     repeated uint64 keys = 2 [packed = true];\\n \\n     // An optional shape that allows the vector to represent a matrix.\\n     // For Exmple, if shape = [ 10, 20 ], floor(keys[i] / 10) gives the row,\\n     // and keys[i] % 20 gives the column.\\n     // This also supports n-dimensonal tensors.\\n     // Note: If the tensor is sparse, you must specify this value.\\n     repeated uint64 shape = 3 [packed = true];\\n }\\n \\n // Support for storing binary data for parsing in other ways (such as JPEG/etc).\\n // This is an example of another type of value and may not immediately be supported.\\n message Bytes {\\n     repeated bytes value = 1;\\n \\n     // If the content type of the data is known, stores it.\\n     // This allows for the possibility of using decoders for common formats\\n     // in the future.\\n     optional string content_type = 2;\\n }\\n \\n66Amazon SageMaker Developer Guide\\nCommon Information\\n message Value {\\n     oneof value {\\n         // The numbering assumes the possible use of:\\n         // - float16, float128\\n         // - int8, int16, int32\\n         Float32Tensor float32_tensor = 2;\\n         Float64Tensor float64_tensor = 3;\\n         Int32Tensor int32_tensor = 7;\\n         Bytes bytes = 9;\\n     }\\n }\\n \\n message Record {\\n     // Map from the name of the feature to the value.\\n     //\\n     // For vectors and libsvm-like datasets,\\n     // a single feature with the name `values`\\n     // should be specified.\\n     map<string, Value> features = 1;\\n \\n     // An optional set of labels for this record.\\n     // Similar to the features field above, the key used for\\n     // generic scalar / vector labels should ve \\'values\\'.\\n     map<string, Value> label = 2;\\n \\n     // A unique identifier for this record in the dataset.\\n     //\\n     // Whilst not necessary, this allows better\\n     // debugging where there are data issues.\\n     //\\n     // This is not used by the algorithm directly.\\n     optional string uid = 3;\\n \\n     // Textual metadata describing the record.\\n     //\\n     // This may include JSON-serialized information\\n     // about the source of the record.\\n     //\\n     // This is not used by the algorithm directly.\\n     optional string metadata = 4;\\n \\n     // An optional serialized JSON object that allows per-record\\n     // hyper-parameters/configuration/other information to be set.\\n     //\\n     // The meaning/interpretation of this field is defined by\\n     // the algorithm author and may not be supported.\\n     //\\n     // This is used to pass additional inference configuration\\n     // when batch inference is used (e.g. types of scores to return).\\n     optional string configuration = 5;\\n }\\nAfter creating the protocol buﬀer, store it in an Amazon S3 location that Amazon SageMaker can access\\nand that can be passed as part of InputDataConfig  in create_training_job .\\nNote\\nFor all Amazon SageMaker algorithms, the ChannelName  in InputDataConfig  must be set to\\ntrain. Some algorithms also support a validation or test input channels . These are typically\\nused to evaluate the model\\'s performance by using a hold-out dataset. Hold-out datasets are\\nnot used in the initial training but can be used to further tune the model.\\nTrained Model Deserialization\\nAmazon SageMaker models are stored as model.tar.gz in the S3 bucket speciﬁed in OutputDataConfig\\nS3OutputPath  parameter of the create_training_job  call. You can specify most of these model\\n67Amazon SageMaker Developer Guide\\nCommon Information\\nartifacts when creating a hosting model. You can also open and review them in your notebook instance.\\nWhen model.tar.gz  is untarred, it contains model_algo-1 , which is a serialized Apache MXNet object.\\nFor example, you use the following to load the k-means model into memory and view it:\\nimport mxnet as mx\\nprint(mx.ndarray.load(\\'model_algo-1\\'))\\nCommon Data Formats for Inference\\nAmazon SageMaker algorithms accept and produce several diﬀerent MIME types for the http payloads\\nused in retrieving online and mini-batch predictions. You can use various AWS services to transform\\nor preprocess records prior to running inference. At a minimum, you need to convert the data for the\\nfollowing:\\n•Inference request serialization (handled by you)\\n•Inference request deserialization (handled by the algorithm)\\n•Inference response serialization (handled by the algorithm)\\n•Inference response deserialization (handled by you)\\nConvert Data for Inference Request Serialization\\nContent type options for Amazon SageMaker algorithm inference requests include: text/csv ,\\napplication/json , and application/x-recordio-protobuf . Algorithms that don\\'t support these\\ntypes, such as XGBoost, which is incompatible, support other types, such as text/x-libsvm .\\nFor text/csv  the value for the Body argument to invoke_endpoint  should be a string with commas\\nseparating the values for each feature. For example, a record for a model with four features might\\nlook like: 1.5,16.0,14,23.0 . Any transformations performed on the training data should also be\\nperformed on the data before obtaining inference. The order of the features matters, and must remain\\nunchanged.\\napplication/json  is signiﬁcantly more ﬂexible and provides multiple possible formats for developers\\nto use in their applications. At a high level, in JavaScript, the payload might look like:\\nlet request = {\\n  // Instances might contain multiple rows that predictions are sought for.\\n  \"instances\": [\\n    {\\n      // Request and algorithm specific inference parameters.\\n      \"configuration\": {},\\n      // Data in the specific format required by the algorithm.\\n      \"data\": {\\n         \"<field name>\": dataElement\\n       }\\n    }\\n  ]\\n}\\nYou have the following options for specifying the dataElement :\\nProtocol buﬀers equivalent:\\n// Has the same format as the protocol buffers implementation described for training.\\nlet dataElement = {\\n  \"keys\": [],\\n  \"values\": [],\\n  \"shape\": []\\n}\\n68Amazon SageMaker Developer Guide\\nCommon Information\\nSimple numeric vector:\\n// An array containing numeric values is treated as an instance containing a\\n// single dense vector.\\nlet dataElement = [1.5, 16.0, 14.0, 23.0]\\n// It will be converted to the following representation by the SDK.\\nlet converted = {\\n  \"features\": {\\n    \"values\": dataElement\\n  }\\n}\\nAnd, for multiple records:\\nlet request = {\\n  \"instances\": [\\n    // First instance.\\n    {\\n      \"features\": [ 1.5, 16.0, 14.0, 23.0 ]\\n    },\\n    // Second instance.\\n    {\\n      \"features\": [ -2.0, 100.2, 15.2, 9.2 ]\\n    }\\n  ]\\n}\\nConvert Data for Inference Response Deserialization\\nAmazon SageMaker algorithms return JSON in several layouts. At a high level, the structure is:\\nlet response = {\\n  \"predictions\": [{\\n    // Fields in the response object are defined on a per algorithm-basis.\\n  }]\\n}\\nThe ﬁelds that are included in predictions diﬀer across algorithms. The following are examples of output\\nfor the k-means algorithm.\\nSingle-record inference:\\nlet response = {\\n  \"predictions\": [{\\n    \"closest_cluster\": 5,\\n    \"distance_to_cluster\": 36.5\\n  }]\\n}\\nMulti-record inference:\\nlet response = {\\n  \"predictions\": [\\n    // First instance prediction.\\n    {\\n      \"closest_cluster\": 5,\\n      \"distance_to_cluster\": 36.5\\n    },\\n    // Second instance prediction.\\n69Amazon SageMaker Developer Guide\\nCommon Information\\n    {\\n      \"closest_cluster\": 2,\\n      \"distance_to_cluster\": 90.3\\n    }\\n  ]\\n}\\nMulti-record inference with protobuf input:\\n{ \\n  \"features\": [],\\n  \"label\": {\\n    \"closest_cluster\": {\\n      \"values\": [ 5.0 ] // e.g. the closest centroid/cluster was 1.0\\n    },\\n    \"distance_to_cluster\": {\\n      \"values\": [ 36.5 ]\\n    }\\n  },\\n  \"uid\": \"abc123\",\\n  \"metadata\": \"{ \"created_at\": \\'2017-06-03\\' }\"\\n}\\nAmazon SageMaker algorithms also support jsonlines format, where the per-record response content\\nis same as that in JSON format. The multi-record structure is a concatenation of per-record response\\nobjects separated by newline characters. The response content for the built-in KMeans algorithm for 2\\ninput data points is:\\n{\"distance_to_cluster\": 23.40593910217285, \"closest_cluster\": 0.0}\\n{\"distance_to_cluster\": 27.250282287597656, \"closest_cluster\": 0.0}\\nWhile running batch transform, it is recommended to use jsonlines  response type by setting the\\nAccept  ﬁeld in the CreateTransformJobRequest  to application/jsonlines .\\nCommon Request Formats for All Algorithms\\nMost algorithms use several of the following inference request formats.\\nJSON Request Format\\nContent-type: application/json\\nDense Format\\nlet request =   {\\n    \"instances\":    [\\n        {\\n            \"features\": [1.5, 16.0, 14.0, 23.0]\\n        }\\n    ]\\n}\\nlet request =   {\\n    \"instances\":    [\\n        {\\n            \"data\": {\\n                \"features\": {\\n                    \"values\": [ 1.5, 16.0, 14.0, 23.0]\\n                }\\n            }\\n70Amazon SageMaker Developer Guide\\nCommon Information\\n        }\\n    ]\\n}\\nSparse Format\\n{\\n \"instances\": [\\n  {\"data\": {\"features\": {\\n     \"keys\": [26, 182, 232, 243, 431],\\n     \"shape\": [2000],\\n     \"values\": [1, 1, 1, 4, 1]\\n    }\\n   }\\n  },\\n  {\"data\": {\"features\": {\\n     \"keys\": [0, 182, 232, 243, 431],\\n     \"shape\": [2000],\\n     \"values\": [13, 1, 1, 4, 1]\\n    }\\n   }\\n  },\\n ]\\n}\\nJSONLINES Request Format\\nContent-type: application/jsonlines\\nDense Format\\nA single record in dense format can be represented as either:\\n{ \"features\": [1.5, 16.0, 14.0, 23.0] }\\nor:\\n{ \"data\": { \"features\": { \"values\": [ 1.5, 16.0, 14.0, 23.0] } }\\nSparse Format\\nA single record in sparse format is represented as:\\n{\"data\": {\"features\": { \"keys\": [26, 182, 232, 243, 431], \"shape\": [2000], \"values\": [1, 1,\\n 1, 4, 1] } } }\\nMultiple records are represented as a concatenation of the above single-record representations,\\nseparated by newline characters:\\n{\"data\": {\"features\": { \"keys\": [0, 1, 3], \"shape\": [4], \"values\": [1, 4, 1] } } }\\n{ \"data\": { \"features\": { \"values\": [ 1.5, 16.0, 14.0, 23.0] } }\\n{ \"features\": [1.5, 16.0, 14.0, 23.0] }\\nCSV Request Format\\nContent-type: text/csv;label_size=0\\nNote\\nCSV support is not available for factorization machines.\\n71Amazon SageMaker Developer Guide\\nCommon Information\\nRECORDIO Request Format\\nContent-type: application/x-recordio-protobuf\\nUse Batch Transform with Build-in Algorithms\\nWhile running batch transform, it\\'s recommended to use jsonlines response type instead of\\nJSON, if supported by the algorithm. This is accomplished by setting the Accept  ﬁeld in the\\nCreateTransformJobRequest  to application/jsonlines .\\nWhen you create a transform job, the SplitType  must be set according to the ContentType  of\\nthe input data. Similarly, depending on the Accept  ﬁeld in the CreateTransformJobRequest ,\\nAssembleWith  must be set accordingly. Please use the following table to help appropriately set these\\nﬁelds:\\nContentType Recommended SplitType\\napplication/x-recordio-protobuf RecordIO\\ntext/csv Line\\napplication/jsonlines Line\\napplication/json None\\napplication/x-image None\\nimage/* None\\nAccept Recommended AssembleWith\\napplication/x-recordio-protobuf None\\napplication/json None\\napplication/jsonlines Line\\nFor more information on response formats for speciﬁc algorithms, see the following:\\n•PCA Response Formats (p. 226)\\n•Linear Learner Response Formats (p. 175)\\n•NTM Response Formats (p. 182)\\n•K-Means Response Formats (p. 147)\\n•Factorization Machine Response Formats (p. 107)\\nInstance Types for Built-in Algorithms\\nFor training and hosting Amazon SageMaker algorithms, we recommend using the following EC2\\ninstance types:\\n•ml.m4.xlarge, ml.m4.4xlarge, and ml.m4.10xlarge\\n•ml.c4.xlarge, ml.c4.2xlarge, and ml.c4.8xlarge\\n•ml.p2.xlarge, ml.p2.8xlarge, and ml.p2.16xlarge\\nMost Amazon SageMaker algorithms have been engineered to take advantage of GPU computing for\\ntraining. Despite higher per-instance costs, GPUs train more quickly, making them more cost eﬀective.\\n72Amazon SageMaker Developer Guide\\nCommon Information\\nExceptions, such as XGBoost, are noted in this guide. (XGBoost implements an open-source algorithm\\nthat has been optimized for CPU computation.)\\nThe size and type of data can have a great eﬀect on which hardware conﬁguration is most eﬀective.\\nWhen the same model is trained on a recurring basis, initial testing across a spectrum of instance types\\ncan discover conﬁgurations that are more cost eﬀective in the long run. Additionally, algorithms that\\ntrain most eﬃciently on GPUs might not require GPUs for eﬃcient inference. Experiment to determine\\nthe most cost eﬀectiveness solution.\\nFor more information on Amazon SageMaker hardware speciﬁcations, see Amazon SageMaker ML\\nInstance Types.\\nLogs for Built-In Algorithms\\nAmazon SageMaker algorithms produce Amazon CloudWatch logs, which provide detailed information\\non the training process. To see the logs, in the AWS management console, choose CloudWatch, choose\\nLogs , and then choose the /aws/sagemaker/TrainingJobs log group. Each training job has one log\\nstream per node that it was trained on. The log stream’s name begins with the value speciﬁed in the\\nTrainingJobName  parameter when the job was created.\\nNote\\nIf a job fails and logs do not appear in CloudWatch, it\\'s likely that an error occurred before the\\nstart of training. Reasons include specifying the wrong training image or S3 location.\\nThe contents of logs vary by algorithms. However, you can typically ﬁnd the following information:\\n•Conﬁrmation of arguments provided at the beginning of the log\\n•Errors that occurred during training\\n•Measurement of an algorithms accuracy or numerical performance\\n•Timings for the algorithm, and any major stages within the algorithm\\nCommon Errors\\nIf a training job fails, some details about the failure are provided by the FailureReason  return value in\\nthe training job description, as follows:\\nsage = boto3.client(\\'sagemaker\\')\\nsage.describe_training_job(TrainingJobName=job_name)[\\'FailureReason\\']\\nOthers are reported only in the CloudWatch logs. Common errors include the following:\\n1.Misspecifying a hyperparameter or specifying a hyperparameter that is invalid for the algorithm.\\nFrom the CloudWatch Log:\\n[10/16/2017 23:45:17 ERROR 139623806805824 train.py:48] \\nAdditional properties are not allowed (u\\'mini_batch_siz\\' was \\nunexpected)\\n2.Specifying an invalid value for a hyperparameter.\\nFailureReason:\\nAlgorithmError: u\\'abc\\' is not valid under any of the given\\nschemas\\\\n\\\\nFailed validating u\\'oneOf\\' in\\nschema[u\\'properties\\'][u\\'feature_dim\\']:\\\\n    {u\\'oneOf\\':\\n[{u\\'pattern\\': u\\'^([1-9][0-9]*)$\\', u\\'type\\': u\\'string\\'},\\\\n\\n73Amazon SageMaker Developer Guide\\nBlazingText\\n{u\\'minimum\\': 1, u\\'type\\': u\\'integer\\'}]}\\\\\\nFailureReason:\\n[10/16/2017 23:57:17 ERROR 140373086025536 train.py:48] u\\'abc\\'\\nis not valid under any of the given schemas\\n3.Inaccurate protobuf ﬁle format.\\nFrom the CloudWatch log:\\n[10/17/2017 18:01:04 ERROR 140234860816192 train.py:48] cannot\\n                   copy sequence with size 785 to array axis with dimension 784\\nBlazingText Algorithm\\nThe Amazon SageMaker BlazingText algorithm provides highly optimized implementations of the\\nWord2vec and text classiﬁcation algorithms. The Word2vec algorithm is useful for many downstream\\nnatural language processing (NLP) tasks, such as sentiment analysis, named entity recognition, machine\\ntranslation, etc. Text classiﬁcation is an important task for applications that perform web searches,\\ninformation retrieval, ranking, and document classiﬁcation.\\nThe Word2vec algorithm maps words to high-quality distributed vectors. The resulting vector\\nrepresentation of a word is called a word embedding . Words that are semantically similar correspond to\\nvectors that are close together. That way, word embeddings capture the semantic relationships between\\nwords.\\nMany natural language processing (NLP) applications learn word embeddings by training on large\\ncollections of documents. These pretrained vector representations provide information about semantics\\nand word distributions that typically improves the generalizability of other models that are later trained\\non a more limited amount of data. Most implementations of the Word2vec algorithm are optimized for\\nmulti-core CPU architectures. This makes it diﬃcult to scale to large datasets.\\nWith the BlazingText algorithm, you can scale to large datasets easily. Similar to Word2vec, it\\nprovides the Skip-gram and continuous bag-of-words (CBOW) training architectures. BlazingText\\'s\\nimplementation of the supervised multi-class, multi-label text classiﬁcation algorithm extends the\\nfastText text classiﬁer to use GPU acceleration with custom CUDA  kernels. You can train a model on\\nmore than a billion words in a couple of minutes using a multi-core CPU or a GPU. And, you achieve\\nperformance on par with the state-of-the-art deep learning text classiﬁcation algorithms.\\nThe Amazon SageMaker BlazingText algorithms provides the following features:\\n•Accelerated training of the fastText text classiﬁer on multi-core CPUs or a GPU and Word2Vec on GPUs\\nusing highly optimized CUDA kernels. For more information, see BlazingText: Scaling and Accelerating\\nWord2Vec using Multiple GPUs.\\n•Enriched Word Vectors with Subword Information by learning vector representations for character n-\\ngrams. This approach enables BlazingText to generate meaningful vectors for out-of-vocabulary (OOV)\\nwords by representing their vectors as the sum of the character n-gram (subword) vectors.\\n•A batch_skipgram  mode for the Word2Vec algorithm that allows faster training and distributed\\ncomputation across multiple CPU nodes. The batch_skipgram  mode  does mini-batching using the\\nNegative Sample Sharing strategy to convert level-1 BLAS operations into level-3 BLAS operations.\\nThis eﬃciently leverages the multiply-add instructions of modern architectures. For more information,\\nsee Parallelizing Word2Vec in Shared and Distributed Memory.\\nTo summarize, the following modes are supported by BlazingText on diﬀerent types instances:\\n74Amazon SageMaker Developer Guide\\nBlazingText\\nModes Word2Vec\\n(Unsupervised Learning)Text Classiﬁcation\\n(Supervised Learning)\\nSingle CPU instance cbow\\nSkip-gram\\nBatch Skip-gramsupervised\\nSingle GPU instance (with 1 or\\nmore GPUs)cbow\\nSkip-gramsupervised  with one GPU\\nMultiple CPU instances Batch Skip-gram None\\nFor more information about the mathematics behind BlazingText, see BlazingText: Scaling and\\nAccelerating Word2Vec using Multiple GPUs.\\nTopics\\n•Input/Output Interface for the BlazingText Algorithm (p. 75)\\n•EC2 Instance Recommendation for the BlazingText Algorithm (p. 77)\\n•BlazingText Sample Notebooks (p. 78)\\n•BlazingText Hyperparameters (p. 78)\\n•Tune a BlazingText Model (p. 82)\\nInput/Output Interface for the BlazingText Algorithm\\nThe BlazingText algorithm expects a single preprocessed text ﬁle with space-separated tokens. Each line\\nin the ﬁle should contain a single sentence. If you need to train on multiple text ﬁles, concatenate them\\ninto one ﬁle and upload the ﬁle in the respective channel.\\nTraining and Validation Data Format\\nTraining and Validation Data Format for the Word2Vec Algorithm\\nFor Word2Vec training, upload the ﬁle under the train  channel. No other channels are supported. The ﬁle\\nshould contain a training sentence per line.\\nTraining and Validation Data Format for the Text Classiﬁcation Algorithm\\nFor supervised mode, you can train with ﬁle mode or with the augmented manifest text format.\\nTrain with File Mode\\nFor supervised  mode, the training/validation ﬁle should contain a training sentence per line along\\nwith the labels. Labels are words that are preﬁxed by the string __label__ . Here is an example of a\\ntraining/validation ﬁle:\\n__label__4  linux ready for prime time , intel says , despite all the linux hype , the\\n open-source movement has yet to make a huge splash in the desktop market . that may be\\n about to change , thanks to chipmaking giant intel corp .\\n__label__2  bowled by the slower one again , kolkata , november 14 the past caught up with\\n sourav ganguly as the indian skippers return to international cricket was short lived . \\n75Amazon SageMaker Developer Guide\\nBlazingText\\nNote\\nThe order of labels within the sentence doesn\\'t matter.\\nUpload the training ﬁle under the train channel, and optionally upload the validation ﬁle under the\\nvalidation channel.\\nTrain with Augmented Manifest Text Format\\nThe supervised mode also supports the augmented manifest format, which enables you to do training in\\npipe mode without needing to create RecordIO ﬁles. While using the format, an S3 manifest ﬁle needs to\\nbe generated that contains the list of sentences and their corresponding labels. The manifest ﬁle format\\nshould be in JSON Lines format in which each line represents one sample. The sentences are speciﬁed\\nusing the source  tag and the label can be speciﬁed using the label  tag. Both source  and label  tags\\nshould be provided under the AttributeNames  parameter value as speciﬁed in the request.\\n{\"source\":\"linux ready for prime time , intel says , despite all the linux hype\",\\n \"label\":1}\\n{\"source\":\"bowled by the slower one again , kolkata , november 14 the past caught up with\\n sourav ganguly\", \"label\":2}\\nFor more information on augmented manifest ﬁles, see Provide Dataset Metadata to Training Jobs with\\nan Augmented Manifest File  (p. 308).\\nModel Artifacts and Inference\\nModel Artifacts for the Word2Vec Algorithm\\nFor Word2Vec training, the model artifacts consist of vectors.txt, which contains words-to-vectors\\nmapping, and vectors.bin , a binary used by BlazingText for hosting, inference, or both. vectors.txt stores\\nthe vectors in a format that is compatible with other tools like Gensim and Spacy. For example, a Gensim\\nuser can run the following commands to load the vectors.txt ﬁle:\\nfrom gensim.models import KeyedVectors\\nword_vectors = KeyedVectors.load_word2vec_format(\\'vectors.txt\\', binary=False)\\nword_vectors.most_similar(positive=[\\'woman\\', \\'king\\'], negative=[\\'man\\'])\\nword_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split())\\nIf the evaluation parameter is set to True , an additional ﬁle, eval.json , is created. This ﬁle contains the\\nsimilarity evaluation results (using Spearman’s rank correlation coeﬃcients) on WS-353 dataset . The\\nnumber of words from the WS-353 dataset that aren\\'t there in the training corpus are reported.\\nFor inference requests, the model accepts a JSON ﬁle containing a list of strings and returns a list of\\nvectors. If the word is not found in vocabulary, inference returns a vector of zeros. If subwords is set to\\nTrue during training, the model is able to generate vectors for out-of-vocabulary (OOV) words.\\nSample JSON Request\\nMime-type: application/json\\n{\\n\"instances\": [\"word1\", \"word2\", \"word3\"]\\n}\\nModel Artifacts for the Text Classiﬁcation Algorithm\\nTraining with supervised outputs creates a model.bin  ﬁle that can be consumed by BlazingText hosting.\\nFor inference, the BlazingText model accepts a JSON ﬁle containing a list of sentences and returns a list\\nof corresponding predicted labels and probability scores. Each sentence is expected to be a string with\\nspace-separated tokens, words, or both.\\n76Amazon SageMaker Developer Guide\\nBlazingText\\nSample JSON Request\\nMime-type: application/json\\n{\\n \"instances\": [\"the movie was excellent\", \"i did not like the plot .\"]\\n}\\nBy default, the server returns only one prediction, the one with the highest probability. For retrieving the\\ntop k predictions, you can set k in the conﬁguration, as follows:\\n{\\n \"instances\": [\"the movie was excellent\", \"i did not like the plot .\"],\\n \"configuration\": {\"k\": 2}\\n}\\nFor BlazingText, the content-type  and accept parameters must be equal. For batch transform, they\\nboth need to be application/jsonlines . If they diﬀer, the Accept ﬁeld is ignored. The format for\\ninput follows:\\ncontent-type: application/jsonlines\\n{\"source\": \"source_0\"}\\n{\"source\": \"source_1\"}\\nif you need to pass the value of k for top-k, then you can do it in the following way:\\n{\"source\": \"source_0\", \"k\": 2}\\n{\"source\": \"source_1\", \"k\": 3}\\nThe format for output follows:\\naccept: application/jsonlines\\n{\"prob\": [prob_1], \"label\": [\"__label__1\"]}\\n{\"prob\": [prob_1], \"label\": [\"__label__1\"]}\\n                    \\nIf you have passed the value of k to be more than 1, then response will be in this format:\\n{\"prob\": [prob_1, prob_2], \"label\": [\"__label__1\", \"__label__2\"]}\\n{\"prob\": [prob_1, prob_2], \"label\": [\"__label__1\", \"__label__2\"]}\\nFor both supervised (text classiﬁcation) and unsupervised (Word2Vec) modes, the binaries (*.bin )\\nproduced by BlazingText can be cross-consumed by fastText and vice versa. You can use binaries\\nproduced by BlazingText by fastText. Likewise, you can host the model binaries created with fastText\\nusing BlazingText.\\nFor more details on dataset formats and model hosting, see the example notebooks Text Classiﬁcation\\nwith the BlazingText Algorithm, FastText Models, and Generating Subword Embeddings with the\\nWord2Vec Algorithm.\\nEC2 Instance Recommendation for the BlazingText Algorithm\\nFor cbow  and skipgram  modes, BlazingText supports single CPU and single GPU instances. Both\\nof these modes support learning of subwords  embeddings. To achieve the highest speed without\\ncompromising accuracy, we recommend that you use an ml.p3.2xlarge instance.\\nFor batch_skipgram  mode, BlazingText supports single or multiple CPU instances. When\\ntraining on multiple instances, set the value of the S3DataDistributionType  ﬁeld of the\\n77Amazon SageMaker Developer Guide\\nBlazingText\\nS3DataSource  (p. 994) object that you pass to CreateTrainingJob  (p. 667) to\\nFullyReplicated . BlazingText takes care of distributing data across machines.\\nFor the supervised text classiﬁcation mode, a C5 instance is recommended if the training dataset is less\\nthan 2 GB. For larger datasets, use an instance with a single GPU (ml.p2.xlarge or ml.p3.2xlarge).\\nBlazingText Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker BlazingText algorithm to train and deploy\\nsupervised binary and multiclass classiﬁcation models, see Blazing Text classiﬁcation on the DBPedia\\ndataset . For instructions for creating and accessing Jupyter notebook instances that you can use\\nto run the example in Amazon SageMaker, see Use Notebook Instances (p. 36). After creating and\\nopening a notebook instance, choose the SageMaker Examples tab to see a list of all the Amazon\\nSageMaker examples. The topic modeling example notebooks that use the Blazing Text are located in\\nthe Introduction to Amazon algorithms section. To open a notebook, choose its Use tab, then choose\\nCreate copy.\\nBlazingText Hyperparameters\\nWhen you start a training job with a CreateTrainingJob  request, you specify a training algorithm.\\nYou can also specify algorithm-speciﬁc hyperparameters as string-to-string maps. The hyperparameters\\nfor the BlazingText algorithm depend on which mode you use: Word2Vec (unsupervised) and Text\\nClassiﬁcation (supervised).\\nWord2Vec Hyperparameters\\nThe following table lists the hyperparameters for the BlazingText Word2Vec training algorithm provided\\nby Amazon SageMaker.\\nParameter Name Description\\nmode The Word2vec architecture used for training.\\nRequired\\nValid values: batch_skipgram , skipgram , or cbow\\nbatch_size The size of each batch when mode  is set to batch_skipgram . Set\\nto a number between 10 and 20.\\nOptional\\nValid values: Positive integer\\nDefault value: 11\\nbuckets The number of hash buckets to use for subwords.\\nOptional\\nValid values: positive integer\\nDefault value: 2000000\\nepochs The number of complete passes through the training data.\\nOptional\\nValid values: Positive integer\\n78Amazon SageMaker Developer Guide\\nBlazingText\\nParameter Name Description\\nDefault value: 5\\nevaluation Whether the trained model is evaluated using the\\nWordSimilarity-353 Test.\\nOptional\\nValid values: (Boolean) True  or False\\nDefault value: True\\nlearning_rate The step size used for parameter updates.\\nOptional\\nValid values: Positive ﬂoat\\nDefault value: 0.05\\nmin_char The minimum number of characters to use for subwords/character\\nn-grams.\\nOptional\\nValid values: positive integer\\nDefault value: 3\\nmin_count Words that appear less than min_count  times are discarded.\\nOptional\\nValid values: Non-negative integer\\nDefault value: 5\\nmax_char The maximum number of characters to use for subwords/character\\nn-grams\\nOptional\\nValid values: positive integer\\nDefault value: 6\\nnegative_samples The number of negative samples for the negative sample sharing\\nstrategy.\\nOptional\\nValid values: Positive integer\\nDefault value: 5\\n79Amazon SageMaker Developer Guide\\nBlazingText\\nParameter Name Description\\nsampling_threshold The threshold for the occurrence of words. Words that appear with\\nhigher frequency in the training data are randomly down-sampled.\\nOptional\\nValid values: Positive fraction. The recommended range is (0, 1e-3]\\nDefault value: 0.0001\\nsubwords Whether to learn subword embeddings on not.\\nOptional\\nValid values: (Boolean) True  or False\\nDefault value: False\\nvector_dim The dimension of the word vectors that the algorithm learns.\\nOptional\\nValid values: Positive integer\\nDefault value: 100\\nwindow_size The size of the context window. The context window is the number\\nof words surrounding the target word used for training.\\nOptional\\nValid values: Positive integer\\nDefault value: 5\\nText Classiﬁcation Hyperparameters\\nThe following table lists the hyperparameters for the Text Classiﬁcation training algorithm provided by\\nAmazon SageMaker.\\nNote\\nAlthough some of the parameters are common between the Text Classiﬁcation and Word2Vec\\nmodes, they might have diﬀerent meanings depending on the context.\\nParameter Name Description\\nmode The training mode.\\nRequired\\nValid values: supervised\\nbuckets The number of hash buckets to use for word n-grams.\\nOptional\\nValid values: Positive integer\\nDefault value: 2000000\\n80Amazon SageMaker Developer Guide\\nBlazingText\\nParameter Name Description\\nearly_stopping Whether to stop training if validation accuracy doesn\\'t improve\\nafter a patience  number of epochs.\\nOptional\\nValid values: (Boolean) True  or False\\nDefault value: False\\nepochs The maximum number of complete passes through the training\\ndata.\\nOptional\\nValid values: Positive integer\\nDefault value: 5\\nlearning_rate The step size used for parameter updates.\\nOptional\\nValid values: Positive ﬂoat\\nDefault value: 0.05\\nmin_count Words that appear less than min_count  times are discarded.\\nOptional\\nValid values: Non-negative integer\\nDefault value: 5\\nmin_epochs The minimum number of epochs to train before early stopping logic\\nis invoked.\\nOptional\\nValid values: Positive integer\\nDefault value: 5\\npatience The number of epochs to wait before applying early stopping\\nwhen no progress is made on the validation set. Used only when\\nearly_stopping  is True .\\nOptional\\nValid values: Positive integer\\nDefault value: 4\\n81Amazon SageMaker Developer Guide\\nBlazingText\\nParameter Name Description\\nvector_dim The dimension of the embedding layer.\\nOptional\\nValid values: Positive integer\\nDefault value: 100\\nword_ngrams The number of word n-gram features to use.\\nOptional\\nValid values: Positive integer\\nDefault value: 2\\nTune a BlazingText Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the BlazingText Algorithm\\nThe BlazingText Word2Vec algorithm (skipgram , cbow , and batch_skipgram  modes) reports on a\\nsingle metric during training: train:mean_rho . This metric is computed on WS-353 word similarity\\ndatasets . When tuning the hyperparameter values for the Word2Vec algorithm, use this metric as the\\nobjective.\\nThe BlazingText Text Classiﬁcation algorithm (supervised  mode), also reports on a single metric during\\ntraining: the validation:accuracy . When tuning the hyperparameter values for the text classiﬁcation\\nalgorithm, use these metrics as the objective.\\nMetric Name Description Optimization Direction\\ntrain:mean_rho The mean rho (Spearman\\'s rank correlation\\ncoeﬃcient) on WS-353 word similarity datasetsMaximize\\nvalidation:accuracy The classiﬁcation accuracy on the user-speciﬁed\\nvalidation datasetMaximize\\nTunable BlazingText Hyperparameters\\nTunable Hyperparameters for the Word2Vec Algorithm\\nTune an Amazon SageMaker BlazingText Word2Vec model with the following hyperparameters.\\nThe hyperparameters that have the greatest impact on Word2Vec objective metrics are: mode , \\nlearning_rate , window_size , vector_dim , and negative_samples .\\n82Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nParameter NameParameter Type Recommended Ranges\\nor Values\\nbatch_size IntegerParameterRange [8-32]\\nepochs IntegerParameterRange [5-15]\\nlearning_rate ContinuousParameterRange MinValue: 0.005,\\nMaxValue: 0.01\\nmin_count IntegerParameterRange [0-100]\\nmode CategoricalParameterRange [\\'batch_skipgram\\' ,\\n\\'skipgram\\' , \\'cbow\\' ]\\nnegative_samples IntegerParameterRange [5-25]\\nsampling_threshold ContinuousParameterRange MinValue: 0.0001,\\nMaxValue: 0.001\\nvector_dim IntegerParameterRange [32-300]\\nwindow_size IntegerParameterRange [1-10]\\nTunable Hyperparameters for the Text Classiﬁcation Algorithm\\nTune an Amazon SageMaker BlazingText text classiﬁcation model with the following hyperparameters.\\nParameter Name Parameter Type Recommended Ranges\\nor Values\\nbuckets IntegerParameterRange [1000000-10000000]\\nepochs IntegerParameterRange [5-15]\\nlearning_rate ContinuousParameterRange MinValue: 0.005,\\nMaxValue: 0.01\\nmin_count IntegerParameterRange [0-100]\\nmode CategoricalParameterRange [\\'supervised\\' ]\\nvector_dim IntegerParameterRange [32-300]\\nword_ngrams IntegerParameterRange [1-3]\\nDeepAR Forecasting Algorithm\\nThe Amazon SageMaker DeepAR forecasting algorithm is a supervised learning algorithm for forecasting\\nscalar (one-dimensional) time series using recurrent neural networks (RNN). Classical forecasting\\nmethods, such as autoregressive integrated moving average (ARIMA) or exponential smoothing (ETS),\\nﬁt a single model to each individual time series. They then use that model to extrapolate the time series\\ninto the future.\\nIn many applications, however, you have many similar time series across a set of cross-sectional units.\\nFor example, you might have time series groupings for demand for diﬀerent products, server loads, and\\nrequests for webpages. For this type of application, you can beneﬁt from training a single model jointly\\n83Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nover all of the time series. DeepAR takes this approach. When your dataset contains hundreds of related\\ntime series, DeepAR outperforms the standard ARIMA and ETS methods. You can also use the trained\\nmodel to generate forecasts for new time series that are similar to the ones it has been trained on.\\nThe training input for the DeepAR algorithm is one or, preferably, more target time series that have\\nbeen generated by the same process or similar processes. Based on this input dataset, the algorithm\\ntrains a model that learns an approximation of this process/processes and uses it to predict how the\\ntarget time series evolves. Each target time series can be optionally associated with a vector of static\\n(time-independent) categorical features provided by the cat ﬁeld and a vector of dynamic (time-\\ndependent) time series provided by the dynamic_feat  ﬁeld. Amazon SageMaker trains the DeepAR\\nmodel by randomly sampling training examples from each target time series in the training dataset. Each\\ntraining example consists of a pair of adjacent context and prediction windows with ﬁxed predeﬁned\\nlengths. To control how far in the past the network can see, use the context_length  hyperparameter.\\nTo control how far in the future predictions can be made, use the prediction_length  hyperparameter.\\nFor more information, see How the DeepAR Algorithm Works (p. 87).\\nTopics\\n•Input/Output Interface for the DeepAR Algorithm (p. 84)\\n•Best Practices for Using the DeepAR Algorithm (p. 86)\\n•EC2 Instance Recommendations for the DeepAR Algorithm (p. 87)\\n•DeepAR Sample Notebooks  (p. 87)\\n•How the DeepAR Algorithm Works (p. 87)\\n•DeepAR Hyperparameters  (p. 90)\\n•Tune a DeepAR Model (p. 94)\\n•DeepAR Inference Formats (p. 95)\\nInput/Output Interface for the DeepAR Algorithm\\nDeepAR supports two data channels. The required train  channel describes the training dataset. The\\noptional test channel describes a dataset that the algorithm uses to evaluate model accuracy after\\ntraining. You can provide training and test datasets in JSON Lines format. Files can be in gzip or Parquet\\nﬁle format.\\nWhen specifying the paths for the training and test data, you can specify a single ﬁle or a directory that\\ncontains multiple ﬁles, which can be stored in subdirectories. If you specify a directory, DeepAR uses all\\nﬁles in the directory as inputs for the corresponding channel, except those that start with a period (.) and\\nthose named _SUCCESS. This ensures that you can directly use output folders produced by Spark jobs as\\ninput channels for your DeepAR training jobs.\\nBy default, the DeepAR model determines the input format from the ﬁle extension (.json , .json.gz ,\\nor .parquet ) in the speciﬁed input path. If the path does not end in one of these extensions, you must\\nexplicitly specify the format in the SDK for Python. Use the content_type  parameter of the s3_input\\nclass.\\nThe records in your input ﬁles should contain the following ﬁelds:\\n•start —A string with the format YYYY-MM-DD HH:MM:SS . The start timestamp can\\'t contain time\\nzone information.\\n•target—An array of ﬂoating-point values or integers that represent the time series. You can encode\\nmissing values as null  literals, or as \"NaN\" strings in JSON, or as nan ﬂoating-point values in Parquet.\\n•dynamic_feat  (optional)—An array of arrays of ﬂoating-point values or integers that represents the\\nvector of custom feature time series (dynamic features). If you set this ﬁeld, all records must have the\\nsame number of inner arrays (the same number of feature time series). In addition, each inner array\\nmust have the same length as the associated target value. Missing values are not supported in the\\nfeatures. For example, if target time series represents the demand of diﬀerent products, an associated\\n84Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\ndynamic_feat  might be a boolean time-series which indicates whether a promotion was applied (1)\\nto the particular product or not (0):\\n{\"start\": ..., \"target\": [1, 5, 10, 2], \"dynamic_feat\": [[0, 1, 1, 0]]}\\n•cat (optional)—An array of categorical features that can be used to encode the groups that\\nthe record belongs to. Categorical features must be encoded as a 0-based sequence of positive\\nintegers. For example, the categorical domain {R, G, B} can be encoded as {0, 1, 2}. All values\\nfrom each categorical domain must be represented in the training dataset. That\\'s because the\\nDeepAR algorithm can forecast only for categories that have been observed during training.\\nAnd, each categorical feature is embedded in a low-dimensional space whose dimensionality is\\ncontrolled by the embedding_dimension  hyperparameter. For more information, see DeepAR\\nHyperparameters  (p. 90).\\nIf you use a JSON ﬁle, it must be in JSON Lines format. For example:\\n{\"start\": \"2009-11-01 00:00:00\", \"target\": [4.3, \"NaN\", 5.1, ...], \"cat\": [0, 1],\\n \"dynamic_feat\": [[1.1, 1.2, 0.5, ...]]}\\n{\"start\": \"2012-01-30 00:00:00\", \"target\": [1.0, -5.0, ...], \"cat\": [2, 3], \"dynamic_feat\":\\n [[1.1, 2.05, ...]]}\\n{\"start\": \"1999-01-30 00:00:00\", \"target\": [2.0, 1.0], \"cat\": [1, 4], \"dynamic_feat\":\\n [[1.3, 0.4]]}\\nIn this example, each time series has two associated categorical features and one time series features.\\nFor Parquet, you use the same three ﬁelds as columns. In addition, \"start\"  can be the datetime  type.\\nYou can compress Parquet ﬁles using gzip (gzip) or the Snappy compression library (snappy ).\\nIf the algorithm is trained without cat and dynamic_feat  ﬁelds, it learns a \"global\" model, that\\nis a model that is agnostic to the speciﬁc identity of the target time series at inference time and is\\nconditioned only on its shape.\\nIf the model is conditioned on the cat and dynamic_feat  feature data provided for each time series,\\nthe prediction will probably be inﬂuenced by the character of time series with the corresponding cat\\nfeatures. For example, if the target time series represents the demand of clothing items, you can\\nassociate a two-dimensional cat vector that encodes the type of item (e.g. 0 = shoes, 1 = dress) in the\\nﬁrst component and the color of an item (e.g. 0 = red, 1 = blue) in the second component. A sample input\\nwould look as follows:\\n{ \"start\": ..., \"target\": ..., \"cat\": [0, 0], ... } # red shoes\\n{ \"start\": ..., \"target\": ..., \"cat\": [1, 1], ... } # blue dress\\nAt inference time, you can request predictions for targets with cat values that are combinations of the\\ncat values observed in the training data, for example:\\n{ \"start\": ..., \"target\": ..., \"cat\": [0, 1], ... } # red dress\\n{ \"start\": ..., \"target\": ..., \"cat\": [1, 1], ... } # blue dress\\nThe following guidelines apply to training data:\\n•The start time and length of the time series can diﬀer. For example, in marketing, products often enter\\na retail catalog at diﬀerent dates, so their start dates naturally diﬀer. But all series must have the same\\nfrequency, number of categorical features, and number of dynamic features.\\n•Shuﬄe the training ﬁle with respect to the position of the time series in the ﬁle. In other words, the\\ntime series should occur in random order in the ﬁle.\\n•Make sure to set the start ﬁeld correctly. The algorithm uses the start timestamp to derive the\\ninternal features.\\n85Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\n•If you use categorical features (cat), all time series must have the same number of categorical\\nfeatures. If the dataset contains the cat ﬁeld, the algorithm uses it and extracts the cardinality of the\\ngroups from the dataset. By default, cardinality  is \"auto\". If the dataset contains the cat ﬁeld,\\nbut you don\\'t want to use it, you can disable it by setting cardinality  to \"\". If a model was trained\\nusing a cat feature, you must include it for inference.\\n•If your dataset contains the dynamic_feat  ﬁeld, the algorithm uses it automatically. All time series\\nhave to have the same number of feature time series. The time points in each of the feature time series\\ncorrespond one-to-one to the time points in the target. In addition, the entry in the dynamic_feat\\nﬁeld should have the same length as the target. If the dataset contains the dynamic_feat  ﬁeld, but\\nyou don\\'t want to use it, disable it by setting(num_dynamic_feat  to \"\"). If the model was trained\\nwith the dynamic_feat  ﬁeld, you must provide this ﬁeld for inference. In addition, each of the\\nfeatures has to have the length of the provided target plus the prediction_length . In other words,\\nyou must provide the feature value in the future.\\nIf you specify optional test channel data, the DeepAR algorithm evaluates the trained model with\\ndiﬀerent accuracy metrics. The algorithm calculates the root mean square error (RMSE) over the test data\\nas follows:\\nyi,t is the true value of time series i at the time t. ŷi,t is the mean prediction. The sum is over all n time\\nseries in the test set and over the last Τ time points for each time series, where Τ corresponds to the\\nforecast horizon. You specify the length of the forecast horizon by setting the prediction_length\\nhyperparameter. For more information, see DeepAR Hyperparameters  (p. 90).\\nIn addition, the algorithm evaluates the accuracy of the forecast distribution using weighted quantile\\nloss. For a quantile in the range [0, 1], the weighted quantile loss is deﬁned as follows:\\nqi,t(τ) is the τ-quantile of the distribution that the model predicts. To specify which quantiles to\\ncalculate loss for, set the test_quantiles  hyperparameter. In addition to these, the average of\\nthe prescribed quantile losses is reported as part of the training logs. For information, see DeepAR\\nHyperparameters  (p. 90).\\nFor inference, DeepAR accepts JSON format and the following ﬁelds:\\n•\"instances\" , which includes one or more time series in JSON Lines format\\n•A name of \"configuration\" , which includes parameters for generating the forecast\\nFor more information, see DeepAR Inference Formats (p. 95).\\nBest Practices for Using the DeepAR Algorithm\\nWhen preparing your time series data, follow these best practices to achieve the best results:\\n•Except for when splitting your dataset for training and testing, always provide the entire time\\nseries for training, testing, and when calling the model for inference. Regardless of how you set\\ncontext_length , don\\'t break up the time series or provide only a part of it. The model uses data\\npoints further back than the value set in context_length  for the lagged values feature.\\n86Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\n•When tuning a DeepAR model, you can split the dataset to create a training dataset and a test dataset.\\nIn a typical evaluation, you would test the model on the same time series used for training, but\\non the future prediction_length  time points that follow immediately after the last time point\\nvisible during training. You can create training and test datasets that satisfy this criteria by using the\\nentire dataset (the full length of all time series that are available) as a test set and removing the last\\nprediction_length  points from each time series for training. During training, the model doesn\\'t see\\nthe target values for time points on which it is evaluated during testing. During testing, the algorithm\\nwithholds the last prediction_length  points of each time series in the test set and generates a\\nprediction. Then it compares the forecast with the withheld values. You can create more complex\\nevaluations by repeating time series multiple times in the test set, but cutting them at diﬀerent\\nendpoints. With this approach, accuracy metrics are averaged over multiple forecasts from diﬀerent\\ntime points. For more information, see Tune a DeepAR Model (p. 94).\\n•Avoid using very large values (>400) for the prediction_length  because it makes the model slow\\nand less accurate. If you want to forecast further into the future, consider aggregating your data at a\\nhigher frequency. For example, use 5min  instead of 1min .\\n•Because lags are used, a model can look further back in the time series than the value speciﬁed for\\ncontext_length . Therefore, you don\\'t need to set this parameter to a large value. We recommend\\nstarting with the value that you used for prediction_length .\\n•We recommend training a DeepAR model on as many time series as are available. Although a DeepAR\\nmodel trained on a single time series might work well, standard forecasting algorithms, such as ARIMA\\nor ETS, might provide more accurate results. The DeepAR algorithm starts to outperform the standard\\nmethods when your dataset contains hundreds of related time series. Currently, DeepAR requires that\\nthe total number of observations available across all training time series is at least 300.\\nEC2 Instance Recommendations for the DeepAR Algorithm\\nYou can train DeepAR on both GPU and CPU instances and in both single and multi-machine settings.\\nWe recommend starting with a single CPU instance (for example, ml.c4.2xlarge or ml.c4.4xlarge), and\\nswitching to GPU instances and multiple machines only when necessary. Using GPUs and multiple\\nmachines improves throughput only for larger models (with many cells per layer and many layers) and\\nfor large mini-batch sizes (for example, greater than 512).\\nFor inference, DeepAR supports only CPU instances.\\nSpecifying large values for context_length , prediction_length , num_cells , num_layers , or\\nmini_batch_size  can create models that are too large for small instances. In this case, use a larger\\ninstance type or reduce the values for these parameters. This problem also frequently occurs when\\nrunning hyperparameter tuning jobs. In that case, use an instance type large enough for the model\\ntuning job and consider limiting the upper values of the critical parameters to avoid job failures.\\nDeepAR Sample Notebooks\\nFor a sample notebook that shows how to prepare a time series dataset for training the Amazon\\nSageMaker DeepAR algorithm and how to deploy the trained model for performing inferences, see Time\\nseries forecasting with DeepAR - Synthetic data as well as DeepAR demo on electricity dataset, which\\nillustrates the advanced features of DeepAR on a real world dataset. For instructions on creating and\\naccessing Jupyter notebook instances that you can use to run the example in Amazon SageMaker, see\\nUse Notebook Instances (p. 36). After creating and opening a notebook instance, choose the SageMaker\\nExamples tab to see a list of all of the Amazon SageMaker examples. To open a notebook, choose its Use\\ntab, and choose Create copy.\\nHow the DeepAR Algorithm Works\\nDuring training, DeepAR accepts a training dataset and an optional test dataset. It uses the test dataset\\nto evaluate the trained model. In general, the datasets don\\'t have to contain the same set of time series.\\n87Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nYou can use a model trained on a given training set to generate forecasts for the future of the time series\\nin the training set, and for other time series. Both the training and the test datasets consist of one or,\\npreferably, more target time series. Each target time series can optionally be associated with a vector\\nof feature time series and a vector of categorical features. For more information, see Input/Output\\nInterface for the DeepAR Algorithm (p. 84).\\nFor example, the following is an element of a training set indexed by i which consists of a target time\\nseries, Zi,t, and two associated feature time series, Xi,1,t and Xi,2,t:\\nThe target time series might contain missing values, which are represented by line breaks in the time\\nseries. DeepAR supports only feature time series that are known in the future. This allows you to run\\n\"what if?\" scenarios. What happens, for example, if I change the price of a product in some way?\\nEach target time series can also be associated with a number of categorical features. You can use these\\nfeatures to encode which groupings a time series belongs to. Categorical features allow the model to\\nlearn typical behavior for groups, which it can use to increase model accuracy. DeepAR implements this\\nby learning an embedding vector for each group that captures the common properties of all time series\\nin the group.\\nHow Feature Time Series Work in the DeepAR Algorithm\\nTo facilitate learning time-dependent patterns, such as spikes during weekends, DeepAR automatically\\ncreates feature time series based on the frequency of the target time series. For example, DeepAR creates\\ntwo feature time series (day of the month and day of the year) for a weekly time series frequency. It uses\\nthese derived feature time series with the custom feature time series that you provide during training\\nand inference. The following ﬁgure shows two of these derived time series features: ui,1,t represents the\\nhour of the day and ui,2,t the day of the week.\\n88Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nThe DeepAR algorithm automatically generates these feature time series. The following table lists the\\nderived features for the supported basic time frequencies.\\nFrequency of the Time Series Derived Features\\nMinute minute-of-hour , hour-of-day , day-of-week , day-of-month ,\\nday-of-year\\nHour hour-of-day , day-of-week , day-of-month , day-of-year\\nDay day-of-week , day-of-month , day-of-year\\nWeek day-of-month , week-of-year\\nMonth month-of-year\\nDeepAR trains a model by randomly sampling several training examples from each of the time series\\nin the training dataset. Each training example consists of a pair of adjacent context and prediction\\nwindows with ﬁxed predeﬁned lengths. The context_length  hyperparameter controls how far in the\\npast the network can see, and the prediction_length  hyperparameter controls how far in the future\\npredictions can be made. During training, the algorithm ignores training set elements containing time\\nseries that are shorter than a speciﬁed prediction length. The following ﬁgure represents ﬁve samples\\nwith context lengths of 12 hours and prediction lengths of 6 hours drawn from element i. For brevity,\\nwe\\'ve omitted the feature time series xi,1,t and ui,2,t.\\nTo capture seasonality patterns, DeepAR also automatically feeds lagged values from the target time\\nseries. In the example with hourly frequency, for each time index, t = T , the model exposes the zi,t values,\\nwhich occurred approximately one, two, and three days in the past.\\n89Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nFor inference, the trained model takes as input target time series, which might or might not have been\\nused during training, and forecasts a probability distribution for the next prediction_length  values.\\nBecause DeepAR is trained on the entire dataset, the forecast takes into account patterns learned from\\nsimilar time series.\\nFor information on the mathematics behind DeepAR, see DeepAR: Probabilistic Forecasting with\\nAutoregressive Recurrent Networks.\\nDeepAR Hyperparameters\\nParameter Name Description\\ncontext_length The number of time-points that the model gets to see before\\nmaking the prediction. The value for this parameter should be\\nabout the same as the\\xa0 prediction_length . The model also\\nreceives lagged inputs from the target, so context_length \\xa0can be\\nmuch smaller than typical seasonalities. For example, a daily time\\nseries can have yearly seasonality. The model automatically includes\\na lag of one year, so the context length can be shorter than a year.\\nThe lag values that the model picks depend on the frequency of the\\ntime series. For example, lag values for daily frequency are previous\\nweek, 2 weeks, 3 weeks, 4 weeks, and year.\\nRequired\\nValid values: Positive integer\\nepochs The maximum number of passes over the training data. The\\noptimal value depends on your data size and learning rate. See also\\nearly_stopping_patience . Typical values range from 10 to\\n1000.\\nRequired\\nValid values: Positive integer\\nprediction_length The number of time-steps that the model is trained to predict, also\\ncalled the forecast horizon. The trained model always generates\\nforecasts with this length. It can\\'t generate longer forecasts. The\\nprediction_length  is ﬁxed when a model is trained and it\\ncannot be changed later.\\n90Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nParameter Name Description\\nRequired\\nValid values: Positive integer\\ntime_freq The granularity of the time series in the dataset. Use time_freq  to\\nselect appropriate date features and lags. The model supports the\\nfollowing basic frequencies. It also supports multiples of these basic\\nfrequencies. For example, 5min speciﬁes a frequency of 5 minutes.\\n•M: monthly\\n•W: weekly\\n•D: daily\\n•H: hourly\\n•min: every minute\\nRequired\\nValid values: An integer followed by M, W,\\xa0D,\\xa0H, or min. For\\nexample, 5min .\\ncardinality When using the categorical features (cat), cardinality  is an\\narray specifying the number of categories (groups) per categorical\\nfeature. Set this to auto to infer the cardinality from the data. The\\nauto mode also works when no categorical features are used in the\\ndataset. This is the recommended setting for the parameter.\\nSet cardinality to ignore to force DeepAR to not use categorical\\nfeatures, even it they are present in the data.\\nTo perform additional data validation, it is possible to explicitly set\\nthis parameter to the actual value. For example, if two categorical\\nfeatures are provided where the ﬁrst has 2 and the other has 3\\npossible values, set this to [2, 3].\\nFor more information on how to use categorical feature, see the\\ndata-section on the main documentation page of DeepAR.\\nOptional\\nValid values: auto , ignore, array of positive integers, empty string,\\nor\\nDefault value: auto\\ndropout_rate The dropout rate to use during training. The model uses zoneout\\nregularization. For each iteration, a random subset of hidden\\nneurons are not updated. Typical values are less than 0.2.\\nOptional\\nValid values: ﬂoat\\nDefault value: 0.1\\n91Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nParameter Name Description\\nearly_stopping_patience If this parameter is set, training stops when no progress is made\\nwithin the speciﬁed number of epochs . The model that has the\\nlowest loss is returned as the ﬁnal model.\\nOptional\\nValid values: integer\\nembedding_dimension Size of embedding vector learned per categorical feature (same\\nvalue is used for all categorical features).\\nThe DeepAR model can learn group-level time series patterns when\\na categorical grouping feature is provided. To do this, the model\\nlearns an embedding vector of size embedding_dimension  for\\neach group, capturing the common properties of all time series in\\nthe group. A larger embedding_dimension  allows the model to\\ncapture more complex patterns. However, because increasing the\\nembedding_dimension  increases the number of parameters in\\nthe model, more training data is required to accurately learn these\\nparameters. Typical values for this parameter are between 10-100.\\nOptional\\nValid values: positive integer\\nDefault value: 10\\nlearning_rate The learning rate used in training. Typical values range from 1e-4 to\\n1e-1.\\nOptional\\nValid values: ﬂoat\\nDefault value: 1e-3\\n92Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nParameter Name Description\\nlikelihood The model generates a probabilistic forecast, and can provide\\nquantiles of the distribution and return samples. Depending on\\nyour data, select an appropriate likelihood (noise model) that is\\nused for uncertainty estimates. The following likelihoods can be\\nselected:\\n•gaussian : Use for real-valued data.\\n•beta: Use for real-valued targets between 0 and 1 inclusive.\\n•negative-binomial : Use for count data (non-negative integers).\\n•student-T : An alternative for real-valued data that works well for\\nbursty data.\\n•deterministic-L1 : A loss function that does not estimate\\nuncertainty and only learns a point forecast.\\nOptional\\nValid values: One of gaussian , beta, negative-binomial , student-T , or\\ndeterministic-L1 .\\nDefault value: student-T\\nmini_batch_size The size of mini-batches used during training. Typical values range\\nfrom 32 to 512.\\nOptional\\nValid values: positive integer\\nDefault value: 128\\nnum_cells The number of cells to use in each hidden layer of the RNN. Typical\\nvalues range from 30 to 100.\\nOptional\\nValid values: positive integer\\nDefault value: 40\\nnum_dynamic_feat The number of dynamic_feat  provided in the data. Set this to\\nauto to infer the number of dynamic features from the data. The\\nauto mode also works when no dynamic features are used in the\\ndataset. This is the recommended setting for the parameter.\\nTo force DeepAR to not use dynamic features, even it they are\\npresent in the data, set num_dynamic_feat  to ignore .\\nTo perform additional data validation, it is possible to explicitly\\nset this parameter to the actual integer value. For example, if two\\ndynamic features are provided, set this to 2.\\nOptional\\nValid values: auto , ignore, positive integer, or empty string\\nDefault value: auto\\n93Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nParameter Name Description\\nnum_eval_samples The number of samples that are used per time-series when\\ncalculating test accuracy metrics. This parameter does not have any\\ninﬂuence on the training or the ﬁnal model. In particular, the model\\ncan be queried with a diﬀerent number of samples. This parameter\\nonly aﬀects the reported accuracy scores on the test channel after\\ntraining. Smaller values result in faster evaluation, but then the\\nevaluation scores are typically worse and more uncertain. When\\nevaluating with higher quantiles, for example 0.95, it may be\\nimportant to increase the number of evaluation samples.\\nOptional\\nValid values: integer\\nDefault value: 100\\nnum_layers The number of hidden layers in the RNN. Typical values range from\\n1 to 4.\\nOptional\\nValid values: positive integer\\nDefault value: 2\\ntest_quantiles Quantiles for which to calculate quantile loss on the test channel.\\nOptional\\nValid values: array of ﬂoats\\nDefault value: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\\nTune a DeepAR Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the DeepAR Algorithm\\nThe DeepAR algorithm reports three metrics, which are computed during training. When tuning a model,\\nchoose one of these as the objective. For the objective, use either the forecast accuracy on a provided\\ntest channel (recommended) or the training loss. For recommendations for the training/test split for the\\nDeepAR algorithm, see  Best Practices for Using the DeepAR Algorithm (p. 86).\\nMetric Name Description Optimization Direction\\ntest:RMSE The root mean square error between the forecast\\nand the actual target computed on the test set.Minimize\\n94Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nMetric Name Description Optimization Direction\\ntest:mean_wQuantileLoss The average overall quantile losses computed on\\nthe test set. To control which quantiles are used,\\nset the test_quantiles  hyperparameter.Minimize\\ntrain:final_loss The training negative log-likelihood loss averaged\\nover the last training epoch for the model.Minimize\\nTunable Hyperparameters for the DeepAR Algorithm\\nTune a DeepAR model with the following hyperparameters. The hyperparameters that have the greatest\\nimpact, listed in order from the most to least impactful, on DeepAR objective metrics are: epochs ,\\ncontext_length , mini_batch_size , learning_rate , and num_cells .\\nParameter Name Parameter Type Recommended Ranges\\nmini_batch_size IntegerParameterRanges MinValue: 32,\\nMaxValue: 1028\\nepochs IntegerParameterRanges MinValue: 1, MaxValue:\\n1000\\ncontext_length IntegerParameterRanges MinValue: 1, MaxValue:\\n200\\nnum_cells IntegerParameterRanges MinValue: 30,\\nMaxValue: 200\\nnum_layers IntegerParameterRanges MinValue: 1, MaxValue:\\n8\\ndropout_rate ContinuousParameterRange MinValue: 0.00,\\nMaxValue: 0.2\\nembedding_dimension IntegerParameterRanges MinValue: 1, MaxValue:\\n50\\nlearning_rate ContinuousParameterRange MinValue: 1e-5,\\nMaxValue: 1e-1\\nDeepAR Inference Formats\\nDeepAR JSON Request Formats\\nQuery a trained model by using the model\\'s endpoint. The endpoint takes the following JSON request\\nformat.\\nIn the request, the instances  ﬁeld corresponds to the time series that should be forecast by the model.\\nIf the model was trained with categories, you must provide a cat for each instance. If the model was\\ntrained without the cat ﬁeld, it should be omitted.\\nIf the model was trained with a custom feature time series (dynamic_feat ), you have to provide the\\nsame number of dynamic_feat values for each instance. Each of them should have a length given by\\nlength(target) + prediction_length , where the last prediction_length  values correspond to\\n95Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\nthe time points in the future that will be predicted. If the model was trained without custom feature time\\nseries, the ﬁeld should not be included in the request.\\n{\\n    \"instances\": [\\n        {\\n            \"start\": \"2009-11-01 00:00:00\",\\n            \"target\": [4.0, 10.0, \"NaN\", 100.0, 113.0],\\n            \"cat\": [0, 1],\\n            \"dynamic_feat\": [[1.0, 1.1, 2.1, 0.5, 3.1, 4.1, 1.2, 5.0, ...]]\\n        },\\n        {\\n            \"start\": \"2012-01-30\",\\n            \"target\": [1.0],\\n            \"cat\": [2, 1],\\n            \"dynamic_feat\": [[2.0, 3.1, 4.5, 1.5, 1.8, 3.2, 0.1, 3.0, ...]]\\n        },\\n        {\\n            \"start\": \"1999-01-30\",\\n            \"target\": [2.0, 1.0],\\n            \"cat\": [1, 3],\\n            \"dynamic_feat\": [[1.0, 0.1, -2.5, 0.3, 2.0, -1.2, -0.1, -3.0, ...]]\\n        }\\n    ],\\n    \"configuration\": {\\n         \"num_samples\": 50,\\n         \"output_types\": [\"mean\", \"quantiles\", \"samples\"],\\n         \"quantiles\": [\"0.5\", \"0.9\"]\\n    }\\n}\\nThe configuration  ﬁeld is optional. configuration.num_samples  sets the number of sample\\npaths that the model generates to estimate the mean and quantiles. configuration.output_types\\ndescribes the information that will be returned in the request. Valid values are \"mean\"\\n\"quantiles\"  and \"samples\" . If you specify \"quantiles\" , each of the quantile values in\\nconfiguration.quantiles  is returned as a time series. If you specify \"samples\" , the model also\\nreturns the raw samples used to calculate the other outputs.\\nDeepAR JSON Response Formats\\nThe following is the format of a response, where [...] are arrays of numbers:\\n{\\n    \"predictions\": [\\n        {\\n            \"quantiles\": {\\n                \"0.9\": [...],\\n                \"0.5\": [...]\\n            },\\n            \"samples\": [...],\\n            \"mean\": [...]\\n        },\\n        {\\n            \"quantiles\": {\\n                \"0.9\": [...],\\n                \"0.5\": [...]\\n            },\\n            \"samples\": [...],\\n            \"mean\": [...]\\n        },\\n        {\\n            \"quantiles\": {\\n                \"0.9\": [...],\\n96Amazon SageMaker Developer Guide\\nDeepAR Forecasting\\n                \"0.5\": [...]\\n            },\\n            \"samples\": [...],\\n            \"mean\": [...]\\n        }\\n    ]\\n}\\nDeepAR has a response timeout of 60 seconds. When passing multiple time series in a single request,\\nthe forecasts are generated sequentially. Because the forecast for each time series typically takes about\\n300 to 1000 milliseconds or longer, depending on the model size, passing too many time series in a\\nsingle request can cause time outs. It\\'s better to send fewer time series per request and send more\\nrequests. Because the DeepAR algorithm uses multiple workers per instance, you can achieve much\\nhigher throughput by sending multiple requests in parallel.\\nBy default, DeepAR uses one worker per CPU for inference, if there is suﬃcient memory per CPU. If the\\nmodel is large and there isn\\'t enough memory to run a model on each CPU, the number of workers is\\nreduced. The number of workers used for inference can be overwritten using the environment variable\\nMODEL_SERVER_WORKERS  For example, by setting MODEL_SERVER_WORKERS=1 ) when calling the\\nAmazon SageMaker CreateModel (p. 648) API.\\nBatch Transform with the DeepAR Algorithm\\nDeepAR forecasting supports getting inferences by using batch transform from data using the JSON\\nLines format. In this format, each record is represented on a single line as a JSON object, and lines\\nare separated by newline characters. The format is identical to the JSON Lines format used for model\\ntraining. For information, see Input/Output Interface for the DeepAR Algorithm (p. 84). For example:\\n{\"start\": \"2009-11-01 00:00:00\", \"target\": [4.3, \"NaN\", 5.1, ...], \"cat\": [0, 1],\\n \"dynamic_feat\": [[1.1, 1.2, 0.5, ..]]}\\n{\"start\": \"2012-01-30 00:00:00\", \"target\": [1.0, -5.0, ...], \"cat\": [2, 3], \"dynamic_feat\":\\n [[1.1, 2.05, ...]]}\\n{\"start\": \"1999-01-30 00:00:00\", \"target\": [2.0, 1.0], \"cat\": [1, 4], \"dynamic_feat\":\\n [[1.3, 0.4]]}\\nNote\\nWhen creating the transformation job with CreateTransformJob (p. 673), set the\\nBatchStrategy  value to SingleRecord  and set the SplitType  value in the\\nTransformInput (p. 1024 ) conﬁguration to Line, as the default values currently cause runtime\\nfailures.\\nSimilar to the hosted endpoint inference request format, the cat and the dynamic_feat  ﬁelds for each\\ninstance are required if both of the following are true:\\n•The model is trained on a dataset that contained both the cat and the dynamic_feat  ﬁelds.\\n•The corresponding cardinality  and num_dynamic_feat  values used in the training job are not set\\nto \"\".\\nUnlike hosted endpoint inference, the conﬁguration ﬁeld is set once for the entire batch\\ninference job using an environment variable named DEEPAR_INFERENCE_CONFIG . The\\nvalue of DEEPAR_INFERENCE_CONFIG  can be passed when the model is created by calling\\nCreateTransformJob (p. 673) API. If DEEPAR_INFERENCE_CONFIG  is missing in the container\\nenvironment, the inference container uses the following default:\\n{\\n    \"num_samples\": 100,\\n    \"output_types\": [\"mean\", \"quantiles\"],\\n97Amazon SageMaker Developer Guide\\nFactorization Machines\\n    \"quantiles\": [\"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\", \"0.7\", \"0.8\", \"0.9\"]\\n}\\nThe output is also in JSON Lines format, with one line per prediction, in an order identical to the instance\\norder in the corresponding input ﬁle. Predictions are encoded as objects identical to the ones returned by\\nresponses in online inference mode. For example:\\n{ \"quantiles\": { \"0.1\": [...], \"0.2\": [...] }, \"samples\": [...], \"mean\": [...] }\\nNote that in the TransformInput (p. 1024 ) conﬁguration of the Amazon SageMaker\\nCreateTransformJob (p. 673) request clients must explicitly set the AssembleWith  value to Line , as\\nthe default value None concatenates all JSON objects on the same line.\\nFor example, here is an Amazon SageMaker CreateTransformJob (p. 673) request for a DeepAR job with\\na custom DEEPAR_INFERENCE_CONFIG :\\n{\\n   \"BatchStrategy\": \"SingleRecord\",\\n   \"Environment\": { \\n      \"DEEPAR_INFERENCE_CONFIG\" : \"{ \\\\\"num_samples\\\\\": 200, \\\\\"output_types\\\\\": [\\\\\"mean\\\\\"] }\",\\n      ...\\n   },\\n   \"TransformInput\": {\\n      \"SplitType\": \"Line\",\\n      ...\\n   },\\n   \"TransformOutput\": { \\n      \"AssembleWith\": \"Line\",\\n      ...\\n   },\\n   ...\\n}\\nFactorization Machines Algorithm\\nA factorization machine is a general-purpose supervised learning algorithm that you can use for both\\nclassiﬁcation and regression tasks. It is an extension of a linear model that is designed to capture\\ninteractions between features within high dimensional sparse datasets economically. For example, in\\na click prediction system, the factorization machine model can capture click rate patterns observed\\nwhen ads from a certain ad-category are placed on pages from a certain page-category. Factorization\\nmachines are a good choice for tasks dealing with high dimensional sparse datasets, such as click\\nprediction and item recommendation.\\nNote\\nThe Amazon SageMaker implementation of factorization machines considers only pair-wise (2nd\\norder) interactions between features.\\nTopics\\n•Input/Output Interface for the Factorization Machines Algorithm (p. 99)\\n•EC2 Instance Recommendation for the Factorization Machines Algorithm (p. 99)\\n•Factorization Machines Sample Notebooks (p. 99)\\n•How Factorization Machines Work (p. 99)\\n•Factorization Machines Hyperparameters (p. 100)\\n•Tune a Factorization Machines Model (p. 105)\\n•Factorization Machine Response Formats (p. 107)\\n98Amazon SageMaker Developer Guide\\nFactorization Machines\\nInput/Output Interface for the Factorization Machines\\nAlgorithm\\nThe factorization machine algorithm can be run in either in binary classiﬁcation mode or regression\\nmode. In each mode, a dataset can be provided to the test channel along with the train channel dataset.\\nThe scoring depends on the mode used. In regression mode, the testing dataset is scored using Root\\nMean Square Error (RMSE). In binary classiﬁcation mode, the test dataset is scored using Binary Cross\\nEntropy (Log Loss), Accuracy (at threshold=0.5) and F1 Score (at threshold =0.5).\\nFor training , the factorization machines algorithm currently supports only the recordIO-protobuf\\nformat with Float32 tensors. Because their use case is predominantly on sparse data, CSV is not a good\\ncandidate. Both File and Pipe mode training are supported for recordIO-wrapped protobuf.\\nFor inference, factorization machines support the application/json  and x-recordio-protobuf\\nformats.\\n•For the binary classiﬁcation problem, the algorithm predicts a score and a label. The label is a number\\nand can be either 0 or 1. The score is a number that indicates how strongly the algorithm believes that\\nthe label should be 1. The algorithm computes score ﬁrst and then derives the label from the score\\nvalue. If the score is greater than or equal to 0.5, the label is 1.\\n•For the regression  problem, just a score is returned and it is the predicted value. For example, if\\nFactorization Machines is used to predict a movie rating, score is the predicted rating value.\\nPlease see Factorization Machines Sample Notebooks (p. 99) for more details on training and\\ninference ﬁle formats.\\nEC2 Instance Recommendation for the Factorization Machines\\nAlgorithm\\nThe Amazon SageMaker Factorization Machines algorithm is highly scalable and can train across\\ndistributed instances. We recommend training and inference with CPU instances for both sparse and\\ndense datasets. In some circumstances, training with one or more GPUs on dense data might provide\\nsome beneﬁt. Training with GPUs is available only on dense data. Use CPU instances for sparse data.\\nFactorization Machines Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker factorization machine learning algorithm to\\nanalyze the images of handwritten digits from zero to nine in the MNIST dataset, see An Introduction\\nto Factorization Machines with MNIST. For instructions how to create and access Jupyter notebook\\ninstances that you can use to run the example in Amazon SageMaker, see Use Notebook Instances (p. 36).\\nOnce you have created a notebook instance and opened it, select the SageMaker Examples tab to see\\na list of all the Amazon SageMaker samples. The topic modeling example notebooks using the NTM\\nalgorithms are located in the Introduction to Amazon algorithms section. To open a notebook, click on\\nits Use tab and select Create copy.\\nHow Factorization Machines Work\\nThe prediction task for a factorization machine model is to estimate a function ŷ from a feature set xi to\\na target domain. This domain is real-valued for regression and binary for classiﬁcation. The factorization\\nmachine model is supervised and so has a training dataset (xi,yj) available. The advantages this model\\npresents lie in the way it uses a factorized parametrization to capture the pairwise feature interactions. It\\ncan be represented mathematically as follows:\\n99Amazon SageMaker Developer Guide\\nFactorization Machines\\nThe three terms in this equation correspond respectively to the three components of the model:\\n•The w 0 term represents the global bias.\\n•The w i linear terms model the strength of the ith variable.\\n•The <v i,vj> factorization terms model the pairwise interaction between the ith and jth variable.\\nThe global bias and linear terms are the same as in a linear model. The pairwise feature interactions\\nare modeled in the third term as the inner product of the corresponding factors learned for each\\nfeature. Learned factors can also be considered as embedding vectors for each feature. For example, in\\na classiﬁcation task, if a pair of features tends to co-occur more often in positive labeled samples, then\\nthe inner product of their factors would be large. In other words, their embedding vectors would be\\nclose to each other in cosine similarity. For more information about the factorization machine model, see\\nFactorization Machines.\\nFor regression tasks, the model is trained by minimizing the squared error between the model prediction\\nŷn and the target value yn. This is known as the square loss:\\nFor a classiﬁcation task, the model is trained by minimizing the cross entropy loss, also known as the log\\nloss:\\nwhere:\\nFor more information about loss functions for classiﬁcation, see Loss functions for classiﬁcation.\\nFactorization Machines Hyperparameters\\nThe following table contains the hyperparameters for the factorization machines algorithm. These\\nare parameters that are set by users to facilitate the estimation of model parameters from data.\\nThe required hyperparameters that must be set are listed ﬁrst, in alphabetical order. The optional\\nhyperparameters that can be set are listed next, also in alphabetical order.\\nParameter Name Description\\nfeature_dim The dimension of the input feature space. This could be very high\\nwith sparse input.\\nRequired\\nValid values: Positive integer. Suggested value range:\\n[10000,10000000]\\nnum_factors The dimensionality of factorization.\\nRequired\\nValid values: Positive integer. Suggested value range: [2,1000], 64 is\\nusually optimal.\\n100Amazon SageMaker Developer Guide\\nFactorization Machines\\nParameter Name Description\\npredictor_type The type of predictor.\\n•binary_classifier : For binary classiﬁcation tasks.\\n•regressor : For regression tasks.\\nRequired\\nValid values: String: binary_classifier  or regressor\\nbias_init_method The initialization method for the bias term:\\n•normal: Initializes weights with random values sampled from a\\nnormal distribution with a mean of zero and standard deviation\\nspeciﬁed by bias_init_sigma .\\n•uniform: Initializes weights with random values uniformly\\nsampled from a range speciﬁed by [-bias_init_scale ,\\n+bias_init_scale ].\\n•constant : Initializes the weights to a scalar value speciﬁed by\\nbias_init_value .\\nOptional\\nValid values: uniform , normal , or constant\\nDefault value: normal\\nbias_init_scale Range for initialization of the bias term. Takes eﬀect if\\nbias_init_method  is set to uniform .\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: None\\nbias_init_sigma The standard deviation for initialization of the bias term. Takes\\neﬀect if bias_init_method  is set to normal .\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.01\\nbias_init_value The initial value of the bias term. Takes eﬀect if\\nbias_init_method  is set to constant .\\nOptional\\nValid values: Float. Suggested value range: [1e-8, 512].\\nDefault value: None\\n101Amazon SageMaker Developer Guide\\nFactorization Machines\\nParameter Name Description\\nbias_lr The learning rate for the bias term.\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.1\\nbias_wd The weight decay for the bias term.\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.01\\nclip_gradient Gradient clipping optimizer parameter. Clips the gradient by\\nprojecting onto the interval [-clip_gradient , +clip_gradient ].\\nOptional\\nValid values: Float\\nDefault value: None\\nepochs The number of training epochs to run.\\nOptional\\nValid values: Positive integer\\nDefault value: 1\\neps Epsilon parameter to avoid division by 0.\\nOptional\\nValid values: Float. Suggested value: small.\\nDefault value: None\\n102Amazon SageMaker Developer Guide\\nFactorization Machines\\nParameter Name Description\\nfactors_init_method The initialization method for factorization terms:\\n•normal Initializes weights with random values sampled from a\\nnormal distribution with a mean of zero and standard deviation\\nspeciﬁed by factors_init_sigma .\\n•uniform: Initializes weights with random values uniformly\\nsampled from a range speciﬁed by [-factors_init_scale ,\\n+factors_init_scale ].\\n•constant : Initializes the weights to a scalar value speciﬁed by\\nfactors_init_value .\\nOptional\\nValid values: uniform , normal , or constant .\\nDefault value: normal\\nfactors_init_scale The range for initialization of factorization terms. Takes eﬀect if\\nfactors_init_method  is set to uniform .\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: None\\nfactors_init_sigma The standard deviation for initialization of factorization terms.\\nTakes eﬀect if factors_init_method  is set to normal .\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.001\\nfactors_init_value The initial value of factorization terms. Takes eﬀect if\\nfactors_init_method  is set to constant .\\nOptional\\nValid values: Float. Suggested value range: [1e-8, 512].\\nDefault value: None\\nfactors_lr The learning rate for factorization terms.\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.0001\\n103Amazon SageMaker Developer Guide\\nFactorization Machines\\nParameter Name Description\\nfactors_wd The weight decay for factorization terms.\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.00001\\nlinear_lr The learning rate for linear terms.\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.001\\nlinear_init_method The initialization method for linear terms:\\n•normal Initializes weights with random values sampled from a\\nnormal distribution with a mean of zero and standard deviation\\nspeciﬁed by linear_init_sigma .\\n•uniform Initializes weights with random values uniformly\\nsampled from a range speciﬁed by [-linear_init_scale ,\\n+linear_init_scale ].\\n•constant  Initializes the weights to a scalar value speciﬁed by\\nlinear_init_value .\\nOptional\\nValid values: uniform , normal , or constant .\\nDefault value: normal\\nlinear_init_scale Range for initialization of linear terms. Takes eﬀect if\\nlinear_init_method  is set to uniform .\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: None\\nlinear_init_sigma The standard deviation for initialization of linear terms. Takes eﬀect\\nif linear_init_method  is set to normal .\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.01\\n104Amazon SageMaker Developer Guide\\nFactorization Machines\\nParameter Name Description\\nlinear_init_value The initial value of linear terms. Takes eﬀect if\\nlinear_init_method  is set to constant .\\nOptional\\nValid values: Float. Suggested value range: [1e-8, 512].\\nDefault value: None\\nlinear_wd The weight decay for linear terms.\\nOptional\\nValid values: Non-negative ﬂoat. Suggested value range: [1e-8,\\n512].\\nDefault value: 0.001\\nmini_batch_size The size of mini-batch used for training.\\nOptional\\nValid values: Positive integer\\nDefault value: 1000\\nrescale_grad Gradient rescaling optimizer parameter. If set, multiplies the\\ngradient with rescale_grad  before updating. Often choose to be\\n1.0/batch_size .\\nOptional\\nValid values: Float\\nDefault value: None\\nTune a Factorization Machines Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the Factorization Machines Algorithm\\nThe factorization machines algorithm has both binary classiﬁcation and regression predictor types. The\\npredictor type determines which metric you can use for automatic model tuning. The algorithm reports a\\ntest:rmse  regressor metric, which is computed during training. When tuning the model for regression\\ntasks, choose this metric as the objective.\\nMetric Name Description Optimization Direction\\ntest:rmse Root Mean Square Error Minimize\\n105Amazon SageMaker Developer Guide\\nFactorization Machines\\nThe factorization machines algorithm reports three binary classiﬁcation metrics, which are computed\\nduring training. When tuning the model for binary classiﬁcation tasks, choose one of these as the\\nobjective.\\nMetric Name Description Optimization Direction\\ntest:binary_classification_accuracy Accuracy Maximize\\ntest:binary_classification_cross_entropy Cross Entropy Minimize\\ntest:binary_f_beta Beta Maximize\\nTunable Factorization Machines Hyperparameters\\nYou can tune the following hyperparameters for the factorization machines algorithm. The initialization\\nparameters that contain the terms bias, linear, and factorization depend on their initialization method.\\nThere are three initialization methods: uniform , normal , and constant . These initialization methods\\nare not themselves tunable. The parameters that are tunable are dependent on this choice of the\\ninitialization method. For example, if the initialization method is uniform , then only the scale\\nparameters are tunable. Speciﬁcally, if bias_init_method==uniform , then bias_init_scale ,\\nlinear_init_scale , and factors_init_scale  are tunable. Similarly, if the initialization method is\\nnormal , then only sigma parameters are tunable. If the initialization method is constant , then only\\nvalue parameters are tunable. These dependencies are listed in the following table.\\nParameter Name Parameter Type Recommended\\nRangesDependency\\nbias_init_scale ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512bias_init_method==uniform\\nbias_init_sigma ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512bias_init_method==normal\\nbias_init_value ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512bias_init_method==constant\\nbias_lr ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512None\\nbias_wd ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512None\\nepoch IntegerParameterRange MinValue: 1,\\nMaxValue: 1000None\\nfactors_init_scale ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512bias_init_method==uniform\\nfactors_init_sigma ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512bias_init_method==normal\\nfactors_init_value ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512bias_init_method==constant\\nfactors_lr ContinuousParameterRange MinValue: 1e-8,\\nMaxValue: 512None\\n106Amazon SageMaker Developer Guide\\nFactorization Machines\\nParameter NameParameter Type Recommended\\nRangesDependency\\nfactors_wd ContinuousParameterRangeMinValue: 1e-8,\\nMaxValue: 512]None\\nlinear_init_scale ContinuousParameterRangeMinValue: 1e-8,\\nMaxValue: 512bias_init_method==uniform\\nlinear_init_sigma ContinuousParameterRangeMinValue: 1e-8,\\nMaxValue: 512bias_init_method==normal\\nlinear_init_value ContinuousParameterRangeMinValue: 1e-8,\\nMaxValue: 512bias_init_method==constant\\nlinear_lr ContinuousParameterRangeMinValue: 1e-8,\\nMaxValue: 512None\\nlinear_wd ContinuousParameterRangeMinValue: 1e-8,\\nMaxValue: 512None\\nmini_batch_size IntegerParameterRange MinValue: 100,\\nMaxValue: 10000None\\nFactorization Machine Response Formats\\nJSON Response Format\\nBinary classiﬁcation\\nlet response =   {\\n    \"predictions\":    [\\n        {\\n            \"score\": 0.4,\\n            \"predicted_label\": 0\\n        } \\n    ]\\n}\\nRegression\\nlet response =   {\\n    \"predictions\":    [\\n        {\\n            \"score\": 0.4\\n        } \\n    ]\\n}\\nJSONLINES Response Format\\nBinary classiﬁcation\\n{\"score\": 0.4, \"predicted_label\": 0}\\nRegression\\n107Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\n{\"score\": 0.4}\\nRECORDIO Response Format\\nBinary classiﬁcation\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'score’: {\\n                keys: [],\\n                values: [0.4]  # float32\\n            },\\n            \\'predicted_label\\': {\\n                keys: [],\\n                values: [0.0]  # float32\\n            }\\n        }\\n    }\\n]\\nRegression\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'score’: {\\n                keys: [],\\n                values: [0.4]  # float32\\n            }   \\n        }\\n    }\\n]\\nImage Classiﬁcation Algorithm\\nThe Amazon SageMaker image classiﬁcation algorithm is a supervised learning algorithm that supports\\nmulti-label classiﬁcation. It takes an image as input and outputs one or more labels assigned to that\\nimage. It uses a convolutional neural network (ResNet) that can be trained from scratch or trained using\\ntransfer learning when a large number of training images are not available.\\nThe recommended input format for the Amazon SageMaker image classiﬁcation algorithms is Apache\\nMXNet RecordIO. However, you can also use raw images in .jpg or .png format.\\nNote\\nTo maintain better interoperability with existing deep learning frameworks, this diﬀers from the\\nprotobuf data formats commonly used by other Amazon SageMaker algorithms.\\nFor more information on convolutional networks, see:\\n•Deep residual learning for image recognition Kaiming He, et al., 2016 IEEE Conference on Computer\\nVision and Pattern Recognition\\n•ImageNet image database\\n•Image classiﬁcation in MXNet\\nTopics\\n108Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\n•Input/Output Interface for the Image Classiﬁcation Algorithm (p. 109)\\n•EC2 Instance Recommendation for the Image Classiﬁcation Algorithm (p. 123)\\n•Image Classiﬁcation Sample Notebooks  (p. 123)\\n•How Image Classiﬁcation Works (p. 123)\\n•Image Classiﬁcation Hyperparameters  (p. 124)\\n•Tune an Image Classiﬁcation Model (p. 130)\\nInput/Output Interface for the Image Classiﬁcation Algorithm\\nThe Amazon SageMaker Image Classiﬁcation algorithm supports both RecordIO (application/x-\\nrecordio ) and image ( image/png , image/jpeg , and application/x-image ) content types for\\ntraining in ﬁle mode and supports RecordIO (application/x-recordio ) content type for training in\\npipe mode. However you can also train in pipe mode using the image ﬁles (image/png , image/jpeg ,\\nand application/x-image ), without creating RecordIO ﬁles, by using the augmented manifest format.\\nDistributed training is currently not supported in pipe mode and can only be used in ﬁle mode. The\\nalgorithm supports image/png , image/jpeg , and application/x-image  for inference.\\nTrain with RecordIO Format\\nIf you use the RecordIO format for training, specify both train  and validation  channels as values for\\nthe InputDataConfig  parameter of the CreateTrainingJob (p. 667) request. Specify one RecordIO\\n(.rec ) ﬁle in the train channel and one RecordIO ﬁle in the validation  channel. Set the content type\\nfor both channels to application/x-recordio .\\nTrain with Image Format\\nIf you use the Image format for training, specify train , validation , train_lst ,\\nand validation_lst  channels as values for the InputDataConfig  parameter of the\\nCreateTrainingJob (p. 667) request. Specify the individual image data (.jpg  or .png  ﬁles) for\\nthe train  and validation  channels. Specify one .lst  ﬁle in each of the train_lst  and\\nvalidation_lst  channels. Set the content type for all four channels to application/x-image .\\nNote\\nAmazon SageMaker reads the training and validation data separately from diﬀerent channels, so\\nyou must store the training and validation data in diﬀerent folders.\\nA .lst ﬁle is a tab-separated ﬁle with three columns that contains a list of image ﬁles. The ﬁrst column\\nspeciﬁes the image index, the second column speciﬁes the class label index for the image, and the third\\ncolumn speciﬁes the relative path of the image ﬁle. The image index in the ﬁrst column must be unique\\nacross all of the images. The set of class label indices are numbered successively and the numbering\\nshould start with 0. For example, 0 for the cat class, 1 for the dog class, and so on for additional classes.\\nThe following is an example of a .lst  ﬁle:\\n5      1   your_image_directory/train_img_dog1.jpg\\n1000   0   your_image_directory/train_img_cat1.jpg\\n22     1   your_image_directory/train_img_dog2.jpg\\nFor example, if your training images are stored in s3://<your_bucket>/train/class_dog , s3://\\n<your_bucket>/train/class_cat , and so on, specify the path for your train  channel as s3://\\n<your_bucket>/train , which is the top-level directory for your data. In the .lst ﬁle, specify the\\nrelative path for an individual ﬁle named train_image_dog1.jpg  in the class_dog  class directory as\\nclass_dog/train_image_dog1.jpg . You can also store all your image ﬁles under one subdirectory\\ninside the train directory. In that case, use that subdirectory for the relative path. For example, s3://\\n<your_bucket>/train/your_image_directory .\\n109Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nTrain with Augmented Manifest Image Format\\nThe augmented manifest format enables you to do training in Pipe mode using image ﬁles without\\nneeding to create RecordIO ﬁles. You need to specify both train and validation channels as values for the\\nInputDataConfig  parameter of the\\nStarts a model training job. After training completes, Amazon SageMaker saves the resulting\\nmodel artifacts to an Amazon S3 location that you specify.\\nIf you choose to host your model using Amazon SageMaker hosting services, you can use the\\nresulting model artifacts as part of the model. You can also use the artifacts in a machine\\nlearning service other than Amazon SageMaker, provided that you know how to use them for\\ninferences.\\nIn the request body, you provide the following:\\n•AlgorithmSpecification  - Identiﬁes the training algorithm to use.\\n•HyperParameters  - Specify these algorithm-speciﬁc parameters to enable the estimation\\nof model parameters during training. Hyperparameters can be tuned to optimize this\\nlearning process. For a list of hyperparameters for each training algorithm provided by\\nAmazon SageMaker, see Algorithms .\\n•InputDataConfig  - Describes the training dataset and the Amazon S3, EFS, or FSx\\nlocation where it is stored.\\n•OutputDataConfig  - Identiﬁes the Amazon S3 bucket where you want Amazon\\nSageMaker to save the results of model training.\\n•ResourceConfig  - Identiﬁes the resources, ML compute instances, and ML storage\\nvolumes to deploy for model training. In distributed training, you specify more than one\\ninstance.\\n•EnableManagedSpotTraining  - Optimize the cost of training machine learning models\\nby up to 80% by using Amazon EC2 Spot instances. For more information, see Managed\\nSpot Training.\\n•RoleARN - The Amazon Resource Number (ARN) that Amazon SageMaker assumes to\\nperform tasks on your behalf during model training. You must grant this role the necessary\\npermissions so that Amazon SageMaker can successfully complete model training.\\n•StoppingCondition  - To help cap training costs, use MaxRuntimeInSeconds  to set a\\ntime limit for training. Use MaxWaitTimeInSeconds  to specify how long you are willing\\nto to wait for a managed spot training job to complete.\\nFor more information about Amazon SageMaker, see How It Works.\\nRequest Syntax\\n{\\n   \"AlgorithmSpecification \": { \\n      \"AlgorithmName \": \"string\",\\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingInputMode \": \"string\"\\n   },\\n   \"CheckpointConfig \": { \\n      \"LocalPath \": \"string\",\\n      \"S3Uri\": \"string\"110Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\n   },\\n   \"EnableInterContainerTrafficEncryption \": boolean,\\n   \"EnableManagedSpotTraining \": boolean,\\n   \"EnableNetworkIsolation \": boolean,\\n   \"HyperParameters \": { \\n      \"string\" : \"string\" \\n   },\\n   \"InputDataConfig \": [ \\n      { \\n         \" ChannelName \": \"string\",\\n         \" CompressionType \": \"string\",\\n         \" ContentType \": \"string\",\\n         \" DataSource \": { \\n            \" FileSystemDataSource \": { \\n               \" DirectoryPath \": \"string\",\\n               \" FileSystemAccessMode \": \"string\",\\n               \" FileSystemId \": \"string\",\\n               \" FileSystemType \": \"string\"\\n            },\\n            \" S3DataSource \": { \\n               \" AttributeNames \": [ \"string\" ],\\n               \" S3DataDistributionType \": \"string\",\\n               \" S3DataType \": \"string\",\\n               \" S3Uri\": \"string\"\\n            }\\n         },\\n         \" InputMode \": \"string\",\\n         \" RecordWrapperType \": \"string\",\\n         \" ShuffleConfig \": { \\n            \" Seed\": number\\n         }\\n      }\\n   ],\\n   \"OutputDataConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"ResourceConfig \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\",\\n      \"VolumeSizeInGB \": number\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,\\n      \"MaxWaitTimeInSeconds \": number\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"TrainingJobName \": \"string\",\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n      \"Subnets\": [ \"string\" ]\\n   }\\n}111Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAlgorithmSpeciﬁcation (p. 667)\\nThe registry path of the Docker image that contains the training algorithm and\\nalgorithm-speciﬁc metadata, including the input mode. For more information\\nabout algorithms provided by Amazon SageMaker, see Algorithms . For information\\nabout providing your own algorithms, see Using Your Own Algorithms with Amazon\\nSageMaker.\\nType: AlgorithmSpeciﬁcation  (p. 863) object\\nRequired: Yes\\nCheckpointConﬁg  (p. 667)\\nContains information about the output location for managed spot training checkpoint\\ndata.\\nType: CheckpointConﬁg  (p. 880) object\\nRequired: No\\nEnableInterContainerTraﬃcEncryption (p. 667)\\nTo encrypt all communications between ML compute instances in distributed training,\\nchoose True. Encryption provides greater security for distributed training, but training\\nmight take longer. How long it takes depends on the amount of communication between\\ncompute instances, especially if you use a deep learning algorithm in distributed training.\\nFor more information, see Protect Communications Between ML Compute Instances in a\\nDistributed Training Job.\\nType: Boolean\\nRequired: No\\nEnableManagedSpotTraining (p. 667)\\nTo train models using managed spot training, choose True . Managed spot training\\nprovides a fully managed and scalable infrastructure for training machine learning\\nmodels. this option is useful when training jobs can be interrupted and when there is\\nﬂexibility when the training job is run.\\nThe complete and intermediate results of jobs are stored in an Amazon S3 bucket,\\nand can be used as a starting point to train models incrementally. Amazon SageMaker\\nprovides metrics and logs in CloudWatch. They can be used to see when managed spot\\ntraining jobs are running, interrupted, resumed, or completed.\\nType: Boolean\\nRequired: No\\nEnableNetworkIsolation (p. 667)\\nIsolates the training container. No inbound or outbound network calls can be made,\\nexcept for calls between peers within a training cluster for distributed training. If you\\nenable network isolation for training jobs that are conﬁgured to use a VPC, Amazon\\n112Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nSageMaker downloads and uploads customer data and model artifacts through the\\nspeciﬁed VPC, but the training container does not have network access.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network\\nisolation.\\nType: Boolean\\nRequired: No\\nHyperParameters (p. 667)\\nAlgorithm-speciﬁc parameters that inﬂuence the quality of the model. You set\\nhyperparameters before you start the learning process. For a list of hyperparameters for\\neach training algorithm provided by Amazon SageMaker, see Algorithms .\\nYou can specify a maximum of 100 hyperparameters. Each hyperparameter is a key-\\nvalue pair. Each key and value is limited to 256 characters, as speciﬁed by the Length\\nConstraint .\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nInputDataConﬁg  (p. 667)\\nAn array of Channel objects. Each channel is a named input source. InputDataConfig\\ndescribes the input data and its location.\\nAlgorithms can accept input data from one or more channels. For example, an algorithm\\nmight have two channels of input data, training_data  and validation_data . The\\nconﬁguration for each channel provides the S3, EFS, or FSx location where the input data\\nis stored. It also provides information about the stored data: the MIME type, compression\\nmethod, and whether the data is wrapped in RecordIO format.\\nDepending on the input mode that the algorithm supports, Amazon SageMaker either\\ncopies input data ﬁles from an S3 bucket to a local directory in the Docker container, or\\nmakes it available as input streams. For example, if you specify an EFS location, input\\ndata ﬁles will be made available as input streams. They do not need to be downloaded.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No\\nOutputDataConﬁg  (p. 667)\\nSpeciﬁes the path to the S3 location where you want to store model artifacts. Amazon\\nSageMaker creates subfolders for the artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: Yes\\n113Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nResourceConﬁg (p. 667)\\nThe resources, including the ML compute instances and ML storage volumes, to use for\\nmodel training.\\nML storage volumes store model artifacts and incremental states. Training algorithms\\nmight also use ML storage volumes for scratch space. If you want Amazon SageMaker\\nto use the ML storage volume to store the training data, choose File  as the\\nTrainingInputMode  in the algorithm speciﬁcation. For distributed training algorithms,\\nspecify an instance count greater than 1.\\nType: ResourceConﬁg (p. 991) object\\nRequired: Yes\\nRoleArn (p. 667)\\nThe Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker can assume to\\nperform tasks on your behalf.\\nDuring model training, Amazon SageMaker needs your permission to read input data\\nfrom an S3 bucket, download a Docker image that contains training code, write model\\nartifacts to an S3 bucket, write logs to Amazon CloudWatch Logs, and publish metrics\\nto Amazon CloudWatch. You grant permissions for all of these tasks to an IAM role. For\\nmore information, see Amazon SageMaker Roles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must\\nhave the iam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStoppingCondition  (p. 667)\\nSpeciﬁes a limit to how long a model training job can run. When the job reaches the time\\nlimit, Amazon SageMaker ends the training job. Use this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays\\njob termination for 120 seconds. Algorithms can use this 120-second window to save the\\nmodel artifacts, so the results of training are not lost.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\nTags (p. 667)\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tags in the\\nAWS Billing and Cost Management User Guide.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTrainingJobName (p. 667)\\nThe name of the training job. The name must be unique within an AWS Region in an AWS\\naccount.\\n114Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nVpcConﬁg (p. 667)\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that you want your training job to\\nconnect to. Control access to and from your training container by conﬁguring the VPC.\\nFor more information, see Protect Training Jobs by Using an Amazon Virtual Private\\nCloud .\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"TrainingJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nTrainingJobArn (p. 672)\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-\\njob/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common\\nErrors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have\\ntoo many training jobs created.\\nHTTP Status Code: 400\\n115Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the\\nfollowing:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n (p. ) request. While using the format, an S3 manifest ﬁle needs to be generated that contains\\nthe list of images and their corresponding annotations. The manifest ﬁle format should be in JSON\\nLines  format in which each line represents one sample. The images are speciﬁed using the \\'source-\\nref\\' tag that points to the S3 location of the image. The annotations are provided under the\\n\"AttributeNames\"  parameter value as speciﬁed in the\\nStarts a model training job. After training completes, Amazon SageMaker saves the resulting\\nmodel artifacts to an Amazon S3 location that you specify.\\nIf you choose to host your model using Amazon SageMaker hosting services, you can use the\\nresulting model artifacts as part of the model. You can also use the artifacts in a machine\\nlearning service other than Amazon SageMaker, provided that you know how to use them for\\ninferences.\\nIn the request body, you provide the following:\\n•AlgorithmSpecification  - Identiﬁes the training algorithm to use.\\n•HyperParameters  - Specify these algorithm-speciﬁc parameters to enable the estimation\\nof model parameters during training. Hyperparameters can be tuned to optimize this\\nlearning process. For a list of hyperparameters for each training algorithm provided by\\nAmazon SageMaker, see Algorithms .\\n•InputDataConfig  - Describes the training dataset and the Amazon S3, EFS, or FSx\\nlocation where it is stored.\\n•OutputDataConfig  - Identiﬁes the Amazon S3 bucket where you want Amazon\\nSageMaker to save the results of model training.\\n•ResourceConfig  - Identiﬁes the resources, ML compute instances, and ML storage\\nvolumes to deploy for model training. In distributed training, you specify more than one\\ninstance.\\n•EnableManagedSpotTraining  - Optimize the cost of training machine learning models\\nby up to 80% by using Amazon EC2 Spot instances. For more information, see Managed\\nSpot Training.\\n•RoleARN - The Amazon Resource Number (ARN) that Amazon SageMaker assumes to\\nperform tasks on your behalf during model training. You must grant this role the necessary\\npermissions so that Amazon SageMaker can successfully complete model training.\\n•StoppingCondition  - To help cap training costs, use MaxRuntimeInSeconds  to set a\\ntime limit for training. Use MaxWaitTimeInSeconds  to specify how long you are willing\\nto to wait for a managed spot training job to complete.\\n116Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nFor more information about Amazon SageMaker, see How It Works.\\nRequest Syntax\\n{\\n   \"AlgorithmSpecification \": { \\n      \"AlgorithmName \": \"string\",\\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingInputMode \": \"string\"\\n   },\\n   \"CheckpointConfig \": { \\n      \"LocalPath \": \"string\",\\n      \"S3Uri\": \"string\"\\n   },\\n   \"EnableInterContainerTrafficEncryption \": boolean,\\n   \"EnableManagedSpotTraining \": boolean,\\n   \"EnableNetworkIsolation \": boolean,\\n   \"HyperParameters \": { \\n      \"string\" : \"string\" \\n   },\\n   \"InputDataConfig \": [ \\n      { \\n         \" ChannelName \": \"string\",\\n         \" CompressionType \": \"string\",\\n         \" ContentType \": \"string\",\\n         \" DataSource \": { \\n            \" FileSystemDataSource \": { \\n               \" DirectoryPath \": \"string\",\\n               \" FileSystemAccessMode \": \"string\",\\n               \" FileSystemId \": \"string\",\\n               \" FileSystemType \": \"string\"\\n            },\\n            \" S3DataSource \": { \\n               \" AttributeNames \": [ \"string\" ],\\n               \" S3DataDistributionType \": \"string\",\\n               \" S3DataType \": \"string\",\\n               \" S3Uri\": \"string\"\\n            }\\n         },\\n         \" InputMode \": \"string\",\\n         \" RecordWrapperType \": \"string\",\\n         \" ShuffleConfig \": { \\n            \" Seed\": number\\n         }\\n      }\\n   ],\\n   \"OutputDataConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"ResourceConfig \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\",\\n      \"VolumeSizeInGB \": number\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,117Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\n      \"MaxWaitTimeInSeconds \": number\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"TrainingJobName \": \"string\",\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n      \"Subnets\": [ \"string\" ]\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAlgorithmSpeciﬁcation (p. 667)\\nThe registry path of the Docker image that contains the training algorithm and\\nalgorithm-speciﬁc metadata, including the input mode. For more information\\nabout algorithms provided by Amazon SageMaker, see Algorithms . For information\\nabout providing your own algorithms, see Using Your Own Algorithms with Amazon\\nSageMaker.\\nType: AlgorithmSpeciﬁcation  (p. 863) object\\nRequired: Yes\\nCheckpointConﬁg  (p. 667)\\nContains information about the output location for managed spot training checkpoint\\ndata.\\nType: CheckpointConﬁg  (p. 880) object\\nRequired: No\\nEnableInterContainerTraﬃcEncryption (p. 667)\\nTo encrypt all communications between ML compute instances in distributed training,\\nchoose True. Encryption provides greater security for distributed training, but training\\nmight take longer. How long it takes depends on the amount of communication between\\ncompute instances, especially if you use a deep learning algorithm in distributed training.\\nFor more information, see Protect Communications Between ML Compute Instances in a\\nDistributed Training Job.\\nType: Boolean\\nRequired: No\\nEnableManagedSpotTraining (p. 667)\\nTo train models using managed spot training, choose True . Managed spot training\\nprovides a fully managed and scalable infrastructure for training machine learning\\nmodels. this option is useful when training jobs can be interrupted and when there is\\nﬂexibility when the training job is run.\\nThe complete and intermediate results of jobs are stored in an Amazon S3 bucket,\\nand can be used as a starting point to train models incrementally. Amazon SageMaker118Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nprovides metrics and logs in CloudWatch. They can be used to see when managed spot\\ntraining jobs are running, interrupted, resumed, or completed.\\nType: Boolean\\nRequired: No\\nEnableNetworkIsolation (p. 667)\\nIsolates the training container. No inbound or outbound network calls can be made,\\nexcept for calls between peers within a training cluster for distributed training. If you\\nenable network isolation for training jobs that are conﬁgured to use a VPC, Amazon\\nSageMaker downloads and uploads customer data and model artifacts through the\\nspeciﬁed VPC, but the training container does not have network access.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network\\nisolation.\\nType: Boolean\\nRequired: No\\nHyperParameters (p. 667)\\nAlgorithm-speciﬁc parameters that inﬂuence the quality of the model. You set\\nhyperparameters before you start the learning process. For a list of hyperparameters for\\neach training algorithm provided by Amazon SageMaker, see Algorithms .\\nYou can specify a maximum of 100 hyperparameters. Each hyperparameter is a key-\\nvalue pair. Each key and value is limited to 256 characters, as speciﬁed by the Length\\nConstraint .\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nInputDataConﬁg  (p. 667)\\nAn array of Channel objects. Each channel is a named input source. InputDataConfig\\ndescribes the input data and its location.\\nAlgorithms can accept input data from one or more channels. For example, an algorithm\\nmight have two channels of input data, training_data  and validation_data . The\\nconﬁguration for each channel provides the S3, EFS, or FSx location where the input data\\nis stored. It also provides information about the stored data: the MIME type, compression\\nmethod, and whether the data is wrapped in RecordIO format.\\nDepending on the input mode that the algorithm supports, Amazon SageMaker either\\ncopies input data ﬁles from an S3 bucket to a local directory in the Docker container, or\\nmakes it available as input streams. For example, if you specify an EFS location, input\\ndata ﬁles will be made available as input streams. They do not need to be downloaded.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No119Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nOutputDataConﬁg  (p. 667)\\nSpeciﬁes the path to the S3 location where you want to store model artifacts. Amazon\\nSageMaker creates subfolders for the artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: Yes\\nResourceConﬁg (p. 667)\\nThe resources, including the ML compute instances and ML storage volumes, to use for\\nmodel training.\\nML storage volumes store model artifacts and incremental states. Training algorithms\\nmight also use ML storage volumes for scratch space. If you want Amazon SageMaker\\nto use the ML storage volume to store the training data, choose File  as the\\nTrainingInputMode  in the algorithm speciﬁcation. For distributed training algorithms,\\nspecify an instance count greater than 1.\\nType: ResourceConﬁg (p. 991) object\\nRequired: Yes\\nRoleArn (p. 667)\\nThe Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker can assume to\\nperform tasks on your behalf.\\nDuring model training, Amazon SageMaker needs your permission to read input data\\nfrom an S3 bucket, download a Docker image that contains training code, write model\\nartifacts to an S3 bucket, write logs to Amazon CloudWatch Logs, and publish metrics\\nto Amazon CloudWatch. You grant permissions for all of these tasks to an IAM role. For\\nmore information, see Amazon SageMaker Roles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must\\nhave the iam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStoppingCondition  (p. 667)\\nSpeciﬁes a limit to how long a model training job can run. When the job reaches the time\\nlimit, Amazon SageMaker ends the training job. Use this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays\\njob termination for 120 seconds. Algorithms can use this 120-second window to save the\\nmodel artifacts, so the results of training are not lost.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\nTags (p. 667)\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tags in the\\nAWS Billing and Cost Management User Guide.\\nType: Array of Tag (p. 1008 ) objects\\n120Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTrainingJobName (p. 667)\\nThe name of the training job. The name must be unique within an AWS Region in an AWS\\naccount.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nVpcConﬁg (p. 667)\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that you want your training job to\\nconnect to. Control access to and from your training container by conﬁguring the VPC.\\nFor more information, see Protect Training Jobs by Using an Amazon Virtual Private\\nCloud .\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"TrainingJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nTrainingJobArn (p. 672)\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-\\njob/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common\\nErrors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400121Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have\\ntoo many training jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the\\nfollowing:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n (p. ) request. It can also contain additional metadata under the metadata  tag, but these are\\nignored by the algorithm. In the following example, the \"AttributeNames\"  are contained in the list of\\nimage and annotation references [\"source-ref\", \"class\"] . The corresponding label value is \"0\"\\nfor the ﬁrst image and “1” for the second image:\\n{\"source-ref\":\"s3://image/filename1.jpg\", \"class\":\"0\"} \\n{\"source-ref\":\"s3://image/filename2.jpg\", \"class\":\"1\", \"class-metadata\": {\"class-name\":\\n \"cat\", \"type\" : \"groundtruth/image-classification\"}}\\nThe order of \"AttributeNames\"  in the input ﬁles matters when training the ImageClassiﬁcation\\nalgorithm. It accepts piped data in a speciﬁc order, with image ﬁrst, followed by label . So the\\n\"AttributeNames\" in this example are provided with \"source-ref\"  ﬁrst, followed by \"class\" .\\nWhen using the ImageClassiﬁcation algorithm with Augmented Manifest, the value of the\\nRecordWrapperType  parameter must be \"RecordIO\" .\\nFor more information on augmented manifest ﬁles, see Provide Dataset Metadata to Training Jobs with\\nan Augmented Manifest File  (p. 308).\\nIncremental Training\\nYou can also seed the training of a new model with the artifacts from a model that you trained\\npreviously with Amazon SageMaker. Incremental training saves training time when you want to train a\\nnew model with the same or similar data. Amazon SageMaker image classiﬁcation models can be seeded\\nonly with another build-in image classiﬁcation model trained in Amazon SageMaker.\\nTo use a pretrained model, in the CreateTrainingJob (p. 667) request, specify the ChannelName\\nas \"model\" in the InputDataConfig  parameter. Set the ContentType  for the model channel to\\napplication/x-sagemaker-model . The input hyperparameters of both the new model and\\nthe pretrained model that you upload to the model channel must have the same settings for the\\nnum_layers , image_shape  and num_classes  input parameters. These parameters deﬁne the network\\narchitecture. For the pretrained model ﬁle, use the compressed model artifacts (in .tar.gz format) output\\nby Amazon SageMaker. You can use either RecordIO or image formats for input data.\\n122Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nFor a sample notebook that shows how to use incremental training with the Amazon SageMaker image\\nclassiﬁcation algorithm, see the End-to-End Incremental Training Image Classiﬁcation Example. For more\\ninformation on incremental training and for instructions on how to use it, see Incremental Training in\\nAmazon SageMaker (p. 282).\\nInference with the Image Format Algorithm\\nThe generated models can be hosted for inference and support encoded .jpg  and .png  image formats\\nas image/png, image/jpeg , and application/x-image  content-type. The output is the probability\\nvalues for all classes encoded in JSON format, or in JSON Lines text format for batch transform. The\\nimage classiﬁcation model processes a single image per request and so outputs only one line in the JSON\\nor JSON Lines format. The following is an example of a response in JSON Lines format:\\naccept: application/jsonlines\\n \\n {\"prediction\": [prob_0, prob_1, prob_2, prob_3, ...]}\\nFor more details on training and inference, see the image classiﬁcation sample notebook instances\\nreferenced in the introduction.\\nEC2 Instance Recommendation for the Image Classiﬁcation\\nAlgorithm\\nFor image classiﬁcation, we support the following GPU instances for training: ml.p2.xlarge ,\\nml.p2.8xlarge , ml.p2.16xlarge , ml.p3.2xlarge , ml.p3.8xlarge and ml.p3.16xlarge . We\\nrecommend using GPU instances with more memory for training with large batch sizes. However, both\\nCPU (such as C4) and GPU (such as P2 and P3) instances can be used for the inference. You can also run\\nthe algorithm on multi-GPU and multi-machine settings for distributed training.\\nBoth P2 and P3 instances are supported in the image classiﬁcation algorithm.\\nImage Classiﬁcation Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker image classiﬁcation algorithm to train a model\\non the caltech-256 dataset  and then to deploy it to perform inferences, see the End-to-End Multiclass\\nImage Classiﬁcation Example . For instructions how to create and access Jupyter notebook instances\\nthat you can use to run the example in Amazon SageMaker, see Use Notebook Instances (p. 36). Once\\nyou have created a notebook instance and opened it, select the SageMaker Examples tab to see a list\\nof all the Amazon SageMaker samples. The example image classiﬁcation notebooks are located in the\\nIntroduction to Amazon algorithms section. To open a notebook, click on its Use tab and select Create\\ncopy.\\nHow Image Classiﬁcation Works\\nThe image classiﬁcation algorithm takes an image as input and classiﬁes it into one of the output\\ncategories. Deep learning has revolutionized the image classiﬁcation domain and has achieved great\\nperformance. Various deep learning networks such as ResNet [1], DenseNet, inception, and so on, have\\nbeen developed to be highly accurate for image classiﬁcation. At the same time, there have been eﬀorts\\nto collect labeled image data that are essential for training these networks. ImageNet[2] is one such\\nlarge dataset that has more than 11 million images with about 11,000 categories. Once a network is\\ntrained with ImageNet data, it can then be used to generalize with other datasets as well, by simple re-\\nadjustment or ﬁne-tuning. In this transfer learning approach, a network is initialized with weights (in\\nthis example, trained on ImageNet), which can be later ﬁne-tuned for an image classiﬁcation task in a\\ndiﬀerent dataset.\\nImage classiﬁcation in Amazon SageMaker can be run in two modes: full training and transfer learning.\\nIn full training mode, the network is initialized with random weights and trained on user data from\\n123Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nscratch. In transfer learning mode, the network is initialized with pre-trained weights and just the top\\nfully connected layer is initialized with random weights. Then, the whole network is ﬁne-tuned with new\\ndata. In this mode, training can be achieved even with a smaller dataset. This is because the network is\\nalready trained and therefore can be used in cases without suﬃcient training data.\\nImage Classiﬁcation Hyperparameters\\nParameter Name Description\\nnum_classes Number of output classes. This parameter deﬁnes the dimensions\\nof the network output and is typically set to the number of classes\\nin the dataset.\\nRequired\\nValid values: positive integer\\nnum_training_samples Number of training examples in the input dataset.\\nIf there is a mismatch between this value and the number\\nof samples in the training set, then the behavior of the\\nlr_scheduler_step  parameter is undeﬁned and distributed\\ntraining accuracy might be aﬀected.\\nRequired\\nValid values: positive integer\\naugmentation_type Data augmentation type. The input images can be augmented in\\nmultiple ways as speciﬁed below.\\n•crop: Randomly crop the image and ﬂip the image horizontally\\n•crop_color : In addition to ‘crop’, three random values in\\nthe range [-36, 36], [-50, 50], and [-50, 50] are added to the\\ncorresponding Hue-Saturation-Lightness channels respectively\\n•crop_color_transform : In addition to crop_color , random\\ntransformations, including rotation, shear, and aspect ratio\\nvariations are applied to the image. The maximum angle of\\nrotation is 10 degrees, the maximum shear ratio is 0.1, and the\\nmaximum aspect changing ratio is 0.25.\\nOptional\\nValid values: crop , crop_color , or crop_color_transform .\\nDefault value: no default value\\nbeta_1 The beta1 for adam, that is the exponential decay rate for the ﬁrst\\nmoment estimates.\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 0.9\\nbeta_2 The beta2 for adam, that is the exponential decay rate for the\\nsecond moment estimates.\\n124Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nParameter Name Description\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 0.999\\ncheckpoint_frequency Period to store model parameters (in number of epochs).\\nOptional\\nValid values: positive integer no greater than epochs .\\nDefault value: None (Save checkpoint at the epoch that has the best\\nvalidation accuracy.)\\nearly_stopping True  to use early stopping logic during training. False  not to use\\nit.\\nOptional\\nValid values: True  or False\\nDefault value: False\\nearly_stopping_min_epochs The minimum number of epochs that must be run before\\nthe early stopping logic can be invoked. It is used only when\\nearly_stopping  = True .\\nOptional\\nValid values: positive integer\\nDefault value: 10\\nearly_stopping_patience The number of epochs to wait before ending training if no\\nimprovement is made in the relevant metric. It is used only when\\nearly_stopping  = True .\\nOptional\\nValid values: positive integer\\nDefault value: 5\\nearly_stopping_tolerance Relative tolerance to measure an improvement in accuracy\\nvalidation metric. If the ratio of the improvement in accuracy\\ndivided by the previous best accuracy is smaller than the\\nearly_stopping_tolerance  value set, early stopping considers\\nthere is no improvement. It is used only when early_stopping  =\\nTrue .\\nOptional\\nValid values: 0 ≤ ﬂoat ≤ 1\\nDefault value: 0.0\\n125Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nParameter Name Description\\nepochs Number of training epochs.\\nOptional\\nValid values: positive integer\\nDefault value: 30\\neps The epsilon for adam  and rmsprop . It is usually set to a small value\\nto avoid division by 0.\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 1e-8\\ngamma The gamma for rmsprop, the decay factor for the moving average\\nof the squared gradient.\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 0.9\\nimage_shape The input image dimensions, which is the same size as the input\\nlayer of the network. The format is deﬁned as \\'num_channels ,\\nheight, width\\'. The image dimension can take on any value as the\\nnetwork can handle varied dimensions of the input. However, there\\nmay be memory constraints if a larger image dimension is used.\\nTypical image dimensions for image classiﬁcation are \\'3, 224, 224\\'.\\nThis is similar to the ImageNet dataset.\\nOptional\\nValid values: string\\nDefault value: ‘3, 224, 224’\\n126Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nParameter Name Description\\nkv_store Weight update synchronization mode during distributed training.\\nThe weight updates can be updated either synchronously or\\nasynchronously across machines. Synchronous updates typically\\nprovide better accuracy than asynchronous updates but can be\\nslower. See distributed training in MXNet for more details.\\nThis parameter is not applicable to single machine training.\\n•dist_sync : The gradients are synchronized after every batch\\nwith all the workers. With dist_sync , batch-size now means\\nthe batch size used on each machine. So if there are n machines\\nand we use batch size b, then dist_sync  behaves like local with\\nbatch size n*b\\n•dist_async : Performs asynchronous updates. The weights are\\nupdated whenever gradients are received from any machine\\nand the weight updates are atomic. However, the order is not\\nguaranteed.\\nOptional\\nValid values: dist_sync  or dist_async\\nDefault value: no default value\\nlearning_rate Initial learning rate.\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 0.1\\nlr_scheduler_factor The ratio to reduce learning rate used in conjunction with the\\nlr_scheduler_step  parameter, deﬁned as lr_new  = lr_old  *\\nlr_scheduler_factor .\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 0.1\\nlr_scheduler_step The epochs at which to reduce the learning rate. As explained\\nin the lr_scheduler_factor  parameter, the learning rate\\nis reduced by lr_scheduler_factor  at these epochs. For\\nexample, if the value is set to \"10, 20\", then the learning rate is\\nreduced by lr_scheduler_factor  after 10th epoch and again\\nby lr_scheduler_factor  after 20th epoch. The epochs are\\ndelimited by \",\".\\nOptional\\nValid values: string\\nDefault value: no default value\\n127Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nParameter Name Description\\nmini_batch_size The batch size for training. In a single-machine multi-GPU setting,\\neach GPU handles mini_batch_size /num_gpu training samples.\\nFor the multi-machine training in dist_sync mode, the actual batch\\nsize is mini_batch_size *number of machines. See MXNet docs\\nfor more details.\\nOptional\\nValid values: positive integer\\nDefault value: 32\\nmomentum The momentum for sgd and nag, ignored for other optimizers.\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 0.9\\nmulti_label Flag to use for multi-label classiﬁcation where each sample can\\nbe assigned multiple labels. Average accuracy across all classes is\\nlogged.\\nOptional\\nValid values: 0 or 1\\nDefault value: 0\\nnum_layers Number of layers for the network. For data with large image size\\n(for example, 224x224 - like ImageNet), we suggest selecting the\\nnumber of layers from the set [18, 34, 50, 101, 152, 200]. For data\\nwith small image size (for example, 28x28 - like CIFAR), we suggest\\nselecting the number of layers from the set [20, 32, 44, 56, 110].\\nThe number of layers in each set is based on the ResNet paper. For\\ntransfer learning, the number of layers deﬁnes the architecture of\\nbase network and hence can only be selected from the set [18, 34,\\n50, 101, 152, 200].\\nOptional\\nValid values: positive integer in [18, 34, 50, 101, 152, 200] or [20,\\n32, 44, 56, 110]\\nDefault value: 152\\n128Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nParameter Name Description\\noptimizer The optimizer type. For more details of the parameters for the\\noptimizers, please refer to MXNet\\'s API.\\nOptional\\nValid values: One of sgd, adam , rmsprop , or nag.\\n•sgd: Stochastic gradient descent\\n•adam : Adaptive momentum estimation\\n•rmsprop : Root mean square propagation\\n•nag: Nesterov accelerated gradient\\nDefault value: sgd\\nprecision_dtype The precision of the weights used for training. The algorithm can\\nuse either single precision (float32) or half precision (float16 )\\nfor the weights. Using half-precision for weights results in reduced\\nmemory consumption.\\nOptional\\nValid values: float32  or float16\\nDefault value: float32\\nresize Resizes the image before using it for training. The images are\\nresized so that the shortest side has the number of pixels speciﬁed\\nby this parameter. If the parameter is not set, then the training data\\nis used without resizing.\\nOptional\\nValid values: positive integer\\nDefault value: no default value\\ntop_k Reports the top-k accuracy during training. This parameter has to\\nbe greater than 1, since the top-1 training accuracy is the same as\\nthe regular training accuracy that has already been reported.\\nOptional\\nValid values: positive integer larger than 1.\\nDefault value: no default value\\n129Amazon SageMaker Developer Guide\\nImage Classiﬁcation Algorithm\\nParameter Name Description\\nuse_pretrained_model Flag to use pre-trained model for training. If set to 1, then the\\npretrained model with the corresponding number of layers is\\nloaded and used for training. Only the top FC layer are reinitialized\\nwith random weights. Otherwise, the network is trained from\\nscratch.\\nOptional\\nValid values: 0 or 1\\nDefault value: 0\\nuse_weighted_loss Flag to use weighted cross-entropy loss for multi-label classiﬁcation\\n(used only when multi_label  = 1), where the weights are\\ncalculated based on the distribution of classes.\\nOptional\\nValid values: 0 or 1\\nDefault value: 0\\nweight_decay The coeﬃcient weight decay for sgd and nag, ignored for other\\noptimizers.\\nOptional\\nValid values: ﬂoat. Range in [0, 1].\\nDefault value: 0.0001\\nTune an Image Classiﬁcation Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the Image Classiﬁcation Algorithm\\nThe image classiﬁcation algorithm is a supervised algorithm. It reports an accuracy metric that is\\ncomputed during training. When tuning the model, choose this metric as the objective metric.\\nMetric Name Description Optimization Direction\\nvalidation:accuracy The ratio of the number of correct predictions to\\nthe total number of predictions made.Maximize\\nTunable Image Classiﬁcation Hyperparameters\\nTune an image classiﬁcation model with the following hyperparameters. The hyperparameters that have\\nthe greatest impact on image classiﬁcation objective metrics are: mini_batch_size , learning_rate ,\\n130Amazon SageMaker Developer Guide\\nIP Insights\\nand optimizer . Tune the optimizer-related hyperparameters, such as momentum , weight_decay ,\\nbeta_1 , beta_2 , eps, and gamma, based on the selected optimizer . For example, use beta_1  and\\nbeta_2  only when adam  is the optimizer .\\nFor more information about which hyperparameters are used in each optimizer, see Image Classiﬁcation\\nHyperparameters  (p. 124).\\nParameter Name Parameter Type Recommended Ranges\\nbeta_1 ContinuousParameterRanges MinValue: 1e-6,\\nMaxValue: 0.999\\nbeta_2 ContinuousParameterRanges MinValue: 1e-6,\\nMaxValue: 0.999\\neps ContinuousParameterRanges MinValue: 1e-8,\\nMaxValue: 1.0\\ngamma ContinuousParameterRanges MinValue: 1e-8,\\nMaxValue: 0.999\\nlearning_rate ContinuousParameterRanges MinValue: 1e-6,\\nMaxValue: 0.5\\nmini_batch_size IntegerParameterRanges MinValue: 8, MaxValue:\\n512\\nmomentum ContinuousParameterRanges MinValue: 0.0,\\nMaxValue: 0.999\\noptimizer CategoricalParameterRanges [\\'sgd\\', ‘adam’, ‘rmsprop’,\\n\\'nag\\']\\nweight_decay ContinuousParameterRanges MinValue: 0.0,\\nMaxValue: 0.999\\nIP Insights Algorithm\\nAmazon SageMaker IP Insights is an unsupervised learning algorithm that learns the usage patterns for\\nIPv4 addresses. It is designed to capture associations between IPv4 addresses and various entities, such\\nas user IDs or account numbers. You can use it to identify a user attempting to log into a web service\\nfrom an anomalous IP address, for example. Or you can use it to identify an account that is attempting\\nto create computing resources from an unusual IP address. Trained IP Insight models can be hosted at an\\nendpoint for making real-time predictions or used for processing batch transforms\\nAmazon SageMaker IP insights ingests historical data as (entity, IPv4 Address) pairs and learns the IP\\nusage patterns of each entity. When queried with an (entity, IPv4 Address) event, an Amazon SageMaker\\nIP Insights model returns a score that infers how anomalous the pattern of the event is. For example,\\nwhen a user attempts to log in from an IP address, if the IP Insights score is high enough, a web login\\nserver might decide to trigger a multi-factor authentication system. In more advanced solutions, you\\ncan feed the IP Insights score into another machine learning model. For example, you can combine the\\nIP Insight score with other features to rank the ﬁndings of another security system, such as those from\\nAmazon GuardDuty.\\nThe Amazon SageMaker IP Insights algorithm can also learn vector representations of IP addresses,\\nknown as embeddings . You can use vector-encoded embeddings as features in downstream machine\\nlearning tasks that use the information observed in the IP addresses. For example, you can use them in\\ntasks such as measuring similarities between IP addresses in clustering and visualization tasks.\\n131Amazon SageMaker Developer Guide\\nIP Insights\\nTopics\\n•Input/Output Interface for the IP Insights Algorithm (p. 132)\\n•EC2 Instance Recommendation for the IP Insights Algorithm (p. 132)\\n•IP Insights Sample Notebooks  (p. 133)\\n•How IP Insights Works (p. 133)\\n•IP Insights Hyperparameters  (p. 134)\\n•Tune an IP Insights Model  (p. 137)\\n•IP Insights Data Formats (p. 138)\\nInput/Output Interface for the IP Insights Algorithm\\nTraining and Validation\\nThe Amazon SageMaker IP Insights algorithm supports training and validation data channels. It uses\\nthe optional validation channel to compute an area-under-curve (AUC) score on a predeﬁned negative\\nsampling strategy. The AUC metric validates how well the model discriminates between positive and\\nnegative samples. Training and validation data content types need to be in text/csv  format. The ﬁrst\\ncolumn of the CSV data is an opaque string that provides a unique identiﬁer for the entity. The second\\ncolumn is an IPv4 address in decimal-dot notation. IP Insights currently supports only File mode. For\\nmore information and some examples, see IP Insights Training Data Formats (p. 138).\\nInference\\nFor inference, IP Insights supports text/csv , application/json , and application/jsonlines\\ndata content types. For more information about the common data formats for inference provided by\\nAmazon SageMaker, see Common Data Formats for Inference  (p. 68). IP Insights inference returns\\noutput formatted as either application/json  or application/jsonlines . Each record in the\\noutput data contains the corresponding dot_product  (or compatibility score) for each input data point.\\nFor more information and some examples, see IP Insights Inference Data Formats (p. 139).\\nEC2 Instance Recommendation for the IP Insights Algorithm\\nThe Amazon SageMaker IP Insights algorithm can run on both GPU and CPU instances. For training\\njobs, we recommend using GPU instances. However, for certain workloads with large training datasets,\\ndistributed CPU instances might reduce training costs. For inference, we recommend using CPU\\ninstances.\\nGPU Instances for the IP Insights Algorithm\\nIP Insights supports all available GPUs. If you need to speed up training, we recommend starting with\\na single GPU instance, such as ml.p3.2xlarge, and then moving to a multi-GPU environment, such as\\nml.p3.8xlarge and ml.p3.16xlarge. Multi-GPUs automatically divide the mini batches of training data\\nacross themselves. If you switch from a single GPU to multiple GPUs, the mini_batch_size  is divided\\nequally into the number of GPUs used. You may want to increase the value of the mini_batch_size  to\\ncompensate for this.\\nCPU Instances for the IP Insights Algorithm\\nThe type of CPU instance that we recommend depends largely on the instance\\'s available memory\\nand the model size. The model size is determined by two hyperparameters: vector_dim  and\\nnum_entity_vectors . The maximum supported model size is 8 GB. The following table lists typical\\nEC2 instance types that you would deploy based on these input parameters for various model sizes.\\nIn Table 1, the value for vector_dim  in the ﬁrst column range from 32 to 2048 and the values for\\nnum_entity_vectors  in the ﬁrst row range from 10,000 to 50,00,000.\\n132Amazon SageMaker Developer Guide\\nIP Insights\\nvector_dim\\n\\\\\\nnum_entity_vectors .10,000 50,000 100,000 500,000 1,000,000 5,000,000 10,000,000 50,000,000\\n32ml.m5.largeml.m5.large ml.m5.large ml.m5.large ml.m5.large ml.m5.xlarge ml.m5.2xlarge ml.m5.4xlarge\\n64ml.m5.largeml.m5.large ml.m5.large ml.m5.large ml.m5.large ml.m5.2xlarge ml.m5.2xlarge \\xa0\\n128ml.m5.largeml.m5.large ml.m5.large ml.m5.large ml.m5.large ml.m5.2xlarge ml.m5.4xlarge \\xa0\\n256ml.m5.largeml.m5.large ml.m5.large ml.m5.large ml.m5.xlarge ml.m5.4xlarge \\xa0 \\xa0\\n512ml.m5.largeml.m5.large ml.m5.large ml.m5.large ml.m5.2xlarge \\xa0 \\xa0 \\xa0\\n1024ml.m5.largeml.m5.large ml.m5.large ml.m5.xlarge ml.m5.4xlarge \\xa0 \\xa0 \\xa0\\n2048ml.m5.largeml.m5.large ml.m5.xlarge ml.m5.xlarge \\xa0 \\xa0 \\xa0 \\xa0\\nThe values for the mini_batch_size , num_ip_encoder_layers ,\\nrandom_negative_sampling_rate , and shuffled_negative_sampling_rate  hyperparameters\\nalso aﬀect the amount of memory required. If these values are large, you might need to use a larger\\ninstance type than normal.\\nIP Insights Sample Notebooks\\nFor a sample notebook that shows how to train the Amazon SageMaker IP Insights algorithm and\\nperform inferences with it, see An Introduction to the Amazon SageMakerIP Insights Algorithm . For\\ninstructions how to create and access Jupyter notebook instances that you can use to run the example\\nin Amazon SageMaker, see Use Notebook Instances (p. 36). After creating a notebook instance, choose\\nthe SageMaker Examples tab to see a list of all the Amazon SageMaker examples. To open a notebook,\\nchoose its Use tab and choose Create copy.\\nHow IP Insights Works\\nAmazon SageMaker IP Insights is an unsupervised algorithm that consumes observed data in the form\\nof (entity, IPv4 address) pairs that associates entities with IP addresses. IP Insights determines how likely\\nit is that an entity would use a particular IP address by learning latent vector representations for both\\nentities and IP addresses. The distance between these two representations can then serve as the proxy\\nfor how likely this association is.\\nThe IP Insights algorithm uses a neural network to learn the latent vector representations for entities\\nand IP addresses. Entities are ﬁrst hashed to a large but ﬁxed hash space and then encoded by a\\nsimple embedding layer. Character strings such as user names or account IDs can be fed directly into\\nIP Insights as they appear in log ﬁles. You don\\'t need to preprocess the data for entity identiﬁers. You\\ncan provide entities as an arbitrary string value during both training and inference. The hash size should\\nbe conﬁgured with a value that is high enough to insure that the number of collisions , which occur\\nwhen distinct entities are mapped to the same latent vector, remain insigniﬁcant. For more information\\nabout how to select appropriate hash sizes, see Feature Hashing for Large Scale Multitask Learning. For\\nrepresenting IP addresses, on the other hand, IP Insights uses a specially designed encoder network to\\nuniquely represent each possible IPv4 address by exploiting the preﬁx structure of IP addresses.\\nDuring training, IP Insights automatically generates negative samples by randomly pairing entities and\\nIP addresses. These negative samples represent data that is less likely to occur in reality. The model\\nis trained to discriminate between positive samples that are observed in the training data and these\\ngenerated negative samples. More speciﬁcally, the model is trained to minimize the cross entropy , also\\nknown as the log loss , deﬁned as follows:\\n133Amazon SageMaker Developer Guide\\nIP Insights\\nyn is the label that indicates whether the sample is from the real distribution governing observed data\\n(yn=1) or from the distribution generating negative samples (yn=0). p n is the probability that the sample\\nis from the real distribution, as predicted by the model.\\nGenerating negative samples is an important process that is used to achieve an accurate model of\\nthe observed data. If negative samples are extremely unlikely, for example, if all of the IP addresses\\nin negative samples are 10.0.0.0, then the model trivially learns to distinguish negative samples and\\nfails to accurately characterize the actual observed dataset. To keep negative samples more realistic,\\nIP Insights generates negative samples both by randomly generating IP addresses and randomly\\npicking IP addresses from training data. You can conﬁgure the type of negative sampling and the\\nrates at which negative samples are generated with the random_negative_sampling_rate  and\\nshuffled_negative_sampling_rate  hyperparameters.\\nGiven an nth (entity, IP address pair), the IP Insights model outputs a score , Sn , that indicates how\\ncompatible the entity is with the IP address. This score corresponds to the log odds ratio for a given\\n(entity, IP address) of the pair coming from a real distribution as compared to coming from a negative\\ndistribution. It is deﬁned as follows:\\nThe score is essentially a measure of the similarity between the vector representations of the nth entity\\nand IP address. It can be interpreted as how much more likely it would be to observe this event in reality\\nthan in a randomly generated dataset. During training, the algorithm uses this score to calculate an\\nestimate of the probability of a sample coming from the real distribution, pn, to use in the cross entropy\\nminimization, where:\\nIP Insights Hyperparameters\\nIn the CreateTransformJob (p. 673) request, you specify the training algorithm. You can also\\nspecify algorithm-speciﬁc hyperparameters as string-to-string maps. The following table lists the\\nhyperparameters for the Amazon SageMaker IP Insights algorithm.\\nParameter Name Description\\nnum_entity_vectors The number of entity vector representations (entity\\nembedding vectors) to train. Each entity in the training\\nset is randomly assigned to one of these vectors using\\na hash function. Because of hash collisions, it might be\\npossible to have multiple entities assigned to the same\\nvector. This would cause the same vector to represent\\nmultiple entities. This generally has a negligible eﬀect on\\nmodel performance, as long as the collision rate is not\\ntoo severe. To keep the collision rate low, set this value as\\nhigh as possible. However, the model size, and, therefore,\\nthe memory requirement, for both training and inference,\\nscales linearly with this hyperparameter. We recommend\\nthat you set this value to twice the number of unique entity\\nidentiﬁers.\\nRequired\\n134Amazon SageMaker Developer Guide\\nIP Insights\\nParameter Name Description\\nValid values: 1 ≤ positive integer ≤ 250,000,000\\nvector_dim The size of embedding vectors to represent entities and IP\\naddresses. The larger the value, the more information that\\ncan be encoded using these representations. In practice,\\nmodel size scales linearly with this parameter and limits\\nhow large the dimension can be. In addition, using vector\\nrepresentations that are too large can cause the model to\\noverﬁt, especially for small training datasets. Overﬁtting\\noccurs when a model doesn\\'t learn any pattern in the\\ndata but eﬀectively memorizes the training data and,\\ntherefore, cannot generalize well and performs poorly\\nduring inference. The recommended value is 128.\\nRequired\\nValid values: 4 ≤ positive integer ≤ 4096\\nbatch_metrics_publish_interval The interval (every X batches) at which the Apache MXNet\\nSpeedometer function prints the training speed of the\\nnetwork (samples/second).\\nOptional\\nValid values: positive integer ≥ 1\\nDefault value: 1,000\\nepochs The number of passes over the training data. The optimal\\nvalue depends on your data size and learning rate. Typical\\nvalues range from 5 to 100.\\nOptional\\nValid values: positive integer ≥ 1\\nDefault value: 10\\nlearning_rate The learning rate for the optimizer. IP Insights use a\\ngradient-descent-based Adam optimizer. The learning\\nrate eﬀectively controls the step size to update model\\nparameters at each iteration. Too large a learning rate can\\ncause the model to diverge because the training is likely\\nto overshoot a minima. On the other hand, too small a\\nlearning rate slows down convergence. Typical values range\\nfrom 1e-4 to 1e-1.\\nOptional\\nValid values: 1e-6 ≤ ﬂoat ≤ 10.0\\nDefault value: 0.001\\n135Amazon SageMaker Developer Guide\\nIP Insights\\nParameter Name Description\\nmini_batch_size The number of examples in each mini batch. The\\ntraining procedure processes data in mini batches.\\nThe optimal value depends on the number of unique\\naccount identiﬁers in the dataset. In general, the larger\\nthe mini_batch_size , the faster the training and the\\ngreater the number of possible shuﬄed-negative-sample\\ncombinations. However, with a large mini_batch_size ,\\nthe training is more likely to converge to a poor local\\nminimum and perform relatively worse for inference.\\nOptional\\nValid values: 1 ≤ positive integer ≤ 500000\\nDefault value: 10,000\\nnum_ip_encoder_layers The number of fully connected layers used to encode the\\nIP address embedding. The larger the number of layers, the\\ngreater the model\\'s capacity to capture patterns among\\nIP addresses. However, using a large number of layers\\nincreases the chance of overﬁtting.\\nOptional\\nValid values: 0 ≤ positive integer ≤ 100\\nDefault value: 1\\nrandom_negative_sampling_rate The number of random negative samples, R, to generate\\nper input example. The training procedure relies on\\nnegative samples to prevent the vector representations\\nof the model collapsing to a single point. Random\\nnegative sampling generates R random IP addresses\\nfor each input account in the mini batch. The sum of\\nthe random_negative_sampling_rate  (R) and\\nshuffled_negative_sampling_rate  (S) must be in the\\ninterval: 1 ≤ R + S ≤ 500.\\nOptional\\nValid values: 0 ≤ positive integer ≤ 500\\nDefault value: 1\\n136Amazon SageMaker Developer Guide\\nIP Insights\\nParameter Name Description\\nshuffled_negative_sampling_rate The number of shuﬄed negative samples, S, to generate\\nper input example. In some cases, it helps to use more\\nrealistic negative samples that are randomly picked\\nfrom the training data itself. This kind of negative\\nsampling is achieved by shuﬄing the data within a\\nmini batch. Shuﬄed negative sampling generates\\nS negative IP addresses by shuﬄing the IP address\\nand account pairings within a mini batch. The sum\\nof the random_negative_sampling_rate  (R) and\\nshuffled_negative_sampling_rate  (S) must be in the\\ninterval: 1 ≤ R + S ≤ 500.\\nOptional\\nValid values: 0 ≤ positive integer ≤ 500\\nDefault value: 1\\nweight_decay The weight decay coeﬃcient. This parameter adds an L2\\nregularization factor that is required to prevent the model\\nfrom overﬁtting the training data.\\nOptional\\nValid values: 0.0 ≤ ﬂoat ≤ 10.0\\nDefault value: 0.00001\\nTune an IP Insights Model\\nAutomatic model tuning , also called hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the IP Insights Algorithm\\nThe Amazon SageMaker IP Insights algorithm is an unsupervised learning algorithm that learns\\nassociations between IP addresses and entities. The algorithm trains a discriminator model , which\\nlearns to separate observed data points (positive samples ) from randomly generated data points\\n(negative samples ). Automatic model tuning on IP Insights helps you ﬁnd the model that can most\\naccurately distinguish between unlabeled validation data and automatically generated negative samples.\\nThe model accuracy on the validation dataset is measured by the area under the receiver operating\\ncharacteristic (ROC) curve. This validation:discriminator_auc  metric can take values between 0.0\\nand 1.0, where 1.0 indicates perfect accuracy.\\nThe IP Insights algorithm computes a validation:discriminator_auc  metric during validation, the\\nvalue of which is used as the objective function to optimize for hyperparameter tuning.\\n137Amazon SageMaker Developer Guide\\nIP Insights\\nMetric Name Description Optimization Direction\\nvalidation:discriminator_auc Area under the ROC curve on the validation\\ndataset. The validation dataset is not labeled. AUC\\nis a metric that describes the model\\'s ability to\\ndiscriminate validation data points from randomly\\ngenerated data points.Maximize\\nTunable IP Insights Hyperparameters\\nYou can tune the following hyperparameters for the Amazon SageMaker IP Insights algorithm.\\nParameter Name Parameter Type Recommended Ranges\\nepochs IntegerParameterRange MinValue: 1, MaxValue:\\n100\\nlearning_rate ContinuousParameterRange MinValue: 1e-4,\\nMaxValue: 0.1\\nmini_batch_size IntegerParameterRanges MinValue: 100,\\nMaxValue: 50000\\nnum_entity_vectors IntegerParameterRanges MinValue: 10000,\\nMaxValue: 1000000\\nnum_ip_encoder_layers IntegerParameterRanges MinValue: 1, MaxValue:\\n10\\nrandom_negative_sampling_rate IntegerParameterRanges MinValue: 0, MaxValue:\\n10\\nshuffled_negative_sampling_rate IntegerParameterRanges MinValue: 0, MaxValue:\\n10\\nvector_dim IntegerParameterRanges MinValue: 8, MaxValue:\\n256\\nweight_decay ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 1.0\\nIP Insights Data Formats\\nThis section provides examples of the available input and output data formats used by the IP Insights\\nalgorithm during training and inference.\\nTopics\\n•IP Insights Training Data Formats (p. 138)\\n•IP Insights Inference Data Formats (p. 139)\\nIP Insights Training Data Formats\\nThe following are the available data input formats for the IP Insights algorithm. Amazon SageMaker\\nbuilt-in algorithms adhere to the common input training format described in  Common Data Formats for\\n138Amazon SageMaker Developer Guide\\nIP Insights\\nTraining  (p. 64). However, the Amazon SageMaker IP Insights algorithm currently supports only the\\nCSV data input format.\\nIP Insights Training Data Input Formats\\nINPUT: CSV\\nThe CSV ﬁle must have two columns. The ﬁrst column is an opaque string that corresponds to an entity\\'s\\nunique identiﬁer. The second column is the IPv4 address of the entity\\'s access event in decimal-dot\\nnotation.\\ncontent-type: text/csv\\nentity_id_1, 192.168.1.2\\nentity_id_2, 10.10.1.2\\nIP Insights Inference Data Formats\\nThe following are the available input and output formats for the IP Insights algorithm. Amazon\\nSageMaker built-in algorithms adhere to the common input inference format described in Common\\nData Formats for Inference  (p. 68). However, the Amazon SageMaker IP Insights algorithm does not\\ncurrently support RecordIO format.\\nIP Insights Input Request Formats\\nINPUT: CSV Format\\nThe CSV ﬁle must have two columns. The ﬁrst column is an opaque string that corresponds to an entity\\'s\\nunique identiﬁer. The second column is the IPv4 address of the entity\\'s access event in decimal-dot\\nnotation.\\ncontent-type: text/csv\\nentity_id_1, 192.168.1.2\\nentity_id_2, 10.10.1.2\\nINPUT: JSON Format\\nJSON data can be provided in diﬀerent formats. IP Insights follows the common Amazon SageMaker\\nformats. For more information about inference formats, see Common Data Formats for Inference\\n (p. 68).\\ncontent-type: application/json\\n{\\n  \"instances\": [\\n    {\"data\": {\"features\": {\"values\": [\"entity_id_1\", \"192.168.1.2\"]}}},\\n    {\"features\": [\"entity_id_2\", \"10.10.1.2\"]}\\n  ]\\n}\\nINPUT: JSONLINES Format\\nThe JSON Lines content type is useful for running batch transform jobs. For more information on\\nAmazon SageMaker inference formats, see Common Data Formats for Inference  (p. 68). For more\\ninformation on running batch transform jobs, see Get Inferences for an Entire Dataset with Batch\\nTransform (p. 10).\\n139Amazon SageMaker Developer Guide\\nIP Insights\\ncontent-type: application/jsonlines\\n{\"data\": {\"features\": {\"values\": [\"entity_id_1\", \"192.168.1.2\"]}}},\\n{\"features\": [\"entity_id_2\", \"10.10.1.2\"]}]\\nIP Insights Output Response Formats\\nOUTPUT: JSON Response Format\\nThe default output of the Amazon SageMaker IP Insights algorithm is the dot_product  between\\nthe input entity and IP address. The dot_product signiﬁes how compatible the model considers the\\nentity and IP address. The dot_product  is unbounded. To make predictions about whether an event is\\nanomalous, you need to set a threshold based on your deﬁned distribution. For information about how\\nto use the dot_product  for anomaly detection, see the An Introduction to the Amazon SageMakerIP\\nInsights Algorithm .\\naccept: application/json\\n{\\n  \"predictions\": [\\n    {\"dot_product\": 0.0},\\n    {\"dot_product\": 2.0}\\n  ]\\n}\\nAdvanced users can access the model\\'s learned entity and IP embeddings by providing the additional\\ncontent-type parameter verbose=True  to the Accept heading. You can use the entity_embedding\\nand ip_embedding  for debugging, visualizing, and understanding the model. Additionally, you can use\\nthese embeddings in other machine learning techniques, such as classiﬁcation or clustering.\\naccept: application/json;verbose=True\\n{\\n  \"predictions\": [\\n    {\\n        \"dot_product\": 0.0,\\n        \"entity_embedding\": [1.0, 0.0, 0.0],\\n        \"ip_embedding\": [0.0, 1.0, 0.0]\\n    },\\n    {\\n        \"dot_product\": 2.0,\\n        \"entity_embedding\": [1.0, 0.0, 1.0],\\n        \"ip_embedding\": [1.0, 0.0, 1.0]\\n    }\\n  ]\\n}\\nOUTPUT: JSONLINES Response Format\\naccept: application/jsonlines\\n{\"dot_product\": 0.0}\\n{\"dot_product\": 2.0}\\naccept: application/jsonlines; verbose=True\\n{\"dot_product\": 0.0, \"entity_embedding\": [1.0, 0.0, 0.0], \"ip_embedding\": [0.0, 1.0, 0.0]}\\n{\"dot_product\": 2.0, \"entity_embedding\": [1.0, 0.0, 1.0], \"ip_embedding\": [1.0, 0.0, 1.0]}\\n140Amazon SageMaker Developer Guide\\nK-Means Algorithm\\nK-Means Algorithm\\nK-means is an unsupervised learning algorithm. It attempts to ﬁnd discrete groupings within data, where\\nmembers of a group are as similar as possible to one another and as diﬀerent as possible from members\\nof other groups. You deﬁne the attributes that you want the algorithm to use to determine similarity.\\nAmazon SageMaker uses a modiﬁed version of the web-scale k-means clustering algorithm. Compared\\nwith the original version of the algorithm, the version used by Amazon SageMaker is more accurate.\\nLike the original algorithm, it scales to massive datasets and delivers improvements in training time. To\\ndo this, the version used by Amazon SageMaker streams mini-batches (small, random subsets) of the\\ntraining data. For more information about mini-batch k-means, see Web-scale k-means Clustering.\\nThe k-means algorithm expects tabular data, where rows represent the observations that you want to\\ncluster, and the columns represent attributes of the observations. The n attributes in each row represent\\na point in n-dimensional space. The Euclidean distance between these points represents the similarity\\nof the corresponding observations. The algorithm groups observations with similar attribute values (the\\npoints corresponding to these observations are closer together). For more information about how k-\\nmeans works in Amazon SageMaker, see How K-Means Clustering Works (p. 142).\\nTopics\\n•Input/Output Interface for the K-Means Algorithm (p. 141)\\n•EC2 Instance Recommendation for the K-Means Algorithm (p. 141)\\n•K-Means Sample Notebooks (p. 141)\\n•How K-Means Clustering Works (p. 142)\\n•K-Means Hyperparameters (p. 144)\\n•Tune a K-Means Model (p. 147)\\n•K-Means Response Formats (p. 147)\\nInput/Output Interface for the K-Means Algorithm\\nFor training, the k-means algorithm expects data to be provided in the train  channel (recommended\\nS3DataDistributionType=ShardedByS3Key ), with an optional test channel (recommended\\nS3DataDistributionType=FullyReplicated ) to score the data on. Both recordIO-wrapped-\\nprotobuf  and CSV formats are supported for training. You can use either File mode or Pipe mode to\\ntrain models on data that is formatted as recordIO-wrapped-protobuf  or as CSV.\\nFor inference, text/csv , application/json , and application/x-recordio-protobuf  are\\nsupported. k-means returns a closest_cluster  label and the distance_to_cluster  for each\\nobservation.\\nFor more information on input and output ﬁle formats, see K-Means Response Formats (p. 147) for\\ninference and the K-Means Sample Notebooks (p. 141). The k-means algorithm does not support\\nmultiple instance learning, in which the training set consists of labeled “bags”, each of which is a\\ncollection of unlabeled instances.\\nEC2 Instance Recommendation for the K-Means Algorithm\\nWe recommend training k-means on CPU instances. You can train on GPU instances, but should limit\\nGPU training to p*.xlarge  instances because only one GPU per instance is used.\\nK-Means Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker K-means algorithm to segment the population\\nof counties in the United States by attributes identiﬁed using principle component analysis, see Analyze\\n141Amazon SageMaker Developer Guide\\nK-Means Algorithm\\nUS census data for population segmentation using Amazon SageMaker. For instructions how to create\\nand access Jupyter notebook instances that you can use to run the example in Amazon SageMaker, see\\nUse Notebook Instances (p. 36). Once you have created a notebook instance and opened it, select the\\nSageMaker Examples tab to see a list of all the Amazon SageMaker samples. To open a notebook, click\\non its Use tab and select Create copy.\\nHow K-Means Clustering Works\\nK-means is an algorithm that trains a model that groups similar objects together. The k-means algorithm\\naccomplishes this by mapping each observation in the input dataset to a point in the n-dimensional\\nspace (where n is the number of attributes of the observation). For example, your dataset might contain\\nobservations of temperature and humidity in a particular location, which are mapped to points (t, h) in 2-\\ndimensional space.\\nNote\\nClustering algorithms are unsupervised. In unsupervised learning, labels that might be\\nassociated with the objects in the training dataset aren\\'t used.\\nIn k-means clustering, each cluster has a center. During model training, the k-means algorithm uses the\\ndistance of the point that corresponds to each observation in the dataset to the cluster centers as the\\nbasis for clustering. You choose the number of clusters (k) to create.\\nFor example, suppose that you want to create a model to recognize handwritten digits and you choose\\nthe MNIST dataset for training. The dataset provides thousands of images of handwritten digits (0\\nthrough 9). In this example, you might choose to create 10 clusters, one for each digit (0, 1, …, 9). As\\npart of model training, the k-means algorithm groups the input images into 10 clusters.\\nEach image in the MNIST dataset is a 28x28-pixel image, with a total of 784 pixels. Each image\\ncorresponds to a point in a 784-dimensional space, similar to a point in a 2-dimensional space (x,y). To\\nﬁnd a cluster to which a point belongs, the k-means algorithm ﬁnds the distance of that point from all of\\nthe cluster centers. It then chooses the cluster with the closest center as the cluster to which the image\\nbelongs.\\nNote\\nAmazon SageMaker uses a customized version of the algorithm where, instead of specifying that\\nthe algorithm create k clusters, you might choose to improve model accuracy by specifying extra\\ncluster centers (K = k*x) . However, the algorithm ultimately reduces these to k clusters.\\nIn Amazon SageMaker, you specify the number of clusters when creating a training job. For more\\ninformation, see CreateTrainingJob (p. 667). In the request body, you add the HyperParameters\\nstring map to specify the k and extra_center_factor  strings.\\nThe following is a summary of how k-means works for model training in Amazon SageMaker:\\n1.It determines the initial K cluster centers.\\nNote\\nIn the following topics, K clusters refer to k * x, where you specify k and x when creating a\\nmodel training job.\\n2.It iterates over input training data and recalculates cluster centers.\\n3.It reduces resulting clusters to k (if the data scientist speciﬁed the creation of k*x clusters in the\\nrequest).\\nThe following sections also explain some of the parameters that a data scientist might specify to\\nconﬁgure a model training job as part of the HyperParameters  string map.\\nTopics\\n142Amazon SageMaker Developer Guide\\nK-Means Algorithm\\n•Step 1: Determine the Initial Cluster Centers  (p. 143)\\n•Step 2: Iterate over the Training Dataset and Calculate Cluster Centers (p. 143)\\n•Step 3: Reduce the Clusters from K to k (p. 144)\\nStep 1: Determine the Initial Cluster Centers\\nWhen using k-means in Amazon SageMaker, the initial cluster centers are chosen from the observations\\nin a small, randomly sampled batch. Choose one of the following strategies to determine how these\\ninitial cluster centers are selected:\\n•The random approach—Randomly choose K observations in your input dataset as cluster centers. For\\nexample, you might choose a cluster center that points to the 784-dimensional space that corresponds\\nto any 10 images in the MNIST training dataset.\\n\\xa0\\n•The k-means++ approach, which works as follows:\\n1.Start with one cluster and determine its center. You randomly select an observation from your\\ntraining dataset and use the point corresponding to the observation as the cluster center. For\\nexample, in the MNIST dataset, randomly choose a handwritten digit image. Then choose the point\\nin the 784-dimensional space that corresponds to the image as your cluster center. This is cluster\\ncenter 1.\\n2.Determine the center for cluster 2. From the remaining observations in the training dataset, pick\\nan observation at random. Choose one that is diﬀerent than the one you previously selected. This\\nobservation corresponds to a point that is far away from cluster center 1. Using the MNIST dataset\\nas an example, you do the following:\\n•For each of the remaining images, ﬁnd the distance of the corresponding point from cluster\\ncenter 1. Square the distance and assign a probability that is proportional to the square of the\\ndistance. That way, an image that is diﬀerent from the one that you previously selected has a\\nhigher probability of getting selected as cluster center 2.\\n•Choose one of the images randomly, based on probabilities assigned in the previous step. The\\npoint that corresponds to the image is cluster center 2.\\n3.Repeat Step 2 to ﬁnd cluster center 3. This time, ﬁnd the distances of the remaining images from\\ncluster center 2.\\n4.Repeat the process until you have the K cluster centers.\\nTo train a model in Amazon SageMaker, you create a training job. In the request, you provide\\nconﬁguration information by specifying the following HyperParameters  string maps:\\n•To specify the number of clusters to create, add the k string.\\n•For greater accuracy, add the optional extra_center_factor  string.\\n•To specify the strategy that you want to use to determine the initial cluster centers, add the\\ninit_method  string and set its value to random  or k-means++ .\\nFor more information, see CreateTrainingJob (p. 667). For an example, see Create and Run a Training\\nJob (AWS SDK for Python (Boto 3)) (p. 23).\\nYou now have an initial set of cluster centers.\\nStep 2: Iterate over the Training Dataset and Calculate Cluster Centers\\nThe cluster centers that you created in the preceding step are mostly random, with some consideration\\nfor the training dataset. In this step, you use the training dataset to move these centers toward the true\\ncluster centers. The algorithm iterates over the training dataset, and recalculates the K cluster centers.\\n143Amazon SageMaker Developer Guide\\nK-Means Algorithm\\n1. Read a mini-batch of observations (a small, randomly chosen subset of all records) from the training\\ndataset and do the following.\\nNote\\nWhen creating a model training job, you specify the batch size in the mini_batch_size\\nstring in the HyperParameters  string map.\\na. Assign all of the observations in the mini-batch to one of the clusters with the closest cluster\\ncenter.\\nb. Calculate the number of observations assigned to each cluster. Then, calculate the proportion of\\nnew points assigned per cluster.\\nFor example, consider the following clusters:\\nCluster c1 = 100 previously assigned points. You added 25 points from the mini-batch in this\\nstep.\\nCluster c2 = 150 previously assigned points. You added 40 points from the mini-batch in this\\nstep.\\nCluster c3 = 450 previously assigned points. You added 5 points from the mini-batch in this\\nstep.\\nCalculate the proportion of new points assigned to each of clusters as follows:\\np1 = proportion of points assigned to c1 = 25/(100+25)\\np2 = proportion of points assigned to c2 = 40/(150+40)\\np3 = proportion of points assigned to c3 = 5/(450+5)\\nc. Compute the center of the new points added to each cluster:\\nd1 = center of the new points added to cluster 1\\nd2 = center of the new points added to cluster 2\\nd3 = center of the new points added to cluster 3\\nd. Compute the weighted average to ﬁnd the updated cluster centers as follows:\\nCenter of cluster 1 = ((1 - p1) * center of cluster 1) + (p1 * d1)\\nCenter of cluster 2 = ((1 - p2) * center of cluster 2) + (p2 * d2)\\nCenter of cluster 3 = ((1 - p3) * center of cluster 3) + (p3 * d3)\\n2. Read the next mini-batch, and repeat Step 1 to recalculate the cluster centers.\\n3. For more information about mini-batch k-means, see Web-Scale k-means Clustering ).\\nStep 3: Reduce the Clusters from K to k\\nIf the algorithm created K clusters— (K = k*x)  where x is greater than 1—then it reduces the K clusters to\\nk clusters. (For more information, see extra_center_factor  in the preceding discussion.) It does this\\nby applying Lloyd\\'s method with kmeans++  initialization to the K cluster centers. For more information\\nabout Lloyd\\'s method, see k-means clustering.\\nK-Means Hyperparameters\\nIn the CreateTrainingJob (p. 667) request, you specify the training algorithm that you want to use.\\nYou can also specify algorithm-speciﬁc hyperparameters as string-to-string maps. The following table\\nlists the hyperparameters for the k-means training algorithm provided by Amazon SageMaker. For more\\ninformation about how k-means clustering works, see How K-Means Clustering Works (p. 142).\\n144Amazon SageMaker Developer Guide\\nK-Means Algorithm\\nParameter Name Description\\nfeature_dim The number of features in the input data.\\nRequired\\nValid values: Positive integer\\nk The number of required clusters.\\nRequired\\nValid values: Positive integer\\nepochs The number of passes done over the training data.\\nOptional\\nValid values: Positive integer\\nDefault value: 1\\neval_metrics A JSON list of metric types used to report a score for the model.\\nAllowed values are msd for Means Square Error and ssd for Sum of\\nSquare Distance. If test data is provided, the score is reported for\\neach of the metrics requested.\\nOptional\\nValid values: Either [\\\\\"msd\\\\\"]  or [\\\\\"ssd\\\\\"]  or [\\\\\"msd\\\\\",\\n\\\\\"ssd\\\\\"]  .\\nDefault value: [\\\\\"msd\\\\\"]\\nextra_center_factor The algorithm creates K centers = num_clusters  *\\nextra_center_factor  as it runs and reduces the number of\\ncenters from K to k when ﬁnalizing the model.\\nOptional\\nValid values: Either a positive integer or auto .\\nDefault value: auto\\nhalf_life_time_size Used to determine the weight given to an observation when\\ncomputing a cluster mean. This weight decays exponentially as\\nmore points are observed. When a point is ﬁrst observed, it is\\nassigned a weight of 1 when computing the cluster mean. The\\ndecay constant for the exponential decay function is chosen so that\\nafter observing half_life_time_size  points, its weight is 1/2. If\\nset to 0, there is no decay.\\nOptional\\nValid values: Non-negative integer\\nDefault value: 0\\ninit_method Method by which the algorithm chooses the initial cluster centers.\\nThe standard k-means approach chooses them at random. An\\n145Amazon SageMaker Developer Guide\\nK-Means Algorithm\\nParameter Name Description\\nalternative k-means++ method chooses the ﬁrst cluster center at\\nrandom. Then it spreads out the position of the remaining initial\\nclusters by weighting the selection of centers with a probability\\ndistribution that is proportional to the square of the distance of the\\nremaining data points from existing centers.\\nOptional\\nValid values: Either random  or kmeans++ .\\nDefault value: random\\nlocal_lloyd_init_method The initialization method for Lloyd\\'s expectation-maximization (EM)\\nprocedure used to build the ﬁnal model containing k centers.\\nOptional\\nValid values: Either random  or kmeans++ .\\nDefault value: kmeans++\\nlocal_lloyd_max_iter The maximum number of iterations for Lloyd\\'s expectation-\\nmaximization (EM) procedure used to build the ﬁnal model\\ncontaining k centers.\\nOptional\\nValid values: Positive integer\\nDefault value: 300\\nlocal_lloyd_num_trials The number of times the Lloyd\\'s expectation-maximization (EM)\\nprocedure with the least loss is run when building the ﬁnal model\\ncontaining k centers.\\nOptional\\nValid values: Either a positive integer or auto .\\nDefault value: auto\\nlocal_lloyd_tol The tolerance for change in loss for early stopping of Lloyd\\'s\\nexpectation-maximization (EM) procedure used to build the ﬁnal\\nmodel containing k centers.\\nOptional\\nValid values: Float. Range in [0, 1].\\nDefault value: 0.0001\\nmini_batch_size The number of observations per mini-batch for the data iterator.\\nOptional\\nValid values: Positive integer\\nDefault value: 5000\\n146Amazon SageMaker Developer Guide\\nK-Means Algorithm\\nTune a K-Means Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nThe Amazon SageMaker k-means algorithm is an unsupervised algorithm that groups data into clusters\\nwhose members are as similar as possible. Because it is unsupervised, it doesn\\'t use a validation dataset\\nthat hyperparameters can optimize against. But it does take a test dataset and emits metrics that depend\\non the squared distance between the data points and the ﬁnal cluster centroids at the end of each\\ntraining run. To ﬁnd the model that reports the tightest clusters on the test dataset, you can use a\\nhyperparameter tuning job. The clusters optimize the similarity of their members.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the K-Means Algorithm\\nThe k-means algorithm computes the following metrics during training. When tuning a model, choose\\none of these metrics as the objective metric.\\nMetric Name Description Optimization Direction\\ntest:msd Mean squared distances between each record in\\nthe test set and the closest center of the model.Minimize\\ntest:ssd Sum of the squared distances between each\\nrecord in the test set and the closest center of the\\nmodel.Minimize\\nTunable K-Means Hyperparameters\\nTune the Amazon SageMaker k-means model with the following hyperparameters. The\\nhyperparameters that have the greatest impact on k-means objective metrics are: mini_batch_size ,\\nextra_center_factor , and init_method . Tuning the hyperparameter epochs generally results in\\nminor improvements.\\nParameter Name Parameter Type Recommended Ranges\\nepochs IntegerParameterRanges MinValue: 1,\\nMaxValue:10\\nextra_center_factor IntegerParameterRanges MinValue: 4,\\nMaxValue:10\\ninit_method CategoricalParameterRanges [\\'kmeans++\\', \\'random\\']\\nmini_batch_size IntegerParameterRanges MinValue: 3000,\\nMaxValue:15000\\nK-Means Response Formats\\nAll Amazon SageMaker built-in algorithms adhere to the common input inference format described\\nin Common Data Formats - Inference. This topic contains a list of the available output formats for the\\nAmazon SageMaker k-means algorithm.\\n147Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\nJSON Response Format\\n{\\n    \"predictions\": [\\n        {\\n            \"closest_cluster\": 1.0,\\n            \"distance_to_cluster\": 3.0,\\n        },\\n        {\\n            \"closest_cluster\": 2.0,\\n            \"distance_to_cluster\": 5.0,\\n        },\\n \\n        ....\\n    ]\\n}\\nJSONLINES Response Format\\n{\"closest_cluster\": 1.0, \"distance_to_cluster\": 3.0}\\n{\"closest_cluster\": 2.0, \"distance_to_cluster\": 5.0}\\nRECORDIO Response Format\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'closest_cluster\\': {\\n                keys: [],\\n                values: [1.0, 2.0]  # float32\\n            },\\n            \\'distance_to_cluster\\': {\\n                keys: [],\\n                values: [3.0, 5.0]  # float32\\n            },\\n        }\\n    }\\n]\\nK-Nearest Neighbors (k-NN) Algorithm\\nAmazon SageMaker k-nearest neighbors (k-NN) algorithm is an index-based algorithm. It uses a non-\\nparametric method for classiﬁcation or regression. For classiﬁcation problems, the algorithm queries the\\nk points that are closest to the sample point and returns the most frequently used label of their class as\\nthe predicted label. For regression problems, the algorithm queries the k closest points to the sample\\npoint and returns the average of their feature values as the predicted value.\\nTraining with the k-NN algorithm has three steps: sampling, dimension reduction, and index building.\\nSampling reduces the size of the initial dataset so that it ﬁts into memory. For dimension reduction,\\nthe algorithm decreases the feature dimension of the data to reduce the footprint of the k-NN model\\nin memory and inference latency. We provide two methods of dimension reduction methods: random\\nprojection and the fast Johnson-Lindenstrauss transform. Typically, you use dimension reduction for\\nhigh-dimensional (d >1000) datasets to avoid the “curse of dimensionality” that troubles the statistical\\nanalysis of data that becomes sparse as dimensionality increases. The main objective of k-NN\\'s training is\\nto construct the index. The index enables eﬃcient lookups of distances between points whose values or\\nclass labels have not yet been determined and the k nearest points to use for inference.\\nTopics\\n148Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\n•Input/Output Interface for the k-NN Algorithm (p. 149)\\n•k-NN Sample Notebooks (p. 149)\\n•How the K-nn Algorithm Works (p. 150)\\n•EC2 Instance Recommendation for the K-nn Algorithm (p. 151)\\n•K-nn Hyperparameters (p. 151)\\n•Tune a K-nn Model (p. 152)\\n•Data Formats for K-nn Training Input (p. 154)\\n•K-nn Request and Response Formats (p. 154)\\nInput/Output Interface for the k-NN Algorithm\\nAmazon SageMaker k-NN supports train and test data channels.\\n•Use a train channel  for data that you want to sample and construct into the k-NN index.\\n•Use a test channel  to emit scores in log ﬁles. Scores are listed as one line per mini-batch: accuracy for\\nclassifier , mean-squared error (mse) for regressor  for score.\\nFor training inputs, k-NN supports text/csv  and application/x-recordio-protobuf  data\\nformats. For input type text/csv , the ﬁrst label_size  columns are interpreted as the label vector\\nfor that row. You can use either File mode or Pipe mode to train models on data that is formatted as\\nrecordIO-wrapped-protobuf  or as CSV.\\nFor inference inputs, k-NN supports the application/json , application/x-recordio-protobuf ,\\nand text/csv  data formats. The text/csv  format accepts a label_size  and encoding parameter. It\\nassumes a label_size  of 0 and a UTF-8 encoding.\\nFor inference outputs, k-NN supports the application/json  and application/x-recordio-\\nprotobuf  data formats. These two data formats also support a verbose output mode. In verbose output\\nmode, the API provides the search results with the distances vector sorted from smallest to largest, and\\ncorresponding elements in the labels vector.\\nFor batch transform, k-NN supports the application/jsonlines  data format for both input and\\noutput. An example input is as follows:\\ncontent-type: application/jsonlines\\n{\"features\": [1.5, 16.0, 14.0, 23.0]}\\n{\"data\": {\"features\": {\"values\": [1.5, 16.0, 14.0, 23.0]}}\\nAn example output is as follows:\\naccept: application/jsonlines\\n{\"predicted_label\": 0.0}\\n{\"predicted_label\": 2.0}\\nFor more information on input and output ﬁle formats, see Data Formats for K-nn Training\\nInput  (p. 154) for training, K-nn Request and Response Formats (p. 154) for inference, and the k-NN\\nSample Notebooks  (p. 149).\\nk-NN Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker k-nearest neighbor algorithm to predict\\nwilderness cover types from geological and forest service data, see the K-Nearest Neighbor Covertype\\n149Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\n. For instructions how to create and access Jupyter notebook instances that you can use to run\\nthe example in Amazon SageMaker, see Use Notebook Instances (p. 36). Once you have created a\\nnotebook instance and opened it, select the SageMaker Examples tab to see a list of all the Amazon\\nSageMaker samples. The topic modeling example notebooks using the NTM algorithms are located in the\\nIntroduction to Amazon algorithms section. To open a notebook, click on its Use tab and select Create\\ncopy.\\nHow the K-nn Algorithm Works\\nStep 1: Sample\\nTo specify the total number of data points to be sampled from the training dataset, use the\\nsample_size parameter. For example, if the initial dataset has 1,000 data points and the sample_size\\nis set to 100, where the total number of instances is 2, each worker would sample 50 points. A total set\\nof 100 data points would be collected. Sampling runs in linear time with respect to the number of data\\npoints.\\nStep 2: Perform Dimension Reduction\\nThe current implementation of k-NN has two methods of dimension reduction. You specify the method\\nin the dimension_reduction_type  hyperparameter. The sign method speciﬁes a random projection,\\nwhich uses a linear projection using a matrix of random signs, and the fjlt  method speciﬁes a fast\\nJohnson-Lindenstrauss transform, a method based on the Fourier transform. Both methods preserve the\\nL2 and inner product distances. The fjlt method should be used when the target dimension is large\\nand has better performance with CPU inference. The methods diﬀer in their computational complexity.\\nThe sign method requires O(ndk) time to reduce the dimension of a batch of n points of dimension d\\ninto a target dimension k. The fjlt method requires O(nd log(d)) time, but the constants involved are\\nlarger. Using dimension reduction introduces noise into the data and this noise can reduce prediction\\naccuracy.\\nStep 3: Build an Index\\nDuring inference, the algorithm queries the index for the k-nearest-neighbors of a sample point. Based\\non the references to the points, the algorithm makes the classiﬁcation or regression prediction. It makes\\nthe prediction based on the class labels or values provided. k-NN provides three diﬀerent types of\\nindexes: a ﬂat index, an inverted index, and an inverted index with product quantization. You specify the\\ntype with the index_type  parameter.\\nSerialize the Model\\nWhen the k-NN algorithm ﬁnishes training, it serializes three ﬁles to prepare for inference.\\n•model_algo-1: Contains the serialized index for computing the nearest neighbors.\\n•model_algo-1.labels: Contains serialized labels (np.ﬂoat32 binary format) for computing the predicted\\nlabel based on the query result from the index.\\n•model_algo-1.json: Contains the JSON-formatted model metadata which stores the k and\\npredictor_type  hyper-parameters from training for inference along with other relevant state.\\nWith the current implementation of k-NN, you can modify the metadata ﬁle to change the way\\npredictions are computed. For example, you can change k to 10 or change predictor_type  to\\nregressor .\\n{\\n  \"k\": 5,\\n  \"predictor_type\": \"classifier\",\\n  \"dimension_reduction\": {\"type\": \"sign\", \"seed\": 3, \"target_dim\": 10, \"input_dim\": 20},\\n  \"normalize\": False,\\n150Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\n  \"version\": \"1.0\"\\n}\\nEC2 Instance Recommendation for the K-nn Algorithm\\nInstance Recommendation for Training with the K-nn Algorithm\\nTo start, try running training on a CPU, using, for example, an ml.m5.2xlarge instance, or on a GPU using,\\nfor example, an ml.p2.xlarge instance.\\nInstance Recommendation for Inference with the K-nn Algorithm\\nInference requests from CPUs generally have a lower average latency than requests from GPUs because\\nthere is a tax on CPU-to-GPU communication when you use GPU hardware. However, GPUs generally\\nhave higher throughput for larger batches.\\nK-nn Hyperparameters\\nParameter Name Description\\nfeature_dim The number of features in the input data.\\nRequired\\nValid values: positive integer.\\nk The number of nearest neighbors.\\nRequired\\nValid values: positive integer\\npredictor_type The type of inference to use on the data labels.\\nRequired\\nValid values: classiﬁer  for classiﬁcation or regressor  for regression.\\nsample_size The number of data points to be sampled from the training data set.\\nRequired\\nValid values: positive integer\\ndimension_reduction_target The target dimension to reduce to.\\nRequired when you specify the dimension_reduction_type\\nparameter.\\nValid values: positive integer greater than 0 and less than feature_dim .\\ndimension_reduction_type The type of dimension reduction method.\\nOptional\\nValid values: sign for random projection or fjlt for the fast Johnson-\\nLindenstrauss transform.\\nDefault value: No dimension reduction\\n151Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\nParameter Name Description\\nfaiss_index_ivf_nlists The number of centroids to construct in the index when index_type  is\\nfaiss.IVFFlat  or faiss.IVFPQ .\\nOptional\\nValid values: positive integer\\nDefault value: auto , which resolves to sqrt(sample_size) .\\nfaiss_index_pq_m The number of vector sub-components to construct in the index when\\nindex_type  is set to faiss.IVFPQ .\\nThe FaceBook AI Similarity Search (FAISS) library requires that the\\nvalue of faiss_index_pq_m  is a divisor of the data dimension. If\\nfaiss_index_pq_m  is not a divisor of the data dimension, we increase\\nthe data dimension to smallest integer divisible by faiss_index_pq_m .\\nIf no dimension reduction is applied, the algorithm adds a padding of\\nzeros. If dimension reduction is applied, the algorithm increase the value\\nof the dimension_reduction_target  hyper-parameter.\\nOptional\\nValid values: One of the following positive integers: 1, 2, 3, 4, 8, 12, 16,\\n20, 24, 28, 32, 40, 48, 56, 64, 96\\nindex_metric The metric to measure the distance between points when ﬁnding nearest\\nneighbors. When training with index_type  set to faiss.IVFPQ , the\\nINNER_PRODUCT  distance and COSINE similarity are not supported.\\nOptional\\nValid values: L2 for Euclidean-distance, INNER_PRODUCT for inner-\\nproduct distance, COSINE for cosine similarity.\\nDefault value: L2\\nindex_type The type of index.\\nOptional\\nValid values: faiss.Flat , faiss.IVFFlat , faiss.IVFPQ .\\nDefault values: faiss.Flat\\nmini_batch_size The number of observations per mini-batch for the data iterator.\\nOptional\\nValid values: positive integer\\nDefault value: 5000\\nTune a K-nn Model\\nThe Amazon SageMaker k-nearest neighbors algorithm is a supervised algorithm. The algorithm\\nconsumes a test data set and emits a metric about the accuracy for a classiﬁcation task or about the\\nmean squared error for a regression task. These accuracy metrics compare the model predictions for\\n152Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\ntheir respective task to the ground truth provided by the empirical test data. To ﬁnd the best model that\\nreports the highest accuracy or lowest error on the test dataset, run a hyperparameter tuning job for k-\\nNN.\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective\\nmetric appropriate for the prediction task of the algorithm. Automatic model tuning searches the\\nhyperparameters chosen to ﬁnd the combination of values that result in the model that optimizes the\\nobjective metric. The hyperparameters are used only to help estimate model parameters and are not\\nused by the trained model to make predictions.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the K-nn Algorithm\\nThe k-nearest neighbors algorithm computes one of two metrics in the following table during training\\ndepending on the type of task speciﬁed by the predictor_type  hyper-parameter.\\n•classiﬁer  speciﬁes a classiﬁcation task and computes test:accuracy\\n•regressor  speciﬁes a regression task and computes test:mse .\\nChoose the predictor_type  value appropriate for the type of task undertaken to calculate the\\nrelevant objective metric when tuning a model.\\nMetric Name Description Optimization Direction\\ntest:accuracy When predictor_type  is set to classiﬁer , k-\\nNN compares the predicted label, based on the\\naverage of the k-nearest neighbors\\' labels, to the\\nground truth label provided in the test channel\\ndata. The accuracy reported ranges from 0.0 (0%)\\nto 1.0 (100%).Maximize\\ntest:mse When predictor_type  is set to regressor , k-\\nNN compares the predicted label, based on the\\naverage of the k-nearest neighbors\\' labels, to the\\nground truth label provided in the test channel\\ndata. The mean squared error is computed by\\ncomparing the two labels.Minimize\\nTunable K-nn Hyperparameters\\nTune the Amazon SageMaker k-nearest neighbor model with the following hyperparameters.\\nParameter Name Parameter Type Recommended Ranges\\nk IntegerParameterRanges MinValue: 1, MaxValue:\\n1024\\nsample_size IntegerParameterRanges MinValue: 256,\\nMaxValue: 20000000\\n153Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\nData Formats for K-nn Training Input\\nAll Amazon SageMaker built-in algorithms adhere to the common input training formats described in\\nCommon Data Formats - Training. This topic contains a list of the available input formats for the Amazon\\nSageMaker k-nearest-neighbor algorithm.\\nCSV Data Format\\ncontent-type: text/csv; label_size=1\\n4,1.2,1.3,9.6,20.3\\nThe ﬁrst label_size  columns are interpreted as the label vector for that row.\\nRECORDIO Data Format\\ncontent-type: application/x-recordio-protobuf\\n[\\n    Record = {\\n        features = {\\n            \\'values\\': {\\n                values: [1.2, 1.3, 9.6, 20.3]  # float32\\n            }\\n        },\\n        label = {\\n            \\'values\\': {\\n                values: [4]  # float32\\n            }\\n        }\\n    }\\n] \\n                \\n}\\nK-nn Request and Response Formats\\nAll Amazon SageMaker built-in algorithms adhere to the common input inference format described\\nin Common Data Formats - Inference. This topic contains a list of the available output formats for the\\nAmazon SageMaker k-nearest-neighbor algorithm.\\nINPUT: CSV Request Format\\ncontent-type: text/csv\\n1.2,1.3,9.6,20.3\\nThis accepts a label_size  or encoding parameter. It assumes a label_size  of 0 and a utf-8 encoding.\\nINPUT: JSON Request Format\\ncontent-type: application/json\\n{\\n  \"instances\": [\\n    {\"data\": {\"features\": {\"values\": [-3, -1, -4, 2]}}},\\n    {\"features\": [3.0, 0.1, 0.04, 0.002]}]\\n154Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\n}\\nINPUT: JSONLINES Request Format\\ncontent-type: application/jsonlines\\n{\"features\": [1.5, 16.0, 14.0, 23.0]}\\n{\"data\": {\"features\": {\"values\": [1.5, 16.0, 14.0, 23.0]}}\\nINPUT: RECORDIO Request Format\\ncontent-type: application/x-recordio-protobuf\\n[\\n    Record = {\\n        features = {\\n            \\'values\\': {\\n                values: [-3, -1, -4, 2]  # float32\\n            }\\n        },\\n        label = {}\\n    },\\n    Record = {\\n        features = {\\n            \\'values\\': {\\n                values: [3.0, 0.1, 0.04, 0.002]  # float32\\n            }\\n        },\\n        label = {}\\n    },\\n] \\nOUTPUT: JSON Response Format\\naccept: application/json\\n{\\n  \"predictions\": [\\n    {\"predicted_label\": 0.0},\\n    {\"predicted_label\": 2.0}\\n  ]\\n}\\nOUTPUT: JSONLINES Response Format\\naccept: application/jsonlines\\n{\"predicted_label\": 0.0}\\n{\"predicted_label\": 2.0}\\nOUTPUT: VERBOSE JSON Response Format\\nIn verbose mode, the API provides the search results with the distances vector sorted from smallest to\\nlargest, with corresponding elements in the labels vector. In this example, k is set to 3.\\naccept: application/json; verbose=true\\n{\\n  \"predictions\": [\\n155Amazon SageMaker Developer Guide\\nK-Nearest Neighbors (k-NN) Algorithm\\n    {\\n        \"predicted_label\": 0.0,\\n        \"distances\": [3.11792408, 3.89746071, 6.32548437],\\n        \"labels\": [0.0, 1.0, 0.0]\\n    },\\n    {\\n        \"predicted_label\": 2.0,\\n        \"distances\": [1.08470316, 3.04917915, 5.25393973],\\n        \"labels\": [2.0, 2.0, 0.0]\\n    }\\n  ]\\n}\\nOUTPUT: RECORDIO-PROTOBUF Response Format\\ncontent-type: application/x-recordio-protobuf\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'predicted_label\\': {\\n                values: [0.0]  # float32\\n            }\\n        }\\n    },\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'predicted_label\\': {\\n                values: [2.0]  # float32\\n            }\\n        }\\n    }\\n]\\nOUTPUT: VERBOSE RECORDIO-PROTOBUF Response Format\\nIn verbose mode, the API provides the search results with the distances vector sorted from smallest to\\nlargest, with corresponding elements in the labels vector. In this example, k is set to 3.\\naccept: application/x-recordio-protobuf; verbose=true\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'predicted_label\\': {\\n                values: [0.0]  # float32\\n            },\\n            \\'distances\\': {\\n                values: [3.11792408, 3.89746071, 6.32548437]  # float32\\n            },\\n            \\'labels\\': {\\n                values: [0.0, 1.0, 0.0]  # float32\\n            }\\n        }\\n    },\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'predicted_label\\': {\\n                values: [0.0]  # float32\\n156Amazon SageMaker Developer Guide\\nLatent Dirichlet Allocation (LDA)\\n            },\\n            \\'distances\\': {\\n                values: [1.08470316, 3.04917915, 5.25393973]  # float32\\n            },\\n            \\'labels\\': {\\n                values: [2.0, 2.0, 0.0]  # float32\\n            }\\n        }\\n    }\\n]\\nSAMPLE OUTPUT for the K-nn Algorithm\\nFor regressor tasks:\\n[06/08/2018 20:15:33 INFO 140026520049408] #test_score (algo-1) : (\\'mse\\',\\n 0.013333333333333334)\\nFor classiﬁer tasks:\\n[06/08/2018 20:15:46 INFO 140285487171328] #test_score (algo-1) : (\\'accuracy\\',\\n 0.98666666666666669)\\nLatent Dirichlet Allocation (LDA) Algorithm\\nThe Amazon SageMaker Latent Dirichlet Allocation (LDA) algorithm is an unsupervised learning\\nalgorithm that attempts to describe a set of observations as a mixture of distinct categories. LDA is most\\ncommonly used to discover a user-speciﬁed number of topics shared by documents within a text corpus.\\nHere each observation is a document, the features are the presence (or occurrence count) of each word,\\nand the categories are the topics. Since the method is unsupervised, the topics are not speciﬁed up front,\\nand are not guaranteed to align with how a human may naturally categorize documents. The topics are\\nlearned as a probability distribution over the words that occur in each document. Each document, in turn,\\nis described as a mixture of topics.\\nThe exact content of two documents with similar topic mixtures will not be the same. But overall, you\\nwould expect these documents to more frequently use a shared subset of words, than when compared\\nwith a document from a diﬀerent topic mixture. This allows LDA to discover these word groups and use\\nthem to form topics. As an extremely simple example, given a set of documents where the only words\\nthat occur within them are: eat, sleep , play, meow , and bark, LDA might produce topics like the following:\\nTopic eat sleep play meow bark\\nTopic 1 0.1 0.3 0.2 0.4 0.0\\nTopic 2 0.2 0.1 0.4 0.0 0.3\\nYou can infer that documents that are more likely to fall into Topic 1 are about cats (who are more likely\\nto meow  and sleep ), and documents that fall into Topic 2 are about dogs (who prefer to play and bark).\\nThese topics can be found even though the words dog and cat never appear in any of the texts.\\nTopics\\n•Input/Output Interface for the LDA Algorithm (p. 158)\\n•EC2 Instance Recommendation for the LDA Algorithm (p. 158)\\n•LDA Sample LDA Notebooks (p. 158)\\n•How LDA Works (p. 158)\\n157Amazon SageMaker Developer Guide\\nLatent Dirichlet Allocation (LDA)\\n•LDA Hyperparameters (p. 160)\\n•Tune an LDA Model (p. 161)\\nInput/Output Interface for the LDA Algorithm\\nLDA expects data to be provided on the train channel, and optionally supports a test channel, which\\nis scored by the ﬁnal model. LDA supports both recordIO-wrapped-protobuf  (dense and sparse)\\nand CSV ﬁle formats. For CSV, the data must be dense and have dimension equal to number of records *\\nvocabulary size. LDA can be trained in File or Pipe mode when using recordIO-wrapped protobuf, but only\\nin File mode for the CSV format.\\nFor inference, text/csv , application/json , and application/x-recordio-protobuf  content\\ntypes are supported. Sparse data can also be passed for application/json  and application/x-\\nrecordio-protobuf . LDA inference returns application/json  or application/x-recordio-\\nprotobuf  predictions , which include the topic_mixture  vector for each observation.\\nPlease see the LDA Sample LDA Notebooks (p. 158) for more detail on training and inference formats.\\nEC2 Instance Recommendation for the LDA Algorithm\\nLDA currently only supports single-instance CPU training. CPU instances are recommended for hosting/\\ninference.\\nLDA Sample LDA Notebooks\\nFor a sample notebook that shows how to train the Amazon SageMaker Latent Dirichlet Allocation\\nalgorithm on a dataset and then how to deploy the trained model to perform inferences about the topic\\nmixtures in input documents, see the An Introduction to SageMaker LDA. For instructions how to create\\nand access Jupyter notebook instances that you can use to run the example in Amazon SageMaker,\\nsee Use Notebook Instances (p. 36). Once you have created a notebook instance and opened it, select\\nthe SageMaker Examples tab to see a list of all the Amazon SageMaker samples. The topic modeling\\nexample notebooks using the NTM algorithms are located in the Introduction to Amazon algorithms\\nsection. To open a notebook, click on its Use tab and select Create copy.\\nHow LDA Works\\nAmazon SageMaker LDA is an unsupervised learning algorithm that attempts to describe a set of\\nobservations as a mixture of diﬀerent categories. These categories are themselves a probability\\ndistribution over the features. LDA is a generative probability model, which means it attempts to\\nprovide a model for the distribution of outputs and inputs based on latent variables. This is opposed to\\ndiscriminative models, which attempt to learn how inputs map to outputs.\\nYou can use LDA for a variety of tasks, from clustering customers based on product purchases to\\nautomatic harmonic analysis in music. However, it is most commonly associated with topic modeling in\\ntext corpuses. Observations are referred to as documents. The feature set is referred to as vocabulary. A\\nfeature is referred to as a word. And the resulting categories are referred to as topics.\\nNote\\nLemmatization signiﬁcantly increases algorithm performance and accuracy. Consider pre-\\nprocessing any input text data.\\nAn LDA model is deﬁned by two parameters:\\n•α—A prior estimate on topic probability (in other words, the average frequency that each topic within\\na given document occurs).\\n•β—a collection of k topics where each topic is given a probability distribution over the vocabulary used\\nin a document corpus, also called a \"topic-word distribution.\"\\n158Amazon SageMaker Developer Guide\\nLatent Dirichlet Allocation (LDA)\\nLDA is a \"bag-of-words\" model, which means that the order of words does not matter. LDA is a\\ngenerative model where each document is generated word-by-word by choosing a topic mixture θ ∼\\nDirichlet(α).\\nFor each word in the document:\\n•Choose a topic z ∼ Multinomial(θ)\\n•Choose the corresponding topic-word distribution β_z.\\n•Draw a word w ∼ Multinomial(β_z).\\nWhen training the model, the goal is to ﬁnd parameters α and β, which maximize the probability that the\\ntext corpus is generated by the model.\\nThe most popular methods for estimating the LDA model use Gibbs sampling or Expectation\\nMaximization (EM) techniques. The Amazon SageMaker LDA uses tensor spectral decomposition. This\\nprovides several advantages:\\n•Theoretical guarantees on results . The standard EM-method is guaranteed to converge only to local\\noptima, which are often of poor quality.\\n•Embarrassingly parallelizable. The work can be trivially divided over input documents in both training\\nand inference. The EM-method and Gibbs Sampling approaches can be parallelized, but not as easily.\\n•Fast. Although the EM-method has low iteration cost it is prone to slow convergence rates. Gibbs\\nSampling is also subject to slow convergence rates and also requires a large number of samples.\\nAt a high-level, the tensor decomposition algorithm follows this process:\\n1.The goal is to calculate the spectral decomposition of a V x V x V tensor, which summarizes the\\nmoments of the documents in our corpus. V is vocabulary size (in other words, the number of distinct\\nwords in all of the documents). The spectral components of this tensor are the LDA parameters α and\\nβ, which maximize the overall likelihood of the document corpus. However, because vocabulary size\\ntends to be large, this V x V x V tensor is prohibitively large to store in memory.\\n2.Instead, it uses a V x V moment matrix, which is the two-dimensional analog of the tensor from step\\n1, to ﬁnd a whitening matrix of dimension V x k. This matrix can be used to convert the V x V moment\\nmatrix into a k x k identity matrix. k is the number of topics in the model.\\n3.This same whitening matrix can then be used to ﬁnd a smaller k x k x k tensor. When spectrally\\ndecomposed, this tensor has components that have a simple relationship with the components of the\\nV x V x V tensor.\\n4.Alternating Least Squares  is used to decompose the smaller k x k x k tensor. This provides a substantial\\nimprovement in memory consumption and speed. The parameters α and β can be found by\\n“unwhitening” these outputs in the spectral decomposition.\\nAfter the LDA model’s parameters have been found, you can ﬁnd the topic mixtures for each document.\\nYou use stochastic gradient descent to maximize the likelihood function of observing a given topic\\nmixture corresponding to these data.\\nTopic quality can be improved by increasing the number of topics to look for in training and then\\nﬁltering out poor quality ones. This is in fact done automatically in Amazon SageMaker LDA: 25% more\\ntopics are computed and only the ones with largest associated Dirichlet priors are returned. To perform\\nfurther topic ﬁltering and analysis, you can increase the topic count and modify the resulting LDA model\\nas follows:\\n> import mxnet as mx\\n> alpha, beta = mx.ndarray.load(‘model.tar.gz’)\\n159Amazon SageMaker Developer Guide\\nLatent Dirichlet Allocation (LDA)\\n> # modify alpha and beta\\n> mx.nd.save(‘new_model.tar.gz’, [new_alpha, new_beta])\\n> # upload to S3 and create new SageMaker model using the console\\nFor more information about algorithms for LDA and the Amazon SageMaker implementation, see the\\nfollowing:\\n•Animashree Anandkumar, Rong Ge, Daniel Hsu, Sham M Kakade, and Matus Telgarsky. Tensor\\nDecompositions for Learning Latent Variable Models, Journal of Machine Learning Research, 15:2773–\\n2832, 2014.\\n•David M Blei, Andrew Y Ng, and Michael I Jordan. Latent Dirichlet Allocation . Journal of Machine\\nLearning Research, 3(Jan):993–1022, 2003.\\n•Thomas L Griﬃths and Mark Steyvers. Finding Scientiﬁc Topics. Proceedings of the National Academy\\nof Sciences, 101(suppl 1):5228–5235, 2004.\\n•Tamara G Kolda and Brett W Bader. Tensor Decompositions and Applications. SIAM Review, 51(3):455–\\n500, 2009.\\nLDA Hyperparameters\\nIn the CreateTrainingJob  request, you specify the training algorithm. You can also specify algorithm-\\nspeciﬁc hyperparameters as string-to-string maps. The following table lists the hyperparameters\\nfor the LDA training algorithm provided by Amazon SageMaker. For more information, see How LDA\\nWorks (p. 158).\\nParameter Name Description\\nnum_topics The number of topics for LDA to ﬁnd within the data.\\nRequired\\nValid values: positive integer\\nfeature_dim The size of the vocabulary of the input document corpus.\\nRequired\\nValid values: positive integer\\nmini_batch_size The total number of documents in the input document corpus.\\nRequired\\nValid values: positive integer\\nalpha0 Initial guess for the concentration parameter: the sum of the\\nelements of the Dirichlet prior. Small values are more likely to\\ngenerate sparse topic mixtures and large values (greater than 1.0)\\nproduce more uniform mixtures.\\nOptional\\nValid values: Positive ﬂoat\\nDefault value: 0.1\\nmax_restarts The number of restarts to perform during the Alternating Least\\nSquares (ALS) spectral decomposition phase of the algorithm.\\n160Amazon SageMaker Developer Guide\\nLatent Dirichlet Allocation (LDA)\\nParameter Name Description\\nCan be used to ﬁnd better quality local minima at the expense of\\nadditional computation, but typically should not be adjusted.\\nOptional\\nValid values: Positive integer\\nDefault value: 10\\nmax_iterations The maximum number of iterations to perform during the ALS\\nphase of the algorithm. Can be used to ﬁnd better quality minima\\nat the expense of additional computation, but typically should not\\nbe adjusted.\\nOptional\\nValid values: Positive integer\\nDefault value: 1000\\ntol Target error tolerance for the ALS phase of the algorithm. Can be\\nused to ﬁnd better quality minima at the expense of additional\\ncomputation, but typically should not be adjusted.\\nOptional\\nValid values: Positive ﬂoat\\nDefault value: 1e-8\\nTune an LDA Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nLDA is an unsupervised topic modeling algorithm that attempts to describe a set of observations\\n(documents) as a mixture of diﬀerent categories (topics). The “per-word log-likelihood” (PWLL) metric\\nmeasures the likelihood that a learned set of topics (an LDA model) accurately describes a test document\\ndataset. Larger values of PWLL indicate that the test data is more likely to be described by the LDA\\nmodel.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the LDA Algorithm\\nThe LDA algorithm reports on a single metric during training: test:pwll . When tuning a model, choose\\nthis metric as the objective metric.\\nMetric Name Description Optimization Direction\\ntest:pwll Per-word log-likelihood on the test dataset. The\\nlikelihood that the test dataset is accurately\\ndescribed by the learned LDA model.Maximize\\n161Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nTunable LDA Hyperparameters\\nYou can tune the following hyperparameters for the LDA algorithm. Both hyperparameters, alpha0  and\\nnum_topics , can aﬀect the LDA objective metric (test:pwll ). If you don\\'t already know the optimal\\nvalues for these hyperparameters, which maximize per-word log-likelihood and produce an accurate LDA\\nmodel, automatic model tuning can help ﬁnd them.\\nParameter Name Parameter Type Recommended Ranges\\nalpha0 ContinuousParameterRanges MinValue: 0.1,\\nMaxValue: 10\\nnum_topics IntegerParameterRanges MinValue: 1, MaxValue:\\n150\\nLinear Learner Algorithm\\nLinear models  are supervised learning algorithms used for solving either classiﬁcation or regression\\nproblems. For input, you give the model labeled examples (x, y). x is a high-dimensional vector and y\\nis a numeric label. For binary classiﬁcation problems, the label must be either 0 or 1. For multiclass\\nclassiﬁcation problems, the labels must be from 0 to num_classes  - 1. For regression problems, y is\\na real number. The algorithm learns a linear function, or, for classiﬁcation problems, a linear threshold\\nfunction, and maps a vector x to an approximation of the label y.\\nThe Amazon SageMaker linear learner algorithm provides a solution for both classiﬁcation and\\nregression problems. With the Amazon SageMaker algorithm, you can simultaneously explore diﬀerent\\ntraining objectives and choose the best solution from a validation set. You can also explore a large\\nnumber of models and choose the best. The best model optimizes either of the following:\\n•Continuous objectives, such as mean square error, cross entropy loss, absolute error.\\n•Discrete objectives suited for classiﬁcation, such as F1 measure, precision, recall, or accuracy.\\nCompared with methods that provide a solution for only continuous objectives, the Amazon SageMaker\\nlinear learner algorithm provides a signiﬁcant increase in speed over naive hyperparameter optimization\\ntechniques. It is also more convenient.\\nThe linear learner algorithm requires a data matrix, with rows representing the observations, and\\ncolumns representing the dimensions of the features. It also requires an additional column that contains\\nthe labels that match the data points. At a minimum, Amazon SageMaker linear learner requires you to\\nspecify input and output data locations, and objective type (classiﬁcation or regression) as arguments.\\nThe feature dimension is also required. For more information, see CreateTrainingJob (p. 667). You\\ncan specify additional parameters in the HyperParameters  string map of the request body. These\\nparameters control the optimization procedure, or speciﬁcs of the objective function that you train on.\\nFor example, the number of epochs, regularization, and loss type.\\nTopics\\n•Input/Output Interface for the Linear Learner Algorithm (p. 163)\\n•EC2 Instance Recommendation for the Linear Learner Algorithm (p. 163)\\n•Linear Learner Sample Notebooks  (p. 163)\\n•How Linear Learner Works (p. 164)\\n•Linear Learner Hyperparameters  (p. 164)\\n•Tune a Linear Learner Model (p. 173)\\n162Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\n•Linear Learner Response Formats (p. 175)\\nInput/Output Interface for the Linear Learner Algorithm\\nThe Amazon SageMaker linear learner algorithm supports three data channels: train, validation\\n(optional), and test (optional). If you provide validation data, it should be FullyReplicated . The\\nalgorithm logs validation loss at every epoch, and uses a sample of the validation data to calibrate and\\nselect the best model. If you don\\'t provide validation data, the algorithm uses a sample of the training\\ndata to calibrate and select the model. If you provide test data, the algorithm logs include the test score\\nfor the ﬁnal model.\\nFor training, the linear learner algorithm supports both recordIO-wrapped protobuf  and CSV\\nformats. For the application/x-recordio-protobuf  input type, only Float32 tensors are\\nsupported. For the text/csv  input type, the ﬁrst column is assumed to be the label, which is the target\\nvariable for prediction. You can use either File mode or Pipe mode to train linear learner models on data\\nthat is formatted as recordIO-wrapped-protobuf  or as CSV.\\nFor inference, the linear learner algorithm supports the application/json ,\\napplication/x-recordio-protobuf , and text/csv  formats. When you make\\npredictions on new data, the format of the response depends on the type of model. For\\nregression  (predictor_type=\\'regressor\\' ), the score is the prediction produced\\nby the model. For classiﬁcation (predictor_type=\\'binary_classifier\\'  or\\npredictor_type=\\'multiclass_classifier\\' ), the model returns a score  and also a\\npredicted_label . The predicted_label  is the class predicted by the model and the score\\nmeasures the strength of that prediction.\\n•For binary classiﬁcation, predicted_label  is 0 or 1, and score is a single ﬂoating point number\\ncorrespond class.\\n•For multiclass classiﬁcation, the predicted_class  will be an integer from 0 to num_classes-1 ,\\nand the score will be a list of one ﬂoating point number per class.\\nTo interpret the score in classiﬁcation problems, you have to consider the loss function used. If the\\nloss hyperparameter value is logistic  for binary classiﬁcation or softmax_loss  for multiclass\\nclassiﬁcation, then the score can be interpreted as the probability of the corresponding class. These\\nare the loss values used by the linear learner when the loss  value is auto  default value. But if the loss\\nis set to hinge_loss , then the score cannot be interpreted as a probability. This is because hinge loss\\ncorresponds to a Support Vector Classiﬁer, which does not produce probability estimates.\\nFor more information on input and output ﬁle formats, see Linear Learner Response Formats (p. 175).\\nFor more information on inference formats, and the Linear Learner Sample Notebooks  (p. 163).\\nEC2 Instance Recommendation for the Linear Learner Algorithm\\nYou can train the linear learner algorithm on single- or multi-machine CPU and GPU instances. During\\ntesting, we have not found substantial evidence that multi-GPU computers are faster than single-GPU\\ncomputers. Results can vary, depending on your speciﬁc use case.\\nLinear Learner Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker linear learner algorithm to analyze the images\\nof handwritten digits from zero to nine in the MNIST dataset, see An Introduction to Linear Learner with\\nMNIST . For instructions on how to create and access Jupyter notebook instances that you can use to\\nrun the example in Amazon SageMaker, see Use Notebook Instances (p. 36). After you have created a\\nnotebook instance and opened it, choose the SageMaker Examples tab to see a list of all of the Amazon\\nSageMaker samples. The topic modeling example notebooks using the linear learning algorithm are\\n163Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nlocated in the Introduction to Amazon algorithms section. To open a notebook, choose its Use tab and\\nchoose Create copy.\\nHow Linear Learner Works\\nThere are three steps involved in the implementation of the linear learner algorithm: preprocess, train,\\nand validate.\\nStep 1: Preprocess\\nNormalization, or feature scaling, is an important preprocessing step for certain loss functions that\\nensures the model being trained on a dataset does not become dominated by the weight of a single\\nfeature. The Amazon SageMaker Linear Learner algorithm has a normalization option to assist with this\\npreprocessing step. If normalization is turned on, the algorithm ﬁrst goes over a small sample of the data\\nto learn the mean value and standard deviation for each feature and for the label. Each of the features in\\nthe full dataset is then shifted to have mean of zero and scaled to have a unit standard deviation.\\nNote\\nFor best results, ensure your data is shuﬄed before training. Training with unshuﬄed data may\\ncause training to fail.\\nYou can conﬁgure whether the linear learner algorithm normalizes the feature data and the labels using\\nthe normalize_data  and normalize_label ) hyperparameters respectively. Normalization is enabled\\nby default for both features and labels for regression. Only the features can be normalized for binary\\nclassiﬁcation and this is the default behavior.\\nStep 2: Train\\nWith the linear learner algorithm, you train with a distributed implementation of stochastic gradient\\ndescent (SGD). You can control the optimization process by choosing the optimization algorithm. For\\nexample, you can choose to use Adam, AdaGrad, stochastic gradient descent, or other optimization\\nalgorithms. You also specify their hyperparameters, such as momentum, learning rate, and the learning\\nrate schedule. If you aren\\'t sure which algorithm or hyperparameter value to use, choose a default that\\nworks for the majority of datasets.\\nDuring training, you simultaneously optimize multiple models, each with slightly diﬀerent objectives. For\\nexample, you vary L1 or L2 regularization and try out diﬀerent optimizer settings.\\nStep 3: Validate and Set the Threshold\\nWhen training multiple models in parallel, the models are evaluated against a validation set to select the\\nmost optimal model once training is complete. For regression, the most optimal model is the one that\\nachieves the best loss on the validation set. For classiﬁcation, a sample of the validation set is used to\\ncalibrate the classiﬁcation threshold. The most optimal model selected is the one that achieves the best\\nbinary classiﬁcation selection criteria on the validation set. Examples of such such criteria include the F1\\nmeasure, accuracy, and cross-entropy loss.\\nNote\\nIf the algorithm is not provided a validation set, then evaluating and selecting the most optimal\\nmodel is not possible. To take advantage of parallel training and model selection ensure you\\nprovide a validation set to the algorithm.\\nLinear Learner Hyperparameters\\nThe following table contains the hyperparameters for the learner learner algorithm. These are\\nparameters that are set by users to facilitate the estimation of model parameters from data. The\\n164Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nrequired hyperparameters that must be set are listed ﬁrst, in alphabetical order. The optional\\nhyperparameters that can be set are listed next, also in alphabetical order.\\nParameter Name Description\\nfeature_dim The number of features in the input data.\\nRequired\\nValid values: Positive integer\\nnum_classes The number of classes for the response variable. The algorithm assumes\\nthat classes are labeled 0, ..., num_classes - 1 .\\nRequired when predictor_type  is multiclass_classifier .\\nOtherwise, the algorithm ignores it.\\nValid values: Integers from 3 to 1,000,000\\npredictor_type Speciﬁes the type of target variable as a binary classiﬁcation, multiclass\\nclassiﬁcation, or regression.\\nRequired\\nValid values: binary_classifier , multiclass_classifier , or\\nregressor\\naccuracy_top_k When computing the top-k accuracy metric for multiclass classiﬁcation,\\nthe value of k. If the model assigns one of the top-k scores to the true\\nlabel, an example is scored as correct.\\nOptional\\nValid values: Positive integers\\nDefault value: 3\\nbalance_multiclass_weights Speciﬁes whether to use class weights, which give each class equal\\nimportance in the loss function. Used only when the predictor_type  is\\nmulticlass_classifier .\\nOptional\\nValid values: true , false\\nDefault value: false\\nbeta_1 The exponential decay rate for ﬁrst-moment estimates. Applies only when\\nthe optimizer  value is adam .\\nOptional\\nValid values: auto or ﬂoating-point value between 0 and 1.0\\nDefault value: auto\\nbeta_2 The exponential decay rate for second-moment estimates. Applies only\\nwhen the optimizer  value is adam .\\nOptional\\n165Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\nValid values: auto or ﬂoating-point integer between 0 and 1.0\\nDefault value: auto\\nbias_lr_mult Allows a diﬀerent learning rate for the bias term. The actual learning rate\\nfor the bias is learning_rate  * bias_lr_mult .\\nOptional\\nValid values: auto or positive ﬂoating-point integer\\nDefault value: auto\\nbias_wd_mult Allows diﬀerent regularization for the bias term. The actual L2\\nregularization weight for the bias is wd * bias_wd_mult . By default, there\\nis no regularization on the bias term.\\nOptional\\nValid values: auto or non-negative ﬂoating-point integer\\nDefault value: auto\\nbinary_classifier_model_selection_criteria When predictor_type  is set to binary_classifier , the model\\nevaluation criteria for the validation dataset (or for the training dataset if\\nyou don\\'t provide a validation dataset). Criteria include:\\n•accuracy —The model with the highest accuracy.\\n•f_beta—The model with the highest F1 score. The default is F1.\\n•precision_at_target_recall —The model with the highest\\nprecision at a given recall target.\\n•recall_at_target_precision —The model with the highest recall\\nat a given precision target.\\n•loss_function —The model with the lowest value of the loss function\\nused in training.\\nOptional\\nValid values: accuracy , f_beta , precision_at_target_recall ,\\nrecall_at_target_precision , or loss_function\\nDefault value: accuracy\\n166Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\nearly_stopping_patience If no improvement is made in the relevant metric, the number of\\nepochs to wait before ending training. If you have provided a value for\\nbinary_classifier_model_selection_criteria . the metric is that\\nvalue. Otherwise, the metric is the same as the value speciﬁed for the\\nloss hyperparameter.\\nThe metric is evaluated on the validation data. If you haven\\'t provided\\nvalidation data, the metric is always the same as the value speciﬁed\\nfor the loss hyperparameter and is evaluated on the training data. To\\ndisable early stopping, set early_stopping_patience  to a value\\ngreater than the value speciﬁed for epochs .\\nOptional\\nValid values: Positive integer\\nDefault value: 3\\nearly_stopping_tolerance The relative tolerance to measure an improvement in loss. If the ratio of\\nthe improvement in loss divided by the previous best loss is smaller than\\nthis value, early stopping considers the improvement to be zero.\\nOptional\\nValid values: Positive ﬂoating-point integer\\nDefault value: 0.001\\nepochs The maximum number of passes over the training data.\\nOptional\\nValid values: Positive integer\\nDefault value: 15\\nf_beta The value of beta to use when calculating F score metrics for binary\\nor multiclass classiﬁcation. Also used if the value speciﬁed for\\nbinary_classifier_model_selection_criteria  is f_beta .\\nOptional\\nValid values: Positive ﬂoating-point integers\\nDefault value: 1.0\\nhuber_delta The parameter for Huber loss. During training and metric evaluation,\\ncompute L2 loss for errors smaller than delta and L1 loss for errors larger\\nthan delta.\\nOptional\\nValid values: Positive ﬂoating-point integer\\nDefault value: 1.0\\n167Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\ninit_bias Initial weight for the bias term.\\nOptional\\nValid values: Floating-point integer\\nDefault value: 0\\ninit_method Sets the initial distribution function used for model weights. Functions\\ninclude:\\n•uniform—Uniformly distributed between (-scale, +scale)\\n•normal —Normal distribution, with mean 0 and sigma\\nOptional\\nValid values: uniform  or normal\\nDefault value: uniform\\ninit_scale Scales an initial uniform distribution for model weights. Applies only\\nwhen the init_method  hyperparameter is set to uniform .\\nOptional\\nValid values: Positive ﬂoating-point integer\\nDefault value: 0.07\\ninit_sigma The initial standard deviation for the normal distribution. Applies only\\nwhen the init_method  hyperparameter is set to normal .\\nOptional\\nValid values: Positive ﬂoating-point integer\\nDefault value: 0.01\\nl1 The L1 regularization parameter. If you don\\'t want to use L1\\nregularization, set the value to 0.\\nOptional\\nValid values: auto or non-negative ﬂoat\\nDefault value: auto\\nlearning_rate The step size used by the optimizer for parameter updates.\\nOptional\\nValid values: auto or positive ﬂoating-point integer\\nDefault value: auto, whose value depends on the optimizer chosen.\\n168Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\nloss Speciﬁes the loss function.\\nThe available loss functions and their default values depend on the value\\nof predictor_type :\\n•If the predictor_type  is set to regressor ,\\nthe available options are auto , squared_loss ,\\nabsolute_loss , eps_insensitive_squared_loss ,\\neps_insensitive_absolute_loss , quantile_loss , and\\nhuber_loss . The default value for auto  is squared_loss .\\n•If the predictor_type  is set to binary_classifier , the available\\noptions are auto ,logistic , and hinge_loss . The default value for\\nauto  is logistic .\\n•If the predictor_type  is set to multiclass_classifier , the\\navailable options are auto  and softmax_loss . The default value for\\nauto  is softmax_loss .\\nValid values: auto , logistic , squared_loss , absolute_loss ,\\nhinge_loss , eps_insensitive_squared_loss ,\\neps_insensitive_absolute_loss , quantile_loss , or huber_loss\\nOptional\\nDefault value: auto\\nloss_insensitivity The parameter for the epsilon-insensitive loss type. During training and\\nmetric evaluation, any error smaller than this value is considered to be\\nzero.\\nOptional\\nValid values: Positive ﬂoating-point integer\\nDefault value: 0.01\\nlr_scheduler_factor For every lr_scheduler_step  hyperparameter, the learning rate\\ndecreases by this quantity. Applies only when the use_lr_scheduler\\nhyperparameter is set to true .\\nOptional\\nValid values: auto or positive ﬂoating-point integer between 0 and 1\\nDefault value: auto\\nlr_scheduler_minimum_lr The learning rate never decreases to a value lower than the value\\nset for lr_scheduler_minimum_lr . Applies only when the\\nuse_lr_scheduler  hyperparameter is set to true .\\nOptional\\nValid values: auto or positive ﬂoating-point integer\\nDefault values: auto\\n169Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\nlr_scheduler_step The number of steps between decreases of the learning rate. Applies only\\nwhen the use_lr_scheduler  hyperparameter is set to true .\\nOptional\\nValid values: auto or positive integer\\nDefault value: auto\\nmargin The margin for the hinge_loss  function.\\nOptional\\nValid values: Positive ﬂoating-point integer\\nDefault value: 1.0\\nmini_batch_size The number of observations per mini-batch for the data iterator.\\nOptional\\nValid values: Positive integer\\nDefault value: 1000\\nmomentum The momentum of the sgd optimizer.\\nOptional\\nValid values: auto or a ﬂoating-point integer between 0 and 1.0\\nDefault value: auto\\nnormalize_data Normalizes the feature data before training. Data normalization shifts\\nthe data for each feature to have a mean of zero and scales it to have unit\\nstandard deviation.\\nOptional\\nValid values: auto , true , or false\\nDefault value: true\\nnormalize_label Normalizes the label. Label normalization shifts the label to have a mean\\nof zero and scales it to have unit standard deviation.\\nThe auto default value normalizes the label for regression problems but\\ndoes not for classiﬁcation problems. If you set the normalize_label\\nhyperparameter to true for classiﬁcation problems, the algorithm ignores\\nit.\\nOptional\\nValid values: auto , true , or false\\nDefault value: auto\\n170Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\nnum_calibration_samples The number of observations from the validation dataset to use for model\\ncalibration (when ﬁnding the best threshold).\\nOptional\\nValid values: auto or positive integer\\nDefault value: auto\\nnum_models The number of models to train in parallel. For the default, auto , the\\nalgorithm decides the number of parallel models to train. One model\\nis trained according to the given training parameter (regularization,\\noptimizer, loss), and the rest by close parameters.\\nOptional\\nValid values: auto or positive integer\\nDefault values: auto\\nnum_point_for_scaler The number of data points to use for calculating normalization or\\nunbiasing of terms.\\nOptional\\nValid values: Positive integer\\nDefault value: 10,000\\noptimizer The optimization algorithm to use.\\nOptional\\nValid values:\\n•auto —The default value.\\n•sgd—Stochastic gradient descent.\\n•adam —Adaptive momentum estimation.\\n•rmsprop—A gradient-based optimization technique that uses a moving\\naverage of squared gradients to normalize the gradient.\\nDefault value: auto. The default setting for auto  is adam .\\npositive_example_weight_mult The weight assigned to positive examples when training a binary classiﬁer.\\nThe weight of negative examples is ﬁxed at 1. If you want the algorithm\\nto choose a weight so that errors in classifying negative vs. positive\\nexamples have equal impact on training loss, specify balanced . If you\\nwant the algorithm to choose the weight that optimizes performance,\\nspecify auto .\\nOptional\\nValid values: balanced , auto, or a positive ﬂoating-point integer\\nDefault value: 1.0\\n171Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\nquantile The quantile for quantile loss. For quantile q, the model attempts to\\nproduce predictions so that the value of true_label  is greater than the\\nprediction with probability q.\\nOptional\\nValid values: Floating-point integer between 0 and 1\\nDefault value: 0.5\\ntarget_precision The target precision. If\\nbinary_classifier_model_selection_criteria  is\\nrecall_at_target_precision , then precision is held at this value\\nwhile recall is maximized.\\nOptional\\nValid values: Floating-point integer between 0 and 1.0\\nDefault value: 0.8\\ntarget_recall The target recall. If\\nbinary_classifier_model_selection_criteria  is\\nprecision_at_target_recall , then recall is held at this value while\\nprecision is maximized.\\nOptional\\nValid values: Floating-point integer between 0 and 1.0\\nDefault value: 0.8\\nunbias_data Unbiases the features before training so that the mean is 0. By default.\\ndata is unbiased if the use_bias  hyperparameter is set to true .\\nOptional\\nValid values: auto , true , or false\\nDefault value: auto\\nunbias_label Unbiases labels before training so that the mean is 0. Applies to\\nregression only if the use_bias  hyperparameter is set to true .\\nOptional\\nValid values: auto , true , or false\\nDefault value: auto\\nuse_bias Speciﬁes whether the model should include a bias term, which is the\\nintercept term in the linear equation.\\nOptional\\nValid values: true  or false\\nDefault value: true\\n172Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter Name Description\\nuse_lr_scheduler Whether to use a scheduler for the learning rate. If you want to use a\\nscheduler, specify true .\\nOptional\\nValid values: true  or false\\nDefault value: true\\nwd The weight decay parameter, also known as the L2 regularization\\nparameter. If you don\\'t want to use L2 regularization, set the value to 0.\\nOptional\\nValid values:auto or non-negative ﬂoating-point integer\\nDefault value: auto\\nTune a Linear Learner Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nThe linear learner algorithm also has an internal mechanism for tuning hyperparameters separate\\nfrom the automatic model tuning feature described here. By default, the linear learner algorithm tunes\\nhyperparameters by training multiple models in parallel. When you use automatic model tuning, the\\nlinear learner internal tuning mechanism is turned oﬀ automatically. This sets the number of parallel\\nmodels, num_models , to 1. The algorithm ignores any value that you set for num_models .\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the Linear Learner Algorithm\\nThe linear learner algorithm reports the metrics in the following table, which are computed during\\ntraining. Choose one of them as the objective metric. To avoid overﬁtting, we recommend tuning the\\nmodel against a validation metric instead of a training metric.\\nMetric Name Description Optimization Direction\\ntest:objective_loss The mean value of the objective loss function\\non the test dataset after the model is trained.\\nBy default, the loss is logistic loss for binary\\nclassiﬁcation and squared loss for regression.\\nTo set the loss to other types, use the loss\\nhyperparameter.Minimize\\ntest:binary_classification_\\naccuracyThe accuracy of the ﬁnal model on the test\\ndataset.Maximize\\ntest:binary_f_beta The F_beta score of the ﬁnal model on the test\\ndataset. By default, it is the F1 score, which is the\\nharmonic mean of precision and recall.Maximize\\n173Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nMetric Name Description Optimization Direction\\ntest:precision The precision of the ﬁnal model on the test\\ndataset. If you choose this metric as the objective,\\nwe recommend setting a target recall by setting\\nthe binary_classifier_model_selection\\nhyperparameter to\\nprecision_at_target_recall  and setting the\\nvalue for the target_recall  hyperparameter.Maximize\\ntest:recall The recall of the ﬁnal model on the test dataset.\\nIf you choose this metric as the objective, we\\nrecommend setting a target precision by setting\\nthe binary_classifier_model_selection\\nhyperparameter to\\nrecall_at_target_precision  and setting the\\nvalue for the target_precison  hyperparameter.Maximize\\nvalidation:objective_loss The mean value of the objective loss function on\\nthe validation dataset every epoch. By default,\\nthe loss is logistic loss for binary classiﬁcation and\\nsquared loss for regression. To set loss to other\\ntypes, use the loss hyperparameter.Minimize\\nvalidation:binary_classific\\nation_accuracyThe accuracy of the ﬁnal model on the validation\\ndataset.Maximize\\nvalidation:binary_f_beta The F_beta score of the ﬁnal model on the\\nvalidation dataset. By default, the F_beta\\nscore is the F1 score, which is the harmonic\\nmean of the validation:precision  and\\nvalidation:recall  metrics.Maximize\\nvalidation:precision The precision of the ﬁnal model on the test\\ndataset. If you choose this metric as the objective,\\nwe recommend setting a target recall by setting\\nthe binary_classifier_model_selection\\nhyperparameter to\\nprecision_at_target_recall  and setting the\\nvalue for the target_recall  hyperparameter.Maximize\\nvalidation:recall The recall of the ﬁnal model on the test dataset.\\nIf you choose this metric as the objective, we\\nrecommend setting a target precision by setting\\nthe binary_classifier_model_selection\\nhyperparameter to\\nrecall_at_target_precision  and setting the\\nvalue for the target_precison  hyperparameter.Maximize\\nTuning Linear Learner Hyperparameters\\nYou can tune a linear learner model with the following hyperparameters.\\n174Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nParameter NameParameter Type Recommended Ranges\\nwd ContinuousParameterRanges MinValue: 1e-7 ,\\nMaxValue : 1\\nl1 ContinuousParameterRanges MinValue : 1e-7 ,\\nMaxValue : 1\\nlearning_rate ContinuousParameterRanges MinValue : 1e-5 ,\\nMaxValue : 1\\nmini_batch_size IntegerParameterRanges MinValue : 100,\\nMaxValue : 5000\\nuse_bias CategoricalParameterRanges [True, False]\\npositive_example_weight_mult ContinuousParameterRanges MinValue : 1e-5,\\nMaxValue : 1e5\\nLinear Learner Response Formats\\nJSON Response Format\\nAll Amazon SageMaker built-in algorithms adhere to the common input inference format described\\nin Common Data Formats - Inference. The following are the available output formats for the Amazon\\nSageMaker linear learner algorithm.\\nBinary Classiﬁcation\\nlet response =   {\\n    \"predictions\":    [\\n        {\\n            \"score\": 0.4,\\n            \"predicted_label\": 0\\n        } \\n    ]\\n}\\nMulticlass Classiﬁcation\\nlet response =   {\\n    \"predictions\":    [\\n        {\\n            \"score\": [0.1, 0.2, 0.4, 0.3],\\n            \"predicted_label\": 2\\n        } \\n    ]\\n}\\nRegression\\nlet response =   {\\n    \"predictions\":    [\\n        {\\n            \"score\": 0.4\\n        } \\n    ]\\n}\\n175Amazon SageMaker Developer Guide\\nLinear Learner Algorithm\\nJSONLINES Response Format\\nBinary Classiﬁcation\\n{\"score\": 0.4, \"predicted_label\": 0}\\nMulticlass Classiﬁcation\\n{\"score\": [0.1, 0.2, 0.4, 0.3], \"predicted_label\": 2}\\nRegression\\n{\"score\": 0.4}\\nRECORDIO Response Format\\nBinary Classiﬁcation\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'score’: {\\n                keys: [],\\n                values: [0.4]  # float32\\n            },\\n            \\'predicted_label\\': {\\n                keys: [],\\n                values: [0.0]  # float32\\n            }\\n        }\\n    }\\n]\\nMulticlass Classiﬁcation\\n[\\n    Record = {\\n    \"features\": [],\\n    \"label\":    {\\n            \"score\":  {\\n                    \"values\":   [0.1, 0.2, 0.3, 0.4]   \\n            },\\n            \"predicted_label\":  {\\n                    \"values\":   [3]\\n            }\\n       },\\n    \"uid\":  \"abc123\",\\n    \"metadata\": \"{created_at: \\'2017-06-03\\'}\"\\n   }\\n]\\nRegression\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'score’: {\\n                keys: [],\\n176Amazon SageMaker Developer Guide\\nNeural Topic Model (NTM) Algorithm\\n                values: [0.4]  # float32\\n            }   \\n        }\\n    }\\n]\\nNeural Topic Model (NTM) Algorithm\\nAmazon SageMaker NTM is an unsupervised learning algorithm that is used to organize a corpus of\\ndocuments into topics  that contain word groupings based on their statistical distribution. Documents\\nthat contain frequent occurrences of words such as \"bike\", \"car\", \"train\", \"mileage\", and \"speed\" are likely\\nto share a topic on \"transportation\" for example. Topic modeling can be used to classify or summarize\\ndocuments based on the topics detected or to retrieve information or recommend content based on\\ntopic similarities. The topics from documents that NTM learns are characterized as a latent representation\\nbecause the topics are inferred from the observed word distributions in the corpus. The semantics of\\ntopics are usually inferred by examining the top ranking words they contain. Because the method is\\nunsupervised, only the number of topics, not the topics themselves, are prespeciﬁed. In addition, the\\ntopics are not guaranteed to align with how a human might naturally categorize documents.\\nTopic modeling provides a way to visualize the contents of a large document corpus in terms of the\\nlearned topics. Documents relevant to each topic might be indexed or searched for based on their soft\\ntopic labels. The latent representations of documents might also be used to ﬁnd similar documents in\\nthe topic space. You can also use the latent representations of documents that the topic model learns for\\ninput to another supervised algorithm such as a document classiﬁer. Because the latent representations\\nof documents are expected to capture the semantics of the underlying documents, algorithms based in\\npart on these representations are expected to perform better than those based on lexical features alone.\\nAlthough you can use both the Amazon SageMaker NTM and LDA algorithms for topic modeling, they\\nare distinct algorithms and can be expected to produce diﬀerent results on the same input data.\\nFor more information on the mathematics behind NTM, see Neural Variational Inference for Text\\nProcessing.\\nTopics\\n•Input/Output Interface for the NTM Algorithm (p. 177)\\n•EC2 Instance Recommendation for the NTM Algorithm (p. 178)\\n•NTM Sample Notebooks  (p. 178)\\n•NTM Hyperparameters  (p. 178)\\n•Tune an NTM Model (p. 181)\\n•NTM Response Formats (p. 182)\\nInput/Output Interface for the NTM Algorithm\\nAmazon SageMaker Neural Topic Model supports four data channels: train, validation, test, and auxiliary.\\nThe validation, test, and auxiliary data channels are optional. If you specify any of these optional\\nchannels, set the value of the S3DataDistributionType  parameter for them to FullyReplicated . If\\nyou provide validation data, the loss on this data is logged at every epoch, and the model stops training\\nas soon as it detects that the validation loss is not improving. If you don\\'t provide validation data, the\\nalgorithm stops early based on the training data, but this can be less eﬃcient. If you provide test data,\\nthe algorithm reports the test loss from the ﬁnal model.\\nThe train, validation, and test data channels for NTM support both recordIO-wrapped-protobuf\\n(dense and sparse) and CSV ﬁle formats. For CSV format, each row must be represented densely with\\nzero counts for words not present in the corresponding document, and have dimension equal to:\\n(number of records) * (vocabulary size). You can use either File mode or Pipe mode to train models on\\ndata that is formatted as recordIO-wrapped-protobuf  or as CSV. The auxiliary channel is used to\\n177Amazon SageMaker Developer Guide\\nNeural Topic Model (NTM) Algorithm\\nsupply a text ﬁle that contains vocabulary. By supplying the vocabulary ﬁle, users are able to see the top\\nwords for each of the topics printed in the log instead of their integer IDs. Having the vocabulary ﬁle also\\nallows NTM to compute the Word Embedding Topic Coherence (WETC) scores, a new metric displayed in\\nthe log that captures similarity among the top words in each topic eﬀectively. The ContentType  for the\\nauxiliary channel is text/plain , with each line containing a single word, in the order corresponding to\\nthe integer IDs provided in the data. The vocabulary ﬁle must be named vocab.txt  and currently only\\nUTF-8 encoding is supported.\\nFor inference, text/csv , application/json , application/jsonlines , and application/x-\\nrecordio-protobuf  content types are supported. Sparse data can also be passed for application/\\njson  and application/x-recordio-protobuf . NTM inference returns application/json  or\\napplication/x-recordio-protobuf  predictions , which include the topic_weights  vector for each\\nobservation.\\nSee the blog post  and the companion notebook  for more details on using the auxiliary channel and the\\nWETC scores. For more information on how to compute the WETC score, see Coherence-Aware Neural\\nTopic Modeling. We used the pairwise WETC described in this paper for the Amazon SageMaker Neural\\nTopic Model.\\nFor more information on input and output ﬁle formats, see NTM Response Formats (p. 182) for\\ninference and the NTM Sample Notebooks  (p. 178).\\nEC2 Instance Recommendation for the NTM Algorithm\\nNTM training supports both GPU and CPU instance types. We recommend GPU instances, but for certain\\nworkloads, CPU instances may result in lower training costs. CPU instances should be suﬃcient for\\ninference.\\nNTM Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker NTM algorithm to uncover topics in documents\\nfrom a synthetic data source where the topic distributions are known, see the Introduction to Basic\\nFunctionality of NTM. For instructions how to create and access Jupyter notebook instances that you\\ncan use to run the example in Amazon SageMaker, see Use Notebook Instances (p. 36). Once you have\\ncreated a notebook instance and opened it, select the SageMaker Examples tab to see a list of all the\\nAmazon SageMaker samples. The topic modeling example notebooks using the NTM algorithms are\\nlocated in the Introduction to Amazon algorithms section. To open a notebook, click on its Use tab and\\nselect Create copy.\\nNTM Hyperparameters\\nParameter Name Description\\nfeature_dim The vocabulary size of the dataset.\\nRequired\\nValid values: Positive integer (min: 1, max: 1,000,000)\\nnum_topics The number of required topics.\\nRequired\\nValid values: Positive integer (min: 2, max: 1000)\\nbatch_norm Whether to use batch normalization during training.\\nOptional\\n178Amazon SageMaker Developer Guide\\nNeural Topic Model (NTM) Algorithm\\nParameter Name Description\\nValid values: true or false\\nDefault value: false\\nclip_gradient The maximum magnitude for each gradient component.\\nOptional\\nValid values: Float (min: 1e-3)\\nDefault value: Inﬁnity\\nencoder_layers The number of layers in the encoder and the output size of each\\nlayer. When set to auto , the algorithm uses two layers of sizes 3 x\\nnum_topics  and 2 x num_topics  respectively.\\nOptional\\nValid values: Comma-separated list of positive integers or auto\\nDefault value: auto\\nencoder_layers_activation The activation function to use in the encoder layers.\\nOptional\\nValid values:\\n•sigmoid : Sigmoid function\\n•tanh : Hyperbolic tangent\\n•relu : Rectiﬁed linear unit\\nDefault value: sigmoid\\nepochs The maximum number of passes over the training data.\\nOptional\\nValid values: Positive integer (min: 1)\\nDefault value: 50\\nlearning_rate The learning rate for the optimizer.\\nOptional\\nValid values: Float (min: 1e-6, max: 1.0)\\nDefault value: 0.001\\nmini_batch_size The number of examples in each mini batch.\\nOptional\\nValid values: Positive integer (min: 1, max: 10000)\\nDefault value: 256\\n179Amazon SageMaker Developer Guide\\nNeural Topic Model (NTM) Algorithm\\nParameter Name Description\\nnum_patience_epochs The number of successive epochs over which early stopping\\ncriterion is evaluated. Early stopping is triggered when the change\\nin the loss function drops below the speciﬁed tolerance  within\\nthe last num_patience_epochs  number of epochs. To disable\\nearly stopping, set num_patience_epochs  to a value larger than\\nepochs .\\nOptional\\nValid values: Positive integer (min: 1)\\nDefault value: 3\\noptimizer The optimizer to use for training.\\nOptional\\nValid values:\\n•sgd: Stochastic gradient descent\\n•adam : Adaptive momentum estimation\\n•adagrad : Adaptive gradient algorithm\\n•adadelta : An adaptive learning rate algorithm\\n•rmsprop : Root mean square propagation\\nDefault value: adadelta\\nrescale_gradient The rescale factor for gradient.\\nOptional\\nValid values: ﬂoat (min: 1e-3, max: 1.0)\\nDefault value: 1.0\\nsub_sample The fraction of the training data to sample for training per epoch.\\nOptional\\nValid values: Float (min: 0.0, max: 1.0)\\nDefault value: 1.0\\ntolerance The maximum relative change in the loss function. Early stopping is\\ntriggered when change in the loss function drops below this value\\nwithin the last num_patience_epochs  number of epochs.\\nOptional\\nValid values: Float (min: 1e-6, max: 0.1)\\nDefault value: 0.001\\n180Amazon SageMaker Developer Guide\\nNeural Topic Model (NTM) Algorithm\\nParameter Name Description\\nweight_decay The weight decay coeﬃcient. Adds L2 regularization.\\nOptional\\nValid values: Float (min: 0.0, max: 1.0)\\nDefault value: 0.0\\nTune an NTM Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nAmazon SageMaker NTM is an unsupervised learning algorithm that learns latent representations of\\nlarge collections of discrete data, such as a corpus of documents. Latent representations use inferred\\nvariables that are not directly measured to model the observations in a dataset. Automatic model tuning\\non NTM helps you ﬁnd the model that minimizes loss over the training or validation data. Training loss\\nmeasures how well the model ﬁts the training data. Validation loss measures how well the model can\\ngeneralize to data that it is not trained on. Low training loss indicates that a model is a good ﬁt to the\\ntraining data. Low validation loss indicates that a model has not overﬁt the training data and so should\\nbe able to model documents on which is has not been trained successfully. Usually, it\\'s preferable to have\\nboth losses be small. However, minimizing training loss too much might result in overﬁtting and increase\\nvalidation loss, which would reduce the generality of the model.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the NTM Algorithm\\nThe NTM algorithm reports a single metric that is computed during training: validation:total_loss .\\nThe total loss is the sum of the reconstruction loss and Kullback-Leibler divergence. When tuning\\nhyperparameter values, choose this metric as the objective.\\nMetric Name Description Optimization Direction\\nvalidation:total_loss Total Loss on validation set Minimize\\nTunable NTM Hyperparameters\\nYou can tune the following hyperparameters for the NTM algorithm. Usually setting low\\nmini_batch_size  and small learning_rate  values results in lower validation losses, although it\\nmight take longer to train. Low validation losses don\\'t necessarily produce more coherent topics as\\ninterpreted by humans. The eﬀect of other hyperparameters on training and validation loss can vary\\nfrom dataset to dataset. To see which values are compatible, see NTM Hyperparameters  (p. 178).\\nParameter Name Parameter Type Recommended Ranges\\nencoder_layers_activation CategoricalParameterRanges [\\'sigmoid\\', \\'tanh\\', \\'relu\\']\\nlearning_rate ContinuousParameterRange MinValue: 1e-4,\\nMaxValue: 0.1\\n181Amazon SageMaker Developer Guide\\nNeural Topic Model (NTM) Algorithm\\nParameter NameParameter Type Recommended Ranges\\nmini_batch_size IntegerParameterRanges MinValue: 16,\\nMaxValue:2048\\noptimizer CategoricalParameterRanges [\\'sgd\\', \\'adam\\', \\'adadelta\\']\\nrescale_gradient ContinuousParameterRange MinValue: 0.1,\\nMaxValue: 1.0\\nweight_decay ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 1.0\\nNTM Response Formats\\nAll Amazon SageMaker built-in algorithms adhere to the common input inference format described\\nin Common Data Formats - Inference. This topic contains a list of the available output formats for the\\nAmazon SageMaker NTM algorithm.\\nJSON Response Format\\n{\\n    \"predictions\":    [\\n        {\"topic_weights\": [0.02, 0.1, 0,...]},\\n        {\"topic_weights\": [0.25, 0.067, 0,...]}\\n    ]\\n}\\nJSONLINES Response Format\\n{\"topic_weights\": [0.02, 0.1, 0,...]}\\n{\"topic_weights\": [0.25, 0.067, 0,...]}\\nRECORDIO Response Format\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'topic_weights\\': {\\n                keys: [],\\n                values: [0.25, 0.067, 0, ...]  # float32\\n            }\\n        }\\n    },\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'topic_weights\\': {\\n                keys: [],\\n                values: [0.25, 0.067, 0, ...]  # float32\\n            }\\n        }\\n    }  \\n]\\n182Amazon SageMaker Developer Guide\\nObject2Vec\\nObject2Vec Algorithm\\nThe Amazon SageMaker Object2Vec algorithm is a general-purpose neural embedding algorithm\\nthat is highly customizable. It can learn low-dimensional dense embeddings of high-dimensional\\nobjects. The embeddings are learned in a way that preserves the semantics of the relationship between\\npairs of objects in the original space in the embedding space. You can use the learned embeddings to\\neﬃciently compute nearest neighbors of objects and to visualize natural clusters of related objects in\\nlow-dimensional space, for example. You can also use the embeddings as features of the corresponding\\nobjects in downstream supervised tasks, such as classiﬁcation or regression.\\nObject2Vec generalizes the well-known Word2Vec embedding technique for words that is optimized in\\nthe Amazon SageMaker BlazingText Algorithm (p. 74). For a blog post that discusses how to apply\\nObject2Vec to some practical use cases, see Introduction to Amazon SageMaker Object2Vec.\\nTopics\\n•I/O Interface for the Object2Vec Algorithm (p. 183)\\n•EC2 Instance Recommendation for the Object2Vec Algorithm (p. 184)\\n•Object2Vec Sample Notebooks (p. 184)\\n•How Object2Vec Works (p. 185)\\n•Object2Vec Hyperparameters (p. 186)\\n•Tune an Object2Vec Model (p. 194)\\n•Data Formats for Object2Vec Training (p. 196)\\n•Data Formats for Object2Vec Inference (p. 196)\\n•Encoder Embeddings for Object2Vec  (p. 198)\\nI/O Interface for the Object2Vec Algorithm\\nYou can use Object2Vec on many input data types, including the following examples.\\nInput Data Type Example\\nSentence-sentence pairs \"A soccer game with multiple males playing.\" and \"Some men are\\nplaying a sport.\"\\nLabels-sequence pairs The genre tags of the movie \"Titanic\", such as \"Romance\" and\\n\"Drama\", and its short description: \"James Cameron\\'s Titanic is\\nan epic, action-packed romance set against the ill-fated maiden\\nvoyage of the R.M.S. Titanic. She was the most luxurious liner of her\\nera, a ship of dreams, which ultimately carried over 1,500 people to\\ntheir death in the ice cold waters of the North Atlantic in the early\\nhours of April 15, 1912.\"\\nCustomer-customer pairs The customer ID of Jane and customer ID of Jackie.\\nProduct-product pairs The product ID of football and product ID of basketball.\\nItem review user-item pairs A user\\'s ID and the items she has bought, such as apple, pear, and\\norange.\\nTo transform the input data into the supported formats, you must preprocess it. Currently, Object2Vec\\nnatively supports two types of input:\\n•A discrete token, which is represented as a list of a single integer-id . For example, [10] .\\n183Amazon SageMaker Developer Guide\\nObject2Vec\\n•A sequences of discrete tokens, which is represented as a list of integer-ids . For example,\\n[0,12,10,13] .\\nThe object in each pair can be asymmetric. For example, the pairs can be (token, sequence) or (token,\\ntoken) or (sequence, sequence). For token inputs, the algorithm supports simple embeddings as\\ncompatible encoders. For sequences of token vectors, the algorithm supports the following as encoders:\\n•Average-pooled embeddings\\n•Hierarchical convolutional neural networks (CNNs),\\n•Multi-layered bidirectional long short-term memory (BiLSTMs)\\nThe input label for each pair can be one of the following:\\n•A categorical label that expresses the relationship between the objects in the pair\\n•A score that expresses the strength of the similarity between the two objects\\nFor categorical labels used in classiﬁcation, the algorithm supports the cross-entropy loss function. For\\nratings/score-based labels used in regression, the algorithm supports the mean squared error (MSE) loss\\nfunction. Specify these loss functions with the output_layer  hyperparameter when you create the\\nmodel training job.\\nEC2 Instance Recommendation for the Object2Vec Algorithm\\nThe type of Amazon Elastic Compute Cloud (Amazon EC2) instance that you use depends on whether you\\nare training or running inferences.\\nInstance Recommendation for Training\\nWhen training a model using the Object2Vec algorithm on a CPU, start with an ml.m5.2xlarge instance.\\nFor training on a GPU, start with an ml.p2.xlarge instance. If the training takes too long on this instance,\\nyou can use a larger instance, such as an ml.m5.4xlarge or an ml.m5.12xlarge instance Currently, the\\nObject2Vec algorithm can train only on a single machine. However, it does oﬀer support for multiple\\nGPUs.\\nInstance Recommendation for Inference\\nFor inference with a trained Object2Vec model that has a deep neural network, we recommend\\nusing ml.p3.2xlarge GPU instance. Due to GPU memory scarcity, the INFERENCE_PREFERRED_MODE\\nenvironment variable can be speciﬁed to optimize on whether the the section called “GPU\\noptimization: Classiﬁcation or Regression” (p. 196) or the section called “GPU optimization: Encoder\\nEmbeddings” (p. 198) inference network is loaded into GPU.\\nObject2Vec Sample Notebooks\\nFor a sample notebook that uses the Amazon SageMaker Object2Vec algorithm to encode sequences\\ninto ﬁxed-length embeddings, see Using Object2Vec to Encode Sentences into Fixed Length\\nEmbeddings . For a sample notebook that uses the Object2Vec algorithm in a multi-label prediction\\nsetting to predict the genre of a movie from its plot description, see Movie genre prediction\\nwith Object2Vec Algorithm. For a sample notebook that uses the Object2Vec algorithm to make\\nmovie recommendations, see An Introduction to SageMaker ObjectToVec model for MovieLens\\nrecommendation. For a sample notebook that uses the Object2Vec algorithm to learn document\\nembeddings, see Using Object2Vec to learn document embeddings. For instructions on how to create\\nand access Jupyter notebook instances that you can use to run the example in Amazon SageMaker,\\nsee Use Notebook Instances (p. 36). After you have created a notebook instance and opened it, choose\\n184Amazon SageMaker Developer Guide\\nObject2Vec\\nSageMaker Examples to see a list of Amazon SageMaker samples. To open a notebook, choose its Use\\ntab and choose Create copy.\\nHow Object2Vec Works\\nWhen using the Amazon SageMaker Object2Vec algorithm, you follow the standard workﬂow: process\\nthe data, train the model, and produce inferences.\\nTopics\\n•Step 1: Process Data (p. 185)\\n•Step 2: Train a Model (p. 185)\\n•Step 3: Produce Inferences  (p. 186)\\nStep 1: Process Data\\nDuring preprocessing, convert the data to the JSON Lines text ﬁle format speciﬁed in  Data Formats\\nfor Object2Vec Training (p. 196) . To get the highest accuracy during training, also randomly shuﬄe\\nthe data before feeding it into the model. How you generate random permutations depends on the\\nlanguage. For python, you could use np.randon.shuffle ; for Unix, shuf .\\nStep 2: Train a Model\\nThe Amazon SageMaker Object2Vec algorithm has the following main components:\\n•Two input channels – The input channels take a pair of objects of the same or diﬀerent types as\\ninputs, and pass them to independent and customizable encoders.\\n•Two encoders – The two encoders, enc0 and enc1, convert each object into a ﬁxed-length embedding\\nvector. The encoded embeddings of the objects in the pair are then passed into a comparator.\\n•A comparator – The comparator compares the embeddings in diﬀerent ways and outputs scores that\\nindicate the strength of the relationship between the paired objects. In the output score for a sentence\\npair. For example, 1 indicates a strong relationship between a sentence pair, and 0 represents a weak\\nrelationship.\\nDuring training, the algorithm accepts pairs of objects and their relationship labels or scores as inputs.\\nThe objects in each pair can be of diﬀerent types, as described earlier. If the inputs to both encoders are\\ncomposed of the same token-level units, you can use a shared token embedding layer by setting the\\ntied_token_embedding_weight  hyperparameter to True when you create the training job. This is\\npossible, for example, when comparing sentences that both have word token-level units. To generate\\nnegative samples at a speciﬁed rate, set the negative_sampling_rate  hyperparameter to the desired\\nratio of negative to positive samples. This hyperparameter expedites learning how to discriminate\\nbetween the positive samples observed in the training data and the negative samples that are not likely\\nto be observed.\\nPairs of objects are passed through independent, customizable encoders that are compatible with the\\ninput types of corresponding objects. The encoders convert each object in a pair into a ﬁxed-length\\nembedding vector of equal length. The pair of vectors are passed to a comparator operator, which\\nassembles the vectors into a single vector using the value speciﬁed in the he comparator_list\\nhyperparameter. The assembled vector then passes through a multilayer perceptron (MLP) layer, which\\nproduces an output that the loss function compares with the labels that you provided. This comparison\\nevaluates the strength of the relationship between the objects in the pair as predicted by the model. The\\nfollowing ﬁgure shows this workﬂow.\\n185Amazon SageMaker Developer Guide\\nObject2Vec\\nArchitecture of the Object2Vec Algorithm from Data Inputs to Scores\\nStep 3: Produce Inferences\\nAfter the model is trained, you can use the trained encoder to preprocess input objects or to perform two\\ntypes of inference:\\n•To convert singleton input objects into ﬁxed-length embeddings using the corresponding encoder\\n•To predict the relationship label or score between a pair of input objects\\nThe inference server automatically ﬁgures out which of the types is requested based on the input data.\\nTo get the embeddings as output, provide only one input. To predict the relationship label or score,\\nprovide both inputs in the pair.\\nObject2Vec Hyperparameters\\nIn the CreateTrainingJob  request, you specify the training algorithm. You can also specify algorithm-\\nspeciﬁc hyperparameters as string-to-string maps. The following table lists the hyperparameters for the\\nObject2Vec training algorithm.\\nParameter Name Description\\nenc0_max_seq_len The maximum sequence length for the enc0 encoder.\\nRequired\\nValid values: 1 ≤ integer ≤ 5000\\nenc0_vocab_size The vocabulary size of enc0 tokens.\\nRequired\\nValid values: 2 ≤ integer ≤ 3000000\\n186Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\nbucket_width The allowed diﬀerence between data sequence length when\\nbucketing is enabled. To enable bucketing, specify a non-zero value\\nfor this parameter.\\nOptional\\nValid values: 0 ≤ integer ≤ 100\\nDefault value: 0 (no bucketing)\\ncomparator_list A list used to customize the way in which two embeddings are\\ncompared. The Object2Vec comparator operator layer takes the\\nencodings from both encoders as inputs and outputs a single\\nvector. This vector is a concatenation of subvectors. The string\\nvalues passed to the comparator_list  and the order in which\\nthey are passed determine how these subvectors are assembled. For\\nexample, if comparator_list=\"hadamard, concat\" , then the\\ncomparator operator constructs the vector by concatenating the\\nHadamard product of two encodings and the concatenation of two\\nencodings. If, on the other hand, comparator_list=\"hadamard\" ,\\nthen the comparator operator constructs the vector as the\\nhadamard product of only two encodings.\\nOptional\\nValid values: A string that contains any combination of the names\\nof the three binary operators: hadamard , concat , or abs_diff .\\nThe Object2Vec algorithm currently requires that the two vector\\nencodings have the same dimension. These operators produce the\\nsubvectors as follows:\\n•hadamard : Constructs a vector as the Hadamard (element-wise)\\nproduct of two encodings.\\n•concat: Constructs a vector as the concatenation of two\\nencodings.\\n•abs_diff : Constructs a vector as the absolute diﬀerence\\nbetween two encodings.\\nDefault value: \"hadamard, concat, abs_diff\"\\ndropout The dropout probability for network layers. Dropout  is a form of\\nregularization used in neural networks that reduces overﬁtting by\\ntrimming codependent neurons.\\nOptional\\nValid values: 0.0 ≤ ﬂoat ≤ 1.0\\nDefault value: 0.0\\n187Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\nearly_stopping_patience The number of consecutive epochs without improvement allowed\\nbefore early stopping is applied. Improvement is deﬁned by with\\nthe early_stopping_tolerance  hyperparameter.\\nOptional\\nValid values: 1 ≤ integer ≤ 5\\nDefault value: 3\\nearly_stopping_tolerance The reduction in the loss function that an algorithm must\\nachieve between consecutive epochs to avoid early stopping\\nafter the number of consecutive epochs speciﬁed in the\\nearly_stopping_patience  hyperparameter concludes.\\nOptional\\nValid values: 0.000001 ≤ ﬂoat ≤ 0.1\\nDefault value: 0.01\\nenc_dim The dimension of the output of the embedding layer.\\nOptional\\nValid values: 4 ≤ integer ≤ 10000\\nDefault value: 4096\\nenc0_network The network model for the enc0 encoder.\\nOptional\\nValid values: hcnn , bilstm , or pooled_embedding\\n•hcnn: A hierarchical convolutional neural network.\\n•bilstm: A bidirectional long short-term memory network\\n(biLSTM), in which the signal propagates backward and forward\\nin time. This is an appropriate recurrent neural network (RNN)\\narchitecture for sequential learning tasks.\\n•pooled_embedding : Averages the embeddings of all of the\\ntokens in the input.\\nDefault value: hcnn\\nenc0_cnn_filter_width The ﬁlter width of the convolutional neural network (CNN) enc0\\nencoder.\\nConditional\\nValid values: 1 ≤ integer ≤ 9\\nDefault value: 3\\n188Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\nenc0_freeze_pretrained_embedding Whether to freeze enc0 pretrained embedding weights.\\nConditional\\nValid values: True  or False\\nDefault value: True\\nenc0_layers The number of layers in the enc0 encoder.\\nConditional\\nValid values: auto  or 1 ≤ integer ≤ 4\\n•For hcnn , auto  means 4.\\n•For bilstm , auto  means 1.\\n•For pooled_embedding , auto ignores the number of layers.\\nDefault value: auto\\nenc0_pretrained_embedding_file The ﬁlename of the pretrained enc0 token embedding ﬁle in the\\nauxiliary data channel.\\nConditional\\nValid values: String with alphanumeric characters, underscore, or\\nperiod. [A-Za-z0-9\\\\.\\\\_]\\nDefault value: \"\" (empty string)\\nenc0_token_embedding_dim The output dimension of the enc0 token embedding layer.\\nConditional\\nValid values: 2 ≤ integer ≤ 1000\\nDefault value: 300\\nenc0_vocab_file The vocabulary ﬁle for mapping pretrained enc0 token embedding\\nvectors to numerical vocabulary IDs.\\nConditional\\nValid values: String with alphanumeric characters, underscore, or\\nperiod. [A-Za-z0-9\\\\.\\\\_]\\nDefault value: \"\" (empty string)\\n189Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\nenc1_network The network model for the enc1 encoder. If you want the enc1\\nencoder to use the same network model as enc0, including the\\nhyperparameter values, set the value to enc0 .\\nNote\\nEven when the enc0 and enc1 encoder networks have\\nsymmetric architectures, you can\\'t shared parameter values\\nfor these networks.\\nOptional\\nValid values: enc0 , hcnn , bilstm , or pooled_embedding\\n•enc0: The network model for the enc0 encoder.\\n•hcnn: A hierarchical convolutional neural network.\\n•bilstm: A bidirectional LSTM, in which the signal propagates\\nbackward and forward in time. This is an appropriate recurrent\\nneural network (RNN) architecture for sequential learning tasks.\\n•pooled_embedding : The averages of the embeddings of all of\\nthe tokens in the input.\\nDefault value: enc0\\nenc1_cnn_filter_width The ﬁlter width of the CNN enc1 encoder.\\nConditional\\nValid values: 1 ≤ integer ≤ 9\\nDefault value: 3\\nenc1_freeze_pretrained_embedding Whether to freeze enc1 pretrained embedding weights.\\nConditional\\nValid values: True  or False\\nDefault value: True\\nenc1_layers The number of layers in the enc1 encoder.\\nConditional\\nValid values: auto  or 1 ≤ integer ≤ 4\\n•For hcnn , auto  means 4.\\n•For bilstm , auto  means 1.\\n•For pooled_embedding , auto ignores the number of layers.\\nDefault value: auto\\nenc1_max_seq_len The maximum sequence length for the enc1 encoder.\\nConditional\\nValid values: 1 ≤ integer ≤ 5000\\n190Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\nenc1_pretrained_embedding_file The name of the enc1 pretrained token embedding ﬁle in the\\nauxiliary data channel.\\nConditional\\nValid values: String with alphanumeric characters, underscore, or\\nperiod. [A-Za-z0-9\\\\.\\\\_]\\nDefault value: \"\" (empty string)\\nenc1_token_embedding_dim The output dimension of the enc1 token embedding layer.\\nConditional\\nValid values: 2 ≤ integer ≤ 1000\\nDefault value: 300\\nenc1_vocab_file The vocabulary ﬁle for mapping pretrained enc1 token embeddings\\nto vocabulary IDs.\\nConditional\\nValid values: String with alphanumeric characters, underscore, or\\nperiod. [A-Za-z0-9\\\\.\\\\_]\\nDefault value: \"\" (empty string)\\nenc1_vocab_size The vocabulary size of enc0 tokens.\\nConditional\\nValid values: 2 ≤ integer ≤ 3000000\\nepochs The number of epochs to run for training.\\nOptional\\nValid values: 1 ≤ integer ≤ 100\\nDefault value: 30\\nlearning_rate The learning rate for training.\\nOptional\\nValid values: 1.0E-6 ≤ ﬂoat ≤ 1.0\\nDefault value: 0.0004\\nmini_batch_size The batch size that the dataset is split into for an optimizer\\nduring training.\\nOptional\\nValid values: 1 ≤ integer ≤ 10000\\nDefault value: 32\\n191Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\nmlp_activation The type of activation function for the multilayer perceptron (MLP)\\nlayer.\\nOptional\\nValid values: tanh , relu , or linear\\n•tanh : Hyperbolic tangent\\n•relu: Rectiﬁed linear unit (ReLU)\\n•linear: Linear function\\nDefault value: linear\\nmlp_dim The dimension of the output from MLP layers.\\nOptional\\nValid values: 2 ≤ integer ≤ 10000\\nDefault value: 512\\nmlp_layers The number of MLP layers in the network.\\nOptional\\nValid values: 0 ≤ integer ≤ 10\\nDefault value: 2\\nnegative_sampling_rate The ratio of negative samples, generated to assist in training\\nthe algorithm, to positive samples that are provided by users.\\nNegative samples represent data that is unlikely to occur in reality\\nand are labelled negatively for training. They facilitate training\\na model to discriminate between the positive samples observed\\nand the negative samples that are not. To specify the ratio of\\nnegative samples to positive samples used for training, set the\\nvalue to a positive integer. For example, if you train the algorithm\\non input data in which all of the samples are positive and set\\nnegative_sampling_rate  to 2, the Object2Vec algorithm\\ninternally generates two negative samples per positive sample. If\\nyou don\\'t want to generate or use negative samples during training,\\nset the value to 0.\\nOptional\\nValid values: 0 ≤ integer\\nDefault value: 0 (oﬀ)\\nnum_classes The number of classes for classiﬁcation training. Amazon\\nSageMaker ignores this hyperparameter for regression problems.\\nOptional\\nValid values: 2 ≤ integer ≤ 30\\nDefault value: 2\\n192Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\noptimizer The optimizer type.\\nOptional\\nValid values: adadelta , adagrad , adam , sgd, or rmsprop .\\n•adadelta : A  per-dimension learning rate method for gradient\\ndescent\\n•adagrad : The adaptive gradient algorithm\\n•adam : The adaptive moment estimation algorithm\\n•sgd: Stochastic gradient descent\\n•rmsprop : Root mean square propagation\\nDefault value: adam\\noutput_layer The type of output layer where you specify that the task is\\nregression or classiﬁcation.\\nOptional\\nValid values: softmax  or mean_squared_error\\n•softmax : The Softmax function used for classiﬁcation.\\n•mean_squared_error : The MSE  used for regression.\\nDefault value: softmax\\ntied_token_embedding_weight Whether to use a shared embedding layer for both encoders. If\\nthe inputs to both encoders use the same token-level units, use\\na shared token embedding layer. For example, for a collection of\\ndocuments, if one encoder encodes sentences and another encodes\\nwhole documents, you can use a shared token embedding layer.\\nThat\\'s because both sentences and documents are composed of\\nword tokens from the same vocabulary.\\nOptional\\nValid values: True  or False\\nDefault value: False\\n193Amazon SageMaker Developer Guide\\nObject2Vec\\nParameter Name Description\\ntoken_embedding_storage_type The mode of gradient update used during training: when the dense\\nmode is used, the optimizer calculates the full gradient matrix for\\nthe token embedding layer even if most rows of the gradient are\\nzero-valued. When sparse mode is used, the optimizer only stores\\nrows of the gradient that are actually being used in the mini-batch.\\nIf you want the algorithm to perform lazy gradient updates, which\\ncalculate the gradients only in the non-zero rows and which speed\\nup training, specify row_sparse . Setting the value to row_sparse\\nconstrains the values available for other hyperparameters, as\\nfollows:\\n•The optimizer  hyperparameter must be set to adam ,\\nadagrad , or sgd. Otherwise, the algorithm throws a\\nCustomerValueError .\\n•The algorithm automatically disables bucketing, setting the\\nbucket_width  hyperparameter to 0.\\nOptional\\nValid values: dense  or row_sparse\\nDefault value: dense\\nweight_decay The weight decay parameter used for optimization.\\nOptional\\nValid values: 0 ≤ ﬂoat ≤ 10000\\nDefault value: 0 (no decay)\\nTune an Object2Vec Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. For the objective metric, you\\nuse one of the metrics that the algorithm computes. Automatic model tuning searches the chosen\\nhyperparameters to ﬁnd the combination of values that result in the model that optimizes the objective\\nmetric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the Object2Vec Algorithm\\nThe Object2Vec algorithm has both classiﬁcation and regression metrics. The output_layer  type\\ndetermines which metric you can use for automatic model tuning.\\nRegressor Metrics Computed by the Object2Vec Algorithm\\nThe algorithm reports a mean squared error regressor metric, which is computed during testing and\\nvalidation. When tuning the model for regression tasks, choose this metric as the objective.\\n194Amazon SageMaker Developer Guide\\nObject2Vec\\nMetric Name Description Optimization Direction\\ntest:mean_squared_error Root Mean Square Error Minimize\\nvalidation:mean_squared_error Root Mean Square Error Minimize\\nClassiﬁcation Metrics Computed by the Object2Vec Algorithm\\nThe Object2Vec algorithm reports accuracy and cross-entropy classiﬁcation metrics, which are computed\\nduring test and validation. When tuning the model for classiﬁcation tasks, choose one of these as the\\nobjective.\\nMetric Name Description Optimization Direction\\ntest:accuracy Accuracy Maximize\\ntest:cross_entropy Cross-entropy Minimize\\nvalidation:accuracy Accuracy Maximize\\nvalidation:cross_entropy Cross-entropy Minimize\\nTunable Object2Vec Hyperparameters\\nYou can tune the following hyperparameters for the Object2Vec algorithm.\\nHyperparameter\\nNameHyperparameter Type Recommended\\nRanges and Values\\ndropout ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 1.0\\nearly_stopping_patience IntegerParameterRange MinValue: 1,\\nMaxValue: 5\\nearly_stopping_tolerance ContinuousParameterRange MinValue: 0.001,\\nMaxValue: 0.1\\nenc_dim IntegerParameterRange MinValue: 4,\\nMaxValue: 4096\\nenc0_cnn_filter_width IntegerParameterRange MinValue: 1,\\nMaxValue: 5\\nenc0_layers IntegerParameterRange MinValue: 1,\\nMaxValue: 4\\nenc0_token_embedding_dim IntegerParameterRange MinValue: 5,\\nMaxValue: 300\\nenc1_cnn_filter_width IntegerParameterRange MinValue: 1,\\nMaxValue: 5\\nenc1_layers IntegerParameterRange MinValue: 1,\\nMaxValue: 4\\n195Amazon SageMaker Developer Guide\\nObject2Vec\\nHyperparameter\\nNameHyperparameter Type Recommended\\nRanges and Values\\nenc1_token_embedding_dim IntegerParameterRange MinValue: 5,\\nMaxValue: 300\\nepochs IntegerParameterRange MinValue: 4,\\nMaxValue: 20\\nlearning_rate ContinuousParameterRangeMinValue: 1e-6,\\nMaxValue: 1.0\\nmini_batch_size IntegerParameterRange MinValue: 1,\\nMaxValue: 8192\\nmlp_activation CategoricalParameterRanges [tanh , relu ,\\nlinear ]\\nmlp_dim IntegerParameterRange MinValue: 16,\\nMaxValue: 1024\\nmlp_layers IntegerParameterRange MinValue: 1,\\nMaxValue: 4\\noptimizer CategoricalParameterRanges [adagrad , adam ,\\nrmsprop , sgd,\\nadadelta ]\\nweight_decay ContinuousParameterRangeMinValue: 0.0,\\nMaxValue: 1.0\\nData Formats for Object2Vec Training\\nInput: JSON Lines Request Format\\nContent-type: application/jsonlines\\n{\"label\": 0, \"in0\": [6, 17, 606, 19, 53, 67, 52, 12, 5, 10, 15, 10178, 7, 33, 652, 80, 15,\\n 69, 821, 4], \"in1\": [16, 21, 13, 45, 14, 9, 80, 59, 164, 4]}\\n{\"label\": 1, \"in0\": [22, 1016, 32, 13, 25, 11, 5, 64, 573, 45, 5, 80, 15, 67, 21, 7, 9,\\n 107, 4], \"in1\": [22, 32, 13, 25, 1016, 573, 3252, 4]}\\n{\"label\": 1, \"in0\": [774, 14, 21, 206], \"in1\": [21, 366, 125]}\\nThe “in0” and “in1” are the inputs for encoder0 and encoder1, respectively. The same format is valid for\\nboth classiﬁcation and regression problems. For regression, the ﬁeld \"label\" can accept real valued\\ninputs.\\nData Formats for Object2Vec Inference\\nGPU optimization: Classiﬁcation or Regression\\nDue to GPU memory scarcity, the INFERENCE_PREFERRED_MODE  environment variable can be speciﬁed\\nto optimize on whether the classiﬁcation/regression or the the section called “Output: Encoder\\nEmbeddings” (p. 198) inference network is loaded into GPU. If the majority of your inference is for\\nclassiﬁcation or regression, specify INFERENCE_PREFERRED_MODE=classification . The following is\\na Batch Transform example of using 4 instances of p3.2xlarge that optimizes for classiﬁcation/regression\\ninference:\\n196Amazon SageMaker Developer Guide\\nObject2Vec\\ntransformer = o2v.transformer(instance_count=4, \\n                              instance_type=\"ml.p2.xlarge\", \\n                              max_concurrent_transforms=2,\\n                              max_payload=1,  # 1MB\\n                              strategy=\\'MultiRecord\\',\\n                              env={\\'INFERENCE_PREFERRED_MODE\\': \\'classification\\'},  # only\\n useful with GPU\\n                              output_path=output_s3_path)\\nInput: Classiﬁcation or Regression Request Format\\nContent-type: application/json\\n{\\n  \"instances\" : [\\n    {\"in0\": [6, 17, 606, 19, 53, 67, 52, 12, 5, 10, 15, 10178, 7, 33, 652, 80, 15, 69, 821,\\n 4], \"in1\": [16, 21, 13, 45, 14, 9, 80, 59, 164, 4]},\\n    {\"in0\": [22, 1016, 32, 13, 25, 11, 5, 64, 573, 45, 5, 80, 15, 67, 21, 7, 9, 107, 4],\\n \"in1\": [22, 32, 13, 25, 1016, 573, 3252, 4]},\\n    {\"in0\": [774, 14, 21, 206], \"in1\": [21, 366, 125]}\\n  ]\\n}\\nContent-type: application/jsonlines\\n{\"in0\": [6, 17, 606, 19, 53, 67, 52, 12, 5, 10, 15, 10178, 7, 33, 652, 80, 15, 69, 821, 4],\\n \"in1\": [16, 21, 13, 45, 14, 9, 80, 59, 164, 4]}\\n{\"in0\": [22, 1016, 32, 13, 25, 11, 5, 64, 573, 45, 5, 80, 15, 67, 21, 7, 9, 107, 4], \"in1\":\\n [22, 32, 13, 25, 1016, 573, 3252, 4]}\\n{\"in0\": [774, 14, 21, 206], \"in1\": [21, 366, 125]}\\nFor classiﬁcation problems, the length of the scores vector corresponds to num_classes . For regression\\nproblems, the length is 1.\\nOuput: Classiﬁcation or Regression Response Format\\nAccept: application/json\\n{\\n    \"predictions\": [\\n        {\\n            \"scores\": [\\n                0.6533935070037842,\\n                0.07582679390907288,\\n                0.2707797586917877\\n            ]\\n        },       \\n        {\\n            \"scores\": [\\n                0.026291321963071823,\\n                0.6577019095420837,\\n                0.31600672006607056\\n            ]\\n        }\\n    ]\\n}\\nAccept: application/jsonlines\\n{\"scores\":[0.195667684078216,0.395351558923721,0.408980727195739]}\\n197Amazon SageMaker Developer Guide\\nObject2Vec\\n{\"scores\":[0.251988261938095,0.258233487606048,0.489778339862823]}\\n{\"scores\":[0.280087798833847,0.368331134319305,0.351581096649169]}\\nIn both the classiﬁcation and regression formats, the scores apply to individual labels.\\nEncoder Embeddings for Object2Vec\\nGPU optimization: Encoder Embeddings\\nDue to GPU memory scarcity, the INFERENCE_PREFERRED_MODE  environment variable can be speciﬁed\\nto optimize on whether the the section called “Inference Formats: Scoring” (p. 196) or the encoder\\nembedding inference network is loaded into GPU. If the majority of your inference is for encoder\\nembeddings, specify INFERENCE_PREFERRED_MODE=embedding . The following is a Batch Transform\\nexample of using 4 instances of p3.2xlarge that optimizes for encoder embedding inference:\\ntransformer = o2v.transformer(instance_count=4, \\n                              instance_type=\"ml.p2.xlarge\", \\n                              max_concurrent_transforms=2,\\n                              max_payload=1,  # 1MB\\n                              strategy=\\'MultiRecord\\',\\n                              env={\\'INFERENCE_PREFERRED_MODE\\': \\'embedding\\'},  # only useful\\n with GPU\\n                              output_path=output_s3_path)\\nInput: Encoder Embeddings\\nContent-type: application/json\\n{\\n  \"instances\" : [\\n    {\"in0\": [6, 17, 606, 19, 53, 67, 52, 12, 5, 10, 15, 10178, 7, 33, 652, 80, 15, 69, 821,\\n 4]},\\n    {\"in0\": [22, 1016, 32, 13, 25, 11, 5, 64, 573, 45, 5, 80, 15, 67, 21, 7, 9, 107, 4]},\\n    {\"in0\": [774, 14, 21, 206]}\\n  ]\\n}\\nContent-type: application/jsonlines\\n{\"in0\": [6, 17, 606, 19, 53, 67, 52, 12, 5, 10, 15, 10178, 7, 33, 652, 80, 15, 69, 821, 4]}\\n{\"in0\": [22, 1016, 32, 13, 25, 11, 5, 64, 573, 45, 5, 80, 15, 67, 21, 7, 9, 107, 4]}\\n{\"in0\": [774, 14, 21, 206]}\\nIn both of these formats, you specify only one input type: “in0”  or “in1.” The inference service then\\ninvokes the corresponding encoder and outputs the embeddings for each of the instances.\\nOutput: Encoder Embeddings\\nContent-type: application/json\\n{\\n  \"predictions\": [\\n    {\"embeddings\":\\n[0.057368703186511,0.030703511089086,0.099890425801277,0.063688032329082,0.026327300816774,0.003637571120634,0.021305780857801,0.004316598642617,0.0,0.003397724591195,0.0,0.000378780066967,0.0,0.0,0.0,0.007419463712722]},\\n    {\"embeddings\":\\n[0.150190666317939,0.05145975202322,0.098204270005226,0.064249359071254,0.056249320507049,0.01513972133398,0.047553978860378,0.0,0.0,0.011533712036907,0.011472506448626,0.010696629062294,0.0,0.0,0.0,0.008508535102009]}\\n  ]\\n198Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\n}\\nContent-type: application/jsonlines\\n{\"embeddings\":\\n[0.057368703186511,0.030703511089086,0.099890425801277,0.063688032329082,0.026327300816774,0.003637571120634,0.021305780857801,0.004316598642617,0.0,0.003397724591195,0.0,0.000378780066967,0.0,0.0,0.0,0.007419463712722]}\\n{\"embeddings\":\\n[0.150190666317939,0.05145975202322,0.098204270005226,0.064249359071254,0.056249320507049,0.01513972133398,0.047553978860378,0.0,0.0,0.011533712036907,0.011472506448626,0.010696629062294,0.0,0.0,0.0,0.008508535102009]}\\nThe vector length of the embeddings output by the inference service is equal to the value of one of\\nthe following hyperparameters that you specify at training time: enc0_token_embedding_dim ,\\nenc1_token_embedding_dim , or enc_dim .\\nObject Detection Algorithm\\nThe Amazon SageMaker Object Detection algorithm detects and classiﬁes objects in images using a\\nsingle deep neural network. It is a supervised learning algorithm that takes images as input and identiﬁes\\nall instances of objects within the image scene. The object is categorized into one of the classes in a\\nspeciﬁed collection with a conﬁdence score that it belongs to the class. Its location and scale in the\\nimage are indicated by a rectangular bounding box. It uses the Single Shot multibox Detector (SSD)\\nframework and supports two base networks: VGG and ResNet. The network can be trained from scratch,\\nor trained with models that have been pre-trained on the ImageNet  dataset.\\nTopics\\n•Input/Output Interface for the Object Detection Algorithm (p. 199)\\n•EC2 Instance Recommendation for the Object Detection Algorithm (p. 214)\\n•Object Detection Sample Notebooks (p. 214)\\n•How Object Detection Works (p. 214)\\n•Object Detection Hyperparameters (p. 215)\\n•Tune an Object Detection Model (p. 220)\\n•Object Detection Request and Response Formats (p. 221)\\nInput/Output Interface for the Object Detection Algorithm\\nThe Amazon SageMaker Object Detection algorithm supports both RecordIO (application/x-\\nrecordio ) and image ( image/png , image/jpeg , and application/x-image ) content types\\nfor training in ﬁle mode and supports RecordIO (application/x-recordio ) for training in pipe\\nmode. However you can also train in pipe mode using the image ﬁles (image/png , image/jpeg , and\\napplication/x-image ), without creating RecordIO ﬁles, by using the augmented manifest format. The\\nrecommended input format for the Amazon SageMaker object detection algorithms is Apache MXNet\\nRecordIO. However, you can also use raw images in .jpg or .png format. The algorithm supports only\\napplication/x-image  for inference.\\nNote\\nTo maintain better interoperability with existing deep learning frameworks, this diﬀers from the\\nprotobuf data formats commonly used by other Amazon SageMaker algorithms.\\nSee the Object Detection Sample Notebooks (p. 214) for more details on data formats.\\nTrain with the RecordIO Format\\nIf you use the RecordIO format for training, specify both train and validation channels as values for\\nthe InputDataConfig  parameter of the CreateTrainingJob (p. 667) request. Specify one RecordIO\\n(.rec) ﬁle in the train channel and one RecordIO ﬁle in the validation channel. Set the content type for\\n199Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nboth channels to application/x-recordio . An example of how to generate RecordIO ﬁle can be\\nfound in the object detection sample notebook. You can also use tools from the MXNet  example to\\ngenerate RecordIO ﬁles for popular datasets like the PASCAL Visual Object Classes and Common Objects\\nin Context (COCO).\\nTrain with the Image Format\\nIf you use the image format for training, specify train , validation , train_annotation ,\\nand validation_annotation  channels as values for the InputDataConfig  parameter of\\nCreateTrainingJob (p. 667) request. Specify the individual image data (.jpg or .png) ﬁles for the\\ntrain and validation channels. For annotation data, you can use the JSON format. Specify the\\ncorresponding .json ﬁles in the train_annotation  and validation_annotation  channels. Set the\\ncontent type for all four channels to image/png  or image/jpeg  based on the image type. You can also\\nuse the content type application/x-image  when your dataset contains both .jpg and .png images.\\nThe following is an example of a .json ﬁle.\\n{\\n   \"file\": \"your_image_directory/sample_image1.jpg\",\\n   \"image_size\": [\\n      {\\n         \"width\": 500,\\n         \"height\": 400,\\n         \"depth\": 3\\n      }\\n   ],\\n   \"annotations\": [\\n      {\\n         \"class_id\": 0,\\n         \"left\": 111,\\n         \"top\": 134,\\n         \"width\": 61,\\n         \"height\": 128\\n      },\\n      {\\n         \"class_id\": 0,\\n         \"left\": 161,\\n         \"top\": 250,\\n         \"width\": 79,\\n         \"height\": 143\\n      },\\n      {\\n         \"class_id\": 1,\\n         \"left\": 101,\\n         \"top\": 185,\\n         \"width\": 42,\\n         \"height\": 130\\n      }\\n   ],\\n   \"categories\": [\\n      {\\n         \"class_id\": 0,\\n         \"name\": \"dog\"\\n      },\\n      {\\n         \"class_id\": 1,\\n         \"name\": \"cat\"\\n      }\\n   ]\\n}\\nEach image needs a .json ﬁle for annotation, and the .json ﬁle should have the same name as the\\ncorresponding image. The name of above .json ﬁle should be \"sample_image1.json\". There are four\\n200Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nproperties in the annotation .json ﬁle. The property \"ﬁle\" speciﬁes the relative path of the image ﬁle.\\nFor example, if your training images and corresponding .json ﬁles are stored in s3://your_bucket /\\ntrain/sample_image and s3:// your_bucket /train_annotation, specify the path for your train and\\ntrain_annotation channels as s3:// your_bucket /train and s3:// your_bucket /train_annotation,\\nrespectively.\\nIn the .json ﬁle, the relative path for an image named sample_image1.jpg should be sample_image/\\nsample_image1.jpg. The \"image_size\"  property speciﬁes the overall image dimensions. The\\nSageMaker object detection algorithm currently only supports 3-channel images. The \"annotations\"\\nproperty speciﬁes the categories and bounding boxes for objects within the image. Each object is\\nannotated by a \"class_id\"  index and by four bounding box coordinates (\"left\" , \"top\" , \"width\" ,\\n\"height\" ). The \"left\" (x-coordinate) and \"top\" (y-coordinate) values represent the upper-left corner\\nof the bounding box. The \"width\" (x-coordinate) and \"height\"  (y-coordinate) values represent the\\ndimensions of the bounding box. The origin (0, 0) is the upper-left corner of the entire image. If you\\nhave multiple objects within one image, all the annotations should be included in a single .json ﬁle. The\\n\"categories\"  property stores the mapping between the class index and class name. The class indices\\nshould be numbered successively and the numbering should start with 0. The \"categories\"  property is\\noptional for the annotation .json ﬁle\\nTrain with Augmented Manifest Image Format\\nThe augmented manifest format enables you to do training in pipe mode using image ﬁles without\\nneeding to create RecordIO ﬁles. You need to specify both train and validation channels as values for the\\nInputDataConfig  parameter of the\\nStarts a model training job. After training completes, Amazon SageMaker saves the resulting\\nmodel artifacts to an Amazon S3 location that you specify.\\nIf you choose to host your model using Amazon SageMaker hosting services, you can use the\\nresulting model artifacts as part of the model. You can also use the artifacts in a machine\\nlearning service other than Amazon SageMaker, provided that you know how to use them for\\ninferences.\\nIn the request body, you provide the following:\\n•AlgorithmSpecification  - Identiﬁes the training algorithm to use.\\n•HyperParameters  - Specify these algorithm-speciﬁc parameters to enable the estimation\\nof model parameters during training. Hyperparameters can be tuned to optimize this\\nlearning process. For a list of hyperparameters for each training algorithm provided by\\nAmazon SageMaker, see Algorithms .\\n•InputDataConfig  - Describes the training dataset and the Amazon S3, EFS, or FSx\\nlocation where it is stored.\\n•OutputDataConfig  - Identiﬁes the Amazon S3 bucket where you want Amazon\\nSageMaker to save the results of model training.\\n•ResourceConfig  - Identiﬁes the resources, ML compute instances, and ML storage\\nvolumes to deploy for model training. In distributed training, you specify more than one\\ninstance.\\n•EnableManagedSpotTraining  - Optimize the cost of training machine learning models\\nby up to 80% by using Amazon EC2 Spot instances. For more information, see Managed\\nSpot Training.\\n•RoleARN - The Amazon Resource Number (ARN) that Amazon SageMaker assumes to\\nperform tasks on your behalf during model training. You must grant this role the necessary\\npermissions so that Amazon SageMaker can successfully complete model training.\\n•StoppingCondition  - To help cap training costs, use MaxRuntimeInSeconds  to set a\\ntime limit for training. Use MaxWaitTimeInSeconds  to specify how long you are willing\\nto to wait for a managed spot training job to complete.\\n201Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nFor more information about Amazon SageMaker, see How It Works.\\nRequest Syntax\\n{\\n   \"AlgorithmSpecification \": { \\n      \"AlgorithmName \": \"string\",\\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingInputMode \": \"string\"\\n   },\\n   \"CheckpointConfig \": { \\n      \"LocalPath \": \"string\",\\n      \"S3Uri\": \"string\"\\n   },\\n   \"EnableInterContainerTrafficEncryption \": boolean,\\n   \"EnableManagedSpotTraining \": boolean,\\n   \"EnableNetworkIsolation \": boolean,\\n   \"HyperParameters \": { \\n      \"string\" : \"string\" \\n   },\\n   \"InputDataConfig \": [ \\n      { \\n         \" ChannelName \": \"string\",\\n         \" CompressionType \": \"string\",\\n         \" ContentType \": \"string\",\\n         \" DataSource \": { \\n            \" FileSystemDataSource \": { \\n               \" DirectoryPath \": \"string\",\\n               \" FileSystemAccessMode \": \"string\",\\n               \" FileSystemId \": \"string\",\\n               \" FileSystemType \": \"string\"\\n            },\\n            \" S3DataSource \": { \\n               \" AttributeNames \": [ \"string\" ],\\n               \" S3DataDistributionType \": \"string\",\\n               \" S3DataType \": \"string\",\\n               \" S3Uri\": \"string\"\\n            }\\n         },\\n         \" InputMode \": \"string\",\\n         \" RecordWrapperType \": \"string\",\\n         \" ShuffleConfig \": { \\n            \" Seed\": number\\n         }\\n      }\\n   ],\\n   \"OutputDataConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"ResourceConfig \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\",\\n      \"VolumeSizeInGB \": number\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,202Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\n      \"MaxWaitTimeInSeconds \": number\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"TrainingJobName \": \"string\",\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n      \"Subnets\": [ \"string\" ]\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAlgorithmSpeciﬁcation (p. 667)\\nThe registry path of the Docker image that contains the training algorithm and\\nalgorithm-speciﬁc metadata, including the input mode. For more information\\nabout algorithms provided by Amazon SageMaker, see Algorithms . For information\\nabout providing your own algorithms, see Using Your Own Algorithms with Amazon\\nSageMaker.\\nType: AlgorithmSpeciﬁcation  (p. 863) object\\nRequired: Yes\\nCheckpointConﬁg  (p. 667)\\nContains information about the output location for managed spot training checkpoint\\ndata.\\nType: CheckpointConﬁg  (p. 880) object\\nRequired: No\\nEnableInterContainerTraﬃcEncryption (p. 667)\\nTo encrypt all communications between ML compute instances in distributed training,\\nchoose True. Encryption provides greater security for distributed training, but training\\nmight take longer. How long it takes depends on the amount of communication between\\ncompute instances, especially if you use a deep learning algorithm in distributed training.\\nFor more information, see Protect Communications Between ML Compute Instances in a\\nDistributed Training Job.\\nType: Boolean\\nRequired: No\\nEnableManagedSpotTraining (p. 667)\\nTo train models using managed spot training, choose True . Managed spot training\\nprovides a fully managed and scalable infrastructure for training machine learning\\nmodels. this option is useful when training jobs can be interrupted and when there is\\nﬂexibility when the training job is run.\\nThe complete and intermediate results of jobs are stored in an Amazon S3 bucket,\\nand can be used as a starting point to train models incrementally. Amazon SageMaker203Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nprovides metrics and logs in CloudWatch. They can be used to see when managed spot\\ntraining jobs are running, interrupted, resumed, or completed.\\nType: Boolean\\nRequired: No\\nEnableNetworkIsolation (p. 667)\\nIsolates the training container. No inbound or outbound network calls can be made,\\nexcept for calls between peers within a training cluster for distributed training. If you\\nenable network isolation for training jobs that are conﬁgured to use a VPC, Amazon\\nSageMaker downloads and uploads customer data and model artifacts through the\\nspeciﬁed VPC, but the training container does not have network access.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network\\nisolation.\\nType: Boolean\\nRequired: No\\nHyperParameters (p. 667)\\nAlgorithm-speciﬁc parameters that inﬂuence the quality of the model. You set\\nhyperparameters before you start the learning process. For a list of hyperparameters for\\neach training algorithm provided by Amazon SageMaker, see Algorithms .\\nYou can specify a maximum of 100 hyperparameters. Each hyperparameter is a key-\\nvalue pair. Each key and value is limited to 256 characters, as speciﬁed by the Length\\nConstraint .\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nInputDataConﬁg  (p. 667)\\nAn array of Channel objects. Each channel is a named input source. InputDataConfig\\ndescribes the input data and its location.\\nAlgorithms can accept input data from one or more channels. For example, an algorithm\\nmight have two channels of input data, training_data  and validation_data . The\\nconﬁguration for each channel provides the S3, EFS, or FSx location where the input data\\nis stored. It also provides information about the stored data: the MIME type, compression\\nmethod, and whether the data is wrapped in RecordIO format.\\nDepending on the input mode that the algorithm supports, Amazon SageMaker either\\ncopies input data ﬁles from an S3 bucket to a local directory in the Docker container, or\\nmakes it available as input streams. For example, if you specify an EFS location, input\\ndata ﬁles will be made available as input streams. They do not need to be downloaded.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\n204Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nRequired: No\\nOutputDataConﬁg  (p. 667)\\nSpeciﬁes the path to the S3 location where you want to store model artifacts. Amazon\\nSageMaker creates subfolders for the artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: Yes\\nResourceConﬁg (p. 667)\\nThe resources, including the ML compute instances and ML storage volumes, to use for\\nmodel training.\\nML storage volumes store model artifacts and incremental states. Training algorithms\\nmight also use ML storage volumes for scratch space. If you want Amazon SageMaker\\nto use the ML storage volume to store the training data, choose File  as the\\nTrainingInputMode  in the algorithm speciﬁcation. For distributed training algorithms,\\nspecify an instance count greater than 1.\\nType: ResourceConﬁg (p. 991) object\\nRequired: Yes\\nRoleArn (p. 667)\\nThe Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker can assume to\\nperform tasks on your behalf.\\nDuring model training, Amazon SageMaker needs your permission to read input data\\nfrom an S3 bucket, download a Docker image that contains training code, write model\\nartifacts to an S3 bucket, write logs to Amazon CloudWatch Logs, and publish metrics\\nto Amazon CloudWatch. You grant permissions for all of these tasks to an IAM role. For\\nmore information, see Amazon SageMaker Roles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must\\nhave the iam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStoppingCondition  (p. 667)\\nSpeciﬁes a limit to how long a model training job can run. When the job reaches the time\\nlimit, Amazon SageMaker ends the training job. Use this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays\\njob termination for 120 seconds. Algorithms can use this 120-second window to save the\\nmodel artifacts, so the results of training are not lost.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\nTags (p. 667)\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tags in the\\nAWS Billing and Cost Management User Guide.\\n205Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTrainingJobName (p. 667)\\nThe name of the training job. The name must be unique within an AWS Region in an AWS\\naccount.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nVpcConﬁg (p. 667)\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that you want your training job to\\nconnect to. Control access to and from your training container by conﬁguring the VPC.\\nFor more information, see Protect Training Jobs by Using an Amazon Virtual Private\\nCloud .\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"TrainingJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nTrainingJobArn (p. 672)\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-\\njob/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common\\nErrors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.206Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have\\ntoo many training jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the\\nfollowing:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n (p. ) request. While using the format, an S3 manifest ﬁle needs to be generated that contains\\nthe list of images and their corresponding annotations. The manifest ﬁle format should be in JSON\\nLines  format in which each line represents one sample. The images are speciﬁed using the \\'source-\\nref\\' tag that points to the S3 location of the image. The annotations are provided under the\\n\"AttributeNames\"  parameter value as speciﬁed in the\\nStarts a model training job. After training completes, Amazon SageMaker saves the resulting\\nmodel artifacts to an Amazon S3 location that you specify.\\nIf you choose to host your model using Amazon SageMaker hosting services, you can use the\\nresulting model artifacts as part of the model. You can also use the artifacts in a machine\\nlearning service other than Amazon SageMaker, provided that you know how to use them for\\ninferences.\\nIn the request body, you provide the following:\\n•AlgorithmSpecification  - Identiﬁes the training algorithm to use.\\n•HyperParameters  - Specify these algorithm-speciﬁc parameters to enable the estimation\\nof model parameters during training. Hyperparameters can be tuned to optimize this\\nlearning process. For a list of hyperparameters for each training algorithm provided by\\nAmazon SageMaker, see Algorithms .\\n•InputDataConfig  - Describes the training dataset and the Amazon S3, EFS, or FSx\\nlocation where it is stored.\\n•OutputDataConfig  - Identiﬁes the Amazon S3 bucket where you want Amazon\\nSageMaker to save the results of model training.\\n•ResourceConfig  - Identiﬁes the resources, ML compute instances, and ML storage\\nvolumes to deploy for model training. In distributed training, you specify more than one\\ninstance.\\n207Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\n•EnableManagedSpotTraining  - Optimize the cost of training machine learning models\\nby up to 80% by using Amazon EC2 Spot instances. For more information, see Managed\\nSpot Training.\\n•RoleARN - The Amazon Resource Number (ARN) that Amazon SageMaker assumes to\\nperform tasks on your behalf during model training. You must grant this role the necessary\\npermissions so that Amazon SageMaker can successfully complete model training.\\n•StoppingCondition  - To help cap training costs, use MaxRuntimeInSeconds  to set a\\ntime limit for training. Use MaxWaitTimeInSeconds  to specify how long you are willing\\nto to wait for a managed spot training job to complete.\\nFor more information about Amazon SageMaker, see How It Works.\\nRequest Syntax\\n{\\n   \"AlgorithmSpecification \": { \\n      \"AlgorithmName \": \"string\",\\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingInputMode \": \"string\"\\n   },\\n   \"CheckpointConfig \": { \\n      \"LocalPath \": \"string\",\\n      \"S3Uri\": \"string\"\\n   },\\n   \"EnableInterContainerTrafficEncryption \": boolean,\\n   \"EnableManagedSpotTraining \": boolean,\\n   \"EnableNetworkIsolation \": boolean,\\n   \"HyperParameters \": { \\n      \"string\" : \"string\" \\n   },\\n   \"InputDataConfig \": [ \\n      { \\n         \" ChannelName \": \"string\",\\n         \" CompressionType \": \"string\",\\n         \" ContentType \": \"string\",\\n         \" DataSource \": { \\n            \" FileSystemDataSource \": { \\n               \" DirectoryPath \": \"string\",\\n               \" FileSystemAccessMode \": \"string\",\\n               \" FileSystemId \": \"string\",\\n               \" FileSystemType \": \"string\"\\n            },\\n            \" S3DataSource \": { \\n               \" AttributeNames \": [ \"string\" ],\\n               \" S3DataDistributionType \": \"string\",\\n               \" S3DataType \": \"string\",\\n               \" S3Uri\": \"string\"\\n            }\\n         },\\n         \" InputMode \": \"string\",\\n         \" RecordWrapperType \": \"string\",\\n         \" ShuffleConfig \": { \\n            \" Seed\": number\\n         }\\n      }\\n   ],208Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\n   \"OutputDataConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"ResourceConfig \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\",\\n      \"VolumeSizeInGB \": number\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,\\n      \"MaxWaitTimeInSeconds \": number\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"TrainingJobName \": \"string\",\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n      \"Subnets\": [ \"string\" ]\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAlgorithmSpeciﬁcation (p. 667)\\nThe registry path of the Docker image that contains the training algorithm and\\nalgorithm-speciﬁc metadata, including the input mode. For more information\\nabout algorithms provided by Amazon SageMaker, see Algorithms . For information\\nabout providing your own algorithms, see Using Your Own Algorithms with Amazon\\nSageMaker.\\nType: AlgorithmSpeciﬁcation  (p. 863) object\\nRequired: Yes\\nCheckpointConﬁg  (p. 667)\\nContains information about the output location for managed spot training checkpoint\\ndata.\\nType: CheckpointConﬁg  (p. 880) object\\nRequired: No\\nEnableInterContainerTraﬃcEncryption (p. 667)\\nTo encrypt all communications between ML compute instances in distributed training,\\nchoose True. Encryption provides greater security for distributed training, but training\\nmight take longer. How long it takes depends on the amount of communication between\\ncompute instances, especially if you use a deep learning algorithm in distributed training.\\nFor more information, see Protect Communications Between ML Compute Instances in a\\nDistributed Training Job.209Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nType: Boolean\\nRequired: No\\nEnableManagedSpotTraining (p. 667)\\nTo train models using managed spot training, choose True . Managed spot training\\nprovides a fully managed and scalable infrastructure for training machine learning\\nmodels. this option is useful when training jobs can be interrupted and when there is\\nﬂexibility when the training job is run.\\nThe complete and intermediate results of jobs are stored in an Amazon S3 bucket,\\nand can be used as a starting point to train models incrementally. Amazon SageMaker\\nprovides metrics and logs in CloudWatch. They can be used to see when managed spot\\ntraining jobs are running, interrupted, resumed, or completed.\\nType: Boolean\\nRequired: No\\nEnableNetworkIsolation (p. 667)\\nIsolates the training container. No inbound or outbound network calls can be made,\\nexcept for calls between peers within a training cluster for distributed training. If you\\nenable network isolation for training jobs that are conﬁgured to use a VPC, Amazon\\nSageMaker downloads and uploads customer data and model artifacts through the\\nspeciﬁed VPC, but the training container does not have network access.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network\\nisolation.\\nType: Boolean\\nRequired: No\\nHyperParameters (p. 667)\\nAlgorithm-speciﬁc parameters that inﬂuence the quality of the model. You set\\nhyperparameters before you start the learning process. For a list of hyperparameters for\\neach training algorithm provided by Amazon SageMaker, see Algorithms .\\nYou can specify a maximum of 100 hyperparameters. Each hyperparameter is a key-\\nvalue pair. Each key and value is limited to 256 characters, as speciﬁed by the Length\\nConstraint .\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nInputDataConﬁg  (p. 667)\\nAn array of Channel objects. Each channel is a named input source. InputDataConfig\\ndescribes the input data and its location.\\nAlgorithms can accept input data from one or more channels. For example, an algorithm\\nmight have two channels of input data, training_data  and validation_data . The\\n210Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nconﬁguration for each channel provides the S3, EFS, or FSx location where the input data\\nis stored. It also provides information about the stored data: the MIME type, compression\\nmethod, and whether the data is wrapped in RecordIO format.\\nDepending on the input mode that the algorithm supports, Amazon SageMaker either\\ncopies input data ﬁles from an S3 bucket to a local directory in the Docker container, or\\nmakes it available as input streams. For example, if you specify an EFS location, input\\ndata ﬁles will be made available as input streams. They do not need to be downloaded.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No\\nOutputDataConﬁg  (p. 667)\\nSpeciﬁes the path to the S3 location where you want to store model artifacts. Amazon\\nSageMaker creates subfolders for the artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: Yes\\nResourceConﬁg (p. 667)\\nThe resources, including the ML compute instances and ML storage volumes, to use for\\nmodel training.\\nML storage volumes store model artifacts and incremental states. Training algorithms\\nmight also use ML storage volumes for scratch space. If you want Amazon SageMaker\\nto use the ML storage volume to store the training data, choose File  as the\\nTrainingInputMode  in the algorithm speciﬁcation. For distributed training algorithms,\\nspecify an instance count greater than 1.\\nType: ResourceConﬁg (p. 991) object\\nRequired: Yes\\nRoleArn (p. 667)\\nThe Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker can assume to\\nperform tasks on your behalf.\\nDuring model training, Amazon SageMaker needs your permission to read input data\\nfrom an S3 bucket, download a Docker image that contains training code, write model\\nartifacts to an S3 bucket, write logs to Amazon CloudWatch Logs, and publish metrics\\nto Amazon CloudWatch. You grant permissions for all of these tasks to an IAM role. For\\nmore information, see Amazon SageMaker Roles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must\\nhave the iam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStoppingCondition  (p. 667)\\nSpeciﬁes a limit to how long a model training job can run. When the job reaches the time\\nlimit, Amazon SageMaker ends the training job. Use this API to cap model training costs.\\n211Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays\\njob termination for 120 seconds. Algorithms can use this 120-second window to save the\\nmodel artifacts, so the results of training are not lost.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\nTags (p. 667)\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tags in the\\nAWS Billing and Cost Management User Guide.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTrainingJobName (p. 667)\\nThe name of the training job. The name must be unique within an AWS Region in an AWS\\naccount.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nVpcConﬁg (p. 667)\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that you want your training job to\\nconnect to. Control access to and from your training container by conﬁguring the VPC.\\nFor more information, see Protect Training Jobs by Using an Amazon Virtual Private\\nCloud .\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"TrainingJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nTrainingJobArn (p. 672)\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-\\njob/.*212Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nErrors\\nFor information about the errors that are common to all actions, see Common\\nErrors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have\\ntoo many training jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the\\nfollowing:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n (p. ) request. It can also contain additional metadata under the metadata  tag, but these are\\nignored by the algorithm. In the following example, the \"AttributeNames  are contained in the list\\n[\"source-ref\", \"bounding-box\"] :\\n{\"source-ref\": \"s3://your_bucket/image1.jpg\", \"bounding-box\":{\"image_size\":[{ \"width\":\\n 500, \"height\": 400, \"depth\":3}], \"annotations\":[{\"class_id\": 0, \"left\": 111, \"top\":\\n 134, \"width\": 61, \"height\": 128}, {\"class_id\": 5, \"left\": 161, \"top\": 250, \"width\": 80,\\n \"height\": 50}]}, \"bounding-box-metadata\":{\"class-map\":{\"0\": \"dog\", \"5\": \"horse\"}, \"type\":\\n \"groundtruth/object_detection\"}}\\n{\"source-ref\": \"s3://your_bucket/image2.jpg\", \"bounding-box\":{\"image_size\":[{ \"width\":\\n 400, \"height\": 300, \"depth\":3}], \"annotations\":[{\"class_id\": 1, \"left\": 100, \"top\": 120,\\n \"width\": 43, \"height\": 78}]}, \"bounding-box-metadata\":{\"class-map\":{\"1\": \"cat\"}, \"type\":\\n \"groundtruth/object_detection\"}}\\nThe order of \"AttributeNames\"  in the input ﬁles matters when training the Object Detection\\nalgorithm. It accepts piped data in a speciﬁc order, with image ﬁrst, followed by annotations . So the\\n\"AttributeNames\" in this example are provided with \"source-ref\"  ﬁrst, followed by \"bounding-box\" .\\nWhen using Object Detection with Augmented Manifest, the value of parameter RecordWrapperType\\nmust be set as \"RecordIO\" .\\nFor more information on augmented manifest ﬁles, see Provide Dataset Metadata to Training Jobs with\\nan Augmented Manifest File  (p. 308).\\n213Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nIncremental Training\\nYou can also seed the training of a new model with the artifacts from a model that you trained\\npreviously with Amazon SageMaker. Incremental training saves training time when you want to train a\\nnew model with the same or similar data. Amazon SageMaker object detection models can be seeded\\nonly with another built-in object detection model trained in Amazon SageMaker.\\nTo use a pretrained model, in the CreateTrainingJob (p. 667) request, specify the ChannelName\\nas \"model\" in the InputDataConfig  parameter. Set the ContentType  for the model channel to\\napplication/x-sagemaker-model . The input hyperparameters of both the new model and\\nthe pretrained model that you upload to the model channel must have the same settings for the\\nbase_network  and num_classes  input parameters. These parameters deﬁne the network architecture.\\nFor the pretrained model ﬁle, use the compressed model artifacts (in .tar.gz format) output by Amazon\\nSageMaker. You can use either RecordIO or image formats for input data.\\nFor a sample notebook that shows how to use incremental training with the Amazon SageMaker object\\ndetection algorithm, see Amazon SageMaker Object Detection Incremental Training sample notebook.\\nFor more information on incremental training and for instructions on how to use it, see Incremental\\nTraining in Amazon SageMaker (p. 282).\\nEC2 Instance Recommendation for the Object Detection\\nAlgorithm\\nFor object detection, we support the following GPU instances for training: ml.p2.xlarge ,\\nml.p2.8xlarge , ml.p2.16xlarge , ml.p3.2xlarge , ml.p3.8xlarge  and ml.p3.16xlarge . We\\nrecommend using GPU instances with more memory for training with large batch sizes. You can also\\nrun the algorithm on multi-GPU and multi-machine settings for distributed training. However, both\\nCPU (such as C5 and M5) and GPU (such as P2 and P3) instances can be used for the inference. All the\\nsupported instance types for inference are itemized on Amazon SageMaker ML Instance Types.\\nObject Detection Sample Notebooks\\nFor a sample notebook that shows how to use the Amazon SageMaker Object Detection algorithm to\\ntrain and host a model on the COCO dataset using the Single Shot multibox Detector algorithm, see\\nObject Detection using the Image and JSON format. For instructions how to create and access Jupyter\\nnotebook instances that you can use to run the example in Amazon SageMaker, see Use Notebook\\nInstances (p. 36). Once you have created a notebook instance and opened it, select the SageMaker\\nExamples tab to see a list of all the Amazon SageMaker samples. The topic modeling example notebooks\\nusing the NTM algorithms are located in the Introduction to Amazon algorithms section. To open a\\nnotebook, click on its Use tab and select Create copy.\\nHow Object Detection Works\\nThe object detection algorithm identiﬁes and locates all instances of objects in an image from a known\\ncollection of object categories. The algorithm takes an image as input and outputs the category that\\nthe object belongs to, along with a conﬁdence score that it belongs to the category. The algorithm\\nalso predicts the object\\'s location and scale with a rectangular bounding box. Amazon SageMaker\\nObject Detection uses the Single Shot multibox Detector (SSD) algorithm that takes a convolutional\\nneural network (CNN) pretrained for classiﬁcation task as the base network. SSD uses the output of\\nintermediate layers as features for detection.\\nVarious CNNs such as VGG and ResNet have achieved great performance on the image classiﬁcation task.\\nObject detection in Amazon SageMaker supports both VGG-16 and ResNet-50 as a base network for SSD.\\nThe algorithm can be trained in full training mode or in transfer learning mode. In full training mode, the\\nbase network is initialized with random weights and then trained on user data. In transfer learning mode,\\nthe base network weights are loaded from pretrained models.\\n214Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nThe object detection algorithm uses standard data augmentation operations, such as ﬂip, rescale, and\\njitter, on the ﬂy internally to help avoid overﬁtting.\\nObject Detection Hyperparameters\\nIn the CreateTrainingJob (p. 667) request, you specify the training algorithm that you want to use. You\\ncan also specify algorithm-speciﬁc hyperparameters that are used to help estimate the parameters of\\nthe model from a training dataset. The following table lists the hyperparameters provided by Amazon\\nSageMaker for training the object detection algorithm. For more information about how object training\\nworks, see How Object Detection Works (p. 214).\\nParameter Name Description\\nnum_classes The number of output classes. This parameter deﬁnes the\\ndimensions of the network output and is typically set to the\\nnumber of classes in the dataset.\\nRequired\\nValid values: positive integer\\nnum_training_samples The number of training examples in the input dataset.\\nNote\\nIf there is a mismatch between this value and the number\\nof samples in the training set, then the behavior of the\\nlr_scheduler_step  parameter will be undeﬁned and\\ndistributed training accuracy may be aﬀected.\\nRequired\\nValid values: positive integer\\nbase_network The base network architecture to use.\\nOptional\\nValid values: \\'vgg-16\\' or \\'resnet-50\\'\\nDefault value: \\'vgg-16\\'\\nearly_stopping True  to use early stopping logic during training. False  not to use\\nit.\\nOptional\\nValid values: True  or False\\nDefault value: False\\nearly_stopping_min_epochs The minimum number of epochs that must be run before\\nthe early stopping logic can be invoked. It is used only when\\nearly_stopping  = True .\\nOptional\\nValid values: positive integer\\nDefault value: 10\\n215Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nParameter Name Description\\nearly_stopping_patience The number of epochs to wait before ending training if no\\nimprovement, as deﬁned by the early_stopping_tolerance\\nhyperparameter, is made in the relevant metric. It is used only when\\nearly_stopping  = True .\\nOptional\\nValid values: positive integer\\nDefault value: 5\\nearly_stopping_tolerance The tolerance value that the relative improvement in\\nvalidation:mAP , the mean average precision (mAP), is required\\nto exceed to avoid early stopping. If the ratio of the change\\nin the mAP divided by the previous best mAP is smaller than\\nthe early_stopping_tolerance  value set, early stopping\\nconsiders that there is no improvement. It is used only when\\nearly_stopping  = True .\\nOptional\\nValid values: 0 ≤ ﬂoat ≤ 1\\nDefault value: 0.0\\nimage_shape The image size for input images. We rescale the input image to a\\nsquare image with this size. We recommend using 300 and 512 for\\nbetter performance.\\nOptional\\nValid values: positive integer ≥300\\nDefault: 300\\nepochs The number of training epochs.\\nOptional\\nValid values: positive integer\\nDefault: 30\\n216Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nParameter Name Description\\nfreeze_layer_pattern The regular expression (regex) for freezing layers in the base\\nnetwork. For example, if we set freeze_layer_pattern  =\\n\"^(conv1_|conv2_).*\" , then any layers with a name that\\ncontains \"conv1_\"  or \"conv2_\"  are frozen, which means that\\nthe weights for these layers are not updated during training. The\\nlayer names can be found in the network symbol ﬁles vgg16-\\nsymbol.json  and resnet-50-symbol.json. Freezing a layer means that\\nits weights can not be modiﬁed further. This can reduce training\\ntime signiﬁcantly in exchange for modest losses in accuracy. This\\ntechnique is commonly used in transfer learning where the lower\\nlayers in the base network do not need to be retrained.\\nOptional\\nValid values: string\\nDefault: No layers frozen.\\nkv_store The weight update synchronization mode used for distributed\\ntraining. The weights can be updated either synchronously or\\nasynchronously across machines. Synchronous updates typically\\nprovide better accuracy than asynchronous updates but can be\\nslower. See the Distributed Training MXNet tutorial for details.\\nNote\\nThis parameter is not applicable to single machine training.\\nOptional\\nValid values: \\'dist_sync\\'  or \\'dist_async\\'\\n•\\'dist_sync\\' : The gradients are synchronized after every batch\\nwith all the workers. With \\'dist_sync\\' , batch-size now means\\nthe batch size used on each machine. So if there are n machines\\nand we use batch size b, then dist_sync behaves like a single\\nmachine with batch size n*b.\\n•\\'dist_async\\' : Performs asynchronous updates. The weights\\nare updated whenever gradients are received from any machine\\nand the weight updates are atomic. However, the order is not\\nguaranteed.\\nDefault: -\\n217Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nParameter Name Description\\nlabel_width The force padding label width used to sync across training and\\nvalidation data. For example, if one image in the data contains at\\nmost 10 objects, and each object\\'s annotation is speciﬁed with 5\\nnumbers, [class_id, left, top, width, height], then the label_width\\nshould be no smaller than (10*5 + header information length). The\\nheader information length is usually 2. We recommend using a\\nslightly larger label_width  for the training, such as 60 for this\\nexample.\\nOptional\\nValid values: Positive integer large enough to accommodate the\\nlargest annotation information length in the data.\\nDefault: 350\\nlearning_rate The initial learning rate.\\nOptional\\nValid values: ﬂoat in (0, 1]\\nDefault: 0.001\\nlr_scheduler_factor The ratio to reduce learning rate. Used in conjunction with the\\nlr_scheduler_step  parameter deﬁned as lr_new  = lr_old  *\\nlr_scheduler_factor .\\nOptional\\nValid values: ﬂoat in (0, 1)\\nDefault: 0.1\\nlr_scheduler_step The epochs at which to reduce the learning rate. The learning rate is\\nreduced by lr_scheduler_factor  at epochs listed in a comma-\\ndelimited string: \"epoch1, epoch2, ...\". For example, if the value is\\nset to \"10, 20\" and the lr_scheduler_factor  is set to 1/2, then\\nthe learning rate is halved after 10th epoch and then halved again\\nafter 20th epoch.\\nOptional\\nValid values: string\\nDefault: empty string\\n218Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nParameter Name Description\\nmini_batch_size The batch size for training. In a single-machine multi-gpu setting,\\neach GPU handles mini_batch_size /num_gpu  training samples.\\nFor the multi-machine training in dist_sync  mode, the actual\\nbatch size is mini_batch_size *number of machines. A large\\nmini_batch_size  usually leads to faster training, but it may\\ncause out of memory problem. The memory usage is related\\nto mini_batch_size , image_shape , and base_network\\narchitecture. For example, on a single p3.2xlarge instance,\\nthe largest mini_batch_size  without an out of memory\\nerror is 32 with the base_network set to \"resnet-50\" and an\\nimage_shape  of 300. With the same instance, you can use 64 as\\nthe mini_batch_size  with the base network vgg-16  and an\\nimage_shape  of 300.\\nOptional\\nValid values: positive integer\\nDefault: 32\\nmomentum The momentum for sgd. Ignored for other optimizers.\\nOptional\\nValid values: ﬂoat in (0, 1]\\nDefault: 0.9\\nnms_threshold The non-maximum suppression threshold.\\nOptional\\nValid values: ﬂoat in (0, 1]\\nDefault: 0.45\\noptimizer The optimizer types. For details on optimizer values, see MXNet\\'s\\nAPI.\\nOptional\\nValid values: [\\'sgd\\', \\'adam\\', \\'rmsprop\\', \\'adadelta\\']\\nDefault: \\'sgd\\'\\noverlap_threshold The evaluation overlap threshold.\\nOptional\\nValid values: ﬂoat in (0, 1]\\nDefault: 0.5\\n219Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nParameter Name Description\\nuse_pretrained_model Indicates whether to use a pre-trained model for training. If set\\nto 1, then the pre-trained model with corresponding architecture\\nis loaded and used for training. Otherwise, the network is trained\\nfrom scratch.\\nOptional\\nValid values: 0 or 1\\nDefault: 1\\nweight_decay The weight decay coeﬃcient for sgd and rmsprop. Ignored for\\nother optimizers.\\nOptional\\nValid values: ﬂoat in (0, 1)\\nDefault: 0.0005\\nTune an Object Detection Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the Object Detection Algorithm\\nThe object detection algorithm reports on a single metric during training: validation:mAP . When\\ntuning a model, choose this metric as the objective metric.\\nMetric Name Description Optimization Direction\\nvalidation:mAP Mean Average Precision (mAP) computed on the\\nvalidation set.Maximize\\nTunable Object Detection Hyperparameters\\nTune the Amazon SageMaker object detection model with the following hyperparameters. The\\nhyperparameters that have the greatest impact on the object detection objective metric are:\\nmini_batch_size , learning_rate , and optimizer .\\nParameter Name Parameter Type Recommended Ranges\\nlearning_rate ContinuousParameterRange MinValue: 1e-6,\\nMaxValue: 0.5\\nmini_batch_size IntegerParameterRanges MinValue: 8, MaxValue:\\n64\\n220Amazon SageMaker Developer Guide\\nObject Detection Algorithm\\nParameter NameParameter Type Recommended Ranges\\nmomentum ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 0.999\\noptimizer CategoricalParameterRanges [\\'sgd\\', \\'adam\\', \\'rmsprop\\',\\n\\'adadelta\\']\\nweight_decay ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 0.999\\nObject Detection Request and Response Formats\\nRequest Format\\nQuery a trained model by using the model\\'s endpoint. The endpoint takes .jpg and .png image formats\\nwith image/jpeg  and image/png  content-types.\\nResponse Formats\\nThe response is the class index with a conﬁdence score and bounding box coordinates for all objects\\nwithin the image encoded in JSON format. The following is an example of response .json ﬁle:\\n{\"prediction\":[\\n  [4.0, 0.86419455409049988, 0.3088374733924866, 0.07030484080314636, 0.7110607028007507,\\n 0.9345266819000244],\\n  [0.0, 0.73376623392105103, 0.5714187026023865, 0.40427327156066895, 0.827075183391571,\\n 0.9712159633636475],\\n  [4.0, 0.32643985450267792, 0.3677481412887573, 0.034883320331573486, 0.6318609714508057,\\n 0.5967587828636169],\\n  [8.0, 0.22552496790885925, 0.6152569651603699, 0.5722782611846924, 0.882301390171051,\\n 0.8985623121261597],\\n  [3.0, 0.42260299175977707, 0.019305512309074402, 0.08386176824569702,\\n 0.39093565940856934, 0.9574796557426453]\\n]}\\nEach row in this .json ﬁle contains an array that represents a detected object. Each of these object\\narrays consists of a list of six numbers. The ﬁrst number is the predicted class label. The second\\nnumber is the associated conﬁdence score for the detection. The last four numbers represent the\\nbounding box coordinates [xmin, ymin, xmax, ymax]. These output bounding box corner indices\\nare normalized by the overall image size. Note that this encoding is diﬀerent than that use by the\\ninput .json format. For example, in the ﬁrst entry of the detection result, 0.3088374733924866 is the\\nleft coordinate (x-coordinate of upper-left corner) of the bounding box as a ratio of the overall image\\nwidth, 0.07030484080314636 is the top coordinate (y-coordinate of upper-left corner) of the bounding\\nbox as a ratio of the overall image height, 0.7110607028007507 is the right coordinate (x-coordinate of\\nlower-right corner) of the bounding box as a ratio of the overall image width, and 0.9345266819000244\\nis the bottom coordinate (y-coordinate of lower-right corner) of the bounding box as a ratio of the\\noverall image height.\\nTo avoid unreliable detection results, you might want to ﬁlter out the detection results with low\\nconﬁdence scores. In the object detection sample notebook, we provide scripts to remove the low\\nconﬁdence detections. Scripts are also provided to plot the bounding boxes on the original image.\\nFor batch transform, the response is in JSON format, where the format is identical to the JSON format\\ndescribed above. The detection results of each image is represented as a JSON ﬁle. For example:\\n{\"prediction\": [[label_id, confidence_score, xmin, ymin, xmax, ymax], [label_id,\\n confidence_score, xmin, ymin, xmax, ymax]]}\\n221Amazon SageMaker Developer Guide\\nPrincipal Component Analysis (PCA) Algorithm\\nFor more details on training and inference, see the Object Detection Sample Notebooks (p. 214).\\nOUTPUT: JSON Response Format\\naccept: application/json;annotation=1\\n{\\n   \"image_size\": [\\n      {\\n         \"width\": 500,\\n         \"height\": 400,\\n         \"depth\": 3\\n      }\\n   ],\\n   \"annotations\": [\\n      {\\n         \"class_id\": 0,\\n         \"score\": 0.943,\\n         \"left\": 111,\\n         \"top\": 134,\\n         \"width\": 61,\\n         \"height\": 128\\n      },\\n      {\\n         \"class_id\": 0,\\n         \"score\": 0.0013,\\n         \"left\": 161,\\n         \"top\": 250,\\n         \"width\": 79,\\n         \"height\": 143\\n      },\\n      {\\n         \"class_id\": 1,\\n         \"score\": 0.0133,\\n         \"left\": 101,\\n         \"top\": 185,\\n         \"width\": 42,\\n         \"height\": 130\\n      }\\n   ]\\n}\\nPrincipal Component Analysis (PCA) Algorithm\\nPCA is an unsupervised machine learning algorithm that attempts to reduce the dimensionality (number\\nof features) within a dataset while still retaining as much information as possible. This is done by\\nﬁnding a new set of features called components , which are composites of the original features that are\\nuncorrelated with one another. They are also constrained so that the ﬁrst component accounts for the\\nlargest possible variability in the data, the second component the second most variability, and so on.\\nIn Amazon SageMaker, PCA operates in two modes, depending on the scenario:\\n•regular : For datasets with sparse data and a moderate number of observations and features.\\n•randomized: For datasets with both a large number of observations and features. This mode uses an\\napproximation algorithm.\\nPCA uses tabular data.\\nThe rows represent observations you want to embed in a lower dimensional space. The columns\\nrepresent features that you want to ﬁnd a reduced approximation for. The algorithm calculates the\\n222Amazon SageMaker Developer Guide\\nPrincipal Component Analysis (PCA) Algorithm\\ncovariance matrix (or an approximation thereof in a distributed manner), and then performs the singular\\nvalue decomposition on this summary to produce the principal components.\\nTopics\\n•Input/Output Interface for the PCA Algorithm (p. 223)\\n•EC2 Instance Recommendation for the PCA Algorithm (p. 223)\\n•PCA Sample Notebooks  (p. 223)\\n•How PCA Works (p. 223)\\n•PCA Hyperparameters  (p. 225)\\n•PCA Response Formats (p. 226)\\nInput/Output Interface for the PCA Algorithm\\nFor training, PCA expects data provided in the train channel, and optionally supports a dataset passed to\\nthe test dataset, which is scored by the ﬁnal algorithm. Both recordIO-wrapped-protobuf  and CSV\\nformats are supported for training. You can use either File mode or Pipe mode to train models on data\\nthat is formatted as recordIO-wrapped-protobuf  or as CSV.\\nFor inference, PCA supports text/csv , application/json , and application/x-recordio-\\nprotobuf . Results are returned in either application/json  or application/x-recordio-\\nprotobuf  format with a vector of \"projections.\"\\nFor more details on training and inference ﬁle formats, see the PCA Sample Notebooks  (p. 223) and the\\nPCA Response Formats (p. 226).\\nFor more information on input and output ﬁle formats, see PCA Response Formats (p. 226) for\\ninference and the PCA Sample Notebooks  (p. 223).\\nEC2 Instance Recommendation for the PCA Algorithm\\nPCA supports both GPU and CPU computation. Which instance type is most performant depends heavily\\non the speciﬁcs of the input data.\\nPCA Sample Notebooks\\nFor a sample notebook that shows how to use the Amazon SageMaker Principal Component Analysis\\nalgorithm to analyze the images of handwritten digits from zero to nine in the MNIST dataset, see An\\nIntroduction to PCA with MNIST. For instructions how to create and access Jupyter notebook instances\\nthat you can use to run the example in Amazon SageMaker, see Use Notebook Instances (p. 36). Once\\nyou have created a notebook instance and opened it, select the SageMaker Examples tab to see a list of\\nall the Amazon SageMaker samples. The topic modeling example notebooks using the NTM algorithms\\nare located in the Introduction to Amazon algorithms section. To open a notebook, click on its Use tab\\nand select Create copy.\\nHow PCA Works\\nPrincipal Component Analysis (PCA) is a learning algorithm that reduces the dimensionality (number of\\nfeatures) within a dataset while still retaining as much information as possible.\\nPCA reduces dimensionality by ﬁnding a new set of features called components , which are composites of\\nthe original features, but are uncorrelated with one another. The ﬁrst component accounts for the largest\\npossible variability in the data, the second component the second most variability, and so on.\\nIt is an unsupervised dimensionality reduction algorithm. In unsupervised learning, labels that might be\\nassociated with the objects in the training dataset aren\\'t used.\\n223Amazon SageMaker Developer Guide\\nPrincipal Component Analysis (PCA) Algorithm\\nGiven the input of a matrix with rows \\n  each of dimension 1 * d, the data is partitioned into\\nmini-batches of rows and distributed among the training nodes (workers). Each worker then computes a\\nsummary of its data. The summaries of the diﬀerent workers are then uniﬁed into a single solution at the\\nend of the computation.\\nModes\\nThe Amazon SageMaker PCA algorithm uses either of two modes to calculate these summaries,\\ndepending on the situation:\\n•regular : for datasets with sparse data and a moderate number of observations and features.\\n•randomized: for datasets with both a large number of observations and features. This mode uses an\\napproximation algorithm.\\nAs the algorithm\\'s last step, it performs the singular value decomposition on the uniﬁed solution, from\\nwhich the principal components are then derived.\\nMode 1: Regular\\nThe workers jointly compute both \\n  and \\n  .\\nNote\\nBecause \\n  are 1 * d row vectors, \\n  is a matrix (not a scalar). Using row vectors within the\\ncode allows us to obtain eﬃcient caching.\\nThe covariance matrix is computed as \\n  , and its top num_components  singular\\nvectors form the model.\\nNote\\nIf subtract_mean  is False, we avoid computing and subtracting \\n  .\\nUse this algorithm when the dimension d of the vectors is small enough so that \\n can ﬁt in memory.\\nMode 2: Randomized\\nWhen the number of features in the input dataset is large, we use a method to approximate\\nthe covariance metric. For every mini-batch \\n of dimension b * d, we randomly initialize a\\n(num_components + extra_components) * b  matrix that we multiply by each mini-batch,\\nto create a (num_components + extra_components) * d  matrix. The sum of these matrices\\nis computed by the workers, and the servers perform SVD on the ﬁnal (num_components +\\nextra_components) * d  matrix. The top right num_components  singular vectors of it are the\\napproximation of the top singular vectors of the input matrix.\\nLet \\n   = num_components + extra_components . Given a mini-batch \\n of dimension b * d , the\\nworker draws a random matrix \\n of dimension \\n  . Depending on whether the environment uses a\\nGPU or CPU and the dimension size, the matrix is either a random sign matrix where each entry is +-1\\nor a FJLT (fast Johnson Lindenstrauss transform; for information, see FJLT Transforms and the follow-\\nup papers). The worker then computes \\n  and maintains \\n  . The worker also maintains \\n ,\\nthe sum of columns of \\n  (T being the total number of mini-batches), and s, the sum of all input\\nrows. After processing the entire shard of data, the worker sends the server B, h, s, and n (the number of\\ninput rows).\\nDenote the diﬀerent inputs to the server as \\n  The server computes B, h, s, n the sums of the\\nrespective inputs. It then computes \\n  , and ﬁnds its singular value decomposition. The top-\\nright singular vectors and singular values of C are used as the approximate solution to the problem.\\n224Amazon SageMaker Developer Guide\\nPrincipal Component Analysis (PCA) Algorithm\\nPCA Hyperparameters\\nIn the CreateTrainingJob  request, you specify the training algorithm. You can also specify algorithm-\\nspeciﬁc HyperParameters as string-to-string maps. The following table lists the hyperparameters for the\\nPCA training algorithm provided by Amazon SageMaker. For more information about how PCA works, see\\nHow PCA Works (p. 223).\\nParameter Name Description\\nfeature_dim Input dimension.\\nRequired\\nValid values: positive integer\\nmini_batch_size Number of rows in a mini-batch.\\nRequired\\nValid values: positive integer\\nnum_components The number of principal components to compute.\\nRequired\\nValid values: positive integer\\nalgorithm_mode Mode for computing the principal components.\\nOptional\\nValid values: regular  or randomized\\nDefault value: regular\\nextra_components As the value increases, the solution becomes more accurate but the\\nruntime and memory consumption increase linearly. The default,\\n-1, means the maximum of 10 and num_components . Valid for\\nrandomized  mode only.\\nOptional\\nValid values: Non-negative integer or -1\\nDefault value: -1\\nsubtract_mean Indicates whether the data should be unbiased both during training\\nand at inference.\\nOptional\\nValid values: One of true or false\\nDefault value: true\\n225Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\nPCA Response Formats\\nAll Amazon SageMaker built-in algorithms adhere to the common input inference format described\\nin Common Data Formats - Inference. This topic contains a list of the available output formats for the\\nAmazon SageMaker PCA algorithm.\\nJSON Response Format\\nAccept—application/json\\n{\\n    \"projections\": [\\n        {\\n            \"projection\": [1.0, 2.0, 3.0, 4.0, 5.0]\\n        },\\n        {\\n            \"projection\": [6.0, 7.0, 8.0, 9.0, 0.0]\\n        },\\n        ....\\n    ]\\n}\\nJSONLINES Response Format\\nAccept—application/jsonlines\\n{ \"projection\": [1.0, 2.0, 3.0, 4.0, 5.0] }\\n{ \"projection\": [6.0, 7.0, 8.0, 9.0, 0.0] }\\nRECORDIO Response Format\\nAccept—application/x-recordio-protobuf\\n[\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'projection\\': {\\n                keys: [],\\n                values: [1.0, 2.0, 3.0, 4.0, 5.0]\\n            }\\n        }\\n    },\\n    Record = {\\n        features = {},\\n        label = {\\n            \\'projection\\': {\\n                keys: [],\\n                values: [1.0, 2.0, 3.0, 4.0, 5.0]\\n            }\\n        }\\n    }  \\n]\\nRandom Cut Forest (RCF) Algorithm\\nAmazon SageMaker Random Cut Forest (RCF) is an unsupervised algorithm for detecting anomalous\\ndata points within a data set. These are observations which diverge from otherwise well-structured or\\n226Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\npatterned data. Anomalies can manifest as unexpected spikes in time series data, breaks in periodicity, or\\nunclassiﬁable data points. They are easy to describe in that, when viewed in a plot, they are often easily\\ndistinguishable from the \"regular\" data. Including these anomalies in a data set can drastically increase\\nthe complexity of a machine learning task since the \"regular\" data can often be described with a simple\\nmodel.\\nWith each data point, RCF associates an anomaly score. Low score values indicate that the data point\\nis considered \"normal.\" High values indicate the presence of an anomaly in the data. The deﬁnitions of\\n\"low\" and \"high\" depend on the application but common practice suggests that scores beyond three\\nstandard deviations from the mean score are considered anomalous.\\nWhile there are many applications of anomaly detection algorithms to one-dimensional time series data\\nsuch as traﬃc volume analysis or sound volume spike detection, RCF is designed to work with arbitrary-\\ndimensional input. Amazon SageMaker RCF scales well with respect to number of features, data set size,\\nand number of instances.\\nTopics\\n•Input/Output Interface for the RCF Algorithm (p. 227)\\n•Instance Recommendations for the RCF Algorithm (p. 228)\\n•RCF Sample Notebooks (p. 228)\\n•How RCF Works (p. 228)\\n•RCF Hyperparameters (p. 231)\\n•Tune an RCF Model (p. 231)\\n•RCF Response Formats (p. 232)\\nInput/Output Interface for the RCF Algorithm\\nAmazon SageMaker Random Cut Forest supports the train  and test  data channels. The optional test\\nchannel is used to compute accuracy, precision, recall, and F1-score metrics on labeled data. Train and\\ntest data content types can be either application/x-recordio-protobuf  or text/csv  formats.\\nFor the test data, when using text/csv format, the content must be speciﬁed as text/csv;label_size=1\\nwhere the ﬁrst column of each row represents the anomaly label: \"1\" for an anomalous data point and\\n\"0\" for a normal data point. You can use either File mode or Pipe mode to train RCF models on data that\\nis formatted as recordIO-wrapped-protobuf  or as CSV\\nAlso note that the train channel only supports S3DataDistributionType=ShardedByS3Key  and the\\ntest channel only supports S3DataDistributionType=FullyReplicated . The S3 distribution type\\ncan be speciﬁed using the Python SDK as follows:\\n  import sagemaker\\n    \\n  # specify Random Cut Forest training job information and hyperparameters\\n  rcf = sagemaker.estimator.Estimator(...)\\n    \\n  # explicitly specify \"SharededByS3Key\" distribution type\\n  train_data = sagemaker.s3_input(\\n       s3_data=s3_training_data_location,\\n       content_type=\\'text/csv;label_size=0\\',\\n       distribution=\\'ShardedByS3Key\\')\\n    \\n  # run the training job on input data stored in S3\\n  rcf.fit({\\'train\\': train_data})\\nSee the Amazon SageMaker Data Types documentation for more information on customizing the S3 data\\nsource attributes. Finally, in order to take advantage of multi-instance training the training data must be\\npartitioned into at least as many ﬁles as instances.\\n227Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\nFor inference, RCF supports application/x-recordio-protobuf , text/csv  and application/\\njson input data content types. See the Common Data Formats for Built-in Algorithms  (p. 64)\\ndocumentation for more information. RCF inference returns application/x-recordio-protobuf\\nor application/json  formatted output. Each record in these output data contains the corresponding\\nanomaly scores for each input data point. See Common Data Formats--Inference for more information.\\nFor more information on input and output ﬁle formats, see RCF Response Formats (p. 232) for\\ninference and the RCF Sample Notebooks (p. 228).\\nInstance Recommendations for the RCF Algorithm\\nFor training, we recommend the ml.m4 , ml.c4 , and ml.c5 instance families. For inference we\\nrecommend using a ml.c5.xl  instance type in particular, for maximum performance as well as\\nminimized cost per hour of usage. Although the algorithm could technically run on GPU instance types it\\ndoes not take advantage of GPU hardware.\\nRCF Sample Notebooks\\nFor an example of how to train an RCF model and perform inferences with it, see the Introduction to\\nSageMaker Random Cut Forests notebook. For a sample notebook that uses the Amazon SageMaker\\nRandom Cut Forest algorithm for anomaly detection, see An Introduction to SageMaker Random Cut\\nForests. For instructions how to create and access Jupyter notebook instances that you can use to run the\\nexample in Amazon SageMaker, see Use Notebook Instances (p. 36). Once you have created a notebook\\ninstance and opened it, select the SageMaker Examples tab to see a list of all the Amazon SageMaker\\nsamples. To open a notebook, click on its Use tab and select Create copy.\\nHow RCF Works\\nAmazon SageMaker Random Cut Forest (RCF) is an unsupervised algorithm for detecting anomalous\\ndata points within a dataset. These are observations which diverge from otherwise well-structured or\\npatterned data. Anomalies can manifest as unexpected spikes in time series data, breaks in periodicity, or\\nunclassiﬁable data points. They are easy to describe in that, when viewed in a plot, they are often easily\\ndistinguishable from the \"regular\" data. Including these anomalies in a dataset can drastically increase\\nthe complexity of a machine learning task since the \"regular\" data can often be described with a simple\\nmodel.\\nThe main idea behind the RCF algorithm is to create a forest of trees where each tree is obtained using\\na partition of a sample of the training data. For example, a random sample of the input data is ﬁrst\\ndetermined. The random sample is then partitioned according to the number of trees in the forest. Each\\ntree is given such a partition and organizes that subset of points into a k-d tree. The anomaly score\\nassigned to a data point by the tree is deﬁned as the expected change in complexity of the tree as a\\nresult adding that point to the tree; which, in approximation, is inversely proportional to the resulting\\ndepth of the point in the tree. The random cut forest assigns an anomaly score by computing the\\naverage score from each constituent tree and scaling the result with respect to the sample size. The RCF\\nalgorithm is based on the one described in reference [1].\\nSample Data Randomly\\nThe ﬁrst step in the RCF algorithm is to obtain a random sample of the training data. In particular,\\nsuppose we want a sample of size \\n from \\n total data points. If the training data is small enough,\\nthe entire dataset can be used, and we could randomly draw \\n elements from this set. However,\\nfrequently the training data is too large to ﬁt all at once, and this approach isn\\'t feasible. Instead, we use\\na technique called reservoir sampling.\\nReservoir sampling is an algorithm for eﬃciently drawing random samples from a dataset \\nwhere the elements in the dataset can only be observed one at a time or in batches. In fact, reservoir\\nsampling works even when \\n is not known a priori . If only one sample is requested, such as when \\n ,\\nthe algorithm is like this:\\n228Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\nAlgorithm: Reservoir Sampling\\n•Input: dataset or data stream \\n•Initialize the random sample \\n•For each observed sample \\n :\\n•Pick a uniform random number \\n•If \\n•Set \\n•Return \\nThis algorithm selects a random sample such that \\n  for all \\n . When \\n  the\\nalgorithm is more complicated. Additionally, a distinction must be made between random sampling that\\nis with and without replacement. RCF performs an augmented reservoir sampling without replacement\\non the training data based on the algorithms described in [2].\\nTrain a RCF Model and Produce Inferences\\nThe next step in RCF is to construct a random cut forest using the random sample of data. First, the\\nsample is partitioned into a number of equal-sized partitions equal to the number of trees in the forest.\\nThen, each partition is sent to an individual tree. The tree recursively organizes its partition into a binary\\ntree by partitioning the data domain into bounding boxes.\\nThis procedure is best illustrated with an example. Suppose a tree is given the following two-dimensional\\ndataset. The corresponding tree is initialized to the root node:\\nA two-dimensional dataset where the majority of data lies in a cluster (blue) except for one anomalous\\ndata point (orange). The tree is initialized with a root node.\\nThe RCF algorithm organizes these data in a tree by ﬁrst computing a bounding box of the data,\\nselecting a random dimension (giving more weight to dimensions with higher \"variance\"), and then\\nrandomly determining the position of a hyperplane \"cut\" through that dimension. The two resulting\\nsubspaces deﬁne their own sub tree. In this example, the cut happens to separate a lone point from the\\nremainder of the sample. The ﬁrst level of the resulting binary tree consists of two nodes, one which will\\nconsist of the subtree of points to the left of the initial cut and the other representing the single point on\\nthe right.\\n229Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\nA random cut partitioning the two-dimensional dataset. An anomalous data point is more likely to lie\\nisolated in a bounding box at a smaller tree depth than other points.\\nBounding boxes are then computed for the left and right halves of the data and the process is repeated\\nuntil every leaf of the tree represents a single data point from the sample. Note that if the lone point\\nis suﬃciently far away then it is more likely that a random cut would result in point isolation. This\\nobservation provides the intuition that tree depth is, loosely speaking, inversely proportional to the\\nanomaly score.\\nWhen performing inference using a trained RCF model the ﬁnal anomaly score is reported as the average\\nacross scores reported by each tree. Note that it is often the case that the new data point does not\\nalready reside in the tree. To determine the score associated with the new point the data point is inserted\\ninto the given tree and the tree is eﬃciently (and temporarily) reassembled in a manner equivalent\\nto the training process described above. That is, the resulting tree is as if the input data point were\\na member of the sample used to construct the tree in the ﬁrst place. The reported score is inversely\\nproportional to the depth of the input point within the tree.\\nChoose Hyperparameters\\nThe primary hyperparameters used to tune the RCF model are num_trees  and\\nnum_samples_per_tree . Increasing num_trees  has the eﬀect of reducing the noise observed in\\nanomaly scores since the ﬁnal score is the average of the scores reported by each tree. While the optimal\\nvalue is application-dependent we recommend using 100 trees to begin with as a balance between score\\nnoise and model complexity. Note that inference time is proportional to the number of trees. Although\\ntraining time is also aﬀected it is dominated by the reservoir sampling algorithm describe above.\\nThe parameter num_samples_per_tree  is related to the expected density of anomalies in the dataset.\\nIn particular, num_samples_per_tree  should be chosen such that 1/num_samples_per_tree\\napproximates the ratio of anomalous data to normal data. For example, if 256 samples are used in each\\ntree then we expect our data to contain anomalies 1/256 or approximately 0.4% of the time. Again, an\\noptimal value for this hyperparameter is dependent on the application.\\nReferences\\n1.Sudipto Guha, Nina Mishra, Gourav Roy, and Okke Schrijvers. \"Robust random cut forest based\\nanomaly detection on streams.\" In International Conference on Machine Learning , pp. 2712-2721.\\n2016.\\n230Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\n2.Byung-Hoon Park, George Ostrouchov, Nagiza F. Samatova, and Al Geist. \"Reservoir-based random\\nsampling with replacement from data stream.\" In Proceedings of the 2004 SIAM International\\nConference on Data Mining , pp. 492-496. Society for Industrial and Applied Mathematics, 2004.\\nRCF Hyperparameters\\nIn the CreateTrainingJob  request, you specify the training algorithm. You can also specify algorithm-\\nspeciﬁc hyperparameters as string-to-string maps. The following table lists the hyperparameters for the\\nAmazon SageMaker RCF algorithm. For more information, including recommendations on how to choose\\nhyperparameters, see How RCF Works (p. 228).\\nParameter Name Description\\nfeature_dim The number of features in the data set. (If you are using the client libraries\\nthrough a notebook, this value is calculated for you and need not be\\nspeciﬁed.)\\nRequired (When the job is run through the console.)\\nValid values: Positive integer (min: 1, max: 10000)\\neval_metrics A list of metrics used to score a labeled test data set. The following\\nmetrics can be selected for output:\\n•accuracy  - returns fraction of correct predictions.\\n•precision_recall_fscore  - returns the positive and negative\\nprecision, recall, and F1-scores.\\nOptional\\nValid values: a list with possible values taken from accuracy  or\\nprecision_recall_fscore .\\nDefault value: Both accuracy , precision_recall_fscore  are\\ncalculated.\\nnum_samples_per_tree Number of random samples given to each tree from the training data set.\\nOptional\\nValid values: Positive integer (min: 1, max: 2048)\\nDefault value: 256\\nnum_trees Number of trees in the forest.\\nOptional\\nValid values: Positive integer (min: 50, max: 1000)\\nDefault value: 100\\nTune an RCF Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\n231Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nThe Amazon SageMaker RCF algorithm is an unsupervised anomaly-detection algorithm that requires a\\nlabeled test dataset for hyperparameter optimization. It calculates anomaly scores for test datapoints\\nand then labels the datapoints as anomalous if their scores are beyond three standard deviations from\\nthe mean score. This is known as the three-sigma limit heuristic. The F1 score is emitted based on the\\ndiﬀerence between calculated labels and actual labels. The hyperparameter tuning job ﬁnds the model\\nthat maximizes that score. The success of hyperparameter optimization depends on the applicability of\\nthe three-sigma limit heuristic to the test dataset.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the RCF Algorithm\\nThe RCF algorithm computes the following metric during training. When tuning the model, choose this\\nmetric as the objective metric.\\nMetric Name Description Optimization Direction\\ntest:f1 F1 score on the test dataset, based on the\\ndiﬀerence between calculated labels and actual\\nlabels.Maximize\\nTunable RCF Hyperparameters\\nYou can tune a RCF model with the following hyperparameters.\\nParameter Name Parameter Type Recommended Ranges\\nnum_samples_per_tree IntegerParameterRanges MinValue: 1,\\nMaxValue:2048\\nnum_trees IntegerParameterRanges MinValue: 50,\\nMaxValue:1000\\nRCF Response Formats\\nAll Amazon SageMaker built-in algorithms adhere to the common input inference format described in\\nCommon Data Formats - Inference. Note that Amazon SageMaker Random Cut Forest supports both\\ndense and sparse JSON and RecordIO formats. This topic contains a list of the available output formats\\nfor the Amazon SageMaker RCF algorithm.\\nJSON Response Format\\nACCEPT: application/json.\\n    {                                                                                      \\n                                                                                           \\n                                                                                           \\n        \\n        \"scores\":    [                                                                     \\n                                                                                           \\n232Amazon SageMaker Developer Guide\\nRandom Cut Forest (RCF) Algorithm\\n                                                                                           \\n        \\n            {\"score\": 0.02},                                                               \\n                                                                                           \\n                                                                                           \\n        \\n            {\"score\": 0.25}                                                                \\n                                                                                           \\n                                                                                           \\n        \\n        ]                                                                                  \\n                                                                                           \\n                                                                                           \\n        \\n    }\\nJSONLINES Response Format\\nACCEPT: application/jsonlines.\\n{\"score\": 0.02},\\n{\"score\": 0.25}\\nRECORDIO Response Format\\nACCEPT: application/x-recordio-protobuf.\\n    [                                                                                      \\n                                                                                           \\n                                                                                           \\n        \\n         Record = {                                                                        \\n                                                                                           \\n                                                                                           \\n             \\n             features = {},                                                                \\n                                                                                           \\n                                                                                           \\n             \\n             label = {                                                                     \\n                                                                                           \\n                                                                                           \\n            \\n                 \\'score\\': {                                                                \\n                                                                                           \\n                                                                                           \\n             \\n                     keys: [],                                                             \\n                                                                                           \\n                                                                                           \\n             \\n                     values: [0.25]  # float32                                             \\n                                                                                           \\n                                                                                           \\n             \\n                 }                                                                         \\n                                                                                           \\n                                                                                           \\n             \\n             }                                                                             \\n                                                                                           \\n233Amazon SageMaker Developer Guide\\nSemantic Segmentation\\n                                                                                           \\n             \\n         },                                                                                \\n                                                                                           \\n                                                                                           \\n             \\n         Record = {                                                                        \\n                                                                                           \\n                                                                                           \\n             \\n             features = {},                                                                \\n                                                                                           \\n                                                                                           \\n             \\n             label = {                                                                     \\n                                                                                           \\n                                                                                           \\n            \\n                 \\'score\\': {                                                                \\n                                                                                           \\n                                                                                           \\n             \\n                     keys: [],                                                             \\n                                                                                           \\n                                                                                           \\n             \\n                     values: [0.23]  # float32                                             \\n                                                                                           \\n                                                                                           \\n             \\n                 }                                                                         \\n                                                                                           \\n                                                                                           \\n             \\n             }                                                                             \\n                                                                                           \\n                                                                                           \\n             \\n         }                                                                                 \\n                                                                                           \\n                                                                                           \\n             \\n    ]\\nSemantic Segmentation Algorithm\\nThe Amazon SageMaker semantic segmentation algorithm provides a ﬁne-grained, pixel-level approach\\nto developing computer vision applications. It tags every pixel in an image with a class label from a\\npredeﬁned set of classes. Tagging is fundamental for understanding scenes, which is critical to an\\nincreasing number of computer vision applications, such as self-driving vehicles, medical imaging\\ndiagnostics, and robot sensing.\\nFor comparison, the Amazon SageMaker Image Classiﬁcation Algorithm  (p. 108) is a supervised\\nlearning algorithm that analyzes only whole images, classifying them into one of multiple output\\ncategories. The Object Detection Algorithm (p. 199) is a supervised learning algorithm that detects and\\nclassiﬁes all instances of an object in an image. It indicates the location and scale of each object in the\\nimage with a rectangular bounding box.\\nBecause the semantic segmentation algorithm classiﬁes every pixel in an image, it also provides\\ninformation about the shapes of the objects contained in the image. The segmentation output is\\nrepresented as an RGB or grayscale image, called a segmentation mask . A segmentation mask is an RGB\\n(or grayscale) image with the same shape as the input image.\\n234Amazon SageMaker Developer Guide\\nSemantic Segmentation\\nAmazon SageMaker semantic segmentation algorithm is built using the MXNet Gluon framework and the\\nGluon CV toolkit  provides you with a choice of three build-in algorithms to train a deep neural network.\\nYou can use the Fully-Convolutional Network (FCN) algorithm , Pyramid Scene Parsing (PSP) algorithm,\\nor DeepLabV3 .\\nEach of the three algorithms has two distinct components:\\n•The backbone  (or encoder )—A network that produces reliable activation maps of features.\\n•The decoder —A network that constructs the segmentation mask from the encoded activation maps.\\nYou also have a choice of backbones for the FCN, PSP, and DeepLabV3 algorithms: ResNet50 or\\nResNet101. These backbones include pretrained artifacts that were originally trained on the ImageNet\\nclassiﬁcation task. You can ﬁne-tune these backbones for segmentation using your own data. Or, you\\ncan initialize and train these networks from scratch using only your own data. The decoders are never\\npretrained.\\nTo deploy the trained model for inference, use the Amazon SageMaker hosting service. During inference,\\nyou can request the segmentation mask either as a PNG image or as a set of probabilities for each class\\nfor each pixel. You can use these masks as part of a larger pipeline that includes additional downstream\\nimage processing or other applications.\\nTopics\\n•Semantic Segmentation Sample Notebooks  (p. 235)\\n•Input/Output Interface for the Semantic Segmentation Algorithm (p. 235)\\n•EC2 Instance Recommendation for the Semantic Segmentation Algorithm (p. 238)\\n•Semantic Segmentation Hyperparameters  (p. 238)\\nSemantic Segmentation Sample Notebooks\\nFor a sample Jupyter notebook that uses the Amazon SageMaker semantic segmentation algorithm\\nto train a model and deploy it to perform inferences, see the Semantic Segmentation Example . For\\ninstructions on how to create and access Jupyter notebook instances that you can use to run the example\\nin Amazon SageMaker, see Use Notebook Instances (p. 36).\\nTo see a list of all of the Amazon SageMaker samples, create and open a notebook instance, and choose\\nthe SageMaker Examples tab. The example semantic segmentation notebooks are located under\\nIntroduction to Amazon algorithms. To open a notebook, choose its Use tab, and choose Create copy.\\nInput/Output Interface for the Semantic Segmentation\\nAlgorithm\\nAmazon SageMaker semantic segmentation expects the customer\\'s training dataset to be on Amazon\\nSimple Storage Service (Amazon S3). Once trained, it produces the resulting model artifacts on Amazon\\nS3. The input interface format for the Amazon SageMaker semantic segmentation is similar to that\\nof most standardized semantic segmentation benchmarking datasets. The dataset in Amazon S3\\nis expected to be presented in two channels, one for train  and one for validation  using four\\ndirectories, two for images and two for annotations. Annotations are expected to be uncompressed\\nPNG images. The dataset might also have a label map that describes how the annotation mappings are\\nestablished. If not, the algorithm uses a default. It also supports the augmented manifest image format\\n(application/x-image ) for training in Pipe input mode straight from Amazon S3. For inference, an\\nendpoint accepts images with an image/jpeg  content type.\\n235Amazon SageMaker Developer Guide\\nSemantic Segmentation\\nHow Training Works\\nThe training data is split into four directories: train , train_annotation , validation , and\\nvalidation_annotation . There is a channel for each of these directories. The dataset also expected\\nto have one label_map.json  ﬁle per channel for train_annotation  and validation_annotation\\nrespectively. If you don\\'t provide these JSON ﬁles, Amazon SageMaker provides the default set label\\nmap.\\nThe dataset specifying these ﬁles should look similar to the following example:\\ns3://bucket_name\\n    |\\n    |- train\\n                 |\\n                 | - 0000.jpg\\n                 | - coffee.jpg\\n    |- validation\\n                 |\\n                 | - 00a0.jpg\\n                 | - bananna.jpg              \\n    |- train_annotation\\n                 |\\n                 | - 0000.png\\n                 | - coffee.png\\n    |- validation_annotation\\n                 |\\n                 | - 00a0.png   \\n                 | - bananna.png \\n    |- label_map\\n                 | - train_label_map.json  \\n                 | - validation_label_map.json \\nEvery JPG image in the train and validation directories has a corresponding PNG label image with\\nthe same name in the train_annotation  and validation_annotation  directories. This naming\\nconvention helps the algorithm to associate a label with its corresponding image during training. The\\ntrain , train_annotation , validation , and validation_annotation  channels are mandatory.\\nThe annotations are single-channel PNG images. The format works as long as the metadata (modes) in\\nthe image helps the algorithm read the annotation images into a single-channel 8-bit unsigned integer.\\nFor more information on our support for modes, see the Python Image Library documentation. We\\nrecommend using the 8-bit pixel, true color P mode.\\nThe image that is encoded is a simple 8-bit integer when using modes. To get from this mapping to a\\nmap of a label, the algorithm uses one mapping ﬁle per channel, called the label map . The label map is\\nused to map the values in the image with actual label indices. In the default label map, which is provided\\nby default if you don’t provide one, the pixel value in an annotation matrix (image) directly index the\\nlabel. These images can be grayscale PNG ﬁles or 8-bit indexed PNG ﬁles. The label map ﬁle for the\\nunscaled default case is the following:\\n{ \\n  \"scale\": \"1\"\\n}  \\nTo provide some contrast for viewing, some annotation software scales the label images by a constant\\namount. To support this, the Amazon SageMaker semantic segmentation algorithm provides a rescaling\\noption to scale down the values to actual label values. When scaling down doesn’t convert the value\\nto an appropriate integer, the algorithm defaults to the greatest integer less than or equal to the scale\\nvalue. The following code shows how to set the scale value to rescale the label values:\\n{ \\n  \"scale\": \"3\"\\n236Amazon SageMaker Developer Guide\\nSemantic Segmentation\\n}  \\nThe following example shows how this \"scale\" value is used to rescale the encoded_label  values of\\nthe input annotation image when they are mapped to the mapped_label  values to be used in training.\\nThe label values in the input annotation image are 0, 3, 6, with scale 3, so they are mapped to 0, 1, 2 for\\ntraining:\\nencoded_label = [0, 3, 6]\\nmapped_label = [0, 1, 2]\\nIn some cases, you might need to specify a particular color mapping for each class. Use the map option\\nin the label mapping as shown in the following example of a label_map  ﬁle:\\n{\\n    \"map\": {\\n        \"0\": 5,\\n        \"1\": 0,\\n        \"2\": 2\\n    }\\n}\\nThis label mapping for this example is:\\nencoded_label = [0, 5, 2]\\nmapped_label = [1, 0, 2]\\nWith label mappings, you can use diﬀerent annotation systems and annotation software to obtain data\\nwithout a lot of preprocessing. You can provide one label map per channel. The ﬁles for a label map in\\nthe label_map  channel must follow the naming conventions for the four directory structure. If you\\ndon\\'t provide a label map, the algorithm assumes a scale of 1 (the default).\\nTraining with the Augmented Manifest Format\\nThe augmented manifest format enables you to do training in Pipe mode using image ﬁles without\\nneeding to create RecordIO ﬁles. The augmented manifest ﬁle contains data objects and should be in\\nJSON Lines format, as described in the CreateTrainingJob (p. 667) request API. Each line in the manifest\\nis an entry containing the Amazon S3 URI for the image and the URI for the annotation image.\\nEach JSON object in the manifest ﬁle must contain a source-ref  key. The source-ref  key\\nshould contain the value of the Amazon S3 URI to the image. The labels are provided under the\\nAttributeNames  parameter value as speciﬁed in the CreateTrainingJob (p. 667) request. It can\\nalso contain additional metadata under the metadata tag, but these are ignored by the algorithm.\\nIn the example below, the AttributeNames  are contained in the list of image and annotation\\nreferences [\"source-ref\", \"city-streets-ref\"] . These names must have -ref  appended to\\nthem. When using the Semantic Segmentation algorithm with Augmented Manifest, the value of the\\nRecordWrapperType  parameter must be \"RecordIO\"  and value of the ContentType  parameter must\\nbe application/x-recordio .\\n{\"source-ref\": \"S3 bucket location\", \"city-streets-ref\": \"S3 bucket location\", \"city-\\nstreets-metadata\": {\"job-name\": \"label-city-streets\", }}\\nFor more information on augmented manifest ﬁles, see Provide Dataset Metadata to Training Jobs with\\nan Augmented Manifest File  (p. 308).\\nIncremental Training\\nYou can also seed the training of a new model with a model that you trained previously using Amazon\\nSageMaker. This incremental training saves training time when you want to train a new model with the\\n237Amazon SageMaker Developer Guide\\nSemantic Segmentation\\nsame or similar data. Currently, incremental training is supported only for models trained with the built-\\nin Amazon SageMaker Semantic Segmentation.\\nTo use your own pre-trained model, specify the ChannelName  as \"model\" in the InputDataConfig\\nfor the CreateTrainingJob (p. 667) request. Set the ContentType  for the model channel to\\napplication/x-sagemaker-model . The backbone , algorithm , crop_size , and num_classes\\ninput parameters that deﬁne the network architecture must be consistently speciﬁed in the input\\nhyperparameters of the new model and the pre-trained model that you upload to the model channel.\\nFor the pretrained model ﬁle, you can use the compressed (.tar.gz) artifacts from Amazon SageMaker\\noutputs. You can use either RecordIO or Image formats for input data. For more information on\\nincremental training and for instructions on how to use it, see Incremental Training in Amazon\\nSageMaker (p. 282).\\nProduce Inferences\\nTo query a trained model that is deployed to an endpoint, you need to provide an image and an\\nAcceptType  that denotes the type of output required. The endpoint takes JPEG images with an\\nimage/jpeg  content type. If you request an AcceptType  of image/png , the algorithm outputs a PNG\\nﬁle with a segmentation mask in the same format as the labels themselves. If you request an accept\\ntype ofapplication/x-recordio-protobuf , the algorithm returns class probabilities encoded in\\nrecordio-protobuf format. The latter format outputs a 3D tensor where the third dimension is the same\\nsize as the number of classes. This component denotes the probability of each class label for each pixel.\\nEC2 Instance Recommendation for the Semantic Segmentation\\nAlgorithm\\nThe Amazon SageMaker semantic segmentation algorithm only supports GPU instances for training,\\nand we recommend using GPU instances with more memory for training with large batch sizes. The\\nalgorithm can be trained using P2/P3 EC2 Amazon Elastic Compute Cloud (Amazon EC2) instances in\\nsingle machine conﬁgurations. It supports the following GPU instances for training:\\n•ml.p2.xlarge\\n•ml.p2.8xlarge\\n•ml.p2.16xlarge\\n•ml.p3.2xlarge\\n•ml.p3.8xlarge\\n•ml.p3.16xlarge\\nFor inference, you can use either CPU instances (such as c5 and m5) and GPU instances (such as p2 and\\np3) or both. For information about the instance types that provide varying combinations of CPU, GPU,\\nmemory, and networking capacity for inference, see Amazon SageMaker ML Instance Types.\\nSemantic Segmentation Hyperparameters\\nThe following tables list the hyperparameters supported by the Amazon SageMaker semantic\\nsegmentation algorithm for network architecture, data inputs, and training. You specify Semantic\\nSegmentation for training in the AlgorithmName  of the CreateTrainingJob (p. 667) request.\\nNetwork Architecture Hyperparameters\\nParameter Name Description\\nbackbone The backbone to use for the algorithm\\'s encoder component.\\n238Amazon SageMaker Developer Guide\\nSemantic Segmentation\\nParameter Name Description\\nOptional\\nValid values: resnet-50 , resnet-101\\nDefault value: resnet-50\\nuse_pretrained_model Whether a pretrained model is to be used for the backbone.\\nOptional\\nValid values: True , False\\nDefault value: True\\nalgorithm The algorithm to use for semantic segmentation.\\nOptional\\nValid values:\\n•fcn: Fully-Convolutional Network (FCN) algorithm\\n•psp: Pyramid Scene Parsing (PSP) algorithm\\n•deeplab : DeepLab V3 algorithm\\nDefault value: fcn\\nData Hyperparameters\\nParameter Name Description\\nnum_classes The number of classes to segment.\\nRequired\\nValid values: 2 ≤ positive integer ≤ 254\\nnum_training_samples The number of samples in the training data. The algorithm uses this value\\nto set up the learning rate scheduler.\\nRequired\\nValid values: positive integer\\ncrop_size The image size for input images. We rescale the input image to a square\\nimage to this crop_size . We do this by rescaling the shorter side to\\nmatch this parameter while maintaining the aspect ratio, and then take a\\nrandom crop along the longer side.\\nOptional\\nValid values: positive integer > 16\\nDefault value: 480\\nTraining Hyperparameters\\n239Amazon SageMaker Developer Guide\\nSemantic Segmentation\\nParameter Name Description\\nearly_stopping Whether to use early stopping logic during training.\\nOptional\\nValid values: True , False\\nDefault value: False\\nearly_stopping_min_epochs The minimum number of epochs that must be run.\\nOptional\\nValid values: integer\\nDefault value: 5\\nearly_stopping_patience The number of epochs that meet the tolerance for lower performance\\nbefore the algorithm enforces an early stop.\\nOptional\\nValid values: integer\\nDefault value: 4\\nearly_stopping_tolerance If the relative improvement of the score of the training job, the mIOU,\\nis smaller than this value, early stopping considers the epoch as not\\nimproved. This is used only when early_stopping  = True .\\nOptional\\nValid values: 0 ≤ ﬂoat ≤ 1\\nDefault value: 0.0\\nepochs The number of epochs with which to train.\\nOptional\\nValid values: positive integer\\nDefault value: 30\\ngamma1 The decay factor for the moving average of the squared gradient for\\nrmsprop . Used only for rmsprop .\\nOptional\\nValid values: 0 ≤ ﬂoat ≤ 1\\nDefault value: 0.9\\ngamma2 The momentum factor for rmsprop .\\nOptional\\nValid values: 0 ≤ ﬂoat ≤ 1\\nDefault value: 0.9\\n240Amazon SageMaker Developer Guide\\nSemantic Segmentation\\nParameter Name Description\\nlearning_rate The initial learning rate.\\nOptional\\nValid values: 0 < ﬂoat ≤ 1\\nDefault value: 0.001\\nlr_scheduler The shape of the learning rate schedule that controls its decrease over\\ntime.\\nOptional\\nValid values:\\n•step: A stepwise decay, where the learning rate is reduced by a factor\\nat certain intervals.\\n•poly: A smooth decay using a polynomial function.\\n•cosine: A smooth decay using a cosine function.\\nDefault value: poly\\nmini_batch_size The batch size for training. Using a large mini_batch_size  usually\\nresults in faster training, but it might cause you to run out of memory.\\nMemory usage is aﬀected by the values of the mini_batch_size  and\\nimage_shape  parameters, and the backbone architecture.\\nOptional\\nValid values: positive integer\\nDefault value: 4\\nmomentum The momentum for the sgd optimizer. When you use other optimizers,\\nthe semantic segmentation algorithm ignores this parameter.\\nOptional\\nValid values: 0 < ﬂoat ≤ 1\\nDefault value: 0.9\\n241Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\noptimizer The type of optimizer. For more information about an optimizer, choose\\nthe appropriate link:\\n•adam : Adaptive momentum estimation\\n•adagrad : Adaptive gradient descent\\n•nag: Nesterov accelerated gradient\\n•rmsprop : Root mean square propagation\\n•sgd: Stochastic gradient descent\\nOptional\\nValid values: adam , adagrad , nag, rmsprop , sgd\\nDefault value: sgd\\nvalidation_mini_batch_size The batch size for validation. A large mini_batch_size  usually\\nresults in faster training, but it might cause you to run out of memory.\\nMemory usage is aﬀected by the values of the mini_batch_size  and\\nimage_shape  parameters, and the backbone architecture.\\n•To score the validation on the entire image without cropping the\\nimages, set this parameter to 1. Use this option if you want to measure\\nperformance on the entire image as a whole.\\nNote\\nSetting the validation_mini_batch_size  parameter to 1\\ncauses the algorithm to create a new network model for every\\nimage. This might slow validation and training.\\n•To crop images to the size speciﬁed in the crop_size  parameter, even\\nduring evaluation, set this parameter to a value greater than 1.\\nOptional\\nValid values: positive integer\\nDefault value: 4\\nweight_decay The weight decay coeﬃcient for the sgd optimizer. When you use other\\noptimizers, the algorithm ignores this parameter.\\nOptional\\nValid values: 0 < ﬂoat < 1\\nDefault value: 0.0001\\nSequence-to-Sequence Algorithm\\nAmazon SageMaker Sequence to Sequence is a supervised learning algorithm where the input is a\\nsequence of tokens (for example, text, audio) and the output generated is another sequence of tokens.\\nExample applications include: machine translation (input a sentence from one language and predict what\\nthat sentence would be in another language), text summarization (input a longer string of words and\\npredict a shorter string of words that is a summary), speech-to-text (audio clips converted into output\\n242Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nsentences in tokens). Recently, problems in this domain have been successfully modeled with deep neural\\nnetworks that show a signiﬁcant performance boost over previous methodologies. Amazon SageMaker\\nseq2seq uses Recurrent Neural Networks (RNNs) and Convolutional Neural Network (CNN) models with\\nattention as encoder-decoder architectures.\\nTopics\\n•Input/Output Interface for the Sequence-to-Sequence Algorithm (p. 243)\\n•EC2 Instance Recommendation for the Sequence-to-Sequence Algorithm (p. 244)\\n•Sequence-to-Sequence Sample Notebooks (p. 244)\\n•How Sequence-to-Sequence Works (p. 244)\\n•Sequence-to-Sequence Hyperparameters (p. 245)\\n•Tune a Sequence-to-Sequence Model  (p. 253)\\nInput/Output Interface for the Sequence-to-Sequence\\nAlgorithm\\nTraining\\nAmazon SageMaker seq2seq expects data in RecordIO-Protobuf format. However, the tokens are\\nexpected as integers, not as ﬂoating points, as is usually the case.\\nA script to convert data from tokenized text ﬁles to the protobuf format is included in the seq2seq\\nexample notebook . In general, it packs the data into 32-bit integer tensors and generates the necessary\\nvocabulary ﬁles, which are needed for metric calculation and inference.\\nAfter preprocessing is done, the algorithm can be invoked for training. The algorithm expects three\\nchannels:\\n•train: It should contain the training data (for example, the train.rec  ﬁle generated by the\\npreprocessing script).\\n•validation : It should contain the validation data (for example, the val.rec ﬁle generated by the\\npreprocessing script).\\n•vocab: It should contain two vocabulary ﬁles (vocab.src.json  and vocab.trg.json )\\nIf the algorithm doesn\\'t ﬁnd data in any of these three channels, training results in an error.\\nInference\\nFor hosted endpoints, inference supports two data formats. To perform inference using space separated\\ntext tokens, use the application/json  format. Otherwise, use the recordio-protobuf  format to\\nwork with the integer encoded data. Both mode supports batching of input data. application/json\\nformat also allows you to visualize the attention matrix.\\n•application/json : Expects the input in JSON format and returns the output in JSON format. Both\\ncontent and accept types should be application/json . Each sequence is expected to be a string\\nwith whitespace separated tokens. This format is recommended when the number of source sequences\\nin the batch is small. It also supports the following additional conﬁguration options:\\nconfiguration : {attention_matrix : true}: Returns the attention matrix for the particular input\\nsequence.\\n•application/x-recordio-protobuf : Expects the input in recordio-protobuf  format and\\nreturns the output in recordio-protobuf format . Both content and accept types should be\\napplications/x-recordio-protobuf . For this format, the source sequences must be converted\\n243Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\ninto a list of integers for subsequent protobuf encoding. This format is recommended for bulk\\ninference.\\nFor batch transform, inference supports JSON Lines format. Batch transform expects the input in JSON\\nLines format and returns the output in JSON Lines format. Both content and accept types should be\\napplication/jsonlines . The format for input is as follows:\\ncontent-type: application/jsonlines\\n{\"source\": \"source_sequence_0\"}\\n{\"source\": \"source_sequence_1\"}\\nThe format for response is as follows:\\naccept: application/jsonlines\\n{\"target\": \"predicted_sequence_0\"}\\n{\"target\": \"predicted_sequence_1\"}\\nFor additional details on how to serialize and deserialize the inputs and outputs to speciﬁc formats for\\ninference, see the Sequence-to-Sequence Sample Notebooks (p. 244) .\\nEC2 Instance Recommendation for the Sequence-to-Sequence\\nAlgorithm\\nCurrently Amazon SageMaker seq2seq is only supported on GPU instance types and is only set up to\\ntrain on a single machine. But it does also oﬀer support for multiple GPUs.\\nSequence-to-Sequence Sample Notebooks\\nFor a sample notebook that shows how to use the Amazon SageMaker Sequence to Sequence algorithm\\nto train a English-German translation model, see Machine Translation English-German Example Using\\nSageMaker Seq2Seq. For instructions how to create and access Jupyter notebook instances that you\\ncan use to run the example in Amazon SageMaker, see Use Notebook Instances (p. 36). Once you have\\ncreated a notebook instance and opened it, select the SageMaker Examples tab to see a list of all the\\nAmazon SageMaker samples. The topic modeling example notebooks using the NTM algorithms are\\nlocated in the Introduction to Amazon algorithms section. To open a notebook, click on its Use tab and\\nselect Create copy.\\nHow Sequence-to-Sequence Works\\nTypically, a neural network for sequence-to-sequence modeling consists of a few layers, including:\\n•An embedding layer. In this layer, the input matrix, which is input tokens encoded in a sparse way\\n(for example, one-hot encoded) are mapped to a dense feature layer. This is required because a high-\\ndimensional feature vector is more capable of encoding information regarding a particular token (word\\nfor text corpora) than a simple one-hot-encoded vector. It is also a standard practice to initialize this\\nembedding layer with a pre-trained word vector like FastText or Glove or to initialize it randomly and\\nlearn the parameters during training.\\n•An encoder layer. After the input tokens are mapped into a high-dimensional feature space,\\nthe sequence is passed through an encoder layer to compress all the information from the input\\nembedding layer (of the entire sequence) into a ﬁxed-length feature vector. Typically, an encoder is\\nmade of RNN-type networks like long short-term memory (LSTM) or gated recurrent units (GRU). (\\nColah\\'s blog explains LSTM in a great detail.)\\n•A decoder layer. The decoder layer takes this encoded feature vector and produces the output\\nsequence of tokens. This layer is also usually built with RNN architectures (LSTM and GRU).\\n244Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nThe whole model is trained jointly to maximize the probability of the target sequence given the source\\nsequence. This model was ﬁrst introduced by Sutskever et al. in 2014.\\nAttention mechanism. The disadvantage of an encoder-decoder framework is that model performance\\ndecreases as and when the length of the source sequence increases because of the limit of how much\\ninformation the ﬁxed-length encoded feature vector can contain. To tackle this problem, in 2015,\\nBahdanau et al. proposed the attention mechanism. In an attention mechanism, the decoder tries to ﬁnd\\nthe location in the encoder sequence where the most important information could be located and uses\\nthat information and previously decoded words to predict the next token in the sequence.\\nFor more in details, see the whitepaper Eﬀective Approaches to Attention-based Neural Machine\\nTranslation by Luong, et al. that explains and simpliﬁes calculations for various attention mechanisms.\\nAdditionally, the whitepaper Google\\'s Neural Machine Translation System: Bridging the Gap between\\nHuman and Machine Translation by Wu, et al. describes Google\\'s architecture for machine translation,\\nwhich uses skip connections between encoder and decoder layers.\\nSequence-to-Sequence Hyperparameters\\nParameter Name Description\\nbatch_size Mini batch size for gradient descent.\\nOptional\\nValid values: positive integer\\nDefault value: 64\\nbeam_size Length of the beam for beam search. Used during training\\nfor computing bleu and used during inference.\\nOptional\\nValid values: positive integer\\nDefault value: 5\\nbleu_sample_size Number of instances to pick from validation dataset\\nto decode and compute bleu score during training.\\nSet to -1 to use full validation set (if bleu  is chosen as\\noptimized_metric ).\\nOptional\\nValid values: integer\\nDefault value: 0\\nbucket_width Returns (source,target) buckets up to\\n(max_seq_len_source , max_seq_len_target ). The\\nlonger side of the data uses steps of bucket_width\\nwhile the shorter side uses steps scaled down by the\\naverage target/source length ratio. If one sided reaches its\\nmaximum length before the other, width of extra buckets\\non that side is ﬁxed to that side of max_len .\\nOptional\\nValid values: positive integer\\n245Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\nDefault value: 10\\nbucketing_enabled Set to false to disable bucketing, unroll to maximum\\nlength.\\nOptional\\nValid values: true  or false\\nDefault value: true\\ncheckpoint_frequency_num_batches Checkpoint and evaluate every x batches.\\nOptional\\nValid values: positive integer\\nDefault value: 1000\\ncheckpoint_threshold Maximum number of checkpoints model is allowed to not\\nimprove in optimized_metric  on validation dataset\\nbefore training is stopped.\\nOptional\\nValid values: positive integer\\nDefault value: 3\\nclip_gradient Clip absolute gradient values greater than this. Set to\\nnegative to disable.\\nOptional\\nValid values: ﬂoat\\nDefault value: 1\\ncnn_activation_type The cnn activation type to be used.\\nOptional\\nValid values: String. One of glu, relu , softrelu ,\\nsigmoid , or tanh .\\nDefault value: glu\\ncnn_hidden_dropout Dropout probability for dropout between convolutional\\nlayers.\\nOptional\\nValid values: Float. Range in [0,1].\\nDefault value: 0\\n246Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\ncnn_kernel_width_decoder Kernel width for the cnn decoder.\\nOptional\\nValid values: positive integer\\nDefault value: 5\\ncnn_kernel_width_encoder Kernel width for the cnn encoder.\\nOptional\\nValid values: positive integer\\nDefault value: 3\\ncnn_num_hidden Number of cnn hidden units for encoder and decoder.\\nOptional\\nValid values: positive integer\\nDefault value: 512\\ndecoder_type Decoder type.\\nOptional\\nValid values: String. Either rnn or cnn.\\nDefault value: rnn\\nembed_dropout_source Dropout probability for source side embeddings.\\nOptional\\nValid values: Float. Range in [0,1].\\nDefault value: 0\\nembed_dropout_target Dropout probability for target side embeddings.\\nOptional\\nValid values: Float. Range in [0,1].\\nDefault value: 0\\nencoder_type Encoder type. The rnn architecture is based on attention\\nmechanism by Bahdanau et al. and cnn architecture is\\nbased on Gehring et al.\\nOptional\\nValid values: String. Either rnn or cnn.\\nDefault value: rnn\\n247Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\nfixed_rate_lr_half_life Half life for learning rate in terms of number of\\ncheckpoints for fixed_rate_ * schedulers.\\nOptional\\nValid values: positive integer\\nDefault value: 10\\nlearning_rate Initial learning rate.\\nOptional\\nValid values: ﬂoat\\nDefault value: 0.0003\\nloss_type Loss function for training.\\nOptional\\nValid values: String. cross-entropy\\nDefault value: cross-entropy\\nlr_scheduler_type Learning rate scheduler type. plateau_reduce  means\\nreduce the learning rate whenever optimized_metric  on\\nvalidation_accuracy  plateaus. inv_t is inverse time\\ndecay. learning_rate /(1+decay_rate *t)\\nOptional\\nValid values: String. One of plateau_reduce ,\\nfixed_rate_inv_t , or fixed_rate_inv_sqrt_t .\\nDefault value: plateau_reduce\\nmax_num_batches Maximum number of updates/batches to process. -1 for\\ninﬁnite.\\nOptional\\nValid values: integer\\nDefault value: -1\\nmax_num_epochs Maximum number of epochs to pass through training\\ndata before ﬁtting is stopped. Training continues until\\nthis number of epochs even if validation accuracy is not\\nimproving if this parameter is passed. Ignored if not passed.\\nOptional\\nValid values: Positive integer and less than or equal to\\nmax_num_epochs.\\nDefault value: none\\n248Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\nmax_seq_len_source Maximum length for the source sequence length.\\nSequences longer than this length are truncated to this\\nlength.\\nOptional\\nValid values: positive integer\\nDefault value: 100\\nmax_seq_len_target Maximum length for the target sequence length. Sequences\\nlonger than this length are truncated to this length.\\nOptional\\nValid values: positive integer\\nDefault value: 100\\nmin_num_epochs Minimum number of epochs the training must run before it\\nis stopped via early_stopping  conditions.\\nOptional\\nValid values: positive integer\\nDefault value: 0\\nmomentum Momentum constant used for sgd. Don\\'t pass this\\nparameter if you are using adam  or rmsprop .\\nOptional\\nValid values: ﬂoat\\nDefault value: none\\nnum_embed_source Embedding size for source tokens.\\nOptional\\nValid values: positive integer\\nDefault value: 512\\nnum_embed_target Embedding size for target tokens.\\nOptional\\nValid values: positive integer\\nDefault value: 512\\n249Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\nnum_layers_decoder Number of layers for Decoder rnn or cnn.\\nOptional\\nValid values: positive integer\\nDefault value: 1\\nnum_layers_encoder Number of layers for Encoder rnn or cnn.\\nOptional\\nValid values: positive integer\\nDefault value: 1\\noptimized_metric Metrics to optimize with early stopping.\\nOptional\\nValid values: String. One of perplexity , accuracy , or\\nbleu .\\nDefault value: perplexity\\noptimizer_type Optimizer to choose from.\\nOptional\\nValid values: String. One of adam , sgd, or rmsprop .\\nDefault value: adam\\nplateau_reduce_lr_factor Factor to multiply learning rate with (for\\nplateau_reduce ).\\nOptional\\nValid values: ﬂoat\\nDefault value: 0.5\\nplateau_reduce_lr_threshold For plateau_reduce  scheduler, multiply learning rate\\nwith reduce factor if optimized_metric  didn\\'t improve\\nfor this many checkpoints.\\nOptional\\nValid values: positive integer\\nDefault value: 3\\n250Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\nrnn_attention_in_upper_layers Pass the attention to upper layers of rnn, like Google NMT\\npaper. Only applicable if more than one layer is used.\\nOptional\\nValid values: boolean (true  or false )\\nDefault value: true\\nrnn_attention_num_hidden Number of hidden units for attention layers. defaults to\\nrnn_num_hidden .\\nOptional\\nValid values: positive integer\\nDefault value: rnn_num_hidden\\nrnn_attention_type Attention model for encoders. mlp refers to concat and\\nbilinear refers to general from the Luong et al. paper.\\nOptional\\nValid values: String. One of dot, fixed , mlp, or bilinear .\\nDefault value: mlp\\nrnn_cell_type Speciﬁc type of rnn architecture.\\nOptional\\nValid values: String. Either lstm  or gru.\\nDefault value: lstm\\nrnn_decoder_state_init How to initialize rnn decoder states from encoders.\\nOptional\\nValid values: String. One of last , avg, or zero .\\nDefault value: last\\nrnn_first_residual_layer First rnn layer to have a residual connection, only\\napplicable if number of layers in encoder or decoder is\\nmore than 1.\\nOptional\\nValid values: positive integer\\nDefault value: 2\\n251Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\nrnn_num_hidden The number of rnn hidden units for encoder and decoder.\\nThis must be a multiple of 2 because the algorithm uses\\nbi-directional Long Term Short Term Memory (LSTM) by\\ndefault.\\nOptional\\nValid values: positive even integer\\nDefault value: 1024\\nrnn_residual_connections Add residual connection to stacked rnn. Number of layers\\nshould be more than 1.\\nOptional\\nValid values: boolean (true  or false )\\nDefault value: false\\nrnn_decoder_hidden_dropout Dropout probability for hidden state that combines the\\ncontext with the rnn hidden state in the decoder.\\nOptional\\nValid values: Float. Range in [0,1].\\nDefault value: 0\\ntraining_metric Metrics to track on training on validation data.\\nOptional\\nValid values: String. Either perplexity  or accuracy .\\nDefault value: perplexity\\nweight_decay Weight decay constant.\\nOptional\\nValid values: ﬂoat\\nDefault value: 0\\nweight_init_scale Weight initialization scale (for uniform  and xavier\\ninitialization).\\nOptional\\nValid values: ﬂoat\\nDefault value: 2.34\\n252Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nParameter Name Description\\nweight_init_type Type of weight initialization.\\nOptional\\nValid values: String. Either uniform  or xavier .\\nDefault value: xavier\\nxavier_factor_type Xavier factor type.\\nOptional\\nValid values: String. One of in, out, or avg.\\nDefault value: in\\nTune a Sequence-to-Sequence Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the Sequence-to-Sequence Algorithm\\nThe sequence to sequence algorithm reports three metrics that are computed during training. Choose\\none of them as an objective to optimize when tuning the hyperparameter values.\\nMetric Name Description Optimization Direction\\nvalidation:accuracy Accuracy computed on the validation dataset. Maximize\\nvalidation:bleu Bleu  score computed on the validation dataset.\\nBecause BLEU computation is expensive, you can\\nchoose to compute BLEU on a random subsample\\nof the validation dataset to speed up the overall\\ntraining process. Use the bleu_sample_size\\nparameter to specify the subsample.Maximize\\nvalidation:perplexity Perplexity, is a loss function computed on the\\nvalidation dataset. Perplexity measures the cross-\\nentropy between an empirical sample and the\\ndistribution predicted by a model and so provides\\na measure of how well a model predicts the\\nsample values, Models that are good at predicting\\na sample have a low perplexity.Minimize\\nTunable Sequence-to-Sequence Hyperparameters\\nYou can tune the following hyperparameters for the Amazon SageMaker Sequence to Sequence\\nalgorithm. The hyperparameters that have the greatest impact on sequence to sequence objective\\n253Amazon SageMaker Developer Guide\\nSequence to Sequence (seq2seq)\\nmetrics are: batch_size , optimizer_type , learning_rate , num_layers_encoder , and\\nnum_layers_decoder .\\nParameter Name Parameter Type Recommended Ranges\\nnum_layers_encoder IntegerParameterRange [1-10]\\nnum_layers_decoder IntegerParameterRange [1-10]\\nbatch_size CategoricalParameterRange [16,32,64,128,256,512,1024,2048]\\noptimizer_type CategoricalParameterRange [\\'adam\\', \\'sgd\\', \\'rmsprop\\']\\nweight_init_type CategoricalParameterRange [\\'xavier\\', \\'uniform\\']\\nweight_init_scale ContinuousParameterRange For the xavier type:\\nMinValue: 2.0,\\nMaxValue: 3.0 For the\\nuniform type: MinValue:\\n-1.0, MaxValue: 1.0\\nlearning_rate ContinuousParameterRange MinValue: 0.00005,\\nMaxValue: 0.2\\nweight_decay ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 0.1\\nmomentum ContinuousParameterRange MinValue: 0.5,\\nMaxValue: 0.9\\nclip_gradient ContinuousParameterRange MinValue: 1.0,\\nMaxValue: 5.0\\nrnn_num_hidden CategoricalParameterRange Applicable only to\\nrecurrent neural\\nnetworks (RNNs).\\n[128,256,512,1024,2048]\\ncnn_num_hidden CategoricalParameterRange Applicable only to\\nconvolutional neural\\nnetworks (CNNs).\\n[128,256,512,1024,2048]\\nnum_embed_source IntegerParameterRange [256-512]\\nnum_embed_target IntegerParameterRange [256-512]\\nembed_dropout_source ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 0.5\\nembed_dropout_target ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 0.5\\nrnn_decoder_hidden_dropout ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 0.5\\ncnn_hidden_dropout ContinuousParameterRange MinValue: 0.0,\\nMaxValue: 0.5\\n254Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter NameParameter Type Recommended Ranges\\nlr_scheduler_type CategoricalParameterRange [\\'plateau_reduce\\',\\n\\'ﬁxed_rate_inv_t\\',\\n\\'ﬁxed_rate_inv_sqrt_t\\']\\nplateau_reduce_lr_factor ContinuousParameterRange MinValue: 0.1,\\nMaxValue: 0.5\\nplateau_reduce_lr_threshold IntegerParameterRange [1-5]\\nfixed_rate_lr_half_life IntegerParameterRange [10-30]\\nXGBoost Algorithm\\nThe XGBoost (eXtreme Gradient Boosting) is a popular and eﬃcient open-source implementation of the\\ngradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm that attempts to\\naccurately predict a target variable by combining an ensemble of estimates from a set of simpler, weaker\\nmodels. XGBoost has done remarkably well in machine learning competitions because it robustly handles\\na variety of data types, relationships, and distributions, and the large number of hyperparameters\\nthat can be tweaked and tuned for improved the ﬁt. This ﬂexibility makes XGBoost a solid choice for\\nproblems in regression, classiﬁcation (binary and multiclass), and ranking.\\nThis current release of the XGBoost algorithm makes upgrades from the open source XGBoost code base\\neasy to install and use in Amazon SageMaker. Customers can use this release of the XGBoost algorithm\\neither as an Amazon SageMaker built-in algorithm, as with the previous 0.72-based version, or as a\\nframework to run training scripts in their local environments as they would typically do, for example,\\nwith a TensorFlow deep learning framework. This implementation has a smaller memory footprint,\\nbetter logging, improved hyperparameter validation, and an expanded set of metrics than the original\\n0.72-based version. It also provides an XGBoost estimator  that executes a training script in a managed\\nXGBoost environment. The current release of Amazon SageMaker XGBoost is based on version 0.90 and\\nwill be upgradeable to future releases. The previous implementation XGBoost Release 0.72 (p. 266) is\\nstill available to customers if they need to postpone migrating to the current version. But this previous\\nimplementation will remain tied to the 0.72 release of XGBoost.\\nTopics\\n•How to Use Amazon SageMaker XGBoost (p. 255)\\n•Input/Output Interface for the XGBoost Algorithm (p. 256)\\n•EC2 Instance Recommendation for the XGBoost Algorithm (p. 257)\\n•XGBoost Sample Notebooks (p. 257)\\n•How XGBoost Works (p. 258)\\n•XGBoost Hyperparameters (p. 258)\\n•Tune an XGBoost Model (p. 264)\\n•XGBoost Previous Versions (p. 266)\\nHow to Use Amazon SageMaker XGBoost\\nThe XGBoost algorithm can be used as a built-in algorithm or as a framework such TensorFlow. Using\\nXGBoost as a framework provides more ﬂexible than using it as a built-in algorithm as it enables more\\nadvanced scenarios that allow pre-processing and post-processing scripts to be incorporated into your\\ntraining script. Using XGBoost as a built-in Amazon SageMaker algorithm is how you had to use the\\noriginal XGBoost Release 0.72 (p. 266) version and nothing changes here except the version of XGBoost\\nthat you use.\\n255Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\n•Use XGBoost as a framework\\nUse XGBoost as a framework to run scripts that can incorporate additional data processing into your\\ntraining jobs. This way of using XGBoost should be to familiar to users who have worked with the open\\nsource XGBoost and other Amazon SageMaker frameworks such as Scikit-learn. You use the Amazon\\nSageMaker Python SDK as you would for other frameworks such as TensorFlow. One change from\\nother Amazon SageMaker frameworks is that the framework_version  ﬁeld of the estimator  for\\nXGBoost is mandatory and is not set by default. Note that the ﬁrst part of the version refers to the\\nupstream module version (aka, 0.90), while the second part refers to the Amazon SageMaker version\\nfor the container. An error is generated if the framework_version  is not set.\\nimport sagemaker.XGBoost\\nestimator = XGBoost(entry_point = ‘myscript.py’, \\n                    source_dir, model_dir, train_instance_type,                    \\n                    train_instance_count, hyperparameters, role, base_job_name, \\n                    framework_version = ‘0.90-1’, \\n                    py_version)\\nestimator.fit({‘train’:’s3://my-bucket/training’, \\n                ‘validation’:’s3://my-bucket/validation})\\nThe AWS SDK for Python (Boto 3) and the CLI also require this ﬁeld.\\n•Use XGBoost as a built-in algorithm\\nUse XGBoost to train and deploy a model as you would other built-in Amazon SageMaker algorithms.\\nUsing the current version of XGBoost as a built-in algorithm will be familiar to users who have used the\\noriginal XGBoost Release 0.72 (p. 266) version with the Amazon SageMaker Python SDK and want to\\ncontinue using the same procedures.\\nimport sagemaker\\nimport sagemaker.xgboost_utils\\n# get the URI for new container\\ncontainer = get_image_uri(boto3.Session().region_name,\\n                          ‘xgboost’, \\n                          repo_version=\\'0.90-1\\'); \\nestimator = sagemaker.estimator.Estimator(container, role, instance_count, instance_type,\\n train_volume_size, output_path, sagemaker.Session());\\nestimator.fit({‘train’:’s3://my-bucket/training’, ‘validation’:’s3://my-bucket/\\nvalidation})\\nIf customers do not specify version in the get_image_uri  function, they get the XGBoost Release\\n0.72  (p. 266) version by default. If you want to migrate to the current version, you have to specify\\nrepo_version=\\'0.90-1\\'  in the get_image_uri  function. If you use the current version, you must\\nupdate your code to use the new hyperparameters that are required by the 0.90 version of upstream\\nalgorithm. The AWS SDK for Python (Boto 3) and the CLI usage is similar. You also have to choose the\\nversion you want to run when using the Console to select the XGBoost algorithm.\\nInput/Output Interface for the XGBoost Algorithm\\nGradient boosting operates on tabular data, with the rows representing observations, one column\\nrepresenting the target variable or label, and the remaining columns representing features.\\nThe Amazon SageMaker implementation of XGBoost supports CSV and libsvm formats for training and\\ninference:\\n•For Training ContentType, valid inputs are text/libsvm (default) or text/csv.\\n•For Inference ContentType, valid inputs are text/libsvm or (the default) text/csv.\\n256Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nNote\\nFor CSV training, the algorithm assumes that the target variable is in the ﬁrst column and that\\nthe CSV does not have a header record. For CSV inference, the algorithm assumes that CSV input\\ndoes not have the label column.\\nFor libsvm training, the algorithm assumes that the label is in the ﬁrst column. Subsequent\\ncolumns contain the zero-based index value pairs for features. So each row has the format:\\n<label> <index0>:<value0> <index1>:<value1> ... Inference requests for libsvm may or may not\\nhave labels in the libsvm format.\\nThis diﬀers from other Amazon SageMaker algorithms, which use the protobuf training input format to\\nmaintain greater consistency with standard XGBoost data formats.\\nFor CSV training input mode, the total memory available to the algorithm (Instance Count * the memory\\navailable in the InstanceType ) must be able to hold the training dataset. For libsvm training input\\nmode, it\\'s not required, but we recommend it.\\nSageMaker XGBoost uses the Python pickle module to serialize/deserialize the model, which can be used\\nfor saving/loading the model.\\nTo use a model trained with SageMaker XGBoost in open source XGBoost\\n• Use the following Python code:\\nimport pickle as pkl \\nmodel = pkl.load(open(model_file_path, \\'rb\\'))\\n# prediction with test data\\npred = model.predict(dtest)\\nTo diﬀerentiate the importance of labelled data points use Instance Weight Supports\\n• Amazon SageMaker XGBoost allows customers to diﬀerentiate the importance of labelled data\\npoints by assigning each instance a weight value. For text/libsvm input, customers can assign\\nweight values to data instances by attaching them after the labels. For example, label:weight\\nidx_0:val_0 idx_1:val_1... . For text/csv input, customers need to turn on the csv_weights\\nﬂag in the parameters and attach weight values in the column after labels. For example:\\nlabel,weight,val_0,val_1,... ).\\nEC2 Instance Recommendation for the XGBoost Algorithm\\nAmazon SageMaker XGBoost currently only trains using CPUs. It is a memory-bound (as opposed to\\ncompute-bound) algorithm. So, a general-purpose compute instance (for example, M4) is a better choice\\nthan a compute-optimized instance (for example, C4). Further, we recommend that you have enough\\ntotal memory in selected instances to hold the training data. Although it supports the use of disk space\\nto handle data that does not ﬁt into main memory (the out-of-core feature available with the libsvm\\ninput mode), writing cache ﬁles onto disk slows the algorithm processing time.\\nXGBoost Sample Notebooks\\nFor a sample notebook that shows how to use Amazon SageMaker XGBoost as a built-in algorithm to\\ntrain and host a regression model, see Regression with the Amazon SageMaker XGBoost algorithm. For\\ninstructions how to create and access Jupyter notebook instances that you can use to run the example\\nin Amazon SageMaker, see Use Notebook Instances (p. 36). Once you have created a notebook instance\\nand opened it, select the SageMaker Examples tab to see a list of all the Amazon SageMaker samples.\\nThe topic modeling example notebooks using the NTM algorithms are located in the Introduction to\\nAmazon algorithms section. To open a notebook, click on its Use tab and select Create copy.\\n257Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nHow XGBoost Works\\nXGBoost is a popular and eﬃcient open-source implementation of the gradient boosted trees algorithm.\\nGradient boosting is a supervised learning algorithm, which attempts to accurately predict a target\\nvariable by combining the estimates of a set of simpler, weaker models.\\nWhen using gradient boosting  for regression, the weak learners are regression trees, and each regression\\ntree maps an input data point to one of its leafs that contains a continuous score. XGBoost minimizes a\\nregularized (L1 and L2) objective function that combines a convex loss function (based on the diﬀerence\\nbetween the predicted and target outputs) and a penalty term for model complexity (in other words, the\\nregression tree functions). The training proceeds iteratively, adding new trees that predict the residuals\\nor errors of prior trees that are then combined with previous trees to make the ﬁnal prediction. It\\'s called\\ngradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new\\nmodels.\\nFor more detail on XGBoost, see:\\n•XGBoost: A Scalable Tree Boosting System\\n•Introduction to Boosted Trees\\nXGBoost Hyperparameters\\nThe following table contains the subset of hyperparameters that are required or most commonly used\\nfor the Amazon SageMaker XGBoost algorithm. These are parameters that are set by users to facilitate\\nthe estimation of model parameters from data. The required hyperparameters that must be set are\\nlisted ﬁrst, in alphabetical order. The optional hyperparameters that can be set are listed next, also in\\nalphabetical order. The Amazon SageMaker XGBoost algorithm is an implementation of the open-source\\nDLMC XGBoost package. Currently Amazon SageMaker supports version 0.90. For details about full set of\\nhyperparameter that can be conﬁgured for this version of XGBoost, see  XGBoost Parameters.\\nParameter Name Description\\nnum_round The number of rounds to run the training.\\nRequired\\nValid values: integer\\nnum_class The number of classes.\\nRequired if objective  is set to multi:softmax or multi:softprob.\\nValid values: integer\\nDefault value:\\nalpha L1 regularization term on weights. Increasing this value makes\\nmodels more conservative.\\nOptional\\nValid values: ﬂoat\\nDefault value: 0\\nbase_score The initial prediction score of all instances, global bias.\\nOptional\\n258Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nValid values: ﬂoat\\nDefault value: 0.5\\nbooster Which booster to use. The gbtree  and dart values use a tree-\\nbased model, while gblinear  uses a linear function.\\nOptional\\nValid values: String. One of gbtree , gblinear , or dart .\\nDefault value: gbtree\\ncolsample_bylevel Subsample ratio of columns for each split, in each level.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 1\\ncolsample_bynode Subsample ratio of columns from each node.\\nOptional\\nValid values: Float. Range: (0,1].\\nDefault value: 1\\ncolsample_bytree Subsample ratio of columns when constructing each tree.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 1\\ncsv_weights When this ﬂag is enabled, XGBoost diﬀerentiates the importance\\nof instances for csv input by taking the second column (the column\\nafter labels) in training data as the instance weights.\\nOptional\\nValid values: 0 or 1\\nDefault value: 0\\nearly_stopping_rounds The model trains until the validation score stops\\nimproving. Validation error needs to decrease at least every\\nearly_stopping_rounds  to continue training. Amazon\\nSageMaker hosting uses the best model for inference.\\nOptional\\nValid values: integer\\nDefault value: -\\n259Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\neta Step size shrinkage used in updates to prevent overﬁtting. After\\neach boosting step, you can directly get the weights of new\\nfeatures. The eta parameter actually shrinks the feature weights to\\nmake the boosting process more conservative.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 0.3\\neval_metric Evaluation metrics for validation data. A default metric is assigned\\naccording to the objective:\\n•rmse: for regression\\n•error : for classiﬁcation\\n•map: for ranking\\nFor a list of valid inputs, see XGBoost Parameters.\\nOptional\\nValid values: string\\nDefault value: Default according to objective.\\ngamma Minimum loss reduction required to make a further partition on\\na leaf node of the tree. The larger, the more conservative the\\nalgorithm is.\\nOptional\\nValid values: Float. Range: [0,∞).\\nDefault value: 0\\ngrow_policy Controls the way that new nodes are added to the tree. Currently\\nsupported only if tree_method  is set to hist .\\nOptional\\nValid values: String. Either depthwise  or lossguide .\\nDefault value: depthwise\\nlambda L2 regularization term on weights. Increasing this value makes\\nmodels more conservative.\\nOptional\\nValid values: ﬂoat\\nDefault value: 1\\n260Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nlambda_bias L2 regularization term on bias.\\nOptional\\nValid values: Float. Range: [0.0, 1.0].\\nDefault value: 0\\nmax_bin Maximum number of discrete bins to bucket continuous features.\\nUsed only if tree_method  is set to hist .\\nOptional\\nValid values: integer\\nDefault value: 256\\nmax_delta_step Maximum delta step allowed for each tree\\'s weight estimation.\\nWhen a positive integer is used, it helps make the update more\\nconservative. The preferred option is to use it in logistic regression.\\nSet it to 1-10 to help control the update.\\nOptional\\nValid values: Integer. Range: [0,∞).\\nDefault value: 0\\nmax_depth Maximum depth of a tree. Increasing this value makes the model\\nmore complex and likely to be overﬁt. 0 indicates no limit. A limit is\\nrequired when grow_policy =depth-wise .\\nOptional\\nValid values: Integer. Range: [0,∞)\\nDefault value: 6\\nmax_leaves Maximum number of nodes to be added. Relevant only if\\ngrow_policy  is set to lossguide .\\nOptional\\nValid values: integer\\nDefault value: 0\\nmin_child_weight Minimum sum of instance weight (hessian) needed in a child. If the\\ntree partition step results in a leaf node with the sum of instance\\nweight less than min_child_weight , the building process gives\\nup further partitioning. In linear regression models, this simply\\ncorresponds to a minimum number of instances needed in each\\nnode. The larger the algorithm, the more conservative it is.\\nOptional\\nValid values: Float. Range: [0,∞).\\nDefault value: 1\\n261Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nnormalize_type Type of normalization algorithm.\\nOptional\\nValid values: Either tree or forest .\\nDefault value: tree\\nnthread Number of parallel threads used to run xgboost.\\nOptional\\nValid values: integer\\nDefault value: Maximum number of threads.\\nobjective Speciﬁes the learning task and the corresponding learning\\nobjective. Examples: reg:linear , reg:logistic ,\\nmulti:softmax . For a full list of valid inputs, refer to XGBoost\\nParameters.\\nOptional\\nValid values: string\\nDefault value: reg:linear\\none_drop When this ﬂag is enabled, at least one tree is always dropped\\nduring the dropout.\\nOptional\\nValid values: 0 or 1\\nDefault value: 0\\nprocess_type The type of boosting process to run.\\nOptional\\nValid values: String. Either default  or update .\\nDefault value: default\\nrate_drop The dropout rate that speciﬁes the fraction of previous trees to\\ndrop during the dropout.\\nOptional\\nValid values: Float. Range: [0.0, 1.0].\\nDefault value: 0.0\\n262Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nrefresh_leaf This is a parameter of the \\'refresh\\' updater plug-in. When set to\\ntrue (1), tree leaves and tree node stats are updated. When set to\\nfalse(0), only tree node stats are updated.\\nOptional\\nValid values: 0/1\\nDefault value: 1\\nsample_type Type of sampling algorithm.\\nOptional\\nValid values: Either uniform  or weighted .\\nDefault value: uniform\\nscale_pos_weight Controls the balance of positive and negative weights. It\\'s useful\\nfor unbalanced classes. A typical value to consider: sum(negative\\ncases)  / sum(positive cases) .\\nOptional\\nValid values: ﬂoat\\nDefault value: 1\\nseed Random number seed.\\nOptional\\nValid values: integer\\nDefault value: 0\\nsilent 0 means print running messages, 1 means silent mode.\\nValid values: 0 or 1\\nOptional\\nDefault value: 0\\nsketch_eps Used only for approximate greedy algorithm. This translates into\\nO(1 / sketch_eps ) number of bins. Compared to directly select\\nnumber of bins, this comes with theoretical guarantee with sketch\\naccuracy.\\nOptional\\nValid values: Float, Range: [0, 1].\\nDefault value: 0.03\\n263Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nskip_drop Probability of skipping the dropout procedure during a boosting\\niteration.\\nOptional\\nValid values: Float. Range: [0.0, 1.0].\\nDefault value: 0.0\\nsubsample Subsample ratio of the training instance. Setting it to 0.5 means\\nthat XGBoost randomly collects half of the data instances to grow\\ntrees. This prevents overﬁtting.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 1\\ntree_method The tree construction algorithm used in XGBoost.\\nOptional\\nValid values: One of auto , exact , approx , or hist .\\nDefault value: auto\\ntweedie_variance_power Parameter that controls the variance of the Tweedie distribution.\\nOptional\\nValid values: Float. Range: (1, 2).\\nDefault value: 1.5\\nupdater A comma-separated string that deﬁnes the sequence of tree\\nupdaters to run. This provides a modular way to construct and to\\nmodify the trees.\\nFor a full list of valid inputs, please refer to XGBoost Parameters.\\nOptional\\nValid values: comma-separated string.\\nDefault value: grow_colmaker , prune\\nTune an XGBoost Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nNote\\nAutomatic model tuning for XGBoost 0.90 is only available from the SDKs, not from the Amazon\\nSageMaker console.\\n264Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the XGBoost Algorithm\\nThe XGBoost algorithm computes the following nine metrics during training. When tuning the model,\\nchoose one of these metrics as the objective to evaluate the model.\\nMetric Name Description Optimization Direction\\nvalidation:accuracy Classiﬁcation rate, calculated as #(right)/#(all\\ncases).Maximize\\nvalidation:auc Area under the curve. Maximize\\nvalidation:error Binary classiﬁcation error rate, calculated as\\n#(wrong cases)/#(all cases).Minimize\\nvalidation:f1 Indicator of classiﬁcation accuracy, calculated as\\nthe harmonic mean of precision and recall.Maximize\\nvalidation:logloss Negative log-likelihood. Minimize\\nvalidation:mae Mean absolute error. Minimize\\nvalidation:map Mean average precision. Maximize\\nvalidation:merror Multiclass classiﬁcation error rate, calculated as\\n#(wrong cases)/#(all cases).Minimize\\nvalidation:mlogloss Negative log-likelihood for multiclass\\nclassiﬁcation.Minimize\\nvalidation:mse Mean squared error. Minimize\\nvalidation:ndcg Normalized Discounted Cumulative Gain. Maximize\\nvalidation:rmse Root mean square error. Minimize\\nTunable XGBoost Hyperparameters\\nTune the open-source XGBoost model with the following hyperparameters. The hyperparameters that\\nhave the greatest eﬀect on XGBoost objective metrics are: alpha , min_child_weight , subsample ,\\neta, and num_round .\\nParameter Name Parameter Type Recommended Ranges\\nalpha ContinuousParameterRanges MinValue: 0, MaxValue:\\n1000\\ncolsample_bylevel ContinuousParameterRanges MinValue: 0.1,\\nMaxValue: 1\\ncolsample_bynode ContinuousParameterRanges MinValue: 0.1,\\nMaxValue: 1\\ncolsample_bytree ContinuousParameterRanges MinValue: 0.5,\\nMaxValue: 1\\n265Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter NameParameter Type Recommended Ranges\\neta ContinuousParameterRanges MinValue: 0.1,\\nMaxValue: 0.5\\ngamma ContinuousParameterRanges MinValue: 0, MaxValue:\\n5\\nlambda ContinuousParameterRanges MinValue: 0, MaxValue:\\n1000\\nmax_delta_step IntegerParameterRanges [0, 10]\\nmax_depth IntegerParameterRanges [0, 10]\\nmin_child_weight ContinuousParameterRanges MinValue: 0, MaxValue:\\n120\\nnum_round IntegerParameterRanges [1, 4000]\\nsubsample ContinuousParameterRanges MinValue: 0.5,\\nMaxValue: 1\\nXGBoost Previous Versions\\nThis page contains links to the documentation for previous versions of Amazon SageMaker XGBoost.\\nTopics\\n•XGBoost Release 0.72 (p. 266)\\nXGBoost Release 0.72\\nThis previous release of the Amazon SageMaker XGBoost algorithm is based on the 0.72 release.\\nXGBoost (eXtreme Gradient Boosting) is a popular and eﬃcient open-source implementation of the\\ngradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm that attempts\\nto accurately predict a target variable by combining the estimates of a set of simpler, weaker models.\\nXGBoost has done remarkably well in machine learning competitions because it robustly handles a\\nvariety of data types, relationships, and distributions, and the large number of hyperparameters that can\\nbe tweaked and tuned for improved ﬁts. This ﬂexibility makes XGBoost a solid choice for problems in\\nregression, classiﬁcation (binary and multiclass), and ranking.\\nCustomers should consider using the new release of XGBoost Algorithm (p. 255). They can use it as\\nan Amazon SageMaker built-in algorithm or as a framework to run scripts in their local environments\\nas they would typically, for example, do with a Tensorﬂow deep learning framework. The new\\nimplementation has a smaller memory footprint, better logging, improved hyperparameter validation,\\nand an expanded set of metrics. The earlier implementation of XGBoost remains available to customers\\nif they need to postpone migrating to the new version. But this previous implementation will remain tied\\nto the 0.72 release of XGBoost.\\nTopics\\n•Input/Output Interface for the XGBoost Release 0.72 (p. 267)\\n•EC2 Instance Recommendation for the XGBoost Release 0.72 (p. 267)\\n•XGBoost Release 0.72 Sample Notebooks (p. 268)\\n•XGBoost Release 0.72 Hyperparameters (p. 268)\\n•Tune an XGBoost Release 0.72 Model (p. 274)\\n266Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nInput/Output Interface for the XGBoost Release 0.72\\nGradient boosting operates on tabular data, with the rows representing observations, one column\\nrepresenting the target variable or label, and the remaining columns representing features.\\nThe Amazon SageMaker implementation of XGBoost supports CSV and libsvm formats for training and\\ninference:\\n•For Training ContentType, valid inputs are text/libsvm (default) or text/csv.\\n•For Inference ContentType, valid inputs are text/libsvm or (the default) text/csv.\\nNote\\nFor CSV training, the algorithm assumes that the target variable is in the ﬁrst column and that\\nthe CSV does not have a header record. For CSV inference, the algorithm assumes that CSV input\\ndoes not have the label column.\\nFor libsvm training, the algorithm assumes that the label is in the ﬁrst column. Subsequent\\ncolumns contain the zero-based index value pairs for features. So each row has the format:\\n<label> <index0>:<value0> <index1>:<value1> ... Inference requests for libsvm may or may not\\nhave labels in the libsvm format.\\nThis diﬀers from other Amazon SageMaker algorithms, which use the protobuf training input format to\\nmaintain greater consistency with standard XGBoost data formats.\\nFor CSV training input mode, the total memory available to the algorithm (Instance Count * the memory\\navailable in the InstanceType ) must be able to hold the training dataset. For libsvm training input\\nmode, it\\'s not required, but we recommend it.\\nSageMaker XGBoost uses the Python pickle module to serialize/deserialize the model, which can be used\\nfor saving/loading the model.\\nTo use a model trained with SageMaker XGBoost in open source XGBoost\\n• Use the following Python code:\\nimport pickle as pkl \\nmodel = pkl.load(open(model_file_path, \\'rb\\'))\\n# prediction with test data\\npred = model.predict(dtest)\\nTo diﬀerentiate the importance of labelled data points use Instance Weight Supports\\n• Amazon SageMaker XGBoost allows customers to diﬀerentiate the importance of labelled data\\npoints by assigning each instance a weight value. For text/libsvm input, customers can assign\\nweight values to data instances by attaching them after the labels. For example, label:weight\\nidx_0:val_0 idx_1:val_1... . For text/csv input, customers need to turn on the csv_weights\\nﬂag in the parameters and attach weight values in the column after labels. For example:\\nlabel,weight,val_0,val_1,... ).\\nEC2 Instance Recommendation for the XGBoost Release 0.72\\nAmazon SageMaker XGBoost currently only trains using CPUs. It is a memory-bound (as opposed to\\ncompute-bound) algorithm. So, a general-purpose compute instance (for example, M4) is a better choice\\nthan a compute-optimized instance (for example, C4). Further, we recommend that you have enough\\ntotal memory in selected instances to hold the training data. Although it supports the use of disk space\\nto handle data that does not ﬁt into main memory (the out-of-core feature available with the libsvm\\ninput mode), writing cache ﬁles onto disk slows the algorithm processing time.\\n267Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nXGBoost Release 0.72 Sample Notebooks\\nFor a sample notebook that shows how to use the latest version of Amazon SageMaker XGBoost as\\na built-in algorithm to train and host a regression model, see Regression with Amazon SageMaker\\nXGBoost algorithm. To use the 0.72 version of XGBoost, you need to change the version in the sample\\ncode to 0.72. For instructions how to create and access Jupyter notebook instances that you can use to\\nrun the example in Amazon SageMaker, see Use Notebook Instances (p. 36). Once you have created a\\nnotebook instance and opened it, select the SageMaker Examples tab to see a list of all the Amazon\\nSageMaker samples. The topic modeling example notebooks using the NTM algorithms are located in the\\nIntroduction to Amazon algorithms section. To open a notebook, click on its Use tab and select Create\\ncopy.\\nXGBoost Release 0.72 Hyperparameters\\nThe following table contains the hyperparameters for the XGBoost algorithm. These are parameters\\nthat are set by users to facilitate the estimation of model parameters from data. The required\\nhyperparameters that must be set are listed ﬁrst, in alphabetical order. The optional hyperparameters\\nthat can be set are listed next, also in alphabetical order. The Amazon SageMaker XGBoost algorithm is\\nan implementation of the open-source XGBoost package. Currently Amazon SageMaker supports version\\n0.72. For more detail about hyperparameter conﬁguration for this version of XGBoost, see  XGBoost\\nParameters.\\nParameter Name Description\\nnum_class The number of classes.\\nRequired if objective  is set to multi:softmax or multi:softprob.\\nValid values: integer\\nnum_round The number of rounds to run the training.\\nRequired\\nValid values: integer\\nalpha L1 regularization term on weights. Increasing this value makes\\nmodels more conservative.\\nOptional\\nValid values: ﬂoat\\nDefault value: 0\\nbase_score The initial prediction score of all instances, global bias.\\nOptional\\nValid values: ﬂoat\\nDefault value: 0.5\\nbooster Which booster to use. The gbtree  and dart values use a tree-\\nbased model, while gblinear  uses a linear function.\\nOptional\\nValid values: String. One of gbtree , gblinear , or dart .\\n268Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nDefault value: gbtree\\ncolsample_bylevel Subsample ratio of columns for each split, in each level.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 1\\ncolsample_bytree Subsample ratio of columns when constructing each tree.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 1\\ncsv_weights When this ﬂag is enabled, XGBoost diﬀerentiates the importance\\nof instances for csv input by taking the second column (the column\\nafter labels) in training data as the instance weights.\\nOptional\\nValid values: 0 or 1\\nDefault value: 0\\nearly_stopping_rounds The model trains until the validation score stops\\nimproving. Validation error needs to decrease at least every\\nearly_stopping_rounds  to continue training. Amazon\\nSageMaker hosting uses the best model for inference.\\nOptional\\nValid values: integer\\nDefault value: -\\neta Step size shrinkage used in updates to prevent overﬁtting. After\\neach boosting step, you can directly get the weights of new\\nfeatures. The eta parameter actually shrinks the feature weights to\\nmake the boosting process more conservative.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 0.3\\n269Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\neval_metric Evaluation metrics for validation data. A default metric is assigned\\naccording to the objective:\\n•rmse: for regression\\n•error : for classiﬁcation\\n•map: for ranking\\nFor a list of valid inputs, see XGBoost Parameters.\\nOptional\\nValid values: string\\nDefault value: Default according to objective.\\ngamma Minimum loss reduction required to make a further partition on\\na leaf node of the tree. The larger, the more conservative the\\nalgorithm is.\\nOptional\\nValid values: Float. Range: [0,∞).\\nDefault value: 0\\ngrow_policy Controls the way that new nodes are added to the tree. Currently\\nsupported only if tree_method  is set to hist .\\nOptional\\nValid values: String. Either depthwise  or lossguide .\\nDefault value: depthwise\\nlambda L2 regularization term on weights. Increasing this value makes\\nmodels more conservative.\\nOptional\\nValid values: ﬂoat\\nDefault value: 1\\nlambda_bias L2 regularization term on bias.\\nOptional\\nValid values: Float. Range: [0.0, 1.0].\\nDefault value: 0\\n270Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nmax_bin Maximum number of discrete bins to bucket continuous features.\\nUsed only if tree_method  is set to hist .\\nOptional\\nValid values: integer\\nDefault value: 256\\nmax_delta_step Maximum delta step allowed for each tree\\'s weight estimation.\\nWhen a positive integer is used, it helps make the update more\\nconservative. The preferred option is to use it in logistic regression.\\nSet it to 1-10 to help control the update.\\nOptional\\nValid values: Integer. Range: [0,∞).\\nDefault value: 0\\nmax_depth Maximum depth of a tree. Increasing this value makes the model\\nmore complex and likely to be overﬁt. 0 indicates no limit. A limit is\\nrequired when grow_policy =depth-wise .\\nOptional\\nValid values: Integer. Range: [0,∞)\\nDefault value: 6\\nmax_leaves Maximum number of nodes to be added. Relevant only if\\ngrow_policy  is set to lossguide .\\nOptional\\nValid values: integer\\nDefault value: 0\\nmin_child_weight Minimum sum of instance weight (hessian) needed in a child. If the\\ntree partition step results in a leaf node with the sum of instance\\nweight less than min_child_weight , the building process gives\\nup further partitioning. In linear regression models, this simply\\ncorresponds to a minimum number of instances needed in each\\nnode. The larger the algorithm, the more conservative it is.\\nOptional\\nValid values: Float. Range: [0,∞).\\nDefault value: 1\\nnormalize_type Type of normalization algorithm.\\nOptional\\nValid values: Either tree or forest .\\nDefault value: tree\\n271Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nnthread Number of parallel threads used to run xgboost.\\nOptional\\nValid values: integer\\nDefault value: Maximum number of threads.\\nobjective Speciﬁes the learning task and the corresponding learning\\nobjective. Examples: reg:linear , reg:logistic ,\\nmulti:softmax . For a full list of valid inputs, refer to XGBoost\\nParameters.\\nOptional\\nValid values: string\\nDefault value: reg:linear\\none_drop When this ﬂag is enabled, at least one tree is always dropped\\nduring the dropout.\\nOptional\\nValid values: 0 or 1\\nDefault value: 0\\nprocess_type The type of boosting process to run.\\nOptional\\nValid values: String. Either default  or update .\\nDefault value: default\\nrate_drop The dropout rate that speciﬁes the fraction of previous trees to\\ndrop during the dropout.\\nOptional\\nValid values: Float. Range: [0.0, 1.0].\\nDefault value: 0.0\\nrefresh_leaf This is a parameter of the \\'refresh\\' updater plug-in. When set to\\ntrue (1), tree leaves and tree node stats are updated. When set to\\nfalse(0), only tree node stats are updated.\\nOptional\\nValid values: 0/1\\nDefault value: 1\\n272Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nsample_type Type of sampling algorithm.\\nOptional\\nValid values: Either uniform  or weighted .\\nDefault value: uniform\\nscale_pos_weight Controls the balance of positive and negative weights. It\\'s useful\\nfor unbalanced classes. A typical value to consider: sum(negative\\ncases)  / sum(positive cases) .\\nOptional\\nValid values: ﬂoat\\nDefault value: 1\\nseed Random number seed.\\nOptional\\nValid values: integer\\nDefault value: 0\\nsilent 0 means print running messages, 1 means silent mode.\\nValid values: 0 or 1\\nOptional\\nDefault value: 0\\nsketch_eps Used only for approximate greedy algorithm. This translates into\\nO(1 / sketch_eps ) number of bins. Compared to directly select\\nnumber of bins, this comes with theoretical guarantee with sketch\\naccuracy.\\nOptional\\nValid values: Float, Range: [0, 1].\\nDefault value: 0.03\\nskip_drop Probability of skipping the dropout procedure during a boosting\\niteration.\\nOptional\\nValid values: Float. Range: [0.0, 1.0].\\nDefault value: 0.0\\n273Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nParameter Name Description\\nsubsample Subsample ratio of the training instance. Setting it to 0.5 means\\nthat XGBoost randomly collects half of the data instances to grow\\ntrees. This prevents overﬁtting.\\nOptional\\nValid values: Float. Range: [0,1].\\nDefault value: 1\\ntree_method The tree construction algorithm used in XGBoost.\\nOptional\\nValid values: One of auto , exact , approx , or hist .\\nDefault value: auto\\ntweedie_variance_power Parameter that controls the variance of the Tweedie distribution.\\nOptional\\nValid values: Float. Range: (1, 2).\\nDefault value: 1.5\\nupdater A comma-separated string that deﬁnes the sequence of tree\\nupdaters to run. This provides a modular way to construct and to\\nmodify the trees.\\nFor a full list of valid inputs, please refer to XGBoost Parameters.\\nOptional\\nValid values: comma-separated string.\\nDefault value: grow_colmaker , prune\\nTune an XGBoost Release 0.72 Model\\nAutomatic model tuning , also known as hyperparameter tuning, ﬁnds the best version of a model by\\nrunning many jobs that test a range of hyperparameters on your dataset. You choose the tunable\\nhyperparameters, a range of values for each, and an objective metric. You choose the objective metric\\nfrom the metrics that the algorithm computes. Automatic model tuning searches the hyperparameters\\nchosen to ﬁnd the combination of values that result in the model that optimizes the objective metric.\\nFor more information about model tuning, see Automatic Model Tuning (p. 288).\\nMetrics Computed by the XGBoost Release 0.72 Algorithm\\nThe XGBoost algorithm based on version 0.72 computes the following nine metrics during training.\\nWhen tuning the model, choose one of these metrics as the objective to evaluate the model.\\nMetric Name Description Optimization Direction\\nvalidation:auc Area under the curve. Maximize\\n274Amazon SageMaker Developer Guide\\nXGBoost Algorithm\\nMetric Name Description Optimization Direction\\nvalidation:error Binary classiﬁcation error rate, calculated as\\n#(wrong cases)/#(all cases).Minimize\\nvalidation:logloss Negative log-likelihood. Minimize\\nvalidation:mae Mean absolute error. Minimize\\nvalidation:map Mean average precision. Maximize\\nvalidation:merror Multiclass classiﬁcation error rate, calculated as\\n#(wrong cases)/#(all cases).Minimize\\nvalidation:mlogloss Negative log-likelihood for multiclass\\nclassiﬁcation.Minimize\\nvalidation:ndcg Normalized Discounted Cumulative Gain.Maximize\\nvalidation:rmse Root mean square error. Minimize\\nTunable XGBoost Release 0.72 Hyperparameters\\nTune the XGBoost model with the following hyperparameters. The hyperparameters that have the\\ngreatest eﬀect on XGBoost objective metrics are: alpha , min_child_weight , subsample , eta, and\\nnum_round .\\nParameter Name Parameter Type Recommended Ranges\\nalpha ContinuousParameterRanges MinValue: 0, MaxValue:\\n1000\\ncolsample_bylevel ContinuousParameterRanges MinValue: 0.1,\\nMaxValue: 1\\ncolsample_bytree ContinuousParameterRanges MinValue: 0.5,\\nMaxValue: 1\\neta ContinuousParameterRanges MinValue: 0.1,\\nMaxValue: 0.5\\ngamma ContinuousParameterRanges MinValue: 0, MaxValue:\\n5\\nlambda ContinuousParameterRanges MinValue: 0, MaxValue:\\n1000\\nmax_delta_step IntegerParameterRanges [0, 10]\\nmax_depth IntegerParameterRanges [0, 10]\\nmin_child_weight ContinuousParameterRanges MinValue: 0, MaxValue:\\n120\\nnum_round IntegerParameterRanges [1, 4000]\\nsubsample ContinuousParameterRanges MinValue: 0.5,\\nMaxValue: 1\\n275Amazon SageMaker Developer Guide\\nMonitor and Analyze Training Jobs Using Metrics\\nTrain a Model\\nFor an overview on training a model with Amazon SageMaker, see Train a Model with Amazon SageMaker\\n (p. 4).\\nAmazon SageMaker provides features to monitor and manage the training and validation of machine\\nlearning models. For guidance on metrics available, incremental training, automatic model tuning, and\\nthe use of augmented manifest ﬁles to label training data, see the following topics.\\n•For guidance on metrics used to monitor and train models, see Monitor and Analyze Training Jobs\\nUsing Metrics  (p. 276).\\n•For guidance on incremental training in Amazon SageMaker, see Incremental Training in Amazon\\nSageMaker (p. 282).\\n•For guidance on using managed spot training in Amazon SageMaker, see Managed Spot Training in\\nAmazon SageMaker (p. 287).\\n•For guidance on using training checkpoints in Amazon SageMaker, see Using Checkpoints in Amazon\\nSageMaker (p. 288).\\n•For guidance on automatic model tuning, also known as hyperparameter tuning, see Automatic Model\\nTuning (p. 288).\\n•For guidance on using an augmented manifest ﬁle to label training data, see Provide Dataset Metadata\\nto Training Jobs with an Augmented Manifest File (p. 308).\\nMonitor and Analyze Training Jobs Using Metrics\\nAn Amazon SageMaker training job is an iterative process that teaches a model to make predictions by\\npresenting examples from a training dataset. Typically, a training algorithm computes several metrics,\\nsuch as training error and prediction accuracy. These metrics help diagnose whether the model is\\nlearning well and will generalize well for making predictions on unseen data. The training algorithm\\nwrites the values of these metrics to logs, which Amazon SageMaker monitors and sends to Amazon\\nCloudWatch in real time. To analyze the performance of your training job, you can view graphs of these\\nmetrics in CloudWatch. When a training job has completed, you can also get a list of the metric values\\nthat it computes in its ﬁnal iteration by calling the DescribeTrainingJob (p. 744) operation.\\nTopics\\n•Training Metrics Sample Notebooks (p. 276)\\n•Deﬁning Training Metrics (p. 277)\\n•Monitoring Training Job Metrics ( Console) (p. 279)\\n•Monitoring Training Job Metrics (Amazon SageMaker Console) (p. 279)\\n•Example: Viewing a Training and Validation Curve (p. 281)\\nTraining Metrics Sample Notebooks\\nThe following sample notebooks show how to view and plot training metrics:\\n•An Introduction to the Amazon SageMaker ObjectToVec Model for Sequence-to-sequence Embedding\\n(object2vec_sentence_similarity.ipynb)\\n276Amazon SageMaker Developer Guide\\nDeﬁning Training Metrics\\n•Regression with the Amazon SageMaker XGBoost Algorithm (xgboost_abalone.ipynb)\\nFor instructions how to create and access Jupyter notebook instances that you can use to run\\nthe examples in Amazon SageMaker, see Use Example Notebooks  (p. 42). To see a list of all\\nthe Amazon SageMaker samples, after creating and opening a notebook instance, choose the\\nSageMaker Examples tab. To access the example notebooks that show how to use training metrics,\\nobject2vec_sentence_similarity.ipynb  and  xgboost_abalone.ipynb ., from the\\nIntroduction to Amazon algorithms section. To open a notebook, choose its Use tab, then choose\\nCreate copy.\\nDeﬁning Training Metrics\\nAmazon SageMaker automatically parses the logs for metrics that built-in algorithms emit and sends\\nthose metrics to CloudWatch. If you want Amazon SageMaker to parse logs from a custom algorithm\\nand send metrics that the algorithm emits to CloudWatch, you have to specify the metrics that you want\\nAmazon SageMaker to send to CloudWatch when you conﬁgure the training job. You specify the name of\\nthe metrics that you want to send and the regular expressions that Amazon SageMaker uses to parse the\\nlogs that your algorithm emits to ﬁnd those metrics.\\nYou can specify the metrics that you want to track with the Amazon SageMaker console;, the Amazon\\nSageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk), or the low-level Amazon\\nSageMaker API.\\nTopics\\n•Deﬁning Regular Expressions for Metrics (p. 277)\\n•Deﬁning Training Metrics (Low-level Amazon SageMaker API) (p. 278)\\n•Deﬁning Training Metrics (Amazon SageMaker Python SDK) (p. 278)\\n•Deﬁne Training Metrics (Console) (p. 279)\\nDeﬁning Regular Expressions for Metrics\\nTo ﬁnd a metric, Amazon SageMaker searches the logs that your algorithm emits and ﬁnds logs that\\nmatch the regular expression that you specify for that metric. If you are using your own algorithm, do\\nthe following:\\n•Make sure that the algorithm writes the metrics that you want to capture to logs\\n•Deﬁne a regular expression that accurately searches the logs to capture the values of the metrics that\\nyou want to send to CloudWatch metrics.\\nFor example, suppose your algorithm emits metrics for training error and validation error by writing logs\\nsimilar to the following to stdout  or stderr :\\nTrain_error=0.138318;  Valid_error = 0.324557;\\nIf you want to monitor both of those metrics in CloudWatch, your AlgorithmSpecification  would\\nlook like the following:\\n\"AlgorithmSpecification\": {\\n        \"TrainingImage\": ContainerName ,\\n        \"TrainingInputMode\": \"File\",\\n        \"MetricDefinitions\" : [\\n            {\\n277Amazon SageMaker Developer Guide\\nDeﬁning Training Metrics\\n            \"Name\": \"train:error\",\\n            \"Regex\": \"Train_error=(.*?);\"\\n        },\\n             {\\n            \"Name\": \"validation:error\",\\n            \"Regex\": \"Valid_error=(.*?);\"\\n        }\\n        \\n    ]}\\nIn the regex for the train:error  metric deﬁned above, the ﬁrst part of the regex ﬁnds the exact\\ntext \"Train_error=\", and the expression (.*?); captures zero or more of any character until the ﬁrst\\nsemicolon character. In this expression, the parenthesis tell the regex to capture what is inside them, .\\nmeans any character, * means zero or more, and ? means capture only until the ﬁrst instance of the ;\\ncharacter.\\nDeﬁning Training Metrics (Low-level Amazon SageMaker API)\\nDeﬁne the metrics that you want to send to CloudWatch by specifying a list of metric names and regular\\nexpressions in the MetricDefinitions  ﬁeld of the AlgorithmSpeciﬁcation  (p. 863) input parameter\\nthat you pass to the CreateTrainingJob (p. 667) operation. For example, if you want to monitor both\\nthe train:error  and validation:error  metrics in CloudWatch, your AlgorithmSpecification\\nwould look like the following:\\n\"AlgorithmSpecification\": {\\n        \"TrainingImage\": ContainerName ,\\n        \"TrainingInputMode\": \"File\",\\n        \"MetricDefinitions\" : [\\n            {\\n            \"Name\": \"train:error\",\\n            \"Regex\": \"Train_error=(.*?);\"\\n        },\\n             {\\n            \"Name\": \"validation:error\",\\n            \"Regex\": \"Valid_error=(.*?);\"\\n        }\\n        \\n    ]}\\nFor more information about deﬁning and running a training job by using the low-level Amazon\\nSageMaker API, see Create and Run a Training Job (AWS SDK for Python (Boto 3)) (p. 23).\\nDeﬁning Training Metrics (Amazon SageMaker Python SDK)\\nDeﬁne the metrics that you want to send to CloudWatch by specifying a list of metric names and\\nregular expressions as the metric_definitions  argument when you initialize an Estimator  object.\\nFor example, if you want to monitor both the train:error  and validation:error  metrics in\\nCloudWatch, your Estimator  initialization would look like the following:\\nestimator =\\n                Estimator(image_name= ImageName ,\\n                role=\\'SageMakerRole\\', train_instance_count=1,\\n                train_instance_type=\\'ml.c4.xlarge\\',\\n                train_instance_type=\\'ml.c4.xlarge\\',\\n                k=10,\\n                sagemaker_session=sagemaker_session,\\n                metric_definitions=[\\n                   {\\'Name\\': \\'train:error\\', \\'Regex\\': \\'Train_error=(.*?);\\'},\\n                   {\\'Name\\': \\'validation:error\\', \\'Regex\\': \\'Valid_error=(.*?);\\'\\n278Amazon SageMaker Developer Guide\\nMonitoring Training Job Metrics ( Console)\\n                ]\\n            )\\nFor more information about training by using Amazon SageMaker Python SDK estimators, see https://\\ngithub.com/aws/sagemaker-python-sdk#sagemaker-python-sdk-overview.\\nDeﬁne Training Metrics (Console)\\nYou can deﬁne metrics for a custom algorithm in the console when you create a training job by providing\\nthe name and regular expression (regex) for Metrics .\\nFor example, if you want to monitor both the train:error  and validation:error  metrics in\\nCloudWatch, your metric deﬁnitions would look like the following:\\n[\\n            {\\n            \"Name\": \"train:error\",\\n            \"Regex\": \"Train_error=(.*?);\"\\n        },\\n             {\\n            \"Name\": \"validation:error\",\\n            \"Regex\": \"Valid_error=(.*?);\"\\n        }\\n        \\n    ]}\\nMonitoring Training Job Metrics ( Console)\\nYou can monitor the metrics that a training job emits in real time in the CloudWatch console.\\nTo monitor training job metrics (CloudWatch console)\\n1. Open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.\\n2. Choose Metrics , then choose /aws/sagemaker/TrainingJobs.\\n3. Choose TrainingJobName.\\n4. On the All metrics  tab, choose the names of the training metrics that you want to monitor.\\n5. On the Graphed metrics  tab, conﬁgure the graph options. For more information about using\\nCloudWatch graphs, see Graph Metrics  in the Amazon CloudWatch User Guide.\\nMonitoring Training Job Metrics (Amazon SageMaker\\nConsole)\\nYou can monitor the metrics that a training job emits in real time by using the Amazon SageMaker\\nconsole.\\nTo monitor training job metrics (Amazon SageMaker console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Training jobs, then choose the training job whose metrics you want to see.\\n3. Choose TrainingJobName.\\n4. In the Monitor  section, you can review the graphs of instance utilization and algorithm metrics.\\n279Amazon SageMaker Developer Guide\\nMonitoring Training Job Metrics\\n(Amazon SageMaker Console)\\n280Amazon SageMaker Developer Guide\\nExample: Viewing a Training and Validation Curve\\nExample: Viewing a Training and Validation Curve\\nTypically, you split the data that you train your model on into training and validation datasets. You use\\nthe training set to train the model parameters that are used to make predictions on the training dataset.\\nThen you test how well the model makes predictions by calculating predictions for the validation set. To\\nanalyze the performance of a training job, you commonly plot a training curve against a validation curve.\\nViewing a graph that shows the accuracy for both the training and validation sets over time can help you\\nto improve the performance of your model. For example, if training accuracy continues to increase over\\ntime, but, at some point, validation accuracy starts to decrease, you are likely overﬁtting your model. To\\naddress this, you can make adjustments to your model, such as increasing regularization.\\nFor this example, you can use the Image-classiﬁcation-full-training  example that is in the Example\\nnotebooks  section of your Amazon SageMaker notebook instance. If you don\\'t have an Amazon\\nSageMaker notebook instance, create one by following the instructions at Step 2: Create an Amazon\\nSageMaker Notebook Instance (p. 17). If you prefer, you can follow along with the End-to-End Multiclass\\nImage Classiﬁcation Example  in the example notebook on GitHub. You also need an Amazon S3 bucket\\nto store the training data and for the model output. If you haven\\'t created a bucket to use with Amazon\\nSageMaker, create one by following the instructions at Step 1: Create an Amazon S3 Bucket (p. 17).\\nTo view training and validation error curves\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebooks , and then choose Notebook instances.\\n3. Choose the notebook instance that you want to use, and then choose Open .\\n4. On the dashboard for your notebook instance, choose SageMaker Examples.\\n5. Expand the Introduction to Amazon Algorithms section, and then choose Use next to Image-\\nclassiﬁcation-full-training.ipynb.\\n6. Choose Create copy. Amazon SageMaker creates an editable copy of the Image-classiﬁcation-full-\\ntraining.ipynb notebook in your notebook instance.\\n7. In the ﬁrst code cell of the notebook, replace <<bucket-name>>  with the name of your S3 bucket.\\n8. Run all of the cells in the notebook up to the Deploy section. You don\\'t need to deploy an endpoint\\nor get inference for this example.\\n9. After the training job starts, open the CloudWatch console at https://console.aws.amazon.com/\\ncloudwatch/ .\\n10. Choose Metrics , then choose /aws/sagemaker/TrainingJobs.\\n11. Choose TrainingJobName.\\n12. On the All metrics  tab, choose the train:accuracy and validation:accuracy metrics for the training\\njob that you created in the notebook.\\n13. On the graph, choose an area that the metric\\'s values to zoom in. You should see something like the\\nfollowing:\\n281Amazon SageMaker Developer Guide\\nIncremental Training\\nIncremental Training in Amazon SageMaker\\nOver time, you might ﬁnd that a model generates inference that are not as good as they were in the\\npast. With incremental training, you can use the artifacts from an existing model and use an expanded\\ndataset to train a new model. Incremental training saves both time and resources.\\nUse incremental training to:\\n•Train a new model using an expanded dataset that contains an underlying pattern that was not\\naccounted for in the previous training and which resulted in poor model performance.\\n•Use the model artifacts or a portion of the model artifacts from a popular publicly available model in a\\ntraining job. You don\\'t need to train a new model from scratch.\\n282Amazon SageMaker Developer Guide\\nPerform Incremental Training (Console)\\n•Resume a training job that was stopped.\\n•Train several variants of a model, either with diﬀerent hyperparameter settings or using diﬀerent\\ndatasets.\\nFor more information about training jobs, see Train a Model with Amazon SageMaker  (p. 4).\\nYou can train incrementally using the Amazon SageMaker console or the Amazon SageMaker Python\\nSDK.\\nImportant\\nOnly two built-in algorithms currently support incremental training: Object Detection\\nAlgorithm  (p. 199) and Image Classiﬁcation Algorithm  (p. 108).\\nTopics\\n•Perform Incremental Training (Console) (p. 283)\\n•Perform Incremental Training (API) (p. 285)\\nPerform Incremental Training (Console)\\nTo complete this procedure, you need:\\n•The URL of the Amazon Simple Storage Service (Amazon S3) bucket where you\\'ve stored the training\\ndata.\\n•The URL of the S3 bucket where you want to store the output of the job.\\n•The Amazon Elastic Container Registry path where the training code is stored. For more information,\\nsee Common Parameters for Built-In Algorithms  (p. 58).\\n•The URL of the S3 bucket where you\\'ve stored the model artifacts that you want to use in incremental\\ntraining. To ﬁnd the URL for the model artifacts, see the details page of the training job used to create\\nthe model. To ﬁnd the details page, in the Amazon SageMaker console, choose Inference, choose\\nModels , and then choose the model.\\nTo restart a stopped training job, use the URL to the model artifacts that are stored in the details page as\\nyou would with a model or a completed training job.\\nTo perform incremental training (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker.\\n2. In the navigation pane, choose Training, then choose Training jobs.\\n3. Choose Create training job .\\n4. Provide a name for the training job. The name must be unique within an AWS Region in an AWS\\naccount. The training job name must have 1 to 63 characters. Valid characters: a-z, A-Z, 0-9, and . : +\\n= @ _ % - (hyphen).\\n5. Choose the algorithm that you want to use. For information about algorithms, see Use Amazon\\nSageMaker Built-in Algorithms  (p. 56).\\n6. (Optional) For Resource conﬁguration, either leave the default values or increase the resource\\nconsumption to reduce computation time.\\na. (Optional) For Instance type, choose the ML compute instance type that you want to use. In\\nmost cases, ml.m4.xlarge  is suﬃcient.\\nb. For Instance count, use the default, 1.\\nc. (Optional) For Additional volume per instance (GB), choose the size of the ML storage volume\\nthat you want to provision. In most cases, you can use the default, 1. If you are using a large\\ndataset, use a larger size.\\n283Amazon SageMaker Developer Guide\\nPerform Incremental Training (Console)\\n7. Provide information about the input data for the training dataset.\\na. For Channel name , either leave the default (train) or enter a more meaningful name for the\\ntraining dataset, such as expanded-training-dataset .\\nb. For InputMode , choose File. For incremental training, you need to use ﬁle input mode.\\nc. For S3 data distribution type, choose FullyReplicated. This causes each ML compute instance\\nto use a full replicate of the expanded dataset when training incrementally.\\nd. If the expanded dataset is uncompressed, set the Compression type to None . If the expanded\\ndataset is compressed using Gzip, set it to Gzip .\\ne. (Optional) If you are using File input mode, leave Content type empty. For Pipe input mode,\\nspecify the appropriate MIME type. Content type  is the multipurpose internet mail extension\\n(MIME) type of the data.\\nf.For Record wrapper, if the dataset is saved in RecordIO format, choose RecordIO. If your\\ndataset is not saved as a RecordIO formatted ﬁle, choose None .\\ng. For S3 data type, if the dataset us stored as a single ﬁle, choose S3Preﬁx . If the dataset is\\nstored as several ﬁles in a folder, choose Manifest .\\nh. For S3 location, provide the URL to the path where you stored the expanded dataset.\\ni. Choose Done .\\n8. To use model artifacts in a training job, you need to add a new channel and provide the needed\\ninformation about the model artifacts.\\na. For Input data conﬁguration, choose Add channel .\\nb. For Channel name , enter model to identify this channel as the source of the model artifacts.\\nc. For InputMode , choose File. Model artifacts are stored as ﬁles.\\nd. For S3 data distribution type, choose FullyReplicated. This indicates that each ML compute\\ninstance should use all of the model artifacts for training.\\ne. For Compression type, choose None  because we are using a model for the channel.\\nf.Leave Content type empty. Content type is the multipurpose internet mail extension (MIME)\\ntype of the data. For model artifacts, we leave it empty.\\ng. Set Record wrapper to None  because model artifacts are not stored in RecordIO format.\\nh. For S3 data type, if you are using a built-in algorithm or an algorithm that stores the model as a\\nsingle ﬁle, choose S3Preﬁx . If you are using an algorithm that stores the model as several ﬁles,\\nchoose Manifest .\\ni. For S3 location, provide the URL to the path where you stored the model artifacts. Typically,\\nthe model is stored with the name model.tar.gz . To ﬁnd the URL for the model artifacts, in\\nthe navigation pane, choose Inference, then choose Models . From the list of models, choose\\na model to display its details page. The URL for the model artifacts is listed under Primary\\ncontainer .\\nj. Choose Done .\\n9. For Output data conﬁguration, provide the following information:\\na. For S3 location, type the path to the S3 bucket where you want to store the output data.\\nb. (Optional) For Encryption key, you can add your AWS Key Management Service (AWS KMS)\\nencryption key to encrypt the output data at rest. Provide the key ID or its Amazon Resource\\nNumber (ARN). For more information, see KMS-Managed Encryption Keys.\\n10. (Optional) For Tags, add one or more tags to the training job. A tag is metadata that you can deﬁne\\nand assign to AWS resources. In this case, you can use tags to help you manage your training jobs. A\\ntag consists of a key and a value, which you deﬁne. For example, you might want to create a tag with\\nProject as a key and a value referring to a project that is related to the training job, such as Home\\nvalue forecasts .\\n11. Choose Create training job . Amazon SageMaker creates and runs training job.\\n284Amazon SageMaker Developer Guide\\nPerform Incremental Training (API)\\nAfter the training job has completed, the newly trained model artifacts are stored under the S3 output\\npath  that you provided in the Output data conﬁguration ﬁeld. To deploy the model to get predictions,\\nsee Step 6: Deploy the Model to Amazon SageMaker (p. 26).\\nPerform Incremental Training (API)\\nThis example shows how to use Amazon SageMaker APIs to train a model using the Amazon SageMaker\\nimage classiﬁcation algorithm and the Caltech 256 Image Dataset , then train a new model using the\\nﬁrst one. It uses Amazon S3 for input and output sources. Please see the incremental training sample\\nnotebook  for more details on using incremental training.\\nNote\\nIn this example we used the original datasets in the incremental training, however you can use\\ndiﬀerent datasets, such as ones that contain newly added samples. Upload the new datasets to\\nS3 and make adjustments to the data_channels  variable used to train the new model.\\nGet an AWS Identity and Access Management (IAM) role that grants required permissions and initialize\\nenvironment variables:\\nimport sagemaker\\nfrom sagemaker import get_execution_role\\nrole = get_execution_role()\\nprint(role)\\nsess = sagemaker.Session()\\nbucket=sess.default_bucket()\\nprint(bucket)\\nprefix = \\'ic-incr-training\\'\\nGet the training image for the image classiﬁcation algorithm:\\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\\ntraining_image = get_image_uri(sess.boto_region_name, \\'image-classification\\',\\n repo_version=\"latest\")\\n#Display the training image\\nprint (training_image)\\nDownload the training and validation datasets, then upload them to Amazon Simple Storage Service\\n(Amazon S3):\\nimport os\\nimport urllib.request\\nimport boto3\\n# Define a download function\\ndef download(url):\\n    filename = url.split(\"/\")[-1]\\n    if not os.path.exists(filename):\\n        urllib.request.urlretrieve(url, filename)\\n# Download the caltech-256 training and validation datasets\\ndownload(\\'http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec\\')\\ndownload(\\'http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec\\')\\n# Create four channels: train, validation, train_lst, and validation_lst\\ns3train = \\'s3://{}/{}/train/\\'.format(bucket, prefix)\\n285Amazon SageMaker Developer Guide\\nPerform Incremental Training (API)\\ns3validation = \\'s3://{}/{}/validation/\\'.format(bucket, prefix)\\n# Upload the first files to the train and validation channels\\n!aws s3 cp caltech-256-60-train.rec $s3train --quiet\\n!aws s3 cp caltech-256-60-val.rec $s3validation --quiet\\nDeﬁne the training hyperparameters:\\n# Define hyperparameters for the estimator\\nhyperparams = { \"num_layers\": \"18\",\\n                \"resize\": \"32\",\\n                \"num_training_samples\": \"50000\",\\n                \"num_classes\": \"10\",\\n                \"image_shape\": \"3,28,28\",\\n                \"mini_batch_size\": \"128\",\\n                \"epochs\": \"3\",\\n                \"learning_rate\": \"0.1\",\\n                \"lr_scheduler_step\": \"2,3\",\\n                \"lr_scheduler_factor\": \"0.1\",\\n                \"augmentation_type\": \"crop_color\",\\n                \"optimizer\": \"sgd\",\\n                \"momentum\": \"0.9\",\\n                \"weight_decay\": \"0.0001\",\\n                \"beta_1\": \"0.9\",\\n                \"beta_2\": \"0.999\",\\n                \"gamma\": \"0.9\",\\n                \"eps\": \"1e-8\",\\n                \"top_k\": \"5\",\\n                \"checkpoint_frequency\": \"1\",\\n                \"use_pretrained_model\": \"0\",\\n                \"model_prefix\": \"\" }\\nCreate an estimator object and train the ﬁrst model using the training and validation datasets:\\n# Fit the base estimator\\ns3_output_location = \\'s3://{}/{}/output\\'.format(bucket, prefix)\\nic = sagemaker.estimator.Estimator(training_image,\\n                                   role,\\n                                   train_instance_count=1,\\n                                   train_instance_type=\\'ml.p2.xlarge\\',\\n                                   train_volume_size=50,\\n                                   train_max_run=360000,\\n                                   input_mode=\\'File\\',\\n                                   output_path=s3_output_location,\\n                                   sagemaker_session=sess,\\n                                   hyperparameters=hyperparams)\\ntrain_data = sagemaker.session.s3_input(s3train, distribution=\\'FullyReplicated\\',\\n                                        content_type=\\'application/x-recordio\\',\\n s3_data_type=\\'S3Prefix\\')\\nvalidation_data = sagemaker.session.s3_input(s3validation, distribution=\\'FullyReplicated\\',\\n                                             content_type=\\'application/x-recordio\\',\\n s3_data_type=\\'S3Prefix\\')\\ndata_channels = {\\'train\\': train_data, \\'validation\\': validation_data}\\nic.fit(inputs=data_channels, logs=True)\\nTo use the model to incrementally train another model, create a new estimator object and use the model\\nartifacts (ic.model_data , in this example) for the model_uri  input argument:\\n# Given the base estimator, create a new one for incremental training\\n286Amazon SageMaker Developer Guide\\nManaged Spot Training\\nincr_ic = sagemaker.estimator.Estimator(training_image,\\n                                        role,\\n                                        train_instance_count=1,\\n                                        train_instance_type=\\'ml.p2.xlarge\\',\\n                                        train_volume_size=50,\\n                                        train_max_run=360000,\\n                                        input_mode=\\'File\\',\\n                                        output_path=s3_output_location,\\n                                        sagemaker_session=sess,\\n                                        hyperparameters=hyperparams,\\n                                        model_uri=ic.model_data) # This parameter will\\n ingest the previous job\\'s model as a new channel\\nincr_ic.fit(inputs=data_channels, logs=True)\\nAfter the training job has completed, the newly trained model artifacts are stored under the S3 output\\npath that you provided in Output_path . To deploy the model to get predictions, see Step 6: Deploy the\\nModel to Amazon SageMaker (p. 26).\\nManaged Spot Training in Amazon SageMaker\\nAmazon SageMaker makes it easy to train machine learning models using managed Amazon EC2 Spot\\ninstances. Managed spot training can optimize the cost of training models up to 90% over on-demand\\ninstances. Amazon SageMaker manages the Spot interruptions on your behalf.\\nManaged Spot Training uses Amazon EC2 Spot instance to run training jobs instead of on-demand\\ninstances. You can specify which training jobs use spot instances and a stopping condition that speciﬁes\\nhow long Amazon SageMaker waits for a job to run using Amazon EC2 Spot instances. Metrics and logs\\ngenerated during training runs are available in CloudWatch.\\nSpot instances can be interrupted, causing jobs to take longer to start or ﬁnish. You can conﬁgure your\\nmanaged spot training job to use checkpoints. Amazon SageMaker copies checkpoint data from a local\\npath to Amazon S3. When the job is restarted, Amazon SageMaker copies the data from Amazon S3 back\\ninto the local path. The training can then resume from the last checkpoint instead of restarting. For more\\ninformation about checkpointing, see Using Checkpoints in Amazon SageMaker (p. 288).\\nNote\\nUnless your training job will complete quickly, we recommend you use checkpointing with\\nmanaged spot training. SageMaker built-in algorithms and marketplace algorithms that do not\\ncheckpoint are currently limited to a MaxWaitTimeInSeconds  of 3600 seconds (60 minutes).\\nTopics\\n•Using Managed Spot Training (p. 287)\\n•Managed Spot Training Lifecycle (p. 288)\\nUsing Managed Spot Training\\nTo use managed spot training, create a training job. Set EnableManagedSpotTraining  to\\nTrue and specify the MaxWaitTimeInSecods . MaxWaitTimeInSeconds  must be larger\\nthan MaxRuntimeInSeconds . For more information about creating a training job, see\\nCreateTrainingJob (p. 667).\\nYou can calculate the savings from using managed spot training using the formula (1\\n- BillableTimeInSeconds / TrainingTimeInSeconds) * 100 . For example, if\\nBillableTimeInSeconds  is 100 and TrainingTimeInSeconds  is 500, the savings is 80%.\\n287Amazon SageMaker Developer Guide\\nManaged Spot Training Lifecycle\\nManaged Spot Training Lifecycle\\nYou can monitor a training job using TrainingJobStatus  and SecondaryStatus  returned by\\nDescribeTrainingJob (p. 744). The list below shows how TrainingJobStatus  and SecondaryStatus\\nvalues change depending on the training scenario:\\n•Spot instances acquired with no interruption during training\\n1.InProgress : Starting ↠ Downloading  ↠ Training  ↠ Uploading\\n•Spot instances interrupted once. Later, enough spot instances were acquired to ﬁnish the training\\njob.\\n1.InProgress : Starting  ↠ Downloading  ↠ Training  ↠ Interrupted  ↠ Starting  ↠\\nDownloading  ↠ Training  ↠ Uploading\\n•Spot instances interrupted twice and MaxWaitTimeInSeconds  exceeded.\\n1.InProgress : Starting  ↠ Downloading  ↠ Training  ↠ Interrupted  ↠ Starting  ↠\\nDownloading  ↠ Training  ↠ Interrupted  ↠ Downloading  ↠ Training\\n2.Stopping : Stopping\\n3.Stopped : MaxWaitTimeExceeded\\n•Spot instances were never launched.\\n1.InProgress : Starting\\n2.Stopping : Stopping\\n3.Stopped : MaxWaitTimeExceeded\\nUsing Checkpoints in Amazon SageMaker\\nA checkpoint is a snapshot of the state of the model. They can be used with Managed Spot Training. If a\\ntraining job is interrupted, a snapshot can be used to resume from a previously saved point. This can save\\ntraining time.\\nSnapshots are saved to an Amazon S3 location you specify. You can conﬁgure the local path to use for\\nsnapshots or use the default. When a training job is interrupted, Amazon SageMaker copies the training\\ndata to Amazon S3. When the training job is restarted, the checkpoint data is copied to the local path. It\\ncan be used to resume at the checkpoint.\\nTo enable checkpoints, provide an Amazon S3 location. You can optionally provide a local path and\\nchoose to use a shared folder. The default local path is /opt/ml/checkpoints/ . For more information,\\nsee CreateTrainingJob (p. 667)\\nAutomatic Model Tuning\\nAmazon SageMaker automatic model tuning, also known as hyperparameter tuning, ﬁnds the best\\nversion of a model by running many training jobs on your dataset using the algorithm and ranges of\\nhyperparameters that you specify. It then chooses the hyperparameter values that result in a model that\\nperforms the best, as measured by a metric that you choose.\\nFor example, suppose that you want to solve a binary classiﬁcation problem on a marketing dataset.\\nYour goal is to maximize the area under the curve (auc) metric of the algorithm by training an XGBoost\\nAlgorithm  (p. 255) model. You don\\'t know which values of the eta, alpha , min_child_weight ,\\nand max_depth  hyperparameters to use to train the best model. To ﬁnd the best values for these\\nhyperparameters, you can specify ranges of values that Amazon SageMaker hyperparameter tuning\\n288Amazon SageMaker Developer Guide\\nHow Hyperparameter Tuning Works\\nsearches to ﬁnd the combination of values that results in the training job that performs the best as\\nmeasured by the objective metric that you chose. Hyperparameter tuning launches training jobs that use\\nhyperparameter values in the ranges that you speciﬁed, and returns the training job with highest auc.\\nYou can use Amazon SageMaker automatic model tuning with built-in algorithms, custom algorithms,\\nand Amazon SageMaker pre-built containers for machine learning frameworks.\\nBefore you start using hyperparameter tuning, you should have a well-deﬁned machine learning\\nproblem, including the following:\\n•A dataset\\n•An understanding of the type of algorithm you need to train\\n•A clear understanding of how you measure success\\nYou should also prepare your dataset and algorithm so that they work in Amazon SageMaker and\\nsuccessfully run a training job at least once. For information about setting up and running a training job,\\nsee Get Started (p. 16).\\nTopics\\n•How Hyperparameter Tuning Works (p. 289)\\n•Deﬁne Metrics  (p. 290)\\n•Deﬁne Hyperparameter Ranges  (p. 292)\\n•Example: Hyperparameter Tuning Job (p. 293)\\n•Stop Training Jobs Early (p. 302)\\n•Run a Warm Start Hyperparameter Tuning Job (p. 303)\\n•Automatic Model Tuning Resource Limits (p. 307)\\n•Best Practices for Hyperparameter Tuning (p. 308)\\nHow Hyperparameter Tuning Works\\nRandom Search\\nIn a random search, hyperparameter tuning chooses a random combination of values from within\\nthe ranges that you specify for hyperparameters for each training job it launches. Because the choice\\nof hyperparameter values doesn\\'t depend on the results of previous training jobs, you can run the\\nmaximum number of concurrent training jobs without aﬀecting the performance of the search.\\nFor an example notebook that uses random search, see https://github.com/awslabs/\\namazon-sagemaker-examples/blob/master/hyperparameter_tuning/xgboost_random_log/\\nhpo_xgboost_random_log.ipynb.\\nBayesian Search\\nBayesian search treats hyperparameter tuning like a [regression]  problem. Given a set of input features\\n(the hyperparameters), hyperparameter tuning optimizes a model for the metric that you choose.\\nTo solve a regression problem, hyperparameter tuning makes guesses about which hyperparameter\\ncombinations are likely to get the best results, and runs training jobs to test these values. After testing\\nthe ﬁrst set of hyperparameter values, hyperparameter tuning uses regression to choose the next set of\\nhyperparameter values to test.\\nHyperparameter tuning uses an Amazon SageMaker implementation of Bayesian optimization.\\n289Amazon SageMaker Developer Guide\\nDeﬁne Metrics\\nWhen choosing the best hyperparameters for the next training job, hyperparameter tuning\\nconsiders everything that it knows about this problem so far. Sometimes it chooses a combination\\nof hyperparameter values close to the combination that resulted in the best previous training job to\\nincrementally improve performance. This allows hyperparameter tuning to exploit the best known\\nresults. Other times, it chooses a set of hyperparameter values far removed from those it has tried.\\nThis allows it to explore the range of hyperparameter values to try to ﬁnd new areas that are not well\\nunderstood. The explore/exploit trade-oﬀ is common in many machine learning problems.\\nFor more information about Bayesian optimization, see the following:\\nBasic Topics on Bayesian Optimization\\n•A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User\\nModeling and Hierarchical Reinforcement Learning\\n•Practical Bayesian Optimization of Machine Learning Algorithms\\n•Taking the Human Out of the Loop: A Review of Bayesian Optimization\\nSpeeding up Bayesian Optimization\\n•Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization\\n•Google Vizier: A Service for Black-Box Optimization\\n•Learning Curve Prediction with Bayesian Neural Networks\\n•Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of\\nlearning curves\\nAdvanced Modeling and Transfer Learning\\n•Scalable Hyperparameter Transfer Learning\\n•Bayesian Optimization with Tree-structured Dependencies\\n•Bayesian Optimization with Robust Bayesian Neural Networks\\n•Scalable Bayesian Optimization Using Deep Neural Networks\\n•Input Warping for Bayesian Optimization of Non-stationary Functions\\nNote\\nHyperparameter tuning might not improve your model. It is an advanced tool for building\\nmachine solutions, and, as such, should be considered part of the scientiﬁc development\\nprocess.\\nWhen you build complex machine learning systems like deep learning neural networks,\\nexploring all of the possible combinations is impractical. Hyperparameter tuning can accelerate\\nyour productivity by trying many variations of a model, focusing on the most promising\\ncombinations of hyperparameter values within the ranges that you specify. To get good results,\\nyou need to choose the right ranges to explore. Because the algorithm itself is stochastic, it’s\\npossible that the hyperparameter tuning model will fail to converge on the best answer, even if\\nthe best possible combination of values is within the ranges that you choose.\\nDeﬁne Metrics\\nNote\\nWhen you use one of the Amazon SageMaker built-in algorithms, you don\\'t need to deﬁne\\nmetrics. Built-in algorithms automatically send metrics to hyperparameter tuning. You do need\\nto choose one of the metrics that the built-in algorithm emits as the objective metric for the\\ntuning job. For a list of metrics that a built-in algorithm emits, see the Metrics  table for the\\nalgorithm in Use Amazon SageMaker Built-in Algorithms  (p. 56).\\n290Amazon SageMaker Developer Guide\\nDeﬁne Metrics\\nTo optimize hyperparameters for a machine learning model, a tuning job evaluates the training\\njobs it launches by using a metric that the training algorithm writes to logs. Amazon SageMaker\\nhyperparameter tuning parses your algorithm’s stdout  and stderr streams to ﬁnd algorithm metrics,\\nsuch as loss or validation-accuracy, that show how well the model is performing on the dataset\\nNote\\nThese are the same metrics that Amazon SageMaker sends to CloudWatch Logs. For more\\ninformation, see Log Amazon SageMaker Events with Amazon CloudWatch (p. 466).\\nIf you use your own algorithm for hyperparameter tuning, make sure that your algorithm emits at least\\none metric by writing evaluation data to stderr  or stdout .\\nNote\\nHyperparameter tuning sends an additional hyperparameter, _tuning_objective_metric\\nto the training algorithm. This hyperparameter speciﬁes the objective metric being used for the\\nhyperparameter tuning job, so that your algorithm can use that information during training.\\nYou can deﬁne up to 20 metrics for your tuning job to monitor. You choose one of those metrics\\nto be the objective metric, which hyperparameter tuning uses to evaluate the training jobs. The\\nhyperparameter tuning job returns the training job that returned the best value for the objective metric\\nas the best training job.\\nYou deﬁne metrics for a tuning job by specifying a name and a regular expression for each metric\\nthat your tuning job monitors. Design the regular expressions to capture the values of metrics that\\nyour algorithm emits. You pass these metrics to the CreateHyperParameterTuningJob (p. 638)\\noperation in the TrainingJobDefinition  parameter as the MetricDefinitions  ﬁeld of the\\nAlgorithmSpecification  ﬁeld.\\nThe following example deﬁnes 4 metrics:\\n=[\\n    {\\n        \"Name\": \"loss\",\\n        \"Regex\": \"Loss = (.*?);\",\\n    },\\n    {\\n        \"Name\": \"ganloss\",\\n        \"Regex\": \"GAN_loss=(.*?);\",\\n    },    \\n    {\\n        \"Name\": \"discloss\",\\n        \"Regex\": \"disc_train_loss=(.*?);\",\\n    },    \\n    {\\n        \"Name\": \"disc-combined\",\\n        \"Regex\": \"disc-combined=(.*?);\",\\n    },    \\n]\\nThe following is an example of the log that the algorithm writes:\\nGAN_loss=0.138318;  Scaled_reg=2.654134; disc:[-0.017371,0.102429] real 93.3% gen 0.0%\\n disc-combined=0.000000; disc_train_loss=1.374587;  Loss = 16.020744;  Iteration 0 took\\n 0.704s;  Elapsed=0s\\nUse the regular expression (regex) to match the algorithm\\'s log output and capture the numeric values\\nof metrics. For example, in the regex for the loss metric deﬁned above, the ﬁrst part of the regex ﬁnds\\nthe exact text \"Loss = \", and the expression (.*?); captures zero or more of any character until the ﬁrst\\nsemicolon character. In this expression, the parenthesis tell the regex to capture what is inside them, .\\nmeans any character, * means zero or more, and ? means capture only until the ﬁrst instance of the ;\\ncharacter.\\n291Amazon SageMaker Developer Guide\\nDeﬁne Hyperparameter Ranges\\nChoose one of the metrics that you deﬁne as the objective metric for the tuning job. If you are\\nusing the API, specify the value of the name key in the HyperParameterTuningJobObjective\\nﬁeld of the HyperParameterTuningJobConfig  parameter that you send to the\\nCreateHyperParameterTuningJob (p. 638) operation.\\nDeﬁne Hyperparameter Ranges\\nHyperparameter tuning ﬁnds the best hyperparameter values for your model by searching over ranges of\\nhyperparameters. You specify the hyperparameters and range of values over which to search by deﬁning\\nhyperparameter ranges for your tuning job. Choosing hyperparameters and ranges signiﬁcantly aﬀects\\nthe performance of your tuning job. For guidance on choosing hyperparameters and ranges, see Best\\nPractices for Hyperparameter Tuning (p. 308).\\nTo deﬁne hyperparameter ranges by using the low-level API, you specify the names of hyperparameters\\nand ranges of values in the ParameterRanges  ﬁeld of the HyperParameterTuningJobConfig\\nparameter that you pass to the CreateHyperParameterTuningJob (p. 638) operation. The\\nParameterRanges  ﬁeld has three subﬁelds, one for each of the categorical, integer, and continuous\\nhyperparameter ranges. You can deﬁne up to 20 hyperparameters to search over. Each value of a\\ncategorical hyperparameter range counts as a hyperparameter against the limit. Hyperparameter ranges\\nhave the following structure:\\n\"ParameterRanges\": {\\n      \"CategoricalParameterRanges\": [\\n        {\\n          \"Name\": \"tree_method\",\\n          \"Values\": [\"auto\", \"exact\", \"approx\", \"hist\"]\\n        }          \\n      ],\\n      \"ContinuousParameterRanges\": [\\n        {\\n          \"Name\": \"eta\",\\n          \"MaxValue\" : \"0.5\",\\n          \"MinValue\": \"0\",\\n          \"ScalingType\": \"Auto\"\\n        }\\n      ],\\n      \"IntegerParameterRanges\": [\\n        {\\n          \"Name\": \"max_depth\",\\n          \"MaxValue\": \"10\",\\n          \"MinValue\": \"1\",\\n          \"ScalingType\": \"Auto\"\\n        }\\n      ]\\n    }\\nHyperparameter Scaling\\nFor integer and continuous hyperparameter ranges, you can choose the scale you want hyperparameter\\ntuning to use to search the range of values by specifying a value for the ScalingType  ﬁeld of the\\nhyperparameter range. You can choose from the following scaling types:\\nAuto\\nAmazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.\\nLinear\\nHyperparameter tuning searches the values in the hyperparameter range by using a linear scale.\\nTypically, you choose this if the range of all values from the lowest to the highest is relatively small\\n292Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\n(within one order of magnitude), because uniformly searching values from the range will give you a\\nreasonable exploration of the entire range.\\nLogarithmic\\nHyperparemeter tuning searches the values in the hyperparameter range by using a logarithmic\\nscale.\\nLogarithmic scaling works only for ranges that have only values greater than 0.\\nChoose logarithmic scaling when you are searching a range that spans several orders of magnitude.\\nFor example, if you are tuning a Tune a Linear Learner Model (p. 162) model, and you specify a range\\nof values between .0001 and 1.0 for the learning_rate  hyperparameter, searching uniformly on\\na logarithmic scale gives you a better sample of the entire range than searching on a linear scale\\nwould, because searching on a linear scale would, on average, devote 90 percent of your training\\nbudget to only the values between .1 and 1.0, leaving only 10 percent of your training budget for\\nthe values between .0001 and .1.\\nReverseLogarithmic\\nHyperparemeter tuning searches the values in the hyperparameter range by using a reverse\\nlogarithmic scale. reverse logarithmic scaling is supported only for continuous hyperparameter\\nranges. It is not supported for integer hyperparameter ranges.\\nReverse logarithmic scaling works only for ranges that are entirely within the range 0<=x<1.0.\\nChoose reverse logarithmic scaling when you are searching a range that is highly sensitive to small\\nchanges that are very close to 1.\\nFor an example notebook that uses hyperparameter scaling, see https://github.com/awslabs/\\namazon-sagemaker-examples/blob/master/hyperparameter_tuning/xgboost_random_log/\\nhpo_xgboost_random_log.ipynb.\\nExample: Hyperparameter Tuning Job\\nThis example shows how to create a new notebook for conﬁguring and launching a hyperparameter\\ntuning job. The tuning job uses the XGBoost Algorithm (p. 255) to train a model to predict whether a\\ncustomer will enroll for a term deposit at a bank after being contacted by phone.\\nYou use the low-level AWS SDK for Python (Boto) to conﬁgure and launch the hyperparameter tuning\\njob, and the AWS Management Console to monitor the status of hyperparameter training jobs. You can\\nalso use the Amazon SageMaker high-level Amazon SageMaker Python SDK to conﬁgure, run, monitor,\\nand analyze hyperparameter tuning jobs. For more information, see https://github.com/aws/sagemaker-\\npython-sdk.\\nPrerequisites\\nTo run the code in this example, you need\\n•An AWS account and an administrator user (p. 14)\\n•An Amazon S3 bucket for storing your training dataset and the model artifacts created during\\ntraining  (p. 17)\\n•A running Amazon SageMaker notebook instance (p. 17)\\nTopics\\n•Create a Notebook (p. 294)\\n293Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\n•Get the Amazon Sagemaker Boto 3 Client (p. 294)\\n•Get the Amazon SageMaker Execution Role (p. 295)\\n•Specify a Bucket and Data Output Location (p. 295)\\n•Download, Prepare, and Upload Training Data (p. 295)\\n•Conﬁgure and Launch a Hyperparameter Tuning Job (p. 296)\\n•Monitor the Progress of a Hyperparameter Tuning Job (p. 299)\\n•Clean up  (p. 301)\\nCreate a Notebook\\nCreate a Jupyter notebook that contains a preinstalled environment with the default Anaconda\\ninstallation and Python3.\\nTo create a Jupyter notebook\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/\\n.\\n2. Open a running notebook instance, by choosing Open  next to its name. The Jupyter notebook server\\npage appears:\\n3. To create a notebook, choose Files, New , and conda_python3. .\\n4. Name the notebook.\\nNext Step\\nGet the Amazon Sagemaker Boto 3 Client (p. 294)\\nGet the Amazon Sagemaker Boto 3 Client\\nImport libraries and get a Boto3 client, which you use to call the hyperparameter tuning APIs.\\nIn the new Jupyter notebook, type the following code:\\nimport sagemaker\\nimport boto3\\nfrom sagemaker.predictor import csv_serializer    # Converts strings for HTTP POST requests\\n on inference\\nimport numpy as np                                # For performing matrix operations and\\n numerical processing\\nimport pandas as pd                               # For manipulating tabular data\\nfrom time import gmtime, strftime                 \\nimport os \\n \\n294Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\nregion = boto3.Session().region_name    \\nsmclient = boto3.Session().client(\\'sagemaker\\')\\nNext Step\\nGet the Amazon SageMaker Execution Role (p. 295)\\nGet the Amazon SageMaker Execution Role\\nGet the execution role for the notebook instance. This is the IAM role that you created when you created\\nyour notebook instance. You pass the role to the tuning job.\\nfrom sagemaker import get_execution_role\\nrole = get_execution_role()\\nprint(role)\\nNext Step\\nSpecify a Bucket and Data Output Location (p. 295)\\nSpecify a Bucket and Data Output Location\\nSpecify the name of the Amazon S3 bucket where you want to store the output of the training jobs that\\nthe tuning job launches. The name of the bucket must contain sagemaker , and be globally unique. The\\nbucket must be in the same AWS Region as the notebook instance that you use for this example. You can\\nuse the bucket that you created when you set up Amazon SageMaker, or you can create a new bucket.\\nFor information, see Step 1: Create an Amazon S3 Bucket (p. 17).\\nNote\\nThe name of the bucket doesn\\'t need to contain sagemaker  if the role that you use to\\nrun the hyperparameter tuning job has a policy that gives the SageMaker service principle\\nS3FullAccess  permission.\\nprefix is the path within the bucket where Amazon SageMaker stores the output from training jobs.\\nbucket = \\'sagemaker-MyBucket\\'                               # Replace with the name of your\\n S3 bucket\\nprefix = \\'sagemaker/DEMO-automatic-model-tuning-xgboost-dm\\'\\nNext Step\\nDownload, Prepare, and Upload Training Data (p. 295)\\nDownload, Prepare, and Upload Training Data\\nFor this example, you use a training dataset of information about bank customers that includes\\nthe customer\\'s job, marital status, and how they were contacted during the bank\\'s direct marketing\\ncampaign. To use a dataset for a hyperparameter tuning job, you download it, transform the data, and\\nthen upload it to an Amazon S3 bucket.\\nFor more information about the dataset and the data transformation that the example performs, see the\\nhpo_xgboost_direct_marketing_sagemaker_APIs notebook in the Hyperparameter Tuning section of the\\nSageMaker Examples tab in your notebook instance.\\n295Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\nDownload and Explore the Training Dataset\\nTo download and explore the dataset, run the following code in your notebook:\\n!wget -N https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-\\nadditional.zip\\n!unzip -o bank-additional.zip\\ndata = pd.read_csv(\\'./bank-additional/bank-additional-full.csv\\', sep=\\';\\')\\npd.set_option(\\'display.max_columns\\', 500)     # Make sure we can see all of the columns\\npd.set_option(\\'display.max_rows\\', 5)         # Keep the output on one page\\ndata\\nPrepare and Upload Data\\nBefore creating the hyperparameter tuning job, prepare the data and upload it to an S3 bucket where\\nthe hyperparameter tuning job can access it.\\nRun the following code in your notebook:\\ndata[\\'no_previous_contact\\'] = np.where(data[\\'pdays\\'] == 999, 1, 0)                         \\n        # Indicator variable to capture when pdays takes a value of 999\\ndata[\\'not_working\\'] = np.where(np.in1d(data[\\'job\\'], [\\'student\\', \\'retired\\', \\'unemployed\\']),\\n 1, 0)   # Indicator for individuals not actively employed\\nmodel_data = pd.get_dummies(data)                                                          \\n        # Convert categorical variables to sets of indicators\\nmodel_data\\nmodel_data = model_data.drop([\\'duration\\', \\'emp.var.rate\\', \\'cons.price.idx\\',\\n \\'cons.conf.idx\\', \\'euribor3m\\', \\'nr.employed\\'], axis=1)\\ntrain_data, validation_data, test_data = np.split(model_data.sample(frac=1,\\n random_state=1729), [int(0.7 * len(model_data)), int(0.9*len(model_data))])  \\npd.concat([train_data[\\'y_yes\\'], train_data.drop([\\'y_no\\', \\'y_yes\\'], axis=1)],\\n axis=1).to_csv(\\'train.csv\\', index=False, header=False)\\npd.concat([validation_data[\\'y_yes\\'], validation_data.drop([\\'y_no\\', \\'y_yes\\'], axis=1)],\\n axis=1).to_csv(\\'validation.csv\\', index=False, header=False)\\npd.concat([test_data[\\'y_yes\\'], test_data.drop([\\'y_no\\', \\'y_yes\\'], axis=1)],\\n axis=1).to_csv(\\'test.csv\\', index=False, header=False)\\nboto3.Session().resource(\\'s3\\').Bucket(bucket).Object(os.path.join(prefix, \\'train/\\ntrain.csv\\')).upload_file(\\'train.csv\\')\\nboto3.Session().resource(\\'s3\\').Bucket(bucket).Object(os.path.join(prefix, \\'validation/\\nvalidation.csv\\')).upload_file(\\'validation.csv\\')\\nNext Step\\nConﬁgure and Launch a Hyperparameter Tuning Job (p. 296)\\nConﬁgure and Launch a Hyperparameter Tuning Job\\nTo conﬁgure and launch a hyperparameter tuning job, complete the following steps.\\nTopics\\n•Specify the Hyperparameter Tuning Job Settings (p. 297)\\n•Conﬁgure the Training Jobs (p. 298)\\n•Name and Launch the Hyperparameter Tuning Job (p. 299)\\n•Next Step (p. 299)\\n296Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\nSpecify the Hyperparameter Tuning Job Settings\\nTo specify settings for the hyperparameter tuning job, you deﬁne a JSON object. You\\npass the object as the value of the HyperParameterTuningJobConfig  parameter to\\nCreateHyperParameterTuningJob (p. 638) when you create the tuning job.\\nIn this JSON object, you specify:\\n•The ranges of hyperparameters that you want to tune. For more information, see Deﬁne\\nHyperparameter Ranges  (p. 292)\\n•The limits of the resource that the hyperparameter tuning job can consume.\\n•The objective metric for the hyperparameter tuning job. An objective metric  is the metric that the\\nhyperparameter tuning job uses to evaluate the training job that it launches.\\nNote\\nTo use your own algorithm for hyperparameter tuning, you need to deﬁne metrics for your\\nalgorithm. For information,see Deﬁne Metrics  (p. 290).\\nThe hyperparameter tuning job deﬁnes ranges for the eta, alpha , min_child_weight , and\\nmax_depth  hyperparameters of the XGBoost Algorithm (p. 255) built-in algorithm. The objective metric\\nfor the hyperparameter tuning job maximizes the validation:auc  metric that the algorithm sends to\\nCloudWatch Logs.\\ntuning_job_config = {\\n    \"ParameterRanges\": {\\n      \"CategoricalParameterRanges\": [],\\n      \"ContinuousParameterRanges\": [\\n        {\\n          \"MaxValue\": \"1\",\\n          \"MinValue\": \"0\",\\n          \"Name\": \"eta\"\\n        },\\n        {\\n          \"MaxValue\": \"2\",\\n          \"MinValue\": \"0\",\\n          \"Name\": \"alpha\"\\n        },\\n        {\\n          \"MaxValue\": \"10\",\\n          \"MinValue\": \"1\",\\n          \"Name\": \"min_child_weight\"\\n        }\\n      ],\\n      \"IntegerParameterRanges\": [\\n        {\\n          \"MaxValue\": \"10\",\\n          \"MinValue\": \"1\",\\n          \"Name\": \"max_depth\"\\n        }\\n      ]\\n    },\\n    \"ResourceLimits\": {\\n      \"MaxNumberOfTrainingJobs\": 20,\\n      \"MaxParallelTrainingJobs\": 3\\n    },\\n    \"Strategy\": \"Bayesian\",\\n    \"HyperParameterTuningJobObjective\": {\\n      \"MetricName\": \"validation:auc\",\\n      \"Type\": \"Maximize\"\\n    }\\n  }\\n297Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\nConﬁgure the Training Jobs\\nTo conﬁgure the training jobs that the tuning job launches, deﬁne a JSON object that you pass as the\\nvalue of the TrainingJobDefinition  parameter of the CreateHyperParameterTuningJob (p. 638)\\ncall.\\nIn this JSON object, you specify:\\n•Optional—Metrics that the training jobs emit.\\nNote\\nDeﬁne metrics only when you use a custom training algorithm. Because this example uses\\na built-in algorithm, you don\\'t specify metrics. For information about deﬁning metrics, see\\nDeﬁne Metrics  (p. 290).\\n•The container image that speciﬁes the training algorithm.\\n•The input conﬁguration for your training and test data.\\n•The storage location for the algorithm\\'s output. Specify the S3 bucket where you want to store the\\noutput of the training jobs.\\n•The values of algorithm hyperparameters that are not tuned in the tuning job.\\n•The type of instance to use for the training jobs.\\n•The stopping condition for the training jobs. This is the maximum duration for each training job.\\nIn this example, we set static values for the eval_metric , num_round , objective , rate_drop , and\\ntweedie_variance_power  parameters of the XGBoost Algorithm (p. 255) built-in algorithm.\\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\\ntraining_image = get_image_uri(boto3.Session().region_name, \\'xgboost\\')\\ns3_input_train = \\'s3://{}/{}/train\\'.format(bucket, prefix)\\ns3_input_validation =\\'s3://{}/{}/validation/\\'.format(bucket, prefix)\\n     \\ntraining_job_definition = {\\n    \"AlgorithmSpecification\": {\\n      \"TrainingImage\": training_image,\\n      \"TrainingInputMode\": \"File\"\\n    },\\n    \"InputDataConfig\": [\\n      {\\n        \"ChannelName\": \"train\",\\n        \"CompressionType\": \"None\",\\n        \"ContentType\": \"csv\",\\n        \"DataSource\": {\\n          \"S3DataSource\": {\\n            \"S3DataDistributionType\": \"FullyReplicated\",\\n            \"S3DataType\": \"S3Prefix\",\\n            \"S3Uri\": s3_input_train\\n          }\\n        }\\n      },\\n      {\\n        \"ChannelName\": \"validation\",\\n        \"CompressionType\": \"None\",\\n        \"ContentType\": \"csv\",\\n        \"DataSource\": {\\n          \"S3DataSource\": {\\n            \"S3DataDistributionType\": \"FullyReplicated\",\\n            \"S3DataType\": \"S3Prefix\",\\n            \"S3Uri\": s3_input_validation\\n          }\\n298Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\n        }\\n      }\\n    ],\\n    \"OutputDataConfig\": {\\n      \"S3OutputPath\": \"s3://{}/{}/output\".format(bucket,prefix)\\n    },\\n    \"ResourceConfig\": {\\n      \"InstanceCount\": 2,\\n      \"InstanceType\": \"ml.c4.2xlarge\",\\n      \"VolumeSizeInGB\": 10\\n    },\\n    \"RoleArn\": role,\\n    \"StaticHyperParameters\": {\\n      \"eval_metric\": \"auc\",\\n      \"num_round\": \"100\",\\n      \"objective\": \"binary:logistic\",\\n      \"rate_drop\": \"0.3\",\\n      \"tweedie_variance_power\": \"1.4\"\\n    },\\n    \"StoppingCondition\": {\\n      \"MaxRuntimeInSeconds\": 43200\\n    }\\n}\\nName and Launch the Hyperparameter Tuning Job\\nNow you can provide a name for the hyperparameter tuning job and then launch it by\\ncalling the CreateHyperParameterTuningJob (p. 638) API. Pass tuning_job_config , and\\ntraining_job_definition  that you created in previous steps as the values of the parameters.\\ntuning_job_name = \"MyTuningJob\"\\nsmclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name,\\n                                           HyperParameterTuningJobConfig =\\n tuning_job_config,\\n                                           TrainingJobDefinition = training_job_definition)\\nNext Step\\nMonitor the Progress of a Hyperparameter Tuning Job (p. 299)\\nMonitor the Progress of a Hyperparameter Tuning Job\\nTo monitor the progress of a hyperparameter tuning job and the training jobs that it launches, use the\\nAmazon SageMaker console.\\nTopics\\n•View the Status of the Hyperparameter Tuning Job (p. 299)\\n•View the Status of the Training Jobs (p. 300)\\n•View the Best Training Job (p. 301)\\nView the Status of the Hyperparameter Tuning Job\\nTo view the status of the hyperparameter tuning job\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/\\n.\\n2. Choose Hyperparameter tuning jobs .\\n299Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\n3. In the list of hyperparameter tuning jobs, check the status of the hyperparameter tuning job you\\nlaunched. A tuning job can be:\\n•Completed —The hyperparameter tuning job successfully completed.\\n•InProgress —The hyperparameter tuning job is in progress. One or more training jobs are still\\nrunning.\\n•Failed—The hyperparameter tuning job failed.\\n•Stopped—The hyperparameter tuning job was manually stopped before it completed. All training\\njobs that the hyperparameter tuning job launched are stopped.\\n•Stopping —The hyperparameter tuning job is in the process of stopping.\\nView the Status of the Training Jobs\\nTo view the status of the training jobs that the hyperparameter tuning job launched\\n1. In the list of hyperparameter tuning jobs, choose the job that you launched.\\n2. Choose Training jobs.\\n3. View the status of each training job. To see more details about a job, choose it in the list of training\\njobs. To view a summary of the status of all of the training jobs that the hyperparameter tuning job\\nlaunched, see Training job status counter.\\n300Amazon SageMaker Developer Guide\\nExample: Hyperparameter Tuning Job\\nA training job can be:\\n•Completed —The training job successfully completed.\\n•InProgress —The training job is in progress.\\n•Stopped—The training job was manually stopped before it completed.\\n•Failed (Retriable) —The training job failed, but can be retried. A failed training job can be\\nretried only if it failed because an internal service error occurred.\\n•Failed (Non-retriable) —The training job failed and can\\'t be retried. A failed training job\\ncan\\'t be retried when a client error occurs.\\nView the Best Training Job\\nA hyperparameter tuning job uses the objective metric that each training job returns to evaluate training\\njobs. While the hyperparameter tuning job is in progress, the best training job is the one that has\\nreturned the best objective metric so far. After the hyperparameter tuning job is complete, the best\\ntraining job is the one that returned the best objective metric.\\nTo view the best training job, choose Best training job .\\nTo deploy the best training job as a model that you can host at an Amazon SageMaker endpoint, choose\\nCreate model .\\nNext Step\\nClean up  (p. 301)\\nClean up\\nTo avoid incurring unnecessary charges, when you are done with the example, use the AWS Management\\nConsole to delete the resources that you created for it.\\nNote\\nIf you plan to explore other examples, you might want to keep some of these resources, such as\\nyour notebook instance, S3 bucket, and IAM role.\\n301Amazon SageMaker Developer Guide\\nStop Training Jobs Early\\n1.Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/ and delete the\\nnotebook instance. Stop the instance before deleting it.\\n2.Open the Amazon S3 console at https://console.aws.amazon.com/s3/ and delete the bucket that you\\ncreated to store model artifacts and the training dataset.\\n3.Open the IAM console at https://console.aws.amazon.com/iam/ and delete the IAM role. If you\\ncreated permission policies, you can delete them, too.\\n4.Open the Amazon CloudWatch console at https://console.aws.amazon.com/cloudwatch/ and delete\\nall of the log groups that have names starting with /aws/sagemaker/ .\\nStop Training Jobs Early\\nStop the training jobs that a hyperparameter tuning job launches early when they are not improving\\nsigniﬁcantly as measured by the objective metric. Stopping training jobs early can help reduce compute\\ntime and helps you avoid overﬁtting your model. To conﬁgure a hyperparameter tuning job to stop\\ntraining jobs early, do one of the following:\\n•If you are using the AWS SDK for Python (Boto 3), set the TrainingJobEarlyStoppingType  ﬁeld\\nof the HyperParameterTuningJobConﬁg (p. 922) object that you use to conﬁgure the tuning job to\\nAUTO .\\n•If you are using the Amazon SageMaker Python SDK, set the early_stopping_type  parameter of\\nthe HyperParameterTuner object to Auto .\\n•In the Amazon SageMaker console, in the Create hyperparameter tuning job workﬂow, under Early\\nstopping , choose Auto .\\nFor a sample notebook that demonstrates how to use early stopping, see https://\\ngithub.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/\\nimage_classiﬁcation_early_stopping/hpo_image_classiﬁcation_early_stopping.ipynb or open the\\nhpo_image_classification_early_stopping.ipynb  notebook in the Hyperparameter Tuning\\nsection of the SageMaker Examples in a notebook instance. For information about using sample\\nnotebooks in a notebook instance, see Use Example Notebooks  (p. 42).\\nHow Early Stopping Works\\nWhen you enable early stopping for a hyperparameter tuning job, Amazon SageMaker evaluates each\\ntraining job the hyperparameter tuning job launches as follows:\\n•After each epoch of training, get the value of the objective metric.\\n•Compute the running average of the objective metric for all previous training jobs up to the same\\nepoch, and then compute the median of all of the running averages.\\n•If the value of the objective metric for the current training job is worse (higher when minimizing\\nor lower when maximizing the objective metric) than the median value of running averages of the\\nobjective metric for previous training jobs up to the same epoch, Amazon SageMaker stops the current\\ntraining job.\\nAlgorithms That Support Early Stopping\\nTo support early stopping, an algorithm must emit objective metrics for each epoch. The following built-\\nin Amazon SageMaker algorithms support early stopping:\\n•Linear Learner Algorithm  (p. 162)—Supported only if you use objective_loss  as the objective\\nmetric.\\n•XGBoost Algorithm (p. 255)\\n302Amazon SageMaker Developer Guide\\nRun a Warm Start Hyperparameter Tuning Job\\n•Image Classiﬁcation Algorithm  (p. 108)\\n•Object Detection Algorithm (p. 199)\\n•Sequence-to-Sequence Algorithm (p. 242)\\n•IP Insights Algorithm  (p. 131)\\nNote\\nThis list of built-in algorithms that support early stopping is current as of December 13, 2018.\\nOther built-in algorithms might support early stopping in the future. If an algorithm emits a\\nmetric that can be used as an objective metric for a hyperparameter tuning job (preferably a\\nvalidation metric), then it supports early stopping.\\nTo use early stopping with your own algorithm, you must write your algorithms such that it emits the\\nvalue of the objective metric after each epoch. The following list shows how you can do that in diﬀerent\\nframeworks:\\nTensorFlow\\nUse the tf.contrib.learn.monitors.ValidationMonitor  class. For information, see https://\\nwww.tensorﬂow.org/api_docs/python/tf/contrib/learn/monitors.\\nMXNet\\nUse the mxnet.callback.LogValidationMetricsCallback . For information, see https://\\nmxnet.apache.org/api/python/callback/callback.html.\\nChainer\\nExtend chainer by using the extensions.Evaluator  class. For information, see https://\\ndocs.chainer.org/en/v1.24.0/reference/extensions.html#evaluator.\\nPyTorch and Spark\\nThere is no high-level support. You must explicitly write your training code so that it computes\\nobjective metrics and writes them to logs after each epoch.\\nRun a Warm Start Hyperparameter Tuning Job\\nUse warm start to start a hyperparameter tuning job using one or more previous tuning jobs as a starting\\npoint. The results of previous tuning jobs are used to inform which combinations of hyperparameters\\nto search over in the new tuning job. Hyperparameter tuning uses either Bayesian or random search to\\nchoose combinations of hyperparameter values from ranges that you specify. For more information, see\\nHow Hyperparameter Tuning Works (p. 289). Using information from previous hyperparameter tuning\\njobs can help increase the performance of the new hyperparameter tuning job by making the search for\\nthe best combination of hyperparameters more eﬃcient.\\nNote\\nWarm start tuning jobs typically take longer to start than standard hyperparameter tuning\\njobs, because the results from the parent jobs have to be loaded before the job can start. The\\nincreased time depends on the total number of training jobs launched by the parent jobs.\\nReasons you might want to consider warm start include:\\n•You want to gradually increase the number of training jobs over several tuning jobs based on the\\nresults you see after each iteration.\\n•You get new data, and want to tune a model using the new data.\\n•You want to change the ranges of hyperparameters that you used in a previous tuning job, change\\nstatic hyperparameters to tunable, or change tunable hyperparameters to static values.\\n•You stopped a previous hyperparameter job early or it stopped unexpectedly.\\n303Amazon SageMaker Developer Guide\\nRun a Warm Start Hyperparameter Tuning Job\\nTopics\\n•Types of Warm Start Tuning Jobs (p. 304)\\n•Warm Start Tuning Restrictions (p. 304)\\n•Warm Start Tuning Sample Notebook (p. 305)\\n•Create a Warm Start Tuning Job (p. 305)\\nTypes of Warm Start Tuning Jobs\\nThere are two diﬀerent types of warm start tuning jobs:\\nIDENTICAL_DATA_AND_ALGORITHM\\nThe new hyperparameter tuning job uses the same input data and training image as the parent\\ntuning jobs. You can change the hyperparameter ranges to search and the maximum number of\\ntraining jobs that the hyperparameter tuning job launches. You can also change hyperparameters\\nfrom tunable to static, and from static to tunable, but the total number of static plus tunable\\nhyperparameters must remain the same as it is in all parent jobs. You cannot use a new version of\\nthe training algorithm, unless the changes in the new version do not aﬀect the algorithm itself. For\\nexample, changes that improve logging or adding support for a diﬀerent data format are allowed.\\nUse identical data and algorithm when you use the same training data as you used in a previous\\nhyperparameter tuning job, but you want to increase the total number of training jobs or change\\nranges or values of hyperparameters.\\nWhen you run an warm start tuning job of type IDENTICAL_DATA_AND_ALGORITHM , there\\nis an additional ﬁeld in the response to DescribeHyperParameterTuningJob (p. 715) named\\nOverallBestTrainingJob . The value of this ﬁeld is the TrainingJobSummary (p. 1019 ) for the\\ntraining job with the best objective metric value of all training jobs launched by this tuning job and\\nall parent jobs speciﬁed for the warm start tuning job.\\nTRANSFER_LEARNING\\nThe new hyperparameter tuning job can include input data, hyperparameter ranges, maximum\\nnumber of concurrent training jobs, and maximum number of training jobs that are diﬀerent than\\nthose of its parent hyperparameter tuning jobs. You can also change hyperparameters from tunable\\nto static, and from static to tunable, but the total number of static plus tunable hyperparameters\\nmust remain the same as it is in all parent jobs. The training algorithm image can also be a diﬀerent\\nversion from the version used in the parent hyperparameter tuning job. When you use transfer\\nlearning, changes in the dataset or the algorithm that signiﬁcantly aﬀect the value of the objective\\nmetric might reduce the usefulness of using warm start tuning.\\nWarm Start Tuning Restrictions\\nThe following restrictions apply to all warm start tuning jobs:\\n•A tuning job can have a maximum of 5 parent jobs, and all parent jobs must be in a terminal state\\n(Completed , Stopped , or Failed) before you start the new tuning job.\\n•The objective metric used in the new tuning job must be the same as the objective metric used in the\\nparent jobs.\\n•The total number of static plus tunable hyperparameters must remain the same between parent\\njobs and the new tuning job. Because of this, if you think you might want to use a hyperparameter\\nas tunable in a future warm start tuning job, you should add it as a static hyperparameter when you\\ncreate a tuning job.\\n•The type of each hyperparameter (continuous, integer, categorical) must not change between parent\\njobs and the new tuning job.\\n304Amazon SageMaker Developer Guide\\nRun a Warm Start Hyperparameter Tuning Job\\n•The number of total changes from tunable hyperparameters in the parent jobs to static\\nhyperparameters in the new tuning job, plus the number of changes in the values of static\\nhyperparameters cannot be more than 10. Each value in a categorical hyperparameter counts against\\nthis limit. For example, if the parent job has a tunable categorical hyperparameter with the possible\\nvalues red and blue, you change that hyperparameter to static in the new tuning job, that counts as\\n2 changes against the allowed total of 10. If the same hyperparameter had a static value of red in the\\nparent job, and you change the static value to blue in the new tuning job, it also counts as 2 changes.\\n•Warm start tuning is not recursive. For example, if you create MyTuningJob3  as a warm start tuning\\njob with MyTuningJob2  as a parent job, and MyTuningJob2  is itself an warm start tuning job with\\na parent job MyTuningJob1 , the information that was learned when running MyTuningJob1  is not\\nused for MyTuningJob3 . If you want to use the information from MyTuningJob1 , you must explicitly\\nadd it as a parent for MyTuningJob3 .\\n•The training jobs launched by every parent job in a warm start tuning job count against the 500\\nmaximum training jobs for a tuning job.\\n•Hyperparameter tuning jobs created before October 1, 2018 cannot be used as parent jobs for warm\\nstart tuning jobs.\\nWarm Start Tuning Sample Notebook\\nFor a sample notebook that shows how to use warm start tuning, see https://github.com/awslabs/\\namazon-sagemaker-examples/blob/master/hyperparameter_tuning/image_classiﬁcation_warmstart/\\nhpo_image_classiﬁcation_warmstart.ipynb. For instructions how to create and access Jupyter\\nnotebook instances that you can use to run the example in Amazon SageMaker, see Use\\nExample Notebooks  (p. 42). Once you have created a notebook instance and opened it, select\\nthe SageMaker Examples tab to see a list of all the Amazon SageMaker samples. The warm\\nstart tuning example notebook is located in the Hyperparameter tuning  section, and is named\\nhpo_image_classification_warmstart.ipynb . To open a notebook, click on its Use tab and select\\nCreate copy.\\nCreate a Warm Start Tuning Job\\nYou can use either the low-level AWS SDK for Python (Boto 3) or the high-level Amazon SageMaker\\nPython SDK to create a warm start tuning job.\\nTopics\\n•Create a Warm Start Tuning Job ( Low-level Amazon SageMaker API for Python (Boto 3)) (p. 305)\\n•Create a Warm Start Tuning Job (Amazon SageMaker Python SDK) (p. 306)\\nCreate a Warm Start Tuning Job ( Low-level Amazon SageMaker API for Python\\n(Boto 3))\\nTo use warm start tuning, you specify the values of a\\nHyperParameterTuningJobWarmStartConﬁg (p. 927) object, and pass that as the WarmStartConfig\\nﬁeld in a call to CreateHyperParameterTuningJob (p. 638).\\nThe following code shows how to create a HyperParameterTuningJobWarmStartConﬁg (p. 927) object\\nand pass it to CreateHyperParameterTuningJob (p. 638) job by using the low-level Amazon SageMaker\\nAPI for Python (Boto 3).\\nCreate the HyperParameterTuningJobWarmStartConfig  object:\\nwarm_start_config = {\\n          \"ParentHyperParameterTuningJobs\" : [ \\n          {\"HyperParameterTuningJobName\" : \\'MyParentTuningJob\\'}\\n305Amazon SageMaker Developer Guide\\nRun a Warm Start Hyperparameter Tuning Job\\n          ],\\n          \"WarmStartType\" : \"IdenticalDataAndAlgorithm\"    \\n}\\nCreate the warm start tuning job:\\nsmclient = boto3.Session().client(\\'sagemaker\\')\\nsmclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName =\\n \\'MyWarmStartTuningJob\\',\\n   HyperParameterTuningJobConfig = tuning_job_config, # See notebook for tuning\\n configuration\\n   TrainingJobDefinition = training_job_definition, # See notebook for job definition\\n   WarmStartConfig = warm_start_config)\\nCreate a Warm Start Tuning Job (Amazon SageMaker Python SDK)\\nTo use the Amazon SageMaker Python SDK to run a warm start tuning job, you:\\n•Specify the parent jobs and the warm start type by using a WarmStartConfig  object.\\n•Pass the WarmStartConfig  object as the value of the warm_start_config  argument of a\\nHyperparameterTuner object.\\n•Call the fit method of the HyperparameterTuner  object.\\nFor more information about using the Amazon SageMaker Python SDK for hyperparameter tuning, see\\nhttps://github.com/aws/sagemaker-python-sdk#sagemaker-automatic-model-tuning.\\nThis example uses an estimator that uses the Image Classiﬁcation Algorithm  (p. 108) algorithm for\\ntraining. The following code sets the hyperparameter ranges that the warm start tuning job searches\\nwithin to ﬁnd the best combination of values. For information about setting hyperparameter ranges, see\\nDeﬁne Hyperparameter Ranges  (p. 292).\\nhyperparameter_ranges = {\\'learning_rate\\': ContinuousParameter(0.0, 0.1),\\n                         \\'momentum\\': ContinuousParameter(0.0, 0.99)}\\nThe following code conﬁgures the warm start tuning job by creating a WarmStartConfig  object.\\nfrom sagemaker.tuner import WarmStartConfig,\\n          WarmStartTypes\\nparent_tuning_job_name = \"MyParentTuningJob\"\\nwarm_start_config = WarmStartConfig(type=WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM,\\n parents={parent_tuning_job_name})\\nNow set the values for static hyperparameters, which are hyperparameters that keep the same\\nvalue for every training job that the warm start tuning job launches. In the following code,\\nimageclassification  is an estimator that was created previously.\\nimageclassification.set_hyperparameters(num_layers=18,\\n                                        image_shape=\\'3,224,224\\',\\n                                        num_classes=257,\\n                                        num_training_samples=15420,\\n                                        mini_batch_size=128,\\n                                        epochs=30,\\n                                        optimizer=\\'sgd\\',\\n                                        top_k=\\'2\\',\\n                                        precision_dtype=\\'float32\\',\\n                                        augmentation_type=\\'crop\\')\\n306Amazon SageMaker Developer Guide\\nAutomatic Model Tuning Resource Limits\\nNow create the HyperparameterTuner  object and pass the WarmStartConfig  object that you\\npreviously created as the warm_start_config  argument.\\ntuner_warm_start = HyperparameterTuner(imageclassification,\\n                            \\'validation:accuracy\\',\\n                            hyperparameter_ranges,\\n                            objective_type=\\'Maximize\\',\\n                            max_jobs=10,\\n                            max_parallel_jobs=2,\\n                            base_tuning_job_name=\\'warmstart\\',\\n                            warm_start_config=warm_start_config)\\nFinally, call the fit method of the HyperparameterTuner  object to launch the warm start tuning job.\\ntuner_warm_start.fit(\\n        {\\'train\\': s3_input_train, \\'validation\\': s3_input_validation},\\n        include_cls_metadata=False)\\nAutomatic Model Tuning Resource Limits\\nAmazon SageMaker sets default limits for the following resources:\\n•Number of concurrent hyperparameter tuning jobs - 100\\n•Number of hyperparameters that can be searched - 20\\nNote\\nEvery possible value in a categorical hyperparameter counts against this limit.\\n•Number of metrics deﬁned per hyperparameter tuning job - 20\\n•Number of concurrent training jobs per hyperparameter tuning job - 10\\n•Number of training jobs per hyperparameter tuning job - 500\\n•Maximum run time for a hyperparameter tuning job - 30 days\\nWhen you plan hyperparameter tuning jobs, you also have to take the limits on training resources into\\naccount. For information about the default resource limits for Amazon SageMaker training jobs, see\\nAmazon SageMaker Limits. Every concurrent training instance that all of your hyperparameter tuning\\njobs run on count against the total number of training instances allowed. For example, suppose you run\\n10 concurrent hyperparameter tuning jobs. Each of those hyperparameter tuning jobs runs 100 total\\ntraining jobs, and runs 20 concurrent training jobs. Each of those traning jobs runs on one ml.m4.xlarge\\ninstance. The following limits apply:\\n•Number of concurrent hyperparameter tuning jobs - You don\\'t need to increase the limit, because 10\\ntuning jobs is below the limit of 100.\\n•Number of training jobs per hyperparameter tuning job - You don\\'t need to increase the limit, because\\n100 training jobs is below the limit of 500.\\n•Number of concurrent training jobs per hyperparameter tuning job - You need to request a limit\\nincrease to 20, because the default limit is 10.\\n•Amazon SageMaker training ml.m4.xlarge  instances - You need to request limit increase to 200,\\nbecause you have 10 hyperparameter tuning jobs, with each of them running 20 concurrent training\\njobs. The default limit is 20 instances.\\n•Amazon SageMaker training total instance count - You need to request a limit increase to 200, because\\nyou have 10 hyperparameter tuning jobs, with each of them running 20 concurrent training jobs. The\\ndefault limit is 20 instances.\\nFor information about requesting limit increases for AWS resources, see AWS Service Limits.\\n307Amazon SageMaker Developer Guide\\nBest Practices for Hyperparameter Tuning\\nBest Practices for Hyperparameter Tuning\\nHyperparameter optimization is not a fully-automated process. To improve optimization, use the\\nfollowing guidelines when you create hyperparameters.\\nTopics\\n•Choosing the Number of Hyperparameters  (p. 308)\\n•Choosing Hyperparameter Ranges  (p. 308)\\n•Using Logarithmic Scales for Hyperparameters  (p. 308)\\n•Choosing the Best Number of Concurrent Training Jobs (p. 308)\\n•Running Training Jobs on Multiple Instances (p. 308)\\nChoosing the Number of Hyperparameters\\nThe diﬃculty of a hyperparameter tuning job depends primarily on the number of hyperparameters\\nthat Amazon SageMaker has to search. Although you can simultaneously use up to 20 variables in a\\nhyperparameter tuning job, limiting your search to a much smaller number is likely to give better results.\\nChoosing Hyperparameter Ranges\\nThe range of values for hyperparameters that you choose to search can signiﬁcantly aﬀect the success of\\nhyperparameter optimization. Although you might want to specify a very large range that covers every\\npossible value for a hyperparameter, you will get better results by limiting your search to a small range\\nof values. If you get the best metric values within a part of a range, consider limiting the range to that\\npart.\\nUsing Logarithmic Scales for Hyperparameters\\nDuring hyperparameter tuning, Amazon SageMaker attempts to ﬁgure out if your hyperparameters\\nare log-scaled or linear-scaled. Initially, it assumes that hyperparameters are linear-scaled. If they\\nshould be log-scaled, it might take some time for Amazon SageMaker to discover that. If you know\\nthat a hyperparameter should be log-scaled and can convert it yourself, doing so could improve\\nhyperparameter optimization.\\nChoosing the Best Number of Concurrent Training Jobs\\nRunning more hyperparameter tuning jobs concurrently gets more work done quickly, but a tuning job\\nimproves only through successive rounds of experiments. Typically, running one training job at a time\\nachieves the best results with the least amount of compute time.\\nRunning Training Jobs on Multiple Instances\\nWhen a training job runs on multiple instances, hyperparameter tuning uses the last-reported objective\\nmetric from all instances of that training job as the value of the objective metric for that training job.\\nDesign distributed training jobs so that you get they report the objective metric that you want.\\nProvide Dataset Metadata to Training Jobs with an\\nAugmented Manifest File\\nTo classify data into diﬀerent groupings, you train a model by using a dataset and metadata that act\\nas labels. To include metadata with your dataset in a training job, use an augmented manifest ﬁle.\\n308Amazon SageMaker Developer Guide\\nAugmented Manifest File format\\nWhen using an augmented manifest ﬁle, your dataset must be stored in Amazon Simple Storage Service\\n(Amazon S3) and you must conﬁgure your training job to use dataset stored there. You specify the\\nlocation and format of this dataset for one or more Channel  (p. 876).\\nWhen specifying a channel\\'s parameters, you specify a path to the ﬁle, called a S3Uri. Amazon\\nSageMaker interprets this URI based on the speciﬁed S3DataType  in S3DataSource (p. 994). The\\nAugmentedManifestFile  option deﬁnes a manifest format that includes metadata with the input\\ndata. Using an augmented manifest ﬁle is an alternative to preprocessing when you have labeled data.\\nFor training jobs using labeled data, you typically need to preprocess the dataset to combine input data\\nwith metadata before training. If your training dataset is large, preprocessing can be time consuming and\\nexpensive.\\nAugmented Manifest File Format\\nAn augmented manifest ﬁle must be formatted in JSON Lines format. In JSON Lines format, each line in\\nthe ﬁle is a complete JSON object followed by a newline separator.\\nDuring training, Amazon SageMaker parses each JSON line and sends some or all of its attributes on to\\nthe training algorithm. You specify which attribute contents to pass and the order in which to pass them\\nwith the AttributeNames  parameter of the CreateTrainingJob (p. 667) API. The AttributeNames\\nparameter is an ordered list of attribute names that Amazon SageMaker looks for in the JSON object to\\nuse as training input.\\nFor example, if you list [\"line\", \"book\"]  for AttributeNames , the input data must include the\\nattribute names of line  and book in the speciﬁed order. For this example, the following augmented\\nmanifest ﬁle content is valid:\\n{\"author\": \"Herman Melville\", \"line\": \"Call me Ishmael\", \"book\": \"Moby Dick\"}\\n{\"line\": \"It was love at first sight.\", \"author\": \"Joseph Heller\", \"book\": \"Catch-22\"}\\nAmazon SageMaker ignores unlisted attribute names even if they precede, follow, or are in between\\nlisted attributes.\\nWhen using augmented manifest ﬁles, observe the following guidelines:\\n•The order of the attributes listed in the AttributeNames  parameter determines the order of the\\nattributes passed to the algorithm in the training job.\\n•The listed AttributeNames  can be a subset of all of the attributes in the JSON line. Amazon\\nSageMaker ignores unlisted attributes in the ﬁle.\\n•You can specify any type of data allowed by the JSON format in AttributeNames , including text,\\nnumerical, data arrays, or objects.\\n•To include an S3 URI as an attribute name, add the suﬃx -ref  to it.\\nIf an attribute name contains the suﬃx -ref, the attribute\\'s value must be an S3 URI to a data ﬁle that\\nis accessible to the training job. For example, if AttributeNames  contains [\"image-ref\", \"is-a-\\ncat\"], a valid augmented manifest ﬁle might contain these lines:\\n{\"image-ref\": \"s3://mybucket/sample01/image1.jpg\", \"is-a-cat\": 1}\\n{\"image-ref\": \"s3://mybucket/sample02/image2.jpg\", \"is-a-cat\": 0}\\nFor the ﬁrst line of this manifest, Amazon SageMaker retrieves the contents of the S3 object s3://\\nmybucket/foo/image1.jpg  and streams it to the algorithm for training. The second line is the string\\nrepresentation of the is-a-cat  attribute \"1\", which is followed by the contents of the second line.\\nTo create an augmented manifest ﬁle, use Amazon SageMaker Ground Truth to create a labeling job. For\\nmore information, see Output Data  (p. 545).\\n309Amazon SageMaker Developer Guide\\nAugmented Manifest File format\\nStream Augmented Manifest File Data\\nAugmented manifest ﬁles are supported only for channels using Pipe input mode. For each channel, the\\ndata is extracted from its augmented manifest ﬁle and streamed (in order) to the algorithm through the\\nchannel\\'s named pipe. Pipe mode uses the ﬁrst in ﬁrst out (FIFO) method, so records are processed in the\\norder in which they are queued. For information about Pipe input mode, see InputMode .\\nAttribute names with a \"-ref\" suﬃx point to preformatted binary data. In some cases, the algorithm\\nknows how to parse the data. In other cases, you might need to wrap the data so that records are\\ndelimited for the algorithm. If the algorithm is compatible with RecordIO-formatted data, specifying\\nRecordIO  for RecordWrapperType  solves this issue. If the algorithm is not compatible with RecordIO\\nformat, specify None  for RecordWrapperType  and make sure that your data is parsed correctly for\\nyour algorithm. Using the [\"image-ref\", \"is-a-cat\"]  example, if you use RecordIO wrapping, the\\nfollowing stream of data is sent to the queue:\\nrecordio_formatted(s3://mybucket/foo/\\nimage1.jpg)recordio_formatted(\"1\")recordio_formatted(s3://mybucket/bar/\\nimage2.jpg)recordio_formatted(\"0\")\\nImages that aren\\'t wrapped with RecordIO format, are streamed with the corresponding is-a-cat\\nattribute value as one record. This can cause a problem because the algorithm might not delimit the\\nimages and attributes correctly.\\nWith augmented manifest ﬁles and Pipe mode in general, size limits of the EBS volume do not\\napply. This includes settings that otherwise must be within the EBS volume size limit such as\\nS3DataDistributionType. For more information about Pipe mode and how to use it, see Using Your Own\\nTraining Algorithms - Input Data Conﬁguration.\\nUse an Augmented Manifest File (Console)\\nTo complete this procedure, you need:\\n•The URL of the S3 bucket where you\\'ve stored the augmented manifest ﬁle.\\n•To store the data that is listed in the augmented manifest ﬁle in an S3 bucket.\\n•The URL of the S3 bucket where you want to store the output of the job.\\nTo use an augmented manifest ﬁle in a training job (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker.\\n2. In the navigation pane, choose Training, then choose Training jobs.\\n3. Choose Create training job .\\n4. Provide a name for the training job. The name must be unique within an AWS Region in an AWS\\naccount. It can have 1 to 63 characters. Valid characters: a-z, A-Z, 0-9, and . : + = @ _ % - (hyphen).\\n5. Choose the algorithm that you want to use. For information about supported built-in algorithms,\\nsee Use Amazon SageMaker Built-in Algorithms  (p. 56). If you want to use a custom algorithm, make\\nsure that it is compatible with Pipe mode.\\n6. (Optional) For Resource conﬁguration, either accept the default values or, to reduce computation\\ntime, increase the resource consumption.\\na. (Optional) For Instance type, choose the ML compute instance type that you want to use. In\\nmost cases, ml.m4.xlarge  is suﬃcient.\\nb. For Instance count, use the default, 1.\\nc. (Optional) For Additional volume per instance (GB), choose the size of the ML storage volume\\nthat you want to provision. In most cases, you can use the default, 1. If you are using a large\\ndataset, use a larger size.\\n310Amazon SageMaker Developer Guide\\nUse an Augmented Manifest File (API)\\n7. Provide information about the input data for the training dataset.\\na. For Channel name , either accept the default (train) or enter a more meaningful name, such as\\ntraining-augmented-manifest-file .\\nb. For InputMode , choose Pipe .\\nc. For S3 data distribution type, choose FullyReplicated. When training incrementally, fully\\nreplicating causes each ML compute instance to use a complete copy of the expanded dataset.\\nFor neural-based algorithms, such as Neural Topic Model (NTM) Algorithm (p. 177), choose\\nShardedByS3Key .\\nd. If the data speciﬁed in the augmented manifest ﬁle is uncompressed, set the Compression type\\nto None . If the data is compressed using gzip, set it to Gzip .\\ne. (Optional) For Content type, specify the appropriate MIME type. Content type is the\\nmultipurpose internet mail extension (MIME) type of the data.\\nf.For Record wrapper, if the dataset speciﬁed in the augmented manifest ﬁle is saved in RecordIO\\nformat, choose RecordIO. If your dataset is not saved as a RecordIO-formatted ﬁle, choose\\nNone .\\ng. For S3 data type, choose AugmentedManifestFile.\\nh. For S3 location, provide the path to the bucket where you stored the augmented manifest ﬁle.\\ni. For AugmentedManifestFile attribute names, specify the name of an attribute that you want\\nto use. The attribute name must be present within the augmented manifest ﬁle, and is case-\\nsensitive.\\nj. (Optional) To add more attribute names, choose Add row and specify another attribute name\\nfor each attribute.\\nk. (Optional) To adjust the order of attribute names, choose the up or down buttons next to the\\nnames. When using an augmented manifest ﬁle, the order of the speciﬁed attribute names is\\nimportant.\\nl. Choose Done .\\n8. For Output data conﬁguration, provide the following information:\\na. For S3 location, type the path to the S3 bucket where you want to store the output data.\\nb. (Optional) You can use your AWS Key Management Service (AWS KMS) encryption key to\\nencrypt the output data at rest. For Encryption key, provide the key ID or its Amazon Resource\\nNumber (ARN). For more information, see KMS-Managed Encryption Keys.\\n9. (Optional) For Tags, add one or more tags to the training job. A tag is metadata that you can deﬁne\\nand assign to AWS resources. In this case, you can use tags to help you manage your training jobs. A\\ntag consists of a key and a value, which you deﬁne. For example, you might want to create a tag with\\nProject as a key and a value that refers to a project that is related to the training job, such as Home\\nvalue forecasts .\\n10. Choose Create training job . Amazon SageMaker creates and runs the training job.\\nAfter the training job has ﬁnished, Amazon SageMaker stores the model artifacts in the bucket whose\\npath you provided for S3 output path  in the Output data conﬁguration ﬁeld. To deploy the model to\\nget predictions, see Step 6: Deploy the Model to Amazon SageMaker (p. 26).\\nUse an Augmented Manifest File (API)\\nThe following shows how to train a model with an augmented manifest ﬁle using the Amazon\\nSageMaker high-level Python library:\\n# Create a model object set to using \"Pipe\" mode.\\nmodel = sagemaker.estimator.Estimator( training_image ,\\n                                      role,\\n                                      train_instance_count=1,\\n311Amazon SageMaker Developer Guide\\nUse an Augmented Manifest File (API)\\n                                      train_instance_type=\\'ml.p3.2xlarge\\',\\n                                      train_volume_size = 50,\\n                                      train_max_run = 360000,\\n                                      input_mode = \\'Pipe\\',\\n                                      output_path= s3_output_location ,\\n                                      sagemaker_session= session)\\n# Create a train data channel with S3_data_type as \\'AugmentedManifestFile\\' and attribute\\n names.\\ntrain_data = sagemaker.session.s3_input( your_augmented_manifest_file ,\\n                                        distribution=\\'FullyReplicated\\',\\n                                        content_type=\\'image/jpeg\\',\\n                                        s3_data_type=\\'AugmentedManifestFile\\',\\n                                        attribute_names=[ \\'source-ref\\' , \\'annotations\\' ]) \\ndata_channels = {\\'train\\': train_data}\\n# Train a model.\\nmodel.fit(inputs=data_channels, logs=True)\\nAfter the training job has ﬁnished, Amazon SageMaker stores the model artifacts in the bucket whose\\npath you provided for S3 output path  in the Output data conﬁguration ﬁeld. To deploy the model to\\nget predictions, see Step 6: Deploy the Model to Amazon SageMaker (p. 26).\\n312Amazon SageMaker Developer Guide\\nPrerequisites\\nDeploy a Model\\nAfter you build and train your model, you can deploy it to get predictions in one of two ways:\\n•To set up a persistent endpoint to get one prediction at a time, use Amazon SageMaker hosting\\nservices. For an overview on deploying a model with Amazon SageMaker hosting services, see Deploy a\\nModel on Amazon SageMaker Hosting Services (p. 7).\\n•To get predictions for an entire dataset, use Amazon SageMaker batch transform. For an overview on\\ndeploying a model with Amazon SageMaker batch transform, see Get Inferences for an Entire Dataset\\nwith Batch Transform (p. 10).\\nPrerequisites\\nThese topics assume that you have built and trained a machine learning model and are ready to\\ndeploy it. If you are new to Amazon SageMaker and have not completed these prerequisite tasks, work\\nthrough the steps in the Get Started (p. 16) tutorial to familiarize yourself with an example of how\\nAmazon SageMaker manages the data science process and how it handles model deployment. For more\\ninformation about building a model, see Build a Model  (p. 56). For information about training a model,\\nsee Train a Model (p. 276).\\nWhat do you want to do?\\nAmazon SageMaker provides features to manage resources and optimize inference performance when\\ndeploying machine learning models. For guidance on using inference pipelines, compiling and deploying\\nmodels with Neo, Elastic Inference, and automatic model scaling, see the following topics.\\n•To manage data processing and real-time predictions or to process batch transforms in a pipeline, see\\nDeploy an Inference Pipeline (p. 314).\\n•To train TensorFlow, Apache MXNet, PyTorch, ONNX, and XGBoost models once and optimize them to\\ndeploy on ARM, Intel, and Nvidia processors, see Amazon SageMaker Neo (p. 328).\\n•To preprocess entire datasets quickly or to get inferences from a trained model for large datasets when\\nyou don\\'t need a persistent endpoint, see Batch Transform (p. 348).\\n•To speed up the throughput and decrease the latency of getting real-time inferences from your deep\\nlearning models that are deployed as Amazon SageMaker hosted models using a GPU instance for your\\nendpoint, see Amazon SageMaker Elastic Inference (EI)  (p. 355).\\n•To dynamically adjust the number of instances provisioned in response to changes in your workload,\\nsee Automatically Scale Amazon SageMaker Models (p. 365).\\nManage Model Deployments\\nFor guidance on managing model deployments, including monitoring, troubleshooting, and best\\npractices, and for information on storage associated with inference hosting instances:\\n•For tools that can be used to monitor model deployments, see Monitor Amazon SageMaker (p. 461).\\n•For troubleshooting model deployments, see Troubleshoot Amazon SageMaker Model Deployments\\n (p. 380).\\n•For model deployment best practices, see Best Practices for Deploying Amazon SageMaker\\nModels  (p. 381).\\n313Amazon SageMaker Developer Guide\\nDeploy Your Own Inference Code\\n•For information about the size of storage volumes provided for diﬀerent sizes of hosting instances, see\\nHosting Instance Storage Volumes (p. 381).\\nDeploy Your Own Inference Code\\nFor developers that need more advanced guidance on how to run your own inference code:\\n•To run your own inference code hosting services, see Use Your Own Inference Code with Hosting\\nServices (p. 408).\\n•To run your own inference code for batch transforms, see Use Your Own Inference Code with Batch\\nTransform (p. 411).\\nGuide to Amazon SageMaker\\nWhat Is Amazon SageMaker? (p. 1)\\nTopics\\n•Deploy an Inference Pipeline (p. 314)\\n•Amazon SageMaker Neo (p. 328)\\n•Batch Transform (p. 348)\\n•Amazon SageMaker Elastic Inference (EI)  (p. 355)\\n•Automatically Scale Amazon SageMaker Models (p. 365)\\n•Troubleshoot Amazon SageMaker Model Deployments  (p. 380)\\n•Best Practices for Deploying Amazon SageMaker Models (p. 381)\\n•Hosting Instance Storage Volumes (p. 381)\\nDeploy an Inference Pipeline\\nAn inference pipeline  is an Amazon SageMaker model that is composed of a linear sequence of two to\\nﬁve containers that process requests for inferences on data. You use an inference pipeline to deﬁne and\\ndeploy any combination of pretrained Amazon SageMaker built-in algorithms and your own custom\\nalgorithms packaged in Docker containers. You can use an inference pipeline to combine preprocessing,\\npredictions, and post-processing data science tasks. Inference pipelines are fully managed.\\nYou can add Amazon SageMaker Spark ML Serving and scikit-learn containers that reuse the data\\ntransformers developed for training models. The entire assembled inference pipeline can be considered\\nas an Amazon SageMaker model that you can use to make either real-time predictions or to process\\nbatch transforms directly without any external preprocessing.\\nWithin an inference pipeline model, Amazon SageMaker handles invocations as a sequence of HTTP\\nrequests. The ﬁrst container in the pipeline handles the initial request, then the intermediate response\\nis sent as a request to the second container, and so on, for each container in the pipeline. Amazon\\nSageMaker returns the ﬁnal response to the client.\\nWhen you deploy the pipeline model, Amazon SageMaker installs and runs all of the containers on\\neach Amazon Elastic Compute Cloud (Amazon EC2) instance in the endpoint or transform job. Feature\\nprocessing and inferences run with low latency because the containers are co-located on the same EC2\\ninstances. You deﬁne the containers for a pipeline model using the CreateModel (p. 648) operation\\nor from the console. Instead of setting one PrimaryContainer , you use the Containers  parameter.\\nto set the containers that make up the pipeline You also specify the order in which the containers are\\nexecuted.\\n314Amazon SageMaker Developer Guide\\nSample Notebooks\\nA pipeline model is immutable, but you can update an inference pipeline by deploying a new one\\nusing the UpdateEndpoint  (p. 840) operation. This modularity supports greater ﬂexibility during\\nexperimentation.\\nThere are no additional costs for using this feature. You pay only for the instances running on an\\nendpoint.\\nTopics\\n•Sample Notebooks for Inference Pipelines (p. 315)\\n•Feature Processing with Spark ML and Scikit-learn (p. 315)\\n•Create a Pipeline Model  (p. 316)\\n•Run Real-time Predictions with an Inference Pipeline (p. 318)\\n•Run Batch Transforms with Inference Pipelines (p. 320)\\n•Inference Pipeline Logs and Metrics (p. 321)\\n•Troubleshoot Inference Pipelines (p. 326)\\nSample Notebooks for Inference Pipelines\\nFor a sample notebook that uploads and processes a dataset, trains a model, and builds a pipeline\\nmodel, see the Inference Pipelines with Spark ML and XGBoost on Abalone notebook. This notebook\\nshows how you can build your machine learning pipeline by using Spark feature Transformers and the\\nAmazon SageMaker XGBoost algorithm. After training the model, the sample shows how to deploy\\nthe pipeline (feature Transformer and XGBoost) for real-time predictions and also performs a batch\\ntransform job using the same pipeline.\\nFor more examples that show how to create and deploy inference pipelines, see the Inference Pipelines\\nwith SparkML and BlazingText on DBPedia and Training using SparkML on EMR and hosting on\\nSageMaker sample notebooks. For instructions on creating and accessing Jupyter notebook instances\\nthat you can use to run the example in Amazon SageMaker, see Use Notebook Instances (p. 36).\\nTo see a list of all the Amazon SageMaker samples, after creating and opening a notebook instance,\\nchoose the SageMaker Examples tab. There are three inference pipeline notebooks. The ﬁrst two\\ninference pipeline notebooks just described are located in the advanced_functionality  folder and\\nthe third notebook is in the sagemaker-python-sdk  folder. To open a notebook, choose its Use tab,\\nthen choose Create copy.\\nFeature Processing with Spark ML and Scikit-learn\\nBefore training a model with either Amazon SageMaker built-in algorithms or custom algorithms, you\\ncan use Spark and scikit-learn preprocessors to transform your data and engineer features.\\nFeature Processing with Spark ML\\nYou can run Spark ML jobs with AWS Glue, a serverless ETL (extract, transform, load) service, from your\\nAmazon SageMaker notebook. You can also connect to existing EMR clusters to run Spark ML jobs with\\nAmazon EMR. To do this, you need an AWS Identity and Access Management (IAM) role that grants\\npermission for making calls from your Amazon SageMaker notebook to AWS Glue.\\nNote\\nCurrently, AWS Glue supports only Python 2.7.\\nAfter engineering features, you package and serialize Spark ML jobs with MLeap into MLeap containers\\nthat you can add to an inference pipeline. You don\\'t need to use externally managed Spark clusters.\\n315Amazon SageMaker Developer Guide\\nCreate a Pipeline Model \\nWith this approach, you can seamlessly scale from a sample of rows to terabytes of data. The same\\ntransformers work for both training and inference, so you don\\'t need to duplicate preprocessing and\\nfeature engineering logic or develop a one-time solution to make the models persist. With inference\\npipelines, you don\\'t need to maintain outside infrastructure, and you can make predictions directly from\\ndata inputs.\\nWhen you run a Spark ML job on AWS Glue, a Spark ML pipeline is serialized into MLeap  format. Then,\\nyou can use the job with the SparkML Model Serving Container in an Amazon SageMaker Inference\\nPipeline. MLeap  is a serialization format and execution engine for machine learning pipelines. It supports\\nSpark, Scikit-learn, and TensorFlow for training pipelines and exporting them to a serialized pipeline\\ncalled an MLeap Bundle. You can deserialize Bundles back into Spark for batch-mode scoring or into the\\nMLeap runtime to power real-time API services.\\nFeature Processing with Sci-kit Learn\\nYou can run and package scikit-learn jobs into containers directly in Amazon SageMaker. For an example\\nof Python code for building a scikit-learn featurizer model that trains on Fisher\\'s Iris ﬂower data set and\\npredicts the species of Iris based on morphological measurements, see IRIS Training and Prediction with\\nSagemaker Scikit-learn.\\nCreate a Pipeline Model\\nTo create a pipeline model that can be deployed to an endpoint or used for a batch transform job, use\\nthe Amazon SageMaker console or the CreateModel  operation.\\nTo create an inference pipeline (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/\\n.\\n2. Choose Models , and then choose Create models  from the Inference group.\\n3. On the Create model  page, provide a model name, choose an IAM role, and, if you want to use a\\nprivate VPC, specify VPC values.\\n4. To add information about the containers in the inference pipeline, choose Add container, then\\nchoose Next.\\n5. Complete the ﬁelds for each container in the order that you want to execute them, up to the\\nmaximum of ﬁve. Complete the Container input options , , Location of inference code image, and,\\noptionally, Location of model artifacts, Container host name , and Environmental variables ﬁelds. .\\n316Amazon SageMaker Developer Guide\\nCreate a Pipeline Model \\n317Amazon SageMaker Developer Guide\\nReal-time Inference\\nThe MyInferencePipelineModel page summarizes the settings for the containers that provide input\\nfor the model. If you provided the environment variables in a corresponding container deﬁnition,\\nAmazon SageMaker shows them in the Environment variables ﬁeld.\\nRun Real-time Predictions with an Inference Pipeline\\nYou can use trained models in an inference pipeline to make real-time predictions directly without\\nperforming external preprocessing. When you conﬁgure the pipeline, you can choose to use the built-\\nin feature transformers already available in Amazon SageMaker. Or, you can implement your own\\ntransformation logic using just a few lines of scikit-learn or Spark code.\\nMLeap , a serialization format and execution engine for machine learning pipelines, supports Spark,\\nscikit-learn, and TensorFlow for training pipelines and exporting them to a serialized pipeline called an\\nMLeap Bundle. You can deserialize Bundles back into Spark for batch-mode scoring or into the MLeap\\nruntime to power real-time API services.\\nThe containers in a pipeline listen on the port speciﬁed in the SAGEMAKER_BIND_TO_PORT  environment\\nvariable (instead of 8080). When running in an inference pipeline, Amazon SageMaker automatically\\nprovides this environment variable to containers. If this environment variable isn\\'t present, containers\\n318Amazon SageMaker Developer Guide\\nReal-time Inference\\ndefault to using port 8080. To indicate that your container complies with this requirement, use the\\nfollowing command to add a label to your Dockerﬁle:\\nLABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\\nIf your container needs to listen on a second port, choose a port in the range speciﬁed by the\\nSAGEMAKER_SAFE_PORT_RANGE  environment variable. Specify the value as an inclusive range in the\\nformat \"XXXX-YYYY\" , where XXXX  and YYYY are multi-digit integers. Amazon SageMaker provides this\\nvalue automatically when you run the container in a multicontainer pipeline.\\nNote\\nTo use custom Docker images in a pipeline that includes Amazon SageMaker built-in algorithms,\\nyou need an Amazon Elastic Container Registry (Amazon ECR) policy. Your Amazon ECR\\nrepository must grant Amazon SageMaker permission to pull the image. For more information,\\nsee Troubleshoot Amazon ECR Permissions for Inference Pipelines (p. 326).\\nCreate and Deploy an Inference Pipeline Endpoint\\nThe following code creates and deploys a real-time inference pipeline model with SparkML and XGBoost\\nmodels in series using the Amazon SageMaker SDK.\\nfrom sagemaker.model import Model\\nfrom sagemaker.pipeline_model import PipelineModel\\nfrom sagemaker.sparkml.model import SparkMLModel\\nsparkml_data = \\'s3://{}/{}/{}\\'.format(s3_model_bucket, s3_model_key_prefix, \\'model.tar.gz\\')\\nsparkml_model = SparkMLModel(model_data=sparkml_data)\\nxgb_model = Model(model_data=xgb_model.model_data, image=training_image)\\nmodel_name = \\'serial-inference-\\' + timestamp_prefix\\nendpoint_name = \\'serial-inference-ep-\\' + timestamp_prefix\\nsm_model = PipelineModel(name=model_name, role=role, models=[sparkml_model, xgb_model])\\nsm_model.deploy(initial_instance_count=1, instance_type=\\'ml.c4.xlarge\\',\\n endpoint_name=endpoint_name)\\nRequest Real-Time Inference from an Inference Pipeline\\nEndpoint\\nThe following example shows how to make real-time predictions by calling an inference endpoint and\\npassing a request payload in JSON format:\\nfrom sagemaker.predictor import json_serializer, json_deserializer, RealTimePredictor\\nfrom sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\\npayload = {\\n        \"input\": [\\n            {\\n                \"name\": \"Pclass\",\\n                \"type\": \"float\",\\n                \"val\": \"1.0\"\\n            },\\n            {\\n                \"name\": \"Embarked\",\\n                \"type\": \"string\",\\n                \"val\": \"Q\"\\n            },\\n            {\\n                \"name\": \"Age\",\\n                \"type\": \"double\",\\n319Amazon SageMaker Developer Guide\\nBatch Transform\\n                \"val\": \"48.0\"\\n            },\\n            {\\n                \"name\": \"Fare\",\\n                \"type\": \"double\",\\n                \"val\": \"100.67\"\\n            },\\n            {\\n                \"name\": \"SibSp\",\\n                \"type\": \"double\",\\n                \"val\": \"1.0\"\\n            },\\n            {\\n                \"name\": \"Sex\",\\n                \"type\": \"string\",\\n                \"val\": \"male\"\\n            }\\n        ],\\n        \"output\": {\\n            \"name\": \"features\",\\n            \"type\": \"double\",\\n            \"struct\": \"vector\"\\n        }\\n    }\\npredictor = RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sess,\\n serializer=json_serializer,\\n                                content_type=CONTENT_TYPE_JSON, accept=CONTENT_TYPE_CSV)\\nprint(predictor.predict(payload))\\nRun Batch Transforms with Inference Pipelines\\nTo get inferences on an entire dataset you run a batch transform on a trained model , To run inferences\\non a full dataset, you can use the same inference pipeline model created and deployed to an endpoint\\nfor real-time processing in a batch transform job. To run a batch transform job in a pipeline, you\\ndownload the input data from Amazon S3 and send it in one or more HTTP requests to the inference\\npipeline model. For an example that shows how to prepare data for a batch transform, see the\\n\"Preparing Data for Batch Transform\" section of the ML Pipeline with SparkML and XGBoost - Training\\nand Inference sample notebook. For information about Amazon SageMaker batch transforms, see Get\\nInferences for an Entire Dataset with Batch Transform (p. 10).\\nNote\\nTo use custom Docker images in a pipeline that includes Amazon SageMaker built-in algorithms,\\nyou need an Amazon Elastic Container Registry (Amazon ECR) policy. Your Amazon ECR\\nrepository must grant Amazon SageMaker permission to pull the image. For more information,\\nsee Troubleshoot Amazon ECR Permissions for Inference Pipelines (p. 326).\\nThe following example shows how to run a transform job using the Amazon SageMaker Python SDK.\\nIn this example, model_name  is the inference pipeline that combines SparkML and XGBoost models\\n(created in previous examples). The Amazon S3 location speciﬁed by input_data_path  contains the\\ninput data, in CSV format, to be downloaded and sent to the Spark ML model. After the transform\\njob has ﬁnished, the Amazon S3 location speciﬁed by output_data_path  contains the output data\\nreturned by the XGBoost model in CVS format.\\ninput_data_path = \\'s3://{}/{}/{}\\'.format(default_bucket, \\'key\\', \\'file_name\\')\\noutput_data_path = \\'s3://{}/{}\\'.format(default_bucket, \\'key\\')\\ntransform_job = sagemaker.transformer.Transformer(\\n    model_name = model_name,\\n    instance_count = 1,\\n    instance_type = \\'ml.m4.xlarge\\',\\n320Amazon SageMaker Developer Guide\\nLogs and Metrics\\n    strategy = \\'SingleRecord\\',\\n    assemble_with = \\'Line\\',\\n    output_path = output_data_path,\\n    base_transform_job_name=\\'inference-pipelines-batch\\',\\n    sagemaker_session=sess,\\n    accept = CONTENT_TYPE_CSV)\\ntransform_job.transform(data = input_data_path, \\n                        content_type = CONTENT_TYPE_CSV, \\n                        split_type = \\'Line\\')\\nInference Pipeline Logs and Metrics\\nMonitoring is important for maintaining the reliability, availability, and performance of Amazon\\nSageMaker resources. To monitor and troubleshoot inference pipeline performance, use Amazon\\nCloudWatch logs and error messages. For information about the monitoring tools that Amazon\\nSageMaker provides, see Monitor Amazon SageMaker (p. 461).\\nUse Metrics to Monitor Multi-container Models\\nTo monitor the multi-container models in Inference Pipelines, use Amazon CloudWatch. CloudWatch\\ncollects raw data and processes it into readable, near real-time metrics. Amazon SageMaker training jobs\\nand endpoints write CloudWatch metrics and logs in the AWS/SageMaker  namespace.\\nThe following tables list the metrics and dimensions for the following:\\n•Endpoint invocations\\n•Training jobs, batch transform jobs, and endpoint instances\\nA dimension  is a name/value pair that uniquely identiﬁes a metric. You can assign up to 10 dimensions\\nto a metric. For more information on monitoring with CloudWatch, see Monitor Amazon SageMaker with\\nAmazon CloudWatch (p. 461).\\nEndpoint Invocation Metrics\\nThe AWS/SageMaker  namespace includes the following request metrics from calls to\\nInvokeEndpoint (p. 853) .\\nMetrics are reported at a 1-minute intervals.\\nMetric Description\\nInvocation4XXErrors The number of InvokeEndpoint  requests that the model returned a 4xx\\nHTTP response code for. For each 4xx response, Amazon SageMaker sends a\\n1.\\nUnits: None\\nValid statistics: Average , Sum\\nInvocation5XXErrors The number of InvokeEndpoint  requests that the model returned a 5xx\\nHTTP response code for. For each 5xx response, Amazon SageMaker sends a\\n1.\\nUnits: None\\nValid statistics: Average , Sum\\n321Amazon SageMaker Developer Guide\\nLogs and Metrics\\nMetric Description\\nInvocations The number of InvokeEndpoint  requests sent to a model endpoint.\\nTo get the total number of requests sent to a model endpoint, use the Sum\\nstatistic.\\nUnits: None\\nValid statistics: Sum, Sample Count\\nInvocationsPerInstance The number of endpoint invocations sent to a model, normalized by\\nInstanceCount  in each ProductionVariant . Amazon SageMaker\\nsends 1/numberOfInstances  as the value for each request, where\\nnumberOfInstances  is the number of active instances for the\\nProductionVariant at the endpoint at the time of the request.\\nUnits: None\\nValid statistics: Sum\\nModelLatency The time the model or models took to respond. This includes the time it\\ntook to send the request, to fetch the response from the model container,\\nand to complete the inference in the container. ModelLatency  is the total\\ntime taken by all containers in an inerence pipeline..\\nUnits: Microseconds\\nValid statistics: Average , Sum, Min, Max, Sample Count\\nOverheadLatency The time added to the time taken to respond to a client request by Amazon\\nSageMaker for overhead. OverheadLatency  is measured from the time\\nthat Amazon SageMaker receives the request until it returns a response\\nto the client, minus the ModelLatency . Overhead latency can vary\\ndepending on request and response payload sizes, request frequency, and\\nauthentication or authorization of the request, among other factors.\\nUnits: Microseconds\\nValid statistics: Average , Sum, Min, Max, Sample Count\\nContainerLatency The time it took for an Inference Pipelines container to respond as viewed\\nfrom Amazon SageMaker. ContainerLatency  includes the time it took to\\nsend the request, to fetch the response from the model\\'s container, and to\\ncomplete inference in the container.\\nUnits: Microseconds\\nValid statistics: Average , Sum, Min, Max, Sample Count\\nDimensions for Endpoint Invocation Metrics\\nDimension Description\\nEndpointName,\\nVariantName,\\nContainerNameFilters endpoint invocation metrics for a ProductionVariant  at the\\nspeciﬁed endpoint and for the speciﬁed variant.\\n322Amazon SageMaker Developer Guide\\nLogs and Metrics\\nFor an inference pipeline endpoint, CloudWatch lists per-container latency metrics in your account as\\nEndpoint Container Metrics  and Endpoint Variant Metrics in the SageMaker namespace, as follows.\\nThe ContainerLatency  metric appears only for inferences pipelines.\\nFor each endpoint and each container, latency metrics display names for the container, endpoint, varian,\\nand metric.\\nTraining Job, Batch Transform Job, and Endpoint Instance Metrics\\nThe namespaces /aws/sagemaker/TrainingJobs , /aws/sagemaker/TransformJobs , and /aws/\\nsagemaker/Endpoints  include the following metrics for training jobs and endpoint instances.\\nMetrics are reported at a 1-minute intervals.\\nMetric Description\\nCPUUtilization The percentage of CPU units that are used by the containers running on\\nan instance. The value ranges from 0% to 100%, and is multiplied by the\\nnumber of CPUs. For example, if there are four CPUs, CPUUtilization  can\\nrange from 0% to 400%.\\nFor training jobs, CPUUtilization  is the CPU utilization of the algorithm\\ncontainer running on the instance.\\nFor batch transform jobs, CPUUtilization  is the CPU utilization of the\\ntransform container running on the instance.\\nFor multi-container models, CPUUtilization  is the sum of CPU utilization\\nby all containers running on the instance.\\nFor endpoint variants, CPUUtilization  is the sum of CPU utilization by all\\nof the containers running on the instance.\\nUnits: Percent\\nMemoryUtilizaton The percentage of memory that is used by the containers running on an\\ninstance. This value ranges from 0% to 100%.\\nFor training jobs, MemoryUtilizaton  is the memory used by the algorithm\\ncontainer running on the instance.\\nFor batch transform jobs, MemoryUtilizaton  is the memory used by the\\ntransform container running on the instance.\\n323Amazon SageMaker Developer Guide\\nLogs and Metrics\\nMetric Description\\nFor multi-container models, MemoryUtilizaton  is the sum of memory\\nused by all containers running on the instance.\\nFor endpoint variants, MemoryUtilizaton  is the sum of memory used by\\nall of the containers running on the instance.\\nUnits: Percent\\nGPUUtilization The percentage of GPU units that are used by the containers running on an\\ninstance. GPUUtilization  ranges from 0% to 100% and is multiplied by\\nthe number of GPUs. For example, if there are four GPUs, GPUUtilization\\ncan range from 0% to 400%.\\nFor training jobs, GPUUtilization  is the GPU used by the algorithm\\ncontainer running on the instance.\\nFor batch transform jobs, GPUUtilization  is the GPU used by the\\ntransform container running on the instance.\\nFor multi-container models, GPUUtilization  is the sum of GPU used by all\\ncontainers running on the instance.\\nFor endpoint variants, GPUUtilization  is the sum of GPU used by all of\\nthe containers running on the instance.\\nUnits: Percent\\nGPUMemoryUtilization The percentage of GPU memory used by the containers running on\\nan instance. GPUMemoryUtilization ranges from 0% to 100% and is\\nmultiplied by the number of GPUs. For example, if there are four GPUs,\\nGPUMemoryUtilization  can range from 0% to 400%.\\nFor training jobs, GPUMemoryUtilization  is the GPU memory used by the\\nalgorithm container running on the instance.\\nFor batch transform jobs, GPUMemoryUtilization  is the GPU memory\\nused by the transform container running on the instance.\\nFor multi-container models, GPUMemoryUtilization  is sum of GPU used\\nby all containers running on the instance.\\nFor endpoint variants, GPUMemoryUtilization  is the sum of the GPU\\nmemory used by all of the containers running on the instance.\\nUnits: Percent\\nDiskUtilization The percentage of disk space used by the containers running on an instance.\\nDiskUtilization ranges from 0% to 100%. This metric is not supported for\\nbatch transform jobs.\\nFor training jobs, DiskUtilization  is the disk space used by the algorithm\\ncontainer running on the instance.\\nFor endpoint variants, DiskUtilization  is the sum of the disk space used\\nby all of the provided containers running on the instance.\\nUnits: Percent\\n324Amazon SageMaker Developer Guide\\nLogs and Metrics\\nDimensions for Training Job, Batch Transform Job, and Endpoint Instance Metrics\\nDimension Description\\nHost For training jobs, Host  has the format [training-job-name]/algo-\\n[instance-number-in-cluster] . Use this dimension to ﬁlter instance\\nmetrics for the speciﬁed training job and instance. This dimension format is\\npresent only in the /aws/sagemaker/TrainingJobs  namespace.\\nFor batch transform jobs, Host  has the format [transform-job-name]/\\n[instance-id] . Use this dimension to ﬁlter instance metrics for the\\nspeciﬁed batch transform job and instance. This dimension format is present\\nonly in the /aws/sagemaker/TransformJobs  namespace.\\nFor endpoints, Host  has the format [endpoint-name]/[ production-\\nvariant-name ]/[instance-id] . Use this dimension to ﬁlter instance\\nmetrics for the speciﬁed endpoint, variant, and instance. This dimension\\nformat is present only in the /aws/sagemaker/Endpoints  namespace.\\nTo help you debug your training jobs, endpoints, and notebook instance lifecycle conﬁgurations, Amazon\\nSageMaker also sends anything an algorithm container, a model container, or a notebook instance\\nlifecycle conﬁguration sends to stdout  or stderr to Amazon CloudWatch Logs. You can use this\\ninformation for debugging and to analyze progress.\\nUse Logs to Monitor an Inference Pipeline\\nThe following table lists the log groups and log streams Amazon SageMaker. sends to Amazon\\nCloudWatch\\nA log stream  is a sequence of log events that share the same source. Each separate source of logs into\\nCloudWatch makes up a separate log stream. A log group  is a group of log streams that share the same\\nretention, monitoring, and access control settings.\\nLogs\\nLog Group Name Log Stream Name\\n/aws/sagemaker/\\nTrainingJobs[training-job-name]/algo-[instance-number-in-cluster]-\\n[epoch_timestamp]\\n[production-variant-name]/[instance-id]\\n[production-variant-name]/[instance-id]/aws/sagemaker/\\nEndpoints/\\n[EndpointName]\\n[production-variant-name]/[instance-id]/[container-name\\nprovided in the Amazon SageMaker model] (For Inference\\nPipelines)  For Inference Pipelines logs, if you don\\'t provide container\\nnames, CloudWatch uses **container-1, container-2**, and so on, in the\\norder that containers are provided in the model.\\n/aws/sagemaker/\\nNotebookInstances[notebook-instance-name]/[LifecycleConfigHook]\\n[transform-job-name]/[instance-id]-[epoch_timestamp] /aws/sagemaker/\\nTransformJobs\\n[transform-job-name]/[instance-id]-[epoch_timestamp]/data-\\nlog\\n325Amazon SageMaker Developer Guide\\nTroubleshooting\\nLog Group Name Log Stream Name\\n[transform-job-name]/[instance-id]-[epoch_timestamp]/\\n[container-name provided in the Amazon SageMaker model]\\n(For Inference Pipelines)  For Inference Pipelines logs, if you don\\'t\\nprovide container names, CloudWatch uses **container-1, container-2**, and\\nso on, in the order that containers are provided in the model.\\nNote\\nAmazon SageMaker creates the /aws/sagemaker/NotebookInstances  log group when you\\ncreate a notebook instance with a lifecycle conﬁguration. For more information, see Customize a\\nNotebook Instance  (p. 40).\\nFor more information about Amazon SageMaker logging, see Log Amazon SageMaker Events with\\nAmazon CloudWatch (p. 466).\\nTroubleshoot Inference Pipelines\\nTo troubleshoot inference pipeline issues, use CloudWatch logs and error messages. If you are using\\ncustom Docker images in a pipeline that includes Amazon SageMaker built-in algorithms, you might also\\nencounter permissions problems. To grant the required permissions, create an Amazon Elastic Container\\nRegistry (Amazon ECR) policy.\\nTopics\\n•Troubleshoot Amazon ECR Permissions for Inference Pipelines (p. 326)\\n•Use CloudWatch Logs to Troubleshoot Amazon SageMaker Inference Pipelines (p. 327)\\n•Use Error Messages to Troubleshoot Inference Pipelines  (p. 327)\\nTroubleshoot Amazon ECR Permissions for Inference Pipelines\\nWhen you use custom Docker images in a pipeline that includes Amazon SageMaker built-in algorithms,\\nyou need an Amazon ECR policy. The policy allows your Amazon ECR repository to grant permission for\\nAmazon SageMaker to pull the image. The policy must add the following permissions:\\n{\\n    \"Version\": \"2008-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"allowSageMakerToPull\",\\n            \"Effect\": \"Allow\",\\n            \"Principal\": {\\n                \"Service\": \"sagemaker.amazonaws.com\"\\n            },\\n            \"Action\": [\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\",\\n                \"ecr:BatchCheckLayerAvailability\"\\n            ]\\n        }\\n    ]\\n}\\n326Amazon SageMaker Developer Guide\\nTroubleshooting\\nUse CloudWatch Logs to Troubleshoot Amazon SageMaker\\nInference Pipelines\\nAmazon SageMaker publishes the container logs for endpoints that deploy an inference pipeline to\\nAmazon CloudWatch at the following path for each container.\\n/aws/sagemaker/Endpoints/{EndpointName}/{Variant}/{InstanceId}/{ContainerHostname}\\nFor example, logs for this endpoint are published to the following log groups and streams:\\nEndpointName: MyInferencePipelinesEndpoint\\nVariant: MyInferencePipelinesVariant\\nInstanceId: i-0179208609ff7e488\\nContainerHostname: MyContainerName1 and MyContainerName2\\nlogGroup: /aws/sagemaker/Endpoints/MyInferencePipelinesEndpoint\\nlogStream: MyInferencePipelinesVariant/i-0179208609ff7e488/MyContainerName1\\nlogStream: MyInferencePipelinesVariant/i-0179208609ff7e488/MyContainerName2\\nA log stream  is a sequence of log events that share the same source. Each separate source of logs into\\nCloudWatch makes up a separate log stream. A log group  is a group of log streams that share the same\\nretention, monitoring, and access control settings.\\nTo see the log groups and streams\\n1. Open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.\\n2. In the navigation page, choose Logs .\\n3. In Log Groups . ﬁlter on MyInferencePipelinesEndpoint :\\n4. To see the log streams, on the CloudWatch Log Groups  page, choose\\nMyInferencePipelinesEndpoint , and then Search Log Group .\\nFor a list of the logs that Amazon SageMaker publishes, see Inference Pipeline Logs and\\nMetrics  (p. 321).\\nUse Error Messages to Troubleshoot Inference Pipelines\\nThe inference pipeline error messages indicate which containers failed.\\n327Amazon SageMaker Developer Guide\\nCompile and Deploy Models with Neo\\nIf an error occurs while Amazon SageMaker is invoking an endpoint, the service returns a ModelError\\n(error code 424), which indicates which container failed. If the request payload (the response from the\\nprevious container) exceeds the limit of 5 MB, Amazon SageMaker provides a detailed error message,\\nsuch as:\\nReceived response from MyContainerName1 with status code 200. However, the request payload\\nfrom MyContainerName1 to MyContainerName2 is 6000000 bytes, which has exceeded the maximum\\nlimit of 5 MB. See https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-\\nwest-2#logEventViewer:group=/aws/sagemaker/Endpoints/MyInferencePipelinesEndpoint in account\\n123456789012 for more information.\\nIf a container fails the ping health check while Amazon SageMaker is creating an endpoint, it returns a\\nClientError  and indicates all of the containers that failed the ping check in the last health check.\\nAmazon SageMaker Neo\\nNeo is a new capability of Amazon SageMaker that enables machine learning models to train once and\\nrun anywhere in the cloud and at the edge.\\nOrdinarily, optimizing machine learning models for inference on multiple platforms is extremely diﬃcult\\nbecause you need to hand-tune models for the speciﬁc hardware and software conﬁguration of each\\nplatform. If you want to get optimal performance for a given workload, you need to know the hardware\\narchitecture, instruction set, memory access patterns, and input data shapes among other factors. For\\ntraditional software development, tools such as compilers and proﬁlers simplify the process. For machine\\nlearning, most tools are speciﬁc to the framework or to the hardware. This forces you into a manual trial-\\nand-error process that is unreliable and unproductive.\\nNeo eliminates the time and eﬀort required to do this by automatically optimizing TensorFlow, Apache\\nMXNet, PyTorch, ONNX, and XGBoost models for deployment on ARM, Intel, and Nvidia processors. Neo\\nconsists of a compiler and a runtime. First, the Neo compilation API reads models exported from various\\nframeworks. It converts the framework-speciﬁc functions and operations into a framework-agnostic\\nintermediate representation. Next, it performs a series of optimizations. Then it generates binary code\\nfor the optimized operations, writes them to a shared object library, and saves the model deﬁnition\\nand parameters into separate ﬁles. Neo also provides a runtime for each target platform that loads and\\nexecutes the compiled model.\\nYou can create a Neo compilation job from either the Amazon SageMaker console, AWS Command Line\\nInterface (AWS CLI), Python notebook, or the Amazon SageMaker SDK. With a few CLI commands, an API\\ninvocation, or a few clicks, you can convert a model for your chosen platform. You can deploy the model\\nto an Amazon SageMaker endpoint or on an AWS IoT Greengrass device quickly. Amazon SageMaker\\nprovides Neo container images for Amazon SageMaker XGBoost and Image Classiﬁcation models, and\\nsupports Amazon SageMaker-compatible containers for your own compiled models.\\nNote\\nNeo currently supports image classiﬁcation models exported as frozen graphs from TensorFlow,\\nMXNet, or PyTorch, and XGBoost models. Neo is available in the following AWS Regions:\\n•US East (N. Virginia), us-east-1\\n•US West (Oregon), us-west-2\\n•EU (Ireland), eu-west-1\\nTopics\\n•Amazon SageMaker Neo Sample Notebooks (p. 329)\\n•Use Neo to Compile a Model  (p. 329)\\n•Deploy a Model (p. 334)\\n328Amazon SageMaker Developer Guide\\nSample Notebooks\\n•Request Inferences from a Deployed Service (p. 342)\\n•Troubleshooting Neo Compilation Errors (p. 342)\\nAmazon SageMaker Neo Sample Notebooks\\nFor sample notebooks that uses Amazon SageMaker Neo to train, compile, optimize, and deploy machine\\nlearning models to make inferences, see:\\n•MNIST Training, Compilation and Deployment with MXNet Module\\n•MNIST Training, Compilation and Deployment with Tensorﬂow Module\\n•Deploying pre-trained PyTorch vision models with Amazon SageMaker Neo\\n•Model Optimization with an Image Classiﬁcation Example\\n•Model Optimization with XGBoost Example\\nFor instructions on how to run these example notebooks in Amazon SageMaker, see Use Example\\nNotebooks  (p. 42). If you need intructions on how to create a notebook instance to run these examples,\\nsee Amazon SageMaker, see Use Notebook Instances (p. 36). To navigate to the relevant example in\\nyour notebook instance, choose the Amazon SageMaker Examples tab to see a list of all of the Amazon\\nSageMaker samples. To open a notebook, choose its Use tab, then choose Create copy.\\nUse Neo to Compile a Model\\nThis section show how to create, describe, stop, and list compilation jobs. There are three options\\navailable in Neo for managing the compilation jobs for machine learning models: Using the Neo CLI, the\\nAmazon SageMaker console, or the Amazon SageMaker SDK.\\nTopics\\n•Compile a Model (API)  (p. 329)\\n•Compile a Model (Console) (p. 330)\\n•Compile a Model (Amazon SageMaker SDK) (p. 333)\\nCompile a Model (API)\\nThis section shows how to manage compilation jobs for machine learning models. You can create,\\ndescribe, stop, and list compilation jobs.\\nCreate a Compilation Job\\nAs shown in the following JSON ﬁle, you specify the data input format, the S3 bucket where you stored\\nyour model, the S3 bucket where you want to write the compiled model, and the target hardware:\\njob.json\\n{\\n    \"CompilationJobName\": \"job002\",\\n    \"RoleArn\": \"arn:aws:iam::<your-account>:role/service-role/AmazonSageMaker-\\nExecutionRole-20180829T140091\",\\n    \"InputConfig\": {\\n        \"S3Uri\": \"s3://<your-bucket>/sagemaker/DEMO-breast-cancer-prediction/train\",\\n        \"DataInputConfig\":  \"{\\\\\"data\\\\\": [1,3,1024,1024]}\",\\n        \"Framework\": \"MXNET\"\\n    },\\n    \"OutputConfig\": {\\n        \"S3OutputLocation\": \"s3://<your-bucket>/sagemaker/DEMO-breast-cancer-prediction/\\ncompile\",\\n329Amazon SageMaker Developer Guide\\nCompile Models\\n        \"TargetDevice\": \"ml_c5\"\\n    },\\n    \"StoppingCondition\": {\\n        \"MaxRuntimeInSeconds\": 300\\n    }\\n}\\naws sagemaker create-compilation-job \\\\\\n--cli-input-json file://job.json \\\\\\n--region us-west-2 \\n# You should get CompilationJobArn\\nDescribe a Compilation Job\\naws sagemaker describe-compilation-job \\\\\\n--compilation-job-name $JOB_NM \\\\\\n--region us-west-2\\nStop a Compilation Job\\naws sagemaker stop-compilation-job \\\\\\n--compilation-job-name $JOB_NM \\\\\\n--region us-west-2\\n# There is no output for compilation-job operation\\nList a Compilation Job\\naws sagemaker list-compilation-jobs \\\\\\n--region us-west-2\\nCompile a Model (Console)\\nYou can create a Neo compilation job in the Amazon SageMaker console. In the Amazon SageMaker\\nconsole, choose Compilation jobs , and then choose Create compilation job.\\nOn the Create compilation job page, for Job name , enter a name. Then select an IAM role.\\n330Amazon SageMaker Developer Guide\\nCompile Models\\nIf you don’t have an IAM role, choose Create a new role.\\nOn the Create an IAM role page, choose Any S3 bucket, and choose Create role.\\n331Amazon SageMaker Developer Guide\\nCompile Models\\nIn the Input conﬁguration section, for Location of model artifacts, enter the path of the S3 bucket that\\ncontains your model artifacts. For Data input conﬁguration, enter the JSON string that speciﬁes how\\nmany data matrix inputs you and the shape of each data matrices. For Machine learning framework,\\nchoose the framework.\\nIn the Output conﬁguration section, for S3 Output location, enter the path to the S3 bucket or folder\\nwhere you want to store the model. For Target device, choose which device you want to deploy your\\nmodel to, and choose Create job .\\n332Amazon SageMaker Developer Guide\\nCompile Models\\nCheck the status of the compilation job when started.\\nCheck the status of the compilation job when completed.\\nCompile a Model (Amazon SageMaker SDK)\\nFollow the steps described in the Running the Training Job section of the MNIST Training, Compilation\\nand Deployment with MXNet Module sample to produce a machine learning model train using Amazon\\nSageMaker. Then you can use Neo to further optimize the model with the following code:\\noutput_path = ‘/’.join( mnist_estimator.output_path.split(‘/’)[:-1])\\ncompiled_model = mnist_estimator.compile_model(target_instance_family=\\'ml_c5\\', \\n333Amazon SageMaker Developer Guide\\nDeploy Models\\n                                               input_shape={\\'data\\':[1, 784]},\\n                                               role=role,\\n                                               output_path=output_path)\\nThis code compiles the model and saves the optimized model in output_path . Sample notebooks of\\nusing SDK are provided in the Amazon SageMaker Neo Sample Notebooks (p. 329) section.\\nDeploy a Model\\nYou can deploy the compact module to performance-critical cloud services with Amazon SageMaker\\nHosting Services or to resource-constrained edge devices with AWS IoT Greengrass.\\nTopics\\n•Deploy a Model Compiled with Neo with Hosting Services (p. 334)\\n•Deploy a Model Compiled with Neo (AWS IoT Greengrass)  (p. 341)\\nDeploy a Model Compiled with Neo with Hosting Services\\nTo deploy a Neo-compiled model to an HTTPS endpoint, you must conﬁgure and create the endpoint for\\nthe model using Amazon SageMaker hosting services. Currently developers can use Amazon SageMaker\\nAPIs to deploy modules on to ml.c5, ml.c4, ml.m5, ml.m4, ml.p3, and ml.p2 instances.\\nWhen you deploy a compiled model, you need to use the same instance for the target that you used for\\ncompilation. This creates an Amazon SageMaker endpoint that you can use to perform inferences. There\\nare three options available for deploying Neo-compiled models:\\nTopics\\n•Deploy a Model Compiled with Neo (AWS CLI) (p. 334)\\n•Deploy a Model Compiled with Neo (Console) (p. 336)\\n•Deploy a Model Compiled with Neo (Amazon SageMaker SDK) (p. 341)\\nDeploy a Model Compiled with Neo (AWS CLI)\\nThe deployment of a Neo-compiled model with the CLI has three steps.\\nTopics\\n•Create a Model That Was Compiled with Neo (AWS CLI) (p. 334)\\n•Create the Endpoint Conﬁguration (AWS CLI) (p. 336)\\n•Create an Endpoint (AWS CLI) (p. 336)\\nCreate a Model That Was Compiled with Neo (AWS CLI)\\nFor the full syntax of the CreateModel  API, see CreateModel (p. 648).\\nFor Neo-compiled models, use one of the following values for\\nPrimaryContainer /ContainerHostname , depending on your region and applications:\\n•Amazon SageMaker Image Classiﬁcation\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/image-classification-neo:latest\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/image-classification-neo:latest\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/image-classification-neo:latest\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/image-classification-neo:latest\\n334Amazon SageMaker Developer Guide\\nDeploy Models\\n•Amazon SageMaker XGBoost\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/xgboost-neo:latest\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/xgboost-neo:latest\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/xgboost-neo:latest\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/xgboost-neo:latest\\n•TensorFlow : The TensorFlow version used must be in TensorFlow SageMaker Estimators list.\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•MXNet The MXNet version used must be in MXNet SageMaker Estimators list.\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•Pytorch The Pytorch version used must be in Pytorch SageMaker Estimators list.\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-pytorch:[pytorch-\\nversion]-[cpu/gpu]-py3\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-pytorch:[pytorch-\\nversion]-[cpu/gpu]-py3\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/sagemaker-neo-pytorch:[pytorch-\\nversion]-[cpu/gpu]-py3\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-neo-pytorch:[pytorch-\\nversion]-[cpu/gpu]-py3\\nAlso, if you are using TensorFlow, Pytorch, or MXNet , add the following key-value pair to\\nPrimaryContainer /Environment :\\n\"Environment\": {\\n\"SAGEMAKER_SUBMIT_DIRECTORY\" : \"[Full S3 path for *.tar.gz file containing the training\\n script]\"\\n}\\nThe script must be packaged as a *.tar.gz  ﬁle. The *.tar.gz  ﬁle must contain the training script at\\nthe root level. The script must contain two additional functions for Neo serving containers:\\n•neo_preprocess(payload, content_type) : Function that takes in the payload and Content-\\nType of each incoming request and returns a NumPy array.\\n•neo_postprocess(result) : Function that takes the prediction results produced by Deep Learning\\nRuntime and returns the response body.\\nNeither of these two functions use any functionalities of MXNet, Pytorch, or Tensorﬂow. See the Amazon\\nSageMaker Neo Sample Notebooks (p. 329) for examples using these functions.\\n335Amazon SageMaker Developer Guide\\nDeploy Models\\nCreate the Endpoint Conﬁguration (AWS CLI)\\nFor the full syntax of the CreateEndpointConfig  API, see CreateEndpointConﬁg (p. 635). You must\\nspecify the correct instance type in ProductionVariants /InstanceType . It is imperative that this\\nvalue matches the instance type speciﬁed in your compilation job.\\nCreate an Endpoint (AWS CLI)\\nFor the full syntax of the CreateEndpoint  API, see CreateEndpoint (p. 632).\\nDeploy a Model Compiled with Neo (Console)\\nYou can create a Neo endpoint in the Amazon SageMaker console. Open the Amazon SageMaker console\\nat https://console.aws.amazon.com/sagemaker/.\\nChoose Models , and then choose Create models  from the Inference group. On the Create model  page,\\ncomplete the Model name , IAM role, and, if needed, VPC ﬁelds.\\nTo add information about the container used to deploy your model, choose Add container, then choose\\nNext. Complete the Container input options , Location of inference code image, and Location of model\\nartifacts, and optionally, Container host name , and Environmental variables ﬁelds.\\n336Amazon SageMaker Developer Guide\\nDeploy Models\\nTo deploy Neo-compiled models, choose the following:\\n•Container input options : Provide model artifacts and inference image\\n•Location of inference code image: Choose one of the following images, depending the region and\\nkind of application:\\n•Amazon SageMaker Image Classiﬁcation\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/image-classification-\\nneo:latest\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/image-classification-\\nneo:latest\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/image-classification-\\nneo:latest\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/image-classification-\\nneo:latest\\n•Amazon SageMaker XGBoost\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/xgboost-neo:latest\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/xgboost-neo:latest\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/xgboost-neo:latest\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/xgboost-neo:latest\\n•TensorFlow : The TensorFlow version used must be in TensorFlow SageMaker Estimators list.\\n337Amazon SageMaker Developer Guide\\nDeploy Models\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-neo-tensorflow:\\n[tensorflow-version]-[cpu/gpu]-py3\\n•MXNet The MXNet version used must be in MXNet SageMaker Estimators list.\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-neo-mxnet:[mxnet-\\nversion]-[cpu/gpu]-py3\\n•Pytorch The Pytorch version used must be in Pytorch SageMaker Estimators list.\\n•301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-neo-pytorch:\\n[pytorch-version]-[cpu/gpu]-py3\\n•785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-pytorch:\\n[pytorch-version]-[cpu/gpu]-py3\\n•007439368137.dkr.ecr.us-east-2.amazonaws.com/sagemaker-neo-pytorch:\\n[pytorch-version]-[cpu/gpu]-py3\\n•802834080501.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-neo-pytorch:\\n[pytorch-version]-[cpu/gpu]-py3\\n•Location of model artifact: the full S3 path of the compiled model artifact generated by the Neo\\ncompilation API.\\n•Environmental variables:\\n•Omit this ﬁeld for SageMaker Image Classiﬁcation and SageMaker XGBoost.\\n•For TensorFlow, Pytorch, and MXNet , specify the environment variable\\nSAGEMAKER_SUBMIT_DIRECTORY as the full S3 path that contains the training script.\\nThe script must be packaged as a *.tar.gz  ﬁle. The *.tar.gz  ﬁle must contain the training script at\\nthe root level. The script must contain two additional functions for Neo serving containers:\\n•neo_preprocess(payload, content_type) : Function that takes in the payload and Content-\\nType of each incoming request and returns a NumPy array.\\n•neo_postprocess(result) : Function that takes the prediction results produced by Deep Learning\\nRuntime and returns the response body.\\nNeither of these two functions use any functionalities of MXNet, Pytorch, or Tensorﬂow. See the Amazon\\nSageMaker Neo Sample Notebooks (p. 329) for examples using these functions.\\nConﬁrm that the information for the containers is accurate, and then choose Create model .This takes\\nyou to the create model landing page. Select the Create endpoint  button there.\\n338Amazon SageMaker Developer Guide\\nDeploy Models\\nIn Create and conﬁgure endpoint diagram, specify the Endpoint name . Choose Create a new endpoint\\nconﬁguration in Attach endpoint conﬁguration.\\nIn New endpoint conﬁguration page, specify the Endpoint conﬁguration name.\\n339Amazon SageMaker Developer Guide\\nDeploy Models\\nThen press Edit next to the name of the model and specify the correct Instance type on the Edit\\nProduction Variant page. It is imperative that the Instance type value match the one speciﬁed in your\\ncompilation job.\\n340Amazon SageMaker Developer Guide\\nDeploy Models\\nWhen you’re done click Save, then click Create endpoint conﬁguration on the New endpoint\\nconﬁguration page, and then click Create endpoint .\\nDeploy a Model Compiled with Neo (Amazon SageMaker SDK)\\nThe object handle for the compiled model supplies the deploy function, which allows you to create an\\nendpoint to serve inference requests. The function lets you set the number and type of instances that\\nare used for the endpoint. You must choose an instance for which you have compiled your model. For\\nexample, in the job compiled in Compile a Model (Amazon SageMaker SDK) (p. 333) section, this is\\nml_c5 . The Neo API uses a special runtime, the Neo runtime , to run Neo-optimized models.\\npredictor = compiled_model.deploy(initial_instance_count = 1, instance_type =\\n \\'ml.c5.4xlarge\\')\\nAfter the command is done, the name of the newly created endpoint is printed in the jupyter notebook.\\nDeploy a Model Compiled with Neo (AWS IoT Greengrass)\\nAWS IoT Greengrass extends cloud capabilities to local devices. It enables devices to collect and analyze\\ndata closer to the source of information, react autonomously to local events, and communicate securely\\nwith each other on local networks. With AWS IoT Greengrass, you can perform machine learning\\ninference at the edge on locally generated data using cloud-trained models. Currently, you can deploy\\nmodels on to all AWS IoT Greengrass devices based on ARM® Cortex-A™, Intel® Atom™, and Nvidia®\\nJetson™ series processors. For more information on deploying a Lambda inference application to\\nperform machine learning inferences with AWS IoT Greengrass, see Perform Machine Learning Inference.\\n341Amazon SageMaker Developer Guide\\nRequest Inferences\\nRequest Inferences from a Deployed Service\\nIf you have followed instructions in Deploy a Model Compiled with Neo with Hosting Services (p. 334),\\nyou should have an Amazon SageMaker endpoint set up and running. You can now submit inference\\nrequests using Boto3 client. Here is an example of sending an image for inference:\\nimport boto3\\nimport json\\n \\nendpoint = \\'<insert name of your endpoint here>\\'\\n \\nruntime = boto3.Session().client(\\'sagemaker-runtime\\')\\n \\n# Read image into memory\\nwith open(image, \\'rb\\') as f:\\n    payload = f.read()\\n# Send image via InvokeEndpoint API\\nresponse = runtime.invoke_endpoint(EndpointName=endpoint, ContentType=\\'application/x-\\nimage\\', Body=payload)\\n# Unpack response\\nresult = json.loads(response[\\'Body\\'].read().decode())\\nFor XGBoost application, you should submit a CSV text instead:\\nimport boto3\\nimport json\\n \\nendpoint = \\'<insert your endpoint here>\\'\\n \\nruntime = boto3.Session().client(\\'sagemaker-runtime\\')\\n \\ncsv_text = \\'1,-1.0,1.0,1.5,2.6\\'\\n# Send CSV text via InvokeEndpoint API\\nresponse = runtime.invoke_endpoint(EndpointName=endpoint, ContentType=\\'text/csv\\',\\n Body=csv_text)\\n# Unpack response\\nresult = json.loads(response[\\'Body\\'].read().decode())\\nNote that BYOM allows for a custom content type. For more information, see InvokeEndpoint (p. 853).\\nTroubleshooting Neo Compilation Errors\\nThis section contains information about how to understand and prevent common errors, the error\\nmessages they generate, and guidance on how to resolve these errors. It also contains lists of the\\nframeworks and the operations in each of those frameworks that Neo supports.\\nTopics\\n•Prevent Neo Input Errors (p. 342)\\n•Neo Error Messages (p. 346)\\n•Resolve Neo Errors (p. 348)\\nPrevent Neo Input Errors\\nSome of the most common errors are due to invalid inputs. This section contains information arranged in\\nquestion and answer form to help you avoid these errors.\\nWhich frameworks does Neo support?\\n342Amazon SageMaker Developer Guide\\nTroubleshoot Errors\\n•TensorFlow\\n•PyTorch\\n•Apache MXNET\\n•XGBoost\\n•ONNX\\nWhich operators does Amazon SageMaker Neo support for these frameworks?\\nThe following table lists the supported operations for each framework.\\nMXNet TensorFlow PyTorch/ONNX\\n\\'_add_scalar\\' \\'Add\\' \\'Abs\\'\\n\\'_add_symbol\\' \\'ArgMax\\' \\'Add\\'\\n\\'_contrib_MultiBoxDetection\\' \\'ArgMin\\' \\'ArgMax\\'\\n\\'_contrib_MultiBoxPrior\\' \\'AvgPool\\' \\'ArgMin\\'\\n\\'_copy\\' \\'BatchNormWithGlobalNormalization\\' \\'AveragePool\\'\\n\\'_div_scalar\\' \\'BiasAdd\\' \\'BatchNormalization\\'\\n\\'_div_symbol\\' \\'Cast\\' \\'Cast\\'\\n\\'_minus_scalar\\' \\'Ceil\\' \\'Ceil\\'\\n\\'_minus_scalar\\' \\'CheckNumerics\\' \\'Clip\\'\\n\\'_mul_symbol\\' \\'Concat\\' \\'Concat\\'\\n\\'_Plus\\' \\'ConcatV2\\' \\'Constant\\'\\n\\'_plus_scalar\\' \\'Conv2D\\' \\'ConstantFill\\'\\n\\'_pow_scalar\\' \\'DecodeJpeg\\' \\'Conv\\'\\n\\'_rdiv_scalar\\' \\'DepthwiseConv2dNative\\' \\'ConvTranspose\\'\\n\\'_rminus_scalar\\' \\'Elu\\' \\'Div\\'\\n\\'_rpow_scalar\\' \\'Equal\\' \\'Dropout\\'\\n\\'_rsub_scalar\\' \\'ExpandDims\\' \\'Elu\\'\\n\\'_sub_scalar\\' \\'Fill\\' \\'Exp\\'\\n\\'_sub_symbol\\' \\'Floor\\' \\'FC\\'\\n\\'Activation\\' \\'FusedBatchNorm\\' \\'Flatten\\'\\n\\'add_n\\' \\'FusedBatchNormV2\\' \\'Floor\\'\\n\\'argmax\\' \\'GatherV2\\' \\'Gather\\'\\n\\'BatchNorm\\' \\'Greater\\' \\'Gemm\\'\\n\\'BatchNorm_v1\\' \\'GreaterEqual\\' \\'GlobalAveragePool\\'\\n343Amazon SageMaker Developer Guide\\nTroubleshoot Errors\\nMXNet TensorFlow PyTorch/ONNX\\n\\'broadcast_add\\' \\'Identity\\' \\'GlobalMaxPool\\'\\n\\'broadcast_div\\' \\'LeakyRelu\\' \\'HardSigmoid\\'\\n\\'broadcast_mul\\' \\'Less\\' \\'Identity\\'\\n\\'broadcast_sub\\' \\'LessEqual\\' \\'ImageScaler\\'\\n\\'broadcast_to\\' \\'LRN\\' \\'LeakyRelu\\'\\n\\'cast\\' \\'MatMul\\' \\'Log\\'\\n\\'Cast\\' \\'Maximum\\' \\'LogSoftmax\\'\\n\\'clip\\' \\'MaxPool\\' \\'LRN\\'\\n\\'Concat\\' \\'Mean\\' \\'MatMul\\'\\n\\'concat\\' \\'Minimum\\' \\'Max\\'\\n\\'Convolution\\' \\'Mul\\'\\xa0 \\'MaxPool\\'\\n\\'Convolution_v1\\' \\'NotEqual\\' \\'Mean\\'\\n\\'Crop\\' \\'Pack\\' \\'Min\\'\\n\\'Deconvolution\\' \\'Pad\\' \\'Mul\\'\\n\\'Dropout\\' \\'PadV2\\' \\'Neg\\'\\n\\'elemwise_add\\' \\'Range\\' \\'Pad\\'\\n\\'elemwise_div\\' \\'Rank\\' \\'ParametricSoftplus\\'\\n\\'elemwise_mul\\' \\'Relu\\' \\'Pow\\'\\n\\'elemwise_sub\\' \\'Relu6\\' \\'PRelu\\'\\n\\'exp\\' \\'Reshape\\' \\'Reciprocal\\'\\n\\'expand_dims\\' \\'ResizeBilinear\\' \\'ReduceMax\\'\\n\\'flatten\\' \\'Rsqrt\\' \\'ReduceMean\\'\\n\\'Flatten\\' \\'Selu\\' \\'ReduceMin\\'\\n\\'FullyConnected\\' \\'Shape\\' \\'ReduceProd\\'\\n\\'LeakyReLU\\' \\'Sigmoid\\' \\'ReduceSum\\'\\n\\'LinearRegressionOutput\\' \\'Softmax\\' \\'Relu\\'\\n\\'log\\' \\'Square\\' \\'Reshape\\'\\n\\'log_softmax\\' \\'Squeeze\\' \\'Scale\\'\\n\\'LRN\\' \\'StridedSlice\\' \\'ScaledTanh\\'\\n\\'max\\' \\'Sub\\' \\'Selu\\'\\n\\'max_axis\\'\\xa0 \\'Sum\\' \\'Shape\\'\\n344Amazon SageMaker Developer Guide\\nTroubleshoot Errors\\nMXNet TensorFlow PyTorch/ONNX\\n\\'min\\' \\'Tanh\\' \\'Sigmoid\\'\\n\\'min_axis\\' \\'Transpose\\' \\'Slice\\'\\n\\'negative\\' \\xa0 \\'Softmax\\'\\n\\'Pooling\\' \\xa0 \\'SoftPlus\\'\\n\\'Pooling_v1\\' \\xa0 \\'Softsign\\'\\n\\'relu\\' \\xa0 \\'SpatialBN\\'\\n\\'Reshape\\' \\xa0 \\'Split\\'\\n\\'reshape\\' \\xa0 \\'Sqrt\\'\\n\\'reshape_like\\' \\xa0 \\'Squeeze\\'\\n\\'sigmoid\\' \\xa0 \\'Sub\\'\\n\\'slice_like\\' \\xa0 \\'Sum\\'\\n\\'SliceChannel\\' \\xa0 \\'Tanh\\'\\n\\'softmax\\' \\xa0 \\'ThresholdedRelu\\'\\n\\'Softmax\\' \\xa0 \\'Transpose\\'\\n\\'SoftmaxActivation\\' \\xa0 \\'Unsqueeze\\'\\n\\'SoftmaxOutput\\' \\xa0 \\'Upsample\\'\\n\\'split\\' \\xa0 \\xa0\\n\\'sum\\' \\xa0 \\xa0\\n\\'sum_axis\\' \\xa0 \\xa0\\n\\'tanh\\' \\xa0 \\xa0\\n\\'transpose\\' \\xa0 \\xa0\\n\\'UpSampling\\' \\xa0 \\xa0\\nWhich model architectures does Neo support?\\nNeo supports image classiﬁcation models.\\nWhich model format ﬁles does Neo read in?\\nThe ﬁle needs to be formatted as a tar.gz ﬁle that includes additional ﬁles that depend on the type of\\nframework.\\n•TensorFlow: Neo supports saved models and frozen models.\\nFor saved models , Neo expects one .pb or one .pbtxt ﬁle and a variables directory that contains\\nvariables.\\nFor frozen models , Neo expect only one .pb or .pbtxt ﬁle.\\n•PyTorch: Neo expects one .pth ﬁle containing the model deﬁnition.\\n345Amazon SageMaker Developer Guide\\nTroubleshoot Errors\\n•MXNET : Neo expects one symbol ﬁle (.json) and one parameter ﬁle (.params).\\n•XGBoost: Neo expects one XGBoost model ﬁle (.model) where the number of nodes in a tree can\\'t\\nexceed 2^31.\\n•ONNX : Neo expects one .onnx ﬁle.\\nWhat input data shapes does Neo expect?\\nNeo expects the name and shape of the expected data inputs for your trained model with a JSON\\ndictionary form or list form. The data inputs are framework speciﬁc.\\n•TensorFlow : You must specify the name and shape (NHWC format) of the expected data inputs using\\na dictionary format for your trained model. The dictionary formats required for the console and CLI are\\ndiﬀerent.\\n•Examples for one input:\\n•If using the console, {\"input\":[1,1024,1024,3]}\\n•If using the CLI, {\\\\\"input\\\\\":[1,1024,1024,3]}\\n•Examples for two inputs:\\n•If using the console, {\"data1\": [1,28,28,1], \"data2\":[1,28,28,1]}\\n•If using the CLI, {\\\\\"data1\\\\\": [1,28,28,1], \\\\\"data2\\\\\":[1,28,28,1]}\\n•MXNET/ONNX : You must specify the name and shape (NCHW format) of the expected data inputs\\nin order using a dictionary format for your trained model. The dictionary formats required for the\\nconsole and CLI are diﬀerent.\\n•Examples for one input:\\n•If using the console, {\"data\":[1,3,1024,1024]}\\n•If using the CLI, {\\\\\"data\\\\\":[1,3,1024,1024]}\\n•Examples for two inputs:\\n•If using the console, {\"var1\": [1,1,28,28], \"var2\":[1,1,28,28]}\\n•If using the CLI, {\\\\\"var1\\\\\": [1,1,28,28], \\\\\"var2\\\\\":[1,1,28,28]}\\n•PyTorch: You can either specify the name and shape (NCHW format) of expected data inputs in order\\nusing a dictionary format for your trained model or you can specify the shape only using a list format.\\nThe dictionary formats required for the console and CLI are diﬀerent. The list formats for the console\\nand CLI are the same.\\n•Examples for one input in dictionary format:\\n•If using the console, {\"input0\":[1,3,224,224]}\\n•If using the CLI, {\\\\\"input0\\\\\":[1,3,224,224]}\\n•Example for one input in list format: [[1,3,224,224]]\\n•Examples for two inputs in dictionary format:\\n•If using the console, {\"input0\":[1,3,224,224], \"input1\":[1,3,224,224]}\\n•If using the CLI, {\\\\\"input0\\\\\":[1,3,224,224], \\\\\"input1\\\\\":[1,3,224,224]}\\n•Example for two inputs in list format: [[1,3,224,224], [1,3,224,224]]\\n•XGBOOST: input data name and shape are not needed.\\nNeo Error Messages\\nThis section lists and classiﬁes Neo errors and error messages.\\nNeo Error Messages\\nThis list catalogs the user and system error messages you can receive from Neo deployments.\\n346Amazon SageMaker Developer Guide\\nTroubleshoot Errors\\n•User error messages\\n•Client permission error : Neo passes the errors for these straight through from the dependent\\nservice.\\nAccess Denied  when calling sts:AssumeRole\\nAny 400 error  when calling S3 to download or upload a client model.\\nPassRole error\\n•Load error : Keywords in error messages, \\'InputConﬁguration\\',\\'ModelSizeTooBig\\'.\\nLoad Error: InputConﬁguration : Exactly one {.xxx} ﬁle is allowed for {yyy} model.\\nLoad Error: ModelSizeTooBig: number of nodes in a tree can\\'t exceed 2^31\\n•Compilation error : Keywords in error messages, \\'OperatorNotImplemented\\',\\'\\nOperatorAttributeNotImplemented\\', \\'OperatorAttributeRequired\\', \\'OperatorAttributeValueNotValid\\'.\\nOperatorNotImplemented : {xxx} is not supported.\\nOperatorAttributeNotImplemented: {xxx} is not supported in {yyy}.\\nOperatorAttributeRequired: Required attribute {xxx} not found in {yyy}.\\nOperatorAttributeValueNotValid: The value of attribute {xxx} in operator {yyy} cannot be negative.\\n•Any Malformed Input Errors\\n•System error messages\\n•For system errors, Neo shows only one error message similar to the following: There was an\\nunexpected error during compilation, check your inputs and try again in a few minutes.\\n•This covers all unexpected errors and errors that are not user errors.\\nNeo Error Classiﬁcations\\nThis list classiﬁes the user errors  you can receive from Neo. These include access and permission errors\\nand load errors for each of the supported frameworks. All other errors are system errors .\\n•Client permission error : Neo passes the errors for these straight through from the dependent service.\\nAccess Denied  when calling sts:AssumeRole\\nAny 400 error  when calling Amazon S3 to download or upload a client model.\\nPassRole error\\n•Load error : Assuming that the Neo compiler successfully loaded .tar.gz from Amazon S3, check\\nwhether the tarball contains the necessary ﬁles for compilation. The checking criteria is framework-\\nspeciﬁc:\\n•TensorFlow: Expects only protobuf ﬁle (*.pb or *.pbtxt). For saved models , expects one variables\\nfolder.\\n•Pytorch: Expect only one pytorch ﬁle (*.pth).\\n•MXNET : Expect only one symbol ﬁle (*.json) and one parameter ﬁle (*.params).\\n•XGBoost: Expect only one XGBoost model ﬁle (*.model). The input model has size limitation.\\n•Compilation error : Assuming that the Neo compiler successfully loaded .tar.gz from Amazon S3, and\\nthat the tarball contains necessary ﬁles for compilation. The checking criteria is:\\n•OperatorNotImplemented: An operator has not been implemented.\\n•OperatorAttributeNotImplemented: The attribute in the speciﬁed operator has not been\\nimplemented.\\n347Amazon SageMaker Developer Guide\\nBatch Transform\\n•OperatorAttributeRequired: An attribute is required for an internal symbol graph, but it is not listed\\nin the user input model graph.\\n•OperatorAttributeValueNotValid: The value of the attribute in the speciﬁc operator is not valid.\\nResolve Neo Errors\\nThis section provides guidance on troubleshooting common issues with Neo. These include permission,\\nload, compilation, and system errors and errors involving invalid inputs and unsupported operations.\\n•Catalog of Known Issues:\\n•If you see Client Permission Error, review the set up documentation and make sure that you have\\ncorrectly granted the permissions that are failing.\\n•If you see Load Error , check the model format ﬁles that Neo expects for diﬀerent frameworks.\\n•If you see Compilation Error , check and address the details error message in your input model\\ngraph.\\n•If you see System Error , try again in a few minutes. If that fails, ﬁle a ticket.\\n•Lack of Roles and Permissions: Review the set up documentation and make sure that you have\\ncorrectly granted the permissions that are failing.\\n•Invalid API and Console Inputs: Fix your input as described in the validation error.\\n•Unsupported Operators:\\n•Check the failure reason where Neo has listed all unsupported operators with the keyword\\n‘OperatorNotImplemented’.\\n•For example: Compilation Error: OperatorNotImplemented: The following operators are not\\nimplemented: {\\'_sample_multinomial\\', \\'RNN\\' }\\n•Remove the unsupported operators from your input model graph and test it again.\\nBatch Transform\\nTo preprocess or get inferences for an entire dataset, use batch transform. Use batch transform when\\nyou need to work with large datasets, process datasets quickly or sub-second latency. Use preprocessing\\nto remove noise or bias from your dataset that interferes with training or inference. Use batch transform\\nfor inference when you don\\'t need a persistent endpoint. You can use batch transform for example, to\\ncompare production variants that deploy diﬀerent models.\\nTo ﬁlter input data before performing inferences or to associate input records with inferences about\\nthose records, use Associate Prediction Results with their Corresponding Input Records (p. 351). This is\\nuseful for example, to provide context for creating and interpreting reports about the output data.\\nFor more information about batch transform, see Get Inferences for an Entire Dataset with Batch\\nTransform (p. 10).\\nTopics\\n•Use Batch Transform with Large Datasets (p. 349)\\n•Speed Up a Batch Transform Job (p. 350)\\n•Use Batch Transform to Test Production Variants (p. 350)\\n•Batch Transform Errors (p. 350)\\n•Batch Transform Sample Notebooks (p. 350)\\n•Associate Prediction Results with their Corresponding Input Records (p. 351)\\n348Amazon SageMaker Developer Guide\\nUse Batch Transform with Large Datasets\\nUse Batch Transform with Large Datasets\\nBatch transform automatically manages the processing of large datasets within the limits of speciﬁed\\nparameters. For example, suppose that you have a dataset ﬁle, input1.csv , stored in an S3 bucket. The\\ncontent of the input ﬁle might look like this:\\nRecord1-Attribute1, Record1-Attribute2, Record1-Attribute3, ..., Record1-AttributeM\\nRecord2-Attribute1, Record2-Attribute2, Record2-Attribute3, ..., Record2-AttributeM\\nRecord3-Attribute1, Record3-Attribute2, Record3-Attribute3, ..., Record3-AttributeM\\n...\\nRecordN-Attribute1, RecordN-Attribute2, RecordN-Attribute3, ..., RecordN-AttributeM        \\n    \\nWhen a batch transform job starts, Amazon SageMaker initializes compute instances and distributes the\\ninference or preprocessing workload between them. When you have multiples ﬁles, one instance might\\nprocess input1.csv , and the other instance might process another ﬁle named input2.csv . To keep\\nlarge payloads within the MaxPayloadInMB limit, you might split an input ﬁle into several mini-batches.\\nFor example, you might create a mini-batch created from input1.csv , as follows.\\nRecord3-Attribute1, Record3-Attribute2, Record3-Attribute3, ..., Record3-AttributeM\\nRecord4-Attribute1, Record4-Attribute2, Record4-Attribute3, ..., Record4-AttributeM\\n            \\nNote\\nAmazon SageMaker processes each input ﬁle separately. It doesn\\'t combine mini-batches from\\ndiﬀerent input ﬁles to comply with the MaxPayloadInMB limit.\\nTo split input ﬁles into mini-batches, when you create a batch transform job, set the SplitType parameter\\nvalue to Line. If SplitType is set to None or if an input ﬁle can\\'t be split into mini-batches, Amazon\\nSageMaker uses the entire input ﬁle in a single request.\\nIf the batch transform job successfully processes all of the records in an input ﬁle, it creates an output\\nﬁle with the same name and an .out ﬁle extension. For multiple input ﬁles, such as input1.csv\\nand input2.csv , the output ﬁles are named input1.csv.out , and input2.csv.out . The\\nbatch transform job stores the output ﬁles in the speciﬁed location in Amazon S3, such as s3://\\nawsexamplebucket/output/ . The predictions in an output ﬁle are listed in the same order as\\nthe corresponding records in the input ﬁle. The following would be the contents of the output ﬁle\\ninput1.csv.out , based on the input ﬁle shown earlier.\\nInference1-Attribute1, Inference1-Attribute2, Inference1-Attribute3, ..., Inference1-\\nAttributeM\\nInference2-Attribute1, Inference2-Attribute2, Inference2-Attribute3, ..., Inference2-\\nAttributeM\\nInference3-Attribute1, Inference3-Attribute2, Inference3-Attribute3, ..., Inference3-\\nAttributeM\\n...\\nInferenceN-Attribute1, Inference3-Attribute2, Inference3-Attribute3, ..., InferenceN-\\nAttributeM            \\nTo combine the results of multiple output ﬁles into a single output ﬁle, set the AssembleWith  parameter\\nto Line .\\nWhen the input data is very large and is transmitted using HTTP chunked encoding, to stream the data\\nto the algorithm, set MaxPayloadInMB to 0. Currently, Amazon SageMaker built-in algorithms don\\'t\\nsupport this feature.\\n349Amazon SageMaker Developer Guide\\nSpeed Up a Batch Transform Job\\nFor information about using the API to create a batch transform job, see the\\nCreateTransformJob (p. 673) API. For more information about the correlation between batch transform\\ninput and output objects, see OutputDataConﬁg . For an example of how to use batch transform, see\\nStep 6.2: Deploy the Model with Batch Transform (p. 28).\\nSpeed Up a Batch Transform Job\\nIf you are using the CreateTransformJob API, you can reduce the time it takes to complete batch\\ntransform jobs by using diﬀerent parameter values, such as MaxPayloadInMB, MaxConcurrentTransforms,\\nand BatchStrategy . Amazon SageMaker automatically ﬁnds the optimal parameter settings for built-in\\nalgorithms. For custom algorithms, provide these values through an execution-parameters endpoint.\\nIf you are using the Amazon SageMaker console, you can reduce the time it takes to complete batch\\ntransform jobs by using diﬀerent parameter values, such as Max payload size (MB), Max concurrent\\ntransforms , and Batch strategy , in the Additional conﬁguration section of the Batch transform job\\nconﬁguration page. Amazon SageMaker automatically ﬁnds the optimal parameter settings for built-in\\nalgorithms. For custom algorithms, provide these values through an execution-parameters endpoint.\\nUse Batch Transform to Test Production Variants\\nTo test diﬀerent models or various hyperparameter settings, create a separate transform job for each\\nnew model variant and use a validation dataset. For each transform job, specify a unique model name\\nand location in Amazon S3 for the output ﬁle. To analyze the results, use Inference Pipeline Logs and\\nMetrics  (p. 321).\\nBatch Transform Errors\\nAmazon SageMaker uses the Amazon S3 Multipart Upload API to upload results from a batch transform\\njob to Amazon S3. If an error occurs, the uploaded results are removed from Amazon S3. In some cases,\\nsuch as when a network outage occurs, an incomplete multipart upload might remain in Amazon S3.\\nTo avoid incurring storage charges, we recommend that you add the S3 bucket policy to the S3 bucket\\nlifecycle rules. This policy deletes incomplete multipart uploads that might be stored in the S3 bucket.\\nFor more information, see Object Lifecycle Management.\\nIf a batch transform job fails to process an input ﬁle because of a problem with the dataset, Amazon\\nSageMaker marks the job as \"failed\" to alert you. If an input ﬁle contains a bad record, the transform\\njob doesn\\'t create an output ﬁle for that input ﬁle because it can\\'t maintain the same order in the\\ntransformed data. When your dataset has multiple input ﬁles, a transform job continues to process input\\nﬁles even if it fails to process one. The processed ﬁles still generate useable results.\\nExceeding the MaxPayloadInMB limit causes an error. This might happen with a large dataset if it can\\'t be\\nsplit, the SplitType parameter is set to none, or individual records within the dataset exceed the limit.\\nIf you are using your own algorithms, you can use placeholder text, such as ERROR , when the algorithm\\nﬁnds a bad record in an input ﬁle. For example, if the last record in a dataset is bad, the algorithm should\\nplace the error placeholder for that record in the output ﬁle.\\nBatch Transform Sample Notebooks\\nFor a sample notebook that uses batch transform to with a PCA model as a data reduction step on user-\\nitem review matrix followed by DBSCAN to cluster movies, see https://github.com/awslabs/amazon-\\nsagemaker-examples/blob/master/sagemaker_batch_transform/introduction_to_batch_transform/\\nbatch_transform_pca_dbscan_movie_clusters.ipynb. For instructions on creating and accessing Jupyter\\nnotebook instances that you can use to run the example in Amazon SageMaker, see Use Notebook\\nInstances (p. 36). After creating and opening a notebook instance, choose the SageMaker Examples tab\\n350Amazon SageMaker Developer Guide\\nAssociate Prediction Results with Input\\nto see a list of all the Amazon SageMaker examples. The topic modeling example notebooks that use the\\nNTM algorithms are located in the Advanced functionality section. To open a notebook, choose its Use\\ntab, then choose Create copy.\\nAssociate Prediction Results with their Corresponding\\nInput Records\\nWhen making predictions on a large dataset, attributes that are not needed for prediction can be\\nexcluded. After the predictions have been made, you often want to associate some of the excluded\\nattributes with those predictions or with other input data in your report. Amazon SageMaker Batch\\nTranform enables these data processing steps, often eliminating the need for any additional pre-\\nprocessing or post-processing. The feature supports JSON and CSV formatted input ﬁles.\\nTopics\\n•Data Processing Workﬂow for a Batch Transform Job (p. 351)\\n•Use Data Processing in Batch Transform Jobs (p. 352)\\n•Supported JSONPath Operators (p. 352)\\n•Examples  (p. 353)\\nData Processing Workﬂow for a Batch Transform Job\\nThe following diagram shows the data processing workﬂow for a batch transform job.\\nTo join the prediction results with the input data, there are three main steps:\\n•Filter the input data that is not needed for inference before passing it to the batch transform job. Use\\nthe InputFilter  parameter to determine which attributes to use as input for the model.\\n•Associate the input data with the inference results. Use JoinSource to combine the input data with the\\ninference.\\n351Amazon SageMaker Developer Guide\\nAssociate Prediction Results with Input\\n•Filter the joined data to retain the inputs needed to provide context for interpreting the predictions in\\nthe reports. Use OutputFilter  to store the speciﬁed portion of the joined dataset in the output ﬁle.\\nUse Data Processing in Batch Transform Jobs\\nTo process the data when creating a batch transform job with CreateTransformJob:\\n1.Specify the portion of the input to pass to the model with the InputFilter  parameter in the\\nDataProcessing  data structure.\\n2.Join the raw input data with the transformed data with the JoinSource  parameter.\\n3.Specify which portion of the joined input and transformed data from the batch transform job to\\ninclude in the output ﬁle with the OutputFilter  parameter.\\n4.Choose either JSON- or CSV-formatted ﬁles for input:\\n•For JSON- or JSON Lines-formatted inputs, Amazon SageMaker either adds SageMakerOutput\\nattribute to the input ﬁle or creates a new JSON output ﬁle with the attributes SageMakerInput\\nand SageMakerOutput . For more information, see DataProcessing (p. 891).\\n•For CSV-formatted input ﬁles, the joined input data is followed by the transformed data and the\\noutput is a CSV ﬁle.\\nIf you use an algorithm with the DataProcessing structure, it must support your chosen format\\nfor both  input and output ﬁles. For example, with the TransformOutput (p. 1030 ) ﬁeld of the\\nCreateTransformJob  API, you must set both the ContentType and Accept parameters to one of\\nthe following values: text/csv , application/json , or application/jsonlines . The syntax for\\nspecifying columns in a CSV ﬁle and specifying attributes in a JSON ﬁle are diﬀerent. Using the wrong\\nsyntax causes an error. For more information, see Examples  (p. 353) For more information about input\\nand output ﬁle formats for build-in algorithms, see Use Amazon SageMaker Built-in Algorithms  (p. 56).\\nThe record delimiters for the input and output must also be consistent with the your chosen ﬁle input.\\nThe SplitType parameter indicates how to split the records in the input dataset. The AssembleWith\\nparameter indicates how to reassemble the records for the output. If you set input and output formats\\nto text/csv , you must also set the SplitType  and AssemblyType  parameters to line. If you\\nset the input and output formats to application/jsonlines , you can set both SplitType  and\\nAssemblyType  to either none  or line .\\nFor JSON ﬁles, the attribute name SageMakerOutput  is reserved for output. The JSON input ﬁle can\\'t\\nhave an attribute with this name. If it does, the data in the input ﬁle might be overwritten.\\nSupported JSONPath Operators\\nTo ﬁlter and join the input data and inference, use a JSONPath subexpression. The following table lists\\nthe supported JSONPath operators.\\nJSONPath Operator Description Example\\n$ The root element to a query. This operator\\nis required at the beginning of all path\\nexpressions.\"$\"\\n.<name> A dot-notated child element. \"$.id\"\\n* A wildcard. Use in place of an attribute name\\nor numeric value.\"$.id.*\"\\n[\\'<name>\\' (,\\'<name>\\')]A bracket-notated element or multiple child\\nelements.\"$[\\'id\\',\\'SageMakerOutput\\']\"\\n352Amazon SageMaker Developer Guide\\nAssociate Prediction Results with Input\\nJSONPath Operator Description Example\\n[<number>\\n(,<number> )]An index or array of indexes. Negative index\\nvalues are also supported. A -1 index refers to\\nthe last element in an array.$[1]  , $[1,3,5]\\n[<start>:<end>]An array slice operator. If you omit <start> ,\\nAmazon SageMaker uses the ﬁrst element\\nof the array. If you omit <end>, Amazon\\nSageMaker uses the last element of the array.$[2:5] , $[:5] , $[2:]\\nNote\\nAmazon SageMaker supports only a subset of the deﬁned JSONPath operators. For more\\ninformation about JSONPath operators, see JsonPath.\\nExamples\\nThe following examples show some common ways to join input data with prediction results.\\nTopics\\n•Output Only Inference Results (p. 353)\\n•Output a Combination of Input Data and Results (p. 353)\\n•Output an ID Column with Results and Exclude the ID Column from the Input (CSV) (p. 354)\\n•Output an ID Attribute with Results and Exclude the ID Attribute from the Input (JSON) (p. 355)\\nOutput Only Inference Results\\nBy default, the DataProcessing parameter doesn\\'t join results with input and only outputs the inference\\nresults.\\nIf you want to explicity specify in code not to join results with input, use the Amazon SageMaker Python\\nSDK and specify these settings in a transformer call.\\nsm_transformer = sagemaker.transformer.Transformer(…)\\nsm_transformer.transform(…, input_filter=\"$\", join_source= \"None\", output_filter=\"$\")\\nThe following code shows the default behavior. To output an inference only using the AWS SDK for\\nPython, add it to your CreateTransformJob request:\\n{\\n    \"DataProcessing\": {\\n        \"InputFilter\": \"$\",\\n        \"JoinSource\": \"None\",\\n        \"OutputFilter\": \"$\"\\n    }\\n}\\nOutput a Combination of Input Data and Results\\nIf you are using the Amazon SageMaker Python SDK, combine the input data with the inference in the\\noutput ﬁle, specify \"Input\"  for the JoinSource parameter in a transformer call.\\nsm_transformer = sagemaker.transformer.Transformer(…)\\n353Amazon SageMaker Developer Guide\\nAssociate Prediction Results with Input\\nsm_transformer.transform(…, join_source= \"Input\")\\nIf you are using the AWS SDK for Python (Boto 3), join all input data with the inference by adding the\\nfollowing code to your CreateTransformJob (p. 673) request.\\n{\\n    \"DataProcessing\":\\n    {\\n        \"JoinSource\": \"Input\"\\n    }\\n}\\nFor JSON or JSON Lines, the results are in the SageMakerOutput  key in the input JSON ﬁle. For\\nexample, if the input is a JSON ﬁle that contains the key-value pair {\"key\":1} , the the data transform\\nresult might be {\"label\":1} .\\nAmazon SageMaker stores both in the input ﬁle under SageMakerInput  key.\\n{\\n    \"key\":1,\\n    \"SageMakerOutput\":{\"label\":1}\\n}\\nNote\\nThe joined result for JSON must be a key-value pair object. If the input is not a key-value pair\\nobject, Amazon SageMaker creates a new JSON ﬁle. In the new JSON ﬁle, the input data is\\nstored in the SageMakerInput  key and the results are stored as the SageMakerOutput  value.\\nFor a CSV ﬁle, for example, if the record is [1,2,3], and the label result is [1], then the output ﬁle\\nwould contain [1,2,3,1] .\\nOutput an ID Column with Results and Exclude the ID Column from the Input\\n(CSV)\\nIf you are using the Amazon SageMaker Python SDK, to include results or an ID column in the output,\\nspecify indexes of the joined dataset in a transformer call. For example, if your data includes ﬁve\\ncolumns an the ﬁrst one is the ID column, use the following transformer request.\\nsm_transformer = sagemaker.transformer.Transformer(…)\\nsm_transformer.transform(…, input_filter=\"$[1:]\", join_source= \"Input\",\\n output_filter=\"$[0,5:]\")\\nIf you are using the AWS SDK for Python (Boto 3), add the following code to your\\nCreateTransformJob (p. 673) request.\\n{\\n    \"DataProcessing\": {\\n        \"InputFilter\": \"$[1:]\",\\n        \"JoinSource\": \"Input\",\\n        \"OutputFilter\": \"$[0,5:]\"\\n    }\\n}\\nTo specify columns in Amazon SageMaker, index the array elements. The ﬁrst column is 0, the second\\ncolumn is 1, and the sixth column is 5. To exclude the ﬁrst column from the input, set InputFilter  to\\n\"$[1:]\" .\\n354Amazon SageMaker Developer Guide\\nElastic Inference\\nThe OutputFilter  parameter applies to the joined input and output. To index correctly, you must know\\nthe sizes of the input data combined with the inference. To include the ﬁrst three columns from the input\\ndata with the output, set the OutputFilter  to \"$[0:2, 5:]\" . The colon ‘:’ tells Amazon SageMaker\\nto include all of the elements between two values. For example, 0:2 speciﬁes the ﬁrst three columns. If\\nyou omit the number after the colon, for example, \"[0, 5:]\" , the subset ends at the last column in the\\njoined data.\\nOutput an ID Attribute with Results and Exclude the ID Attribute from the Input\\n(JSON)\\nIf you are using the Amazon SageMaker Python SDK, include results or an ID attribute in the output by\\nspecifying it in a transformer call. For example, if you store data under the features  attribute and the\\nrecord ID under the ID attribute, you would use the following transformer request.\\nsm_transformer = sagemaker.transformer.Transformer(…)\\nsm_transformer.transform(…, input_filter=\"$.features\", join_source= \"Input\",\\n output_filter=\"$[\\'id\\',\\'SageMakerOutput\\']\")\\nIf you are using the AWS SDK for Python (Boto 3), join all input data with the inference by adding the\\nfollowing code to your CreateTransformJob (p. 673) request.\\n{\\n    \"DataProcessing\": {\\n        \"InputFilter\": \"$.features\",\\n        \"JoinSource\": \"Input\",\\n        \"OutputFilter\": \"$[\\'id\\',\\'SageMakerOutput\\']\"\\n    }\\n}\\nWarning\\nThe attribute name SageMakerOutput  is reserved for the JSON output ﬁle. The JSON input ﬁle\\nmust not have an attribute with this name. If it does, the input ﬁle values might be overwritten\\nwith the inference.\\nAmazon SageMaker Elastic Inference (EI)\\nBy using Amazon Elastic Inference (EI), you can speed up the throughput and decrease the latency of\\ngetting real-time inferences from your deep learning models that are deployed as Amazon SageMaker\\nhosted models , but at a fraction of the cost of using a GPU instance for your endpoint. EI allows you to\\nadd inference acceleration to a hosted endpoint for a fraction of the cost of using a full GPU instance.\\nAdd an EI accelerator in one of the available sizes to a deployable model in addition to a CPU instance\\ntype, and then add that model as a production variant to an endpoint conﬁguration that you use to\\ndeploy a hosted endpoint. You can also add an EI accelerator to a Amazon SageMaker notebook instance\\nso that you can test and evaluate inference performance when you are building your models.\\nElastic Inference is supported in EI-enabled versions of TensorFlow and MXNet. To use any other deep\\nlearning framework, export your model by using ONNX, and then import your model into MXNet. You\\ncan then use your model with EI as an MXNet model. For information about importing an ONNX model\\ninto MXNet, see https://mxnet.incubator.apache.org/tutorials/onnx/super_resolution.html.\\nTopics\\n•How EI Works (p. 356)\\n•Choose an EI Accelerator Type (p. 356)\\n355Amazon SageMaker Developer Guide\\nHow EI Works\\n•Use EI in a Amazon SageMaker Notebook Instance (p. 356)\\n•Use EI on a Hosted Endpoint  (p. 357)\\n•Frameworks that Support EI (p. 357)\\n•Use EI with Amazon SageMaker Built-in Algorithms (p. 357)\\n•EI Sample Notebooks  (p. 357)\\n•Set Up to Use EI  (p. 358)\\n•Attach EI to a Notebook Instance (p. 361)\\n•Use EI on Amazon SageMaker Hosted Endpoints (p. 363)\\nHow EI Works\\nEI accelerators are network attached devices that work along with EC2 instances in your endpoint to\\naccelerate your inference calls. When your model is deployed as an endpoint, ML frameworks use a\\ncombination of EC2 instance and accelerator resources to execute inference calls.\\nThe following EI accelerator types are available. You can conﬁgure your endpoints or notebook instances\\nwith any EI accelerator type.\\nIn the table, the throughput in teraﬂops (TFLOPS) is listed for both single-precision ﬂoating-point (F32)\\nand half-precision ﬂoating-point (F16) operations. The memory in GB is also listed.\\nAccelerator Type F32 Throughput in\\nTFLOPSF16 Throughput in\\nTFLOPSMemory in GB\\nml.eia1.medium 1 8 1\\nml.eia1.large 2 16 2\\nml.eia1.xlarge 4 32 4\\nChoose an EI Accelerator Type\\nConsider the following factors when choosing an accelerator type for a hosted model:\\n•Models, input tensors and batch sizes inﬂuence the amount of accelerator memory you need. Start\\nwith an accelerator type that provides at least as much memory as the ﬁle size of your trained model.\\n•Demands on CPU compute resources, GPU-based acceleration, and CPU memory vary signiﬁcantly\\nbetween diﬀerent kinds of deep learning models. The latency and throughput requirements of the\\napplication also determine the amount of compute and acceleration you need. Thoroughly test\\ndiﬀerent conﬁgurations of instance types and EI accelerator sizes to make sure you choose the\\nconﬁguration that best ﬁts the performance needs of your application.\\nUse EI in a Amazon SageMaker Notebook Instance\\nTypically, you build and test machine learning models in a Amazon SageMaker notebook before you\\ndeploy them for production. You can attach EI to your notebook instance when you create the notebook\\ninstance. You can set up an endpoint that is hosted locally on the notebook instance by using the local\\nmode supported by TensorFlow and MXNet estimators and models in the Amazon SageMaker Python\\nSDK to test inference performance. For instructions on how to attach EI to a notebook instance and set\\nup a local endpoint for inference, see Attach EI to a Notebook Instance (p. 361).\\n356Amazon SageMaker Developer Guide\\nUse EI on a Hosted Endpoint\\nUse EI on a Hosted Endpoint\\nWhen you are ready to deploy your model for production to provide inferences, you create a Amazon\\nSageMaker hosted endpoint. You can attach EI to the instance where your endpoint is hosted to increase\\nits performance at providing inferences. For instructions on how to attach EI to a hosted endpoint\\ninstance, see Use EI on Amazon SageMaker Hosted Endpoints (p. 363).\\nFrameworks that Support EI\\nEI is designed to be used with AWS enhanced versions of TensorFlow or Apache MXNet machine learning\\nframeworks. These enhanced versions of the frameworks are automatically built into containers when\\nyou use the Amazon SageMaker Python SDK, or you can download them as binary ﬁles and import\\nthem in your own Docker containers. You can download the EI-enabled binary for TensorFlow from\\nthe Amazon S3 bucket at  https://s3.console.aws.amazon.com/s3/buckets/amazonei-tensorﬂow.\\nFor information about building a container that uses the EI-enabled version of TensorFlow, see\\nhttps://github.com/aws/sagemaker-tensorﬂow-container#building-the-sagemaker-elastic-inference-\\ntensorﬂow-serving-container. You can download the EI-enabled binary for Apache MXNet from the\\npublic Amazon S3 bucket at https://s3.console.aws.amazon.com/s3/buckets/amazonei-apachemxnet.\\nFor information about buidling a container that uses the EI-enabled version of MXNet, see https://\\ngithub.com/aws/sagemaker-mxnet-container#building-the-sagemaker-elastic-inference-mxnet-\\ncontainer.\\nTo use EI in a hosted endpoint, you can use any of the following, depending on your needs.\\n•SageMaker Python SDK TensorFlow - if you want to use TensorFlow and you don\\'t need to build a\\ncustom container.\\n•SageMaker Python SDK MXNet - if you want to use MXNet and you don\\'t need to build a custom\\ncontainer.\\n•The low-level AWS Amazon SageMaker SDK for Python (Boto 3) - if you need to build a custom\\ncontainer.\\nTypically, you don\\'t need to create a custom container unless your model is very complex and requires\\nextensions to a framework that the Amazon SageMaker pre-built containers do not support.\\nUse EI with Amazon SageMaker Built-in Algorithms\\nCurrently, the Image Classiﬁcation Algorithm  (p. 108) and Object Detection Algorithm (p. 199) built-in\\nalgorithms support EI. For an example that uses the Image Classiﬁcation algorithm with EI, see https://\\ngithub.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/\\nimageclassiﬁcation_caltech/Image-classiﬁcation-fulltraining.ipynb.\\nEI Sample Notebooks\\nThe following Sample notebooks provide examples of using EI in Amazon SageMaker:\\n•https://github.com/awslabs/amazon-sagemaker-examples/blob/master/\\nsagemaker-python-sdk/tensorﬂow_iris_dnn_classiﬁer_using_estimators/\\ntensorﬂow_iris_dnn_classiﬁer_using_estimators_elastic_inference.ipynb\\n•https://github.com/awslabs/amazon-sagemaker-examples/blob/master/\\nsagemaker-python-sdk/tensorﬂow_iris_dnn_classiﬁer_using_estimators/\\ntensorﬂow_iris_dnn_classiﬁer_using_estimators_elastic_inference_local.ipynb\\n•https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/\\nmxnet_mnist/mxnet_mnist_elastic_inference.ipynb\\n357Amazon SageMaker Developer Guide\\nSet Up to Use EI\\n•https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/\\nmxnet_mnist/mxnet_mnist_elastic_inference_local.ipynb\\n•https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-\\npython-sdk/tensorﬂow_serving_using_elastic_inference_with_your_own_model/\\ntensorﬂow_serving_pretrained_model_elastic_inference.ipynb\\nSet Up to Use EI\\nUse the instructions in this topic only if one of the following applies to you:\\n•You want to use a customized role or permission policy.\\n•You want to use a VPC for your hosted model or notebook instance.\\nNote\\nIf you already have an execution role that has the AmazonSageMakerFullAccess  managed\\npolicy attached (this is true for any IAM role that you create when you create a notebook\\ninstance, training job, or model in the console) and you are not connecting to an EI model or\\nnotebook instance in a VPC, you do not need to make any of these changes to use EI in Amazon\\nSageMaker.\\nTopics\\n•Set Up Required Permissions (p. 358)\\n•Use a Custom VPC to Connect to EI (p. 360)\\nSet Up Required Permissions\\nTo use EI in Amazon SageMaker, the role that you use to open a notebook instance or create a\\ndeployable model must have a policy with the required permissions attached. You can attach the\\nAmazonSageMakerFullAccess  managed policy, which contains the required permissions, to the role,\\nor you can add a custom policy that has the required permissions. For information about creating an IAM\\nrole, see Creating a Role for an AWS Service (Console) in the AWS Identity and Access Management User\\nGuide . For information about attaching a policy to a role, see Adding and Removing IAM Policies .\\nAdd these permissions speciﬁcally for connecting EI in an IAM policy:\\n{\\n    \"Effect\": \"Allow\",\\n    \"Action\": [\\n        \"elastic-inference:Connect\",\\n        \"ec2:DescribeVpcEndpoints\"\\n    ],\\n    \"Resource\": \"*\"\\n}\\n            \\nThe following IAM policy is the complete list of required permissions to use EI in Amazon SageMaker:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"elastic-inference:Connect\",\\n                \"ec2:DescribeVpcEndpoints\"\\n358Amazon SageMaker Developer Guide\\nSet Up to Use EI\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:*\"\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"ecr:GetAuthorizationToken\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\",\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"cloudwatch:PutMetricData\",\\n                \"cloudwatch:PutMetricAlarm\",\\n                \"cloudwatch:DescribeAlarms\",\\n                \"cloudwatch:DeleteAlarms\",\\n                \"ec2:CreateNetworkInterface\",\\n                \"ec2:CreateNetworkInterfacePermission\",\\n                \"ec2:DeleteNetworkInterface\",\\n                \"ec2:DeleteNetworkInterfacePermission\",\\n                \"ec2:DescribeNetworkInterfaces\",\\n                \"ec2:DescribeVpcs\",\\n                \"ec2:DescribeDhcpOptions\",\\n                \"ec2:DescribeSubnets\",\\n                \"ec2:DescribeSecurityGroups\",\\n                \"application-autoscaling:DeleteScalingPolicy\",\\n                \"application-autoscaling:DeleteScheduledAction\",\\n                \"application-autoscaling:DeregisterScalableTarget\",\\n                \"application-autoscaling:DescribeScalableTargets\",\\n                \"application-autoscaling:DescribeScalingActivities\",\\n                \"application-autoscaling:DescribeScalingPolicies\",\\n                \"application-autoscaling:DescribeScheduledActions\",\\n                \"application-autoscaling:PutScalingPolicy\",\\n                \"application-autoscaling:PutScheduledAction\",\\n                \"application-autoscaling:RegisterScalableTarget\",\\n                \"logs:CreateLogGroup\",\\n                \"logs:CreateLogStream\",\\n                \"logs:DescribeLogStreams\",\\n                \"logs:GetLogEvents\",\\n                \"logs:PutLogEvents\"\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:GetObject\",\\n                \"s3:PutObject\",\\n                \"s3:DeleteObject\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3:::*SageMaker*\",\\n                \"arn:aws:s3:::*Sagemaker*\",\\n                \"arn:aws:s3:::*sagemaker*\"\\n            ]\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:CreateBucket\",\\n                \"s3:GetBucketLocation\",\\n359Amazon SageMaker Developer Guide\\nSet Up to Use EI\\n                \"s3:ListBucket\",\\n                \"s3:ListAllMyBuckets\"\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:GetObject\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEqualsIgnoreCase\": {\\n                    \"s3:ExistingObjectTag/SageMaker\": \"true\"\\n                }\\n            }\\n        },\\n        {\\n            \"Action\": \"iam:CreateServiceLinkedRole\",\\n            \"Effect\": \"Allow\",\\n            \"Resource\": \"arn:aws:iam::*:role/aws-service-role/sagemaker.application-\\nautoscaling.amazonaws.com/AWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint\",\\n            \"Condition\": {\\n                \"StringLike\": {\\n                    \"iam:AWSServiceName\": \"sagemaker.application-autoscaling.amazonaws.com\"\\n                }\\n            }\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"iam:PassRole\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\\n                }\\n            }\\n        }\\n    ]\\n}\\n            \\nUse a Custom VPC to Connect to EI\\nTo use EI with Amazon SageMaker in a VPC, you need to create and conﬁgure two security groups,\\nand set up a PrivateLink VPC interface endpoint. EI uses VPC interface endpoint to communicate with\\nAmazon SageMaker endpoints in your VPC. The security groups you create are used to connect to the\\nVPC interface endpoint.\\nSet up Security Groups to Connect to EI\\nTo use EI within a VPC, you need to create two security groups:\\n•A security group to control access to the VPC interface endpoint that you will set up for EI.\\n•A security group that allows Amazon SageMaker to call into the ﬁrst security group.\\nComplete the following steps to conﬁgure the two security groups:\\n1. Create a security group with no outbound connections. You will attach this to the VPC endpoint\\ninterface you create in the next section.\\n360Amazon SageMaker Developer Guide\\nAttaching EI to a Notebook Instance\\n2. Create a second security group with no inbound connections, but with an outbound connection to\\nthe ﬁrst security group.\\n3. Edit the ﬁrst security group to allow inbound connections only to the second security group an all\\noutbound connections.\\nFor more information about VPC security groups, see Security Groups for Your VPC in the Amazon Virtual\\nPrivate Cloud User Guide .\\nSet up a VPC Interface Endpoint to Connect to EI\\nTo use EI with Amazon SageMaker in a custom VPC, you need to set up a VPC interface endpoint\\n(PrivateLink) for the EI service.\\n•Set up a VPC interface endpoint (PrivateLink) for the EI. Follow the instructions at Creating\\nan Interface Endpoint. In the list of services, choose com.amazonaws.<region>.elastic-\\ninference.runtime. For Security group, make sure you select the ﬁrst security group you created in the\\nprevious section to the endpoint.\\n•When you set up the interface endpoint, choose all of the Availability Zones where EI is available. EI\\nfails if you do not set up at least two Availability Zones. For information about VPC subnets, see VPCs\\nand Subnets .\\nAttach EI to a Notebook Instance\\nTo test and evaluate inference performance using EI, you can attach EI to a notebook instance when you\\ncreate or update a notebook instance. You can then use EI in local mode to host a model at an endpoint\\nhosted on the notebook instance. You should test various sizes of notebook instances and EI accelerators\\nto evaluate the conﬁguration that works best for your use case.\\nSet Up to Use EI\\nTo use EI locally in a notebook instance, create a notebook instance with an EI instance. To do this:\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker\\n2. In the navigation pane, choose Notebook instances.\\n3. Choose Create notebook instance.\\n4. For Notebook instance name, provide a unique name for your notebook instance.\\n5. For notebook instance type, choose a CPU instance such as ml.t2.medium.\\n6. For Elastic Inference (EI), choose an instance from the list, such as ml.eia1.medium .\\n7. For IAM role, choose an IAM role that has the required permissions to use Amazon SageMaker and\\nEI.\\n8. (Optional) For VPC - Optional , if you want the notebook instance to use a VPC, choose one from the\\navailable list, otherwise leave it as No VPC . If you use a VPC follow the instructions at Use a Custom\\nVPC to Connect to EI (p. 360).\\n9. (Optional) For Lifecycle conﬁguration - optional, either leave it as No conﬁguration or choose a\\nlifecycle conﬁguration. For more information, see Customize a Notebook Instance  (p. 40).\\n10. (Optional) For Encryption key - optional, Optional) If you want Amazon SageMaker to use an AWS\\nKey Management Service key to encrypt data in the ML storage volume attached to the notebook\\ninstance, specify the key.\\n11. (Optional) For Volume Size In GB - optional, leave the default value of 5.\\n12. (Optional) For Tags, add tags to the notebook instance. A tag is a label you assign to help manage\\nyour notebook instances. A tag consists of a key and a value both of which you deﬁne.\\n361Amazon SageMaker Developer Guide\\nAttaching EI to a Notebook Instance\\n13. Choose Create Notebook Instance.\\nAfter you create your notebook instance with EI attached, you can create a Jupyter notebook and set up\\nan EI endpoint that is hosted locally on the notebook instance.\\nTopics\\n•Use EI in Local Mode in Amazon SageMaker (p. 362)\\nUse EI in Local Mode in Amazon SageMaker\\nTo use EI locally in an endpoint hosted on a notebook instance, use local mode with the Amazon\\nSageMaker Python SDK versions of either the TensorFlow or MXNet estimators or models. For more\\ninformation about local mode support in the Amazon SageMaker Python SDK, see https://github.com/\\naws/sagemaker-python-sdk#sagemaker-python-sdk-overview.\\nTopics\\n•Use EI in Local Mode with Amazon SageMaker TensorFlow Estimators and Models (p. 362)\\n•Use EI in Local Mode with Amazon SageMaker Apache MXNet Estimators and Models (p. 362)\\nUse EI in Local Mode with Amazon SageMaker TensorFlow Estimators and\\nModels\\nTo use EI with TensorFlow in local mode, specify local  for instance_type  and\\nlocal_sagemaker_notebook  for accelerator_type  when you call the deploy  method of an\\nestimator or a model object. For more information about Amazon SageMaker Python SDK TensorFlow\\nestimators and models, see https://github.com/aws/sagemaker-python-sdk/blob/master/src/\\nsagemaker/tensorﬂow/README.rst.\\nThe following code shows how to use local mode with an estimator object. To call the deploy  method,\\nyou must have previously either:\\n•Trained the model by calling the fit method of an estimator.\\n•Pass a model artifact when you initialize the model object.\\n# Deploys the model to a local endpoint\\ntf_predictor = tf_model.deploy(initial_instance_count=1,\\n                               instance_type=\\'local\\',\\n                               accelerator_type=\\'local_sagemaker_notebook\\')\\nFor a complete example of using EI in local mode with TensorFlow, see the sample\\nnotebook at https://github.com/awslabs/amazon-sagemaker-examples/blob/\\nmaster/sagemaker-python-sdk/tensorﬂow_iris_dnn_classiﬁer_using_estimators/\\ntensorﬂow_iris_dnn_classiﬁer_using_estimators_elastic_inference_local.ipynb\\nUse EI in Local Mode with Amazon SageMaker Apache MXNet Estimators and\\nModels\\nTo use EI with MXNet in local mode, specify local  for instance_type  and\\nlocal_sagemaker_notebook  for accelerator_type  when you call the deploy  method of an\\nestimator or a model object. For more information about Amazon SageMaker Python SDK MXNet\\nestimators and models, see https://github.com/aws/sagemaker-python-sdk/blob/master/src/\\nsagemaker/mxnet/README.rst.\\n362Amazon SageMaker Developer Guide\\nEndpoints with Elastic Inference\\nThe following code shows how to use local mode with an estimator object. You must have previously\\ncalled the fit method of the estimator to train the model.\\n# Deploys the model to a local endpoint\\nmxnet_predictor = mxnet_estimator.deploy(initial_instance_count=1,\\n                                         instance_type=\\'local\\',\\n                                         accelerator_type=\\'local_sagemaker_notebook\\')\\nFor a complete example of using EI in local mode with MXNet, see the sample notebook at https://\\ngithub.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/\\nmxnet_mnist_elastic_inference_local.ipynb .\\nUse EI on Amazon SageMaker Hosted Endpoints\\nTo use Elastic Inference (EI) in Amazon SageMaker with a hosted endpoint for real-time inference, specify\\nan EI accelerator when you create the deployable model to be hosted at that endpoint. You can do this in\\none of the following ways:\\n•Use the Amazon SageMaker Python SDK versions of either the TensorFlow or MXNet and the Amazon\\nSageMaker pre-built containers for TensorFlow and MXNet\\n•Build your own container, and use the low-level Amazon SageMaker API (Boto 3). You will need to\\nimport the EI-enabled version of either TensorFlow or MXNet from the provided Amazon S3 locations\\ninto your container, and use one of those versions to write your training script.\\n•Use either the Image Classiﬁcation Algorithm  (p. 108) or Object Detection Algorithm (p. 199) build-\\nin algorithms, and use Boto 3 to run your training job and create your deployable model and hosted\\nendpoint.\\nTopics\\n•Use EI with an Amazon SageMaker TensorFlow Container (p. 363)\\n•Use EI with an Amazon SageMaker MXNet Container (p. 364)\\n•Use EI with Your Own Container (p. 364)\\nUse EI with an Amazon SageMaker TensorFlow Container\\nTo use TensorFlow with EI in Amazon SageMaker, you need to call the deploy  method of either the\\nEstimator  or Model  objects. You then specify an accelerator type using the accelerator_type input\\nargument. For information on using TensorFlow in the Amazon SageMaker Python SDK, see: https://\\ngithub.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorﬂow/README.rst.\\nAmazon SageMaker provides default model training and inference code for your convenience. For custom\\nﬁle formats, you might need to implement custom model training and inference code.\\nUse an Estimator Object\\nTo use an estimator object with EI, include the accelerator_type  input argument when you use the\\ndeploy method. The estimator returns a predictor object which we call its deploy method as shown in the\\nexample code:\\n# Deploy an estimator using EI (using the accelerator_type input argument)\\npredictor = estimator.deploy(initial_instance_count=1,\\n                             instance_type=\\'ml.m4.xlarge\\',\\n                             accelerator_type=\\'ml.eia1.medium\\')\\n363Amazon SageMaker Developer Guide\\nEndpoints with Elastic Inference\\nUse a Model Object\\nTo use a model object with EI, include the accelerator_type  input argument when you use the deploy\\nmethod. The estimator returns a predictor object which we call its deploy method as shown in the\\nexample code:\\n# Deploy a model using EI (using the accelerator_type input argument)\\npredictor = model.deploy(initial_instance_count=1,\\n                             instance_type=\\'ml.m4.xlarge\\',\\n                             accelerator_type=\\'ml.eia1.medium\\')\\nUse EI with an Amazon SageMaker MXNet Container\\nTo use MXNet with EI in Amazon SageMaker, you need to call the deploy  method of either the Estimator\\nor Model  objects. You then specify an accelerator type using the accelerator_type input argument.\\nFor information on using MXNet in the Amazon SageMaker Python SDK, see https://github.com/aws/\\nsagemaker-python-sdk/blob/master/src/sagemaker/mxnet/README.rst\\nAmazon SageMaker provides default model training and inference code for your convenience. For custom\\nﬁle formats, you might need to implement custom model training and inference code.\\nUse an Estimator Object\\nTo use an estimator object with EI, include the accelerator_type  input argument when you use the\\ndeploy method. The estimator returns a predictor object which we call its deploy method as shown in the\\nexample code:\\n# Deploy an estimator using EI (using the accelerator_type input argument)\\npredictor = estimator.deploy(initial_instance_count=1,\\n                             instance_type=\\'ml.m4.xlarge\\',\\n                             accelerator_type=\\'ml.eia1.medium\\')\\nUse a Model Object\\nTo use a model object with EI, include the accelerator_type  input argument when you use the deploy\\nmethod. The estimator returns a predictor object which we call its deploy method as shown in the\\nexample code:\\n# Deploy a model using EI (using the accelerator_type input argument)\\npredictor = model.deploy(initial_instance_count=1,\\n                             instance_type=\\'ml.m4.xlarge\\',\\n                             accelerator_type=\\'ml.eia1.medium\\')\\nFor a complete example of using EI with MXNet in Amazon SageMaker, see the sample notebook at\\nhttps://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/\\nmxnet_mnist/mxnet_mnist_elastic_inference.ipynb\\nUse EI with Your Own Container\\nTo use EI with a model in a custom container that you build, use the low-level Amazon SageMaker SDK\\nfor Python (Boto 3). download and import the AWS EI-enabled versions of TensorFlow or Apache MXNet\\nmachine learning frameworks, and write your training script using those frameworks.\\nImport the EI Version of TensorFlow or MXNet into Your Docker Container\\nTo use EI with your own container, you need to import either the Amazon EI TensorFlow Serving library\\nor the Amazon EI Apache MXNet library into your container. The EI-enabled versions of TensorFlow and\\n364Amazon SageMaker Developer Guide\\nAutomatically Scale Amazon SageMaker Models\\nMXNet are currently available as binary ﬁles stored in Amazon S3 locations. You can download the EI-\\nenabled binary for TensorFlow from the Amazon S3 bucket at  https://s3.console.aws.amazon.com/\\ns3/buckets/amazonei-tensorﬂow. For information about building a container that uses the EI-enabled\\nversion of TensorFlow, see https://github.com/aws/sagemaker-tensorﬂow-container#building-the-\\nsagemaker-elastic-inference-tensorﬂow-serving-container. You can download the EI-enabled binary for\\nApache MXNet from the public Amazon S3 bucket at https://s3.console.aws.amazon.com/s3/buckets/\\namazonei-apachemxnet. For information about building a container that uses the EI-enabled version\\nof MXNet, see https://github.com/aws/sagemaker-mxnet-container#building-the-sagemaker-elastic-\\ninference-mxnet-container.\\nCreate an EI Endpoint with Boto 3\\nTo create an endpoint by using Boto 3, you ﬁrst create an endpoint conﬁguration. The endpoint\\nconﬁguration speciﬁes one or more models (called production variants) that you want to host at the\\nendpoint. To attach EI to one or more of the production variants hosted at the endpoint, you specify one\\nof the EI instance types as the AcceleratorType  ﬁeld for that ProductionVariant . You then pass\\nthat endpoint conﬁguration when you create the endpoint.\\nCreate an Endpoint Conﬁguration\\nTo use EI, you need to specify an accelerator type in the endpoint conﬁguration:\\n# Create Endpoint Configuration\\nfrom time import gmtime, strftime\\nendpoint_config_name = \\'ImageClassificationEndpointConfig-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\",\\n gmtime())\\nprint(endpoint_config_name)\\ncreate_endpoint_config_response = sagemaker.create_endpoint_config(\\n    EndpointConfigName = endpoint_config_name,\\n    ProductionVariants=[{\\n        \\'InstanceType\\':\\'ml.m4.xlarge\\',\\n        \\'InitialInstanceCount\\':1,\\n        \\'ModelName\\':model_name,\\n        \\'VariantName\\':\\'AllTraffic\\',\\n        \\'AcceleratorType\\':\\'ml.eia1.medium\\'}])\\nprint(\"Endpoint Config Arn: \" + create_endpoint_config_response[\\'EndpointConfigArn\\'])\\nCreate an Endpoint\\nAfter you create an endpoint conﬁguration with an accelerator type, you can proceed to create an\\nendpoint.\\nendpoint_name = \\'ImageClassificationEndpoint-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nendpoint_response = sagemaker.create_endpoint(\\n    EndpointName=endpoint_name,\\n    EndpointConfigName=endpoint_config_name)\\nAfter the endpoint is created you can invoke it using the invoke_endpoint method in a boto3 runtime\\nobject as you would any other endpoint.\\nAutomatically Scale Amazon SageMaker Models\\nAmazon SageMaker supports automatic scaling for production variants. Automatic scaling  dynamically\\nadjusts the number of instances provisioned for a production variant in response to changes in your\\n365Amazon SageMaker Developer Guide\\nAutomatic Scaling Components\\nworkload. When the workload increases, automatic scaling brings more instances online. When the\\nworkload decreases, automatic scaling removes unnecessary instances so that you don\\'t pay for\\nprovisioned variant instances that you aren\\'t using.\\nTo use automatic scaling for a production variant, you deﬁne and apply a scaling policy that uses\\nAmazon CloudWatch metrics and target values that you assign. Automatic scaling uses the policy to\\nadjust the number of instances up or down in response to actual workloads.\\nYou can use the AWS Management Console to apply a scaling policy based on a predeﬁned metric. A\\npredeﬁned metric  is deﬁned in an enumeration so that you can specify it by name in code or use it in the\\nAWS Management Console. Alternatively, you can use either the AWS Command Line Interface (AWS CLI)\\nor the Application Auto Scaling API to apply a scaling policy based on a predeﬁned or custom metric.\\nWe strongly recommend that you load test your automatic scaling conﬁguration to ensure that it works\\ncorrectly before using it to manage production traﬃc.\\nFor information about deploying trained models as endpoints, see Step 6.1: Deploy the Model to\\nAmazon SageMaker Hosting Services  (p. 26).\\nTopics\\n•Automatic Scaling Components  (p. 366)\\n•Before You Begin (p. 368)\\n•Related Topics (p. 369)\\n•Conﬁgure Automatic Scaling for a Production Variant (p. 369)\\n•Edit a Scaling Policy (p. 375)\\n•Delete a Scaling Policy (p. 375)\\n•Update Endpoints that Use Automatic Scaling  (p. 377)\\n•Load Testing for Production Variant Automatic Scaling (p. 377)\\n•Best Practices for Conﬁguring Automatic Scaling (p. 378)\\nAutomatic Scaling Components\\nTo adjust the number of instances hosting a production variant, Amazon SageMaker automatic scaling\\nuses a scaling policy . Automatic scaling has the following components:\\n•Required permissions—Permissions that are required to perform automatic scaling actions.\\n•A service-linked role—An AWS Identity and Access Management (IAM) role that is linked to a speciﬁc\\nAWS service. A service-linked role includes all of the permissions that the service requires to call other\\nAWS services on your behalf. Amazon SageMaker automatic scaling automatically generates this role,\\nAWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint , for you.\\n•A target metric—The Amazon CloudWatch metric that Amazon SageMaker automatic scaling uses to\\ndetermine when and how much to scale.\\n•Minimum and maximum capacity—The minimum and maximum number of instances to use for scaling\\nthe variant.\\n•A cool down period—The amount of time, in seconds, after a scale-in or scale-out activity completes\\nbefore another scale-out activity can start.\\nRequired Permissions for Automatic Scaling\\nThe SagemakerFullAccessPolicy  IAM policy has all of the permissions required to perform\\nautomatic scaling actions. For more information about Amazon SageMaker IAM roles, see Amazon\\nSageMaker Roles  (p. 496).\\n366Amazon SageMaker Developer Guide\\nAutomatic Scaling Components\\nIf you are using a custom permission policy, you must include the following permissions:\\n{ \\n \"Effect\": \"Allow\", \\n \"Action\": [ \\n  \"sagemaker:DescribeEndpoint\", \\n  \"sagemaker:DescribeEndpointConfig\", \\n  \"sagemaker:UpdateEndpointWeightsAndCapacities\" \\n ], \\n \"Resource\": \"*\"  \\n}\\n                {\\n    \"Action\": [\\n        \"application-autoscaling:*\"\\n    ],\\n    \"Effect\": \"Allow\",\\n    \"Resource\": \"*\"\\n}\\n{\\n \"Action\": \"iam:CreateServiceLinkedRole\",\\n \"Effect\": \"Allow\",\\n \"Resource\":\\n \"arn:aws:iam::*:role/aws-service-role/sagemaker.application-autoscaling.amazonaws.com/\\nAWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint\",\\n \"Condition\": {\\n  \"StringLike\": { \"iam:AWSServiceName\": \"sagemaker.application-autoscaling.amazonaws.com\" }\\n }\\n}\\n{ \\n \"Effect\": \"Allow\", \\n \"Action\": [ \\n  \"cloudwatch:PutMetricAlarm\", \\n  \"cloudwatch:DescribeAlarms\", \\n  \"cloudwatch:DeleteAlarms\" \\n ], \\n \"Resource\": \"*\" \\n}\\n                \\n            \\nService-Linked Role for Automatic Scaling\\nA service-linked role is a unique type of IAM role that is linked directly to an AWS service.\\nService-linked roles are predeﬁned by the service and include all of the permissions that\\nthe service requires to call other AWS services on your behalf. Automatic scaling uses the\\nAWSServiceRoleForApplicationAutoScaling_SageMakerEndpoint  service-linked role. For more\\ninformation, see Service-Linked Roles for Application Auto Scaling in the Application Auto Scaling User\\nGuide .\\nTarget Metric for Automatic Scaling\\nAmazon SageMaker automatic scaling uses target-tracking scaling policies. You conﬁgure the target-\\ntracking scaling policy by specifying a predeﬁned or custom metric and a target value for the metric . For\\nmore information, see Target Tracking Scaling Policies.\\nAmazon CloudWatch alarms trigger the scaling policy , which calculate how to adjust scaling based\\non the metric and target value that you set. The scaling policy adds or removes endpoint instances\\nas required to keep the metric at, or close to, the speciﬁed target value. In addition, a target-tracking\\nscaling policy also adjusts to ﬂuctuations in the metric when a workload changes. The policy minimizes\\nrapid ﬂuctuations in the number of available instances for your variant.\\n367Amazon SageMaker Developer Guide\\nBefore You Begin\\nFor example, a scaling policy that uses the predeﬁned InvocationsPerInstance  metric with a target\\nvalue of 70 can keep InvocationsPerInstance  at, or close to 70.\\nMinimum and Maximum Capacity for Automatic Scaling\\nYou can specify the maximum number of endpoint instances that Application Auto Scaling manages for\\nthe variant. The maximum value must be equal to or greater than the value speciﬁed for the minimum\\nnumber of endpoint instances. Amazon SageMaker automatic scaling does not enforce a limit for this\\nvalue.\\nYou can also specify the minimum number of instances that Application Auto Scaling manages for the\\nvariant. This value must be at least 1, and equal to or less than the value speciﬁed for the maximum\\nnumber of variant instances.\\nTo determine the minimum and maximum number of instances that you need for typical traﬃc, test your\\nautomatic scaling conﬁguration with the expected rate of traﬃc to your variant.\\nCooldown Period for Automatic Scaling\\nTune the responsiveness of a target-tracking scaling policy by adding a cooldown period. A cooldown\\nperiod  controls when your variant is scaled in and out by blocking subsequent scale-in or scale-out\\nrequests until the period expires. This slows the deletion of variant instances for scale-in requests, and\\nthe creation of variant instances for scale-out requests. A cooldown period helps to ensure that it doesn\\'t\\nlaunch or terminate additional instances before the previous scaling activity takes eﬀect. After automatic\\nscaling dynamically scales using a scaling policy, it waits for the cooldown period to complete before\\nresuming scaling activities.\\nYou conﬁgure the cooldown period in your automatic scaling policy. You can specify the following\\ncooldown periods:\\n•A scale-in activity reduces the number of variant instances. A scale-in cooldown period speciﬁes the\\namount of time, in seconds, after a scale-in activity completes before another scale-in activity can\\nstart.\\n•A scale-out activity increases the number of variant instances. A scale-out cooldown period speciﬁes\\nthe amount of time, in seconds, after a scale-out activity completes before another scale-out activity\\ncan start.\\nIf you don\\'t specify a scale-in or a scale-out cooldown period automatic scaling use the default, which is\\n300 seconds for each.\\nIf instances are being added or removed too quickly when you test your automatic scaling conﬁguration,\\nconsider increasing this value. You can see this behavior if the traﬃc to your variant has a lot of spikes, or\\nif you have multiple automatic scaling policies deﬁned for a variant.\\nIf instances are not being added quickly enough to address increased traﬃc, consider decreasing this\\nvalue.\\nBefore You Begin\\nBefore you can use automatically scaled model deployment, create an Amazon SageMaker model\\ndeployment. For more information about deploying a model endpoint, see Step 6.1: Deploy the Model to\\nAmazon SageMaker Hosting Services  (p. 26).\\nWhen automatic scaling adds a new variant instance, it is the same instance class as the one used by the\\nprimary instance.\\n368Amazon SageMaker Developer Guide\\nRelated Topics\\nRelated Topics\\n•What Is Application Auto Scaling?\\nConﬁgure Automatic Scaling for a Production Variant\\nYou can conﬁgure automatic scaling for a variant with the AWS Management Console, the AWS CLI, or\\nthe Application Auto Scaling API.\\nTopics\\n•Conﬁgure Automatic Scaling for a Production Variant (Console) (p. 369)\\n•Conﬁgure Automatic Scaling for a Production Variant (AWS CLI or the Application Auto Scaling\\nAPI) (p. 370)\\nConﬁgure Automatic Scaling for a Production Variant (Console)\\nTo conﬁgure automatic scaling for a production variant (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. In the navigation pane, choose Endpoints .\\n3. Choose the endpoint that you want to conﬁgure.\\n4. For Endpoint runtime settings, choose the variant that you want to conﬁgure.\\n5. For Endpoint runtime settings, choose Conﬁgure auto scaling .\\nThe Conﬁgure variant automatic scaling  page appears.\\n6. For Minimum capacity, type the minimum number of instances that you want the scaling policy to\\nmaintain. At least 1 instance is required.\\n7. For Maximum capacity, type the maximum number of instances that you want the scaling policy to\\nmaintain.\\n8. For the target value, type the average number of invocations per instance per minute for the variant.\\nTo determine this value, follow the guidelines in Load Testing (p. 377).\\nApplication Auto Scaling adds or removes instances to keep the metric close to the value that you\\nspecify.\\n9. For Scale-in cool down (seconds) and Scale-out cool down (seconds), type the number seconds for\\neach cool down period. Assuming that the order in the list is based on either most important to less\\nimportant of ﬁrst applied to last applied.\\n10. Select Disable scale in to prevent the scaling policy from deleting variant instances if you want to\\nensure that your variant scales out to address increased traﬃc, but are not concerned with removing\\ninstances to reduce costs when traﬃc decreases, disable scale-in activities.\\nScale-out activities are always enabled so that the scaling policy can create endpoint instances as\\nneeded.\\n11. Choose Save.\\nThis procedure registers a variant as a scalable target with Application Auto Scaling. When you register a\\nvariant, Application Auto Scaling performs validation checks to ensure the following:\\n•The variant exists\\n•The permissions are suﬃcient\\n369Amazon SageMaker Developer Guide\\nConﬁgure Automatic Scaling for a Production Variant\\n•You aren\\'t registering a variant with an instance that is a burstable performance instance such as T2\\nNote\\nAmazon SageMaker automatic scaling doesn\\'t support automatic scaling for burstable\\ninstances such as T2, because they already allow for increased capacity under increased\\nworkloads. For information about burstable performance instances, see Amazon EC2 Instance\\nTypes.\\nConﬁgure Automatic Scaling for a Production Variant (AWS CLI\\nor the Application Auto Scaling API)\\nWith the AWS CLI or the Application Auto Scaling API, you can conﬁgure automatic scaling based on\\neither a predeﬁned or a custom metric.\\nRegister a Production Variant\\nTo deﬁne the scaling limits for the variant, register your variant with Application Auto Scaling.\\nApplication Auto Scaling dynamically scales the number of variant instances.\\nTo register your variant, you can use either the AWS CLI or the Application Auto Scaling API.\\nWhen you register a variant, Application Auto Scaling performs validation checks to ensure the\\nfollowing:\\n•The variant resource exists\\n•The permissions are suﬃcient\\n•You aren\\'t registering a variant with an instance that is a Burstable Performance Instance such as T2\\nNote\\nAmazon SageMaker automatic scaling doesn\\'t support automatic scaling for burstable\\ninstances such as T2, because burstable instances already allow for increased capacity under\\nincreased workloads. For information about Burstable Performance Instances, see Amazon\\nEC2 Instance Types.\\nRegister a Production Variant (AWS CLI)\\nTo register your endpoint, use the register-scalable-target  AWS CLI command with the following\\nparameters:\\n•--service-namespace —Set this value to sagemaker .\\n•--resource-id —The resource identiﬁer for the production variant. For this parameter, the resource\\ntype is endpoint  and the unique identiﬁer is the name of the variant. For example endpoint/\\nMyEndpoint/variant/MyVariant .\\n•--scalable-dimension —Set this value to sagemaker:variant:DesiredInstanceCount .\\n•--min-capacity —The minimum number of instances that Application Auto Scaling must manage\\nfor this endpoint. Set min-capacity  to at least 1. It must be equal to or less than the value speciﬁed\\nfor max-capacity .\\n•--max-capacity —The maximum number of instances that Application Auto Scaling should manage.\\nSet max-capacity  to a minimum of 1, It must be equal to or greater than the value speciﬁed for\\nmin-capacity .\\nExample\\nThe following example shows how to register an endpoint variant named MyVariant  that is dynamically\\nscaled to have one to eight instances:\\n370Amazon SageMaker Developer Guide\\nConﬁgure Automatic Scaling for a Production Variant\\naws application-autoscaling register-scalable-target \\\\\\n    --service-namespace sagemaker \\\\\\n    --resource-id endpoint/MyEndPoint/variant/MyVariant \\\\\\n    --scalable-dimension sagemaker:variant:DesiredInstanceCount \\\\\\n    --min-capacity 1 \\\\\\n    --max-capacity 8\\n                    \\nRegister a Production Variant (Application Auto Scaling API)\\nTo register your endpoint variant with Application Auto Scaling, use the RegisterScalableTarget\\nApplication Auto Scaling API action with the following parameters:\\n•ServiceNamespace —Set this value to sagemaker .\\n•ResourceID —The resource identiﬁer for the production variant. For this parameter, the resource\\ntype is endpoint  and the unique identiﬁer is the name of the variant, for example endpoint/\\nMyEndPoint/variant/MyVariant .\\n•ScalableDimension —Set this value to sagemaker:variant:DesiredInstanceCount .\\n•MinCapacity —The minimum number of instances to be managed by Application Auto Scaling. This\\nvalue must be set to at least 1 and must be equal to or less than the value speciﬁed for MaxCapacity .\\n•MaxCapacity —The maximum number of instances to be managed by Application Auto Scaling.\\nThis value must be set to at least 1 and must be equal to or greater than the value speciﬁed for\\nMinCapacity .\\nExample\\nThe following example shows how to register an Amazon SageMaker production variant that is\\ndynamically scaled to use one to eight instances:\\nPOST / HTTP/1.1\\nHost: autoscaling.us-east-2.amazonaws.com\\nAccept-Encoding: identity\\nX-Amz-Target: AnyScaleFrontendService.RegisterScalableTarget\\nX-Amz-Date: 20160506T182145Z\\nUser-Agent: aws-cli/1.10.23 Python/2.7.11 Darwin/15.4.0 botocore/1.4.8\\nContent-Type: application/x-amz-json-1.1\\nAuthorization: AUTHPARAMS\\n{\\n    \"ServiceNamespace\": \"sagemaker\",\\n    \"ResourceId\": \"endpoint/MyEndPoint/variant/MyVariant\",\\n    \"ScalableDimension\": \"sagemaker:variant:DesiredInstanceCount\",\\n    \"MinCapacity\": 1,\\n    \"MaxCapacity\": 8\\n}\\nDeﬁne a Target-Tracking Scaling Policy\\nTo specify the metrics and target values for a scaling policy, you conﬁgure a target-tracking scaling\\npolicy. You can use either a predeﬁned metric or a custom metric.\\nScaling policy conﬁguration is represented by a JSON block. You save your scaling policy\\nconﬁguration as a JSON block in a text ﬁle. You use that text ﬁle when invoking the AWS CLI or\\nthe Application Auto Scaling API. For more information about policy conﬁguration syntax, see\\nTargetTrackingScalingPolicyConfiguration  in the Application Auto Scaling API Reference.\\nThe following options are available for deﬁning a target-tracking scaling policy conﬁguration.\\n371Amazon SageMaker Developer Guide\\nConﬁgure Automatic Scaling for a Production Variant\\nTopics\\n•Use a Predeﬁned Metric (p. 372)\\n•Use a Custom Metric  (p. 372)\\n•Add a Cooldown Period (p. 373)\\n•Disable Scale-in Activity (p. 373)\\nUse a Predeﬁned Metric\\nTo quickly deﬁne a target-tracking scaling policy for a variant, use the\\nSageMakerVariantInvocationsPerInstance  predeﬁned metric.\\nSageMakerVariantInvocationsPerInstance  is the average number of times per minute that each\\ninstance for a variant is invoked. We strongly recommend using this metric.\\nTo use a predeﬁned metric in a scaling policy, create a target tracking conﬁguration for your policy. In the\\ntarget tracking conﬁguration, include a PredefinedMetricSpecification  for the predeﬁned metric\\nand a TargetValue  for the target value of that metric.\\nExample\\nThe following example is a typical policy conﬁguration for target-tracking scaling for a variant. In this\\nconﬁguration, we use the SageMakerVariantInvocationsPerInstance  predeﬁned metric to adjust\\nthe number of variant instances so that each instance has a InvocationsPerInstance  metric of 70.\\n{\\n    \"TargetValue\": 70.0,\\n    \"PredefinedMetricSpecification\":\\n    {\\n        \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"\\n    }\\n}\\nUse a Custom Metric\\nIf you need to deﬁne a target-tracking scaling policy that meets your custom requirements, deﬁne a\\ncustom metric. You can deﬁne a custom metric based on any production variant metric that changes in\\nproportion to scaling.\\nNot all Amazon SageMaker metrics work for target tracking. The metric must be a valid utilization\\nmetric, and it must describe how busy an instance is. The value of the metric must increase or decrease\\nin inverse proportion to the number of variant instances. That is, the value of the metric should decrease\\nwhen the number of instances increases.\\nImportant\\nBefore deploying automatic scaling in production, you must test automatic scaling with your\\ncustom metric.\\nExample\\nThe following example is a target-tracking conﬁguration for a scaling policy. In this conﬁguration, for a\\nvariant named my-variant , a custom metric adjusts the variant based on an average CPU utilization of\\n50 percent across all instances.\\n{\\n    \"TargetValue\": 50,\\n    \"CustomizedMetricSpecification\":\\n    {\\n372Amazon SageMaker Developer Guide\\nConﬁgure Automatic Scaling for a Production Variant\\n        \"MetricName\": \"CPUUtilization\",\\n        \"Namespace\": \"/aws/sagemaker/Endpoints\",\\n        \"Dimensions\": [\\n            {\"Name\": \"EndpointName\", \"Value\": \"my-endpoint\" },\\n            {\"Name\": \"VariantName\",\"Value\": \"my-variant\"}\\n        ],\\n        \"Statistic\": \"Average\",\\n        \"Unit\": \"Percent\"\\n    }\\n}\\nAdd a Cooldown Period\\nTo add a cooldown period for scaling out your variant, specify a value, in seconds, for\\nScaleOutCooldown  . Similarly, to add a cooldown period for scaling in your variant, add a\\nvalue, in seconds, for ScaleInCooldown  . For more information about ScaleInCooldown  and\\nScaleOutCooldown , see TargetTrackingScalingPolicyConfiguration  in the Application Auto\\nScaling API Reference.\\nExample\\nThe following is an example of a target-tracking policy conﬁguration for a scaling policy. In this\\nconﬁguration, the SageMakerVariantInvocationsPerInstance  predeﬁned metric is used to adjust\\na variant based on an average of 70 across all instances of that variant. The conﬁguration provides a\\nscale-in cooldown period of 10 minutes and a scale-out cooldown period of 5 minutes.\\n{\\n    \"TargetValue\": 70.0,\\n    \"PredefinedMetricSpecification\":\\n    {\\n        \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"\\n    },\\n    \"ScaleInCooldown\": 600,\\n    \"ScaleOutCooldown\": 300\\n}\\nDisable Scale-in Activity\\nYou can prevent the target-tracking scaling policy conﬁguration from scaling in your variant by disabling\\nscale-in activity. Disabling scale-in activity prevents the scaling policy from deleting instances, while still\\nallowing it to create them as needed.\\nTo enable or disable scale-in activity for your variant, specify a Boolean value for DisableScaleIn . For\\nmore information about DisableScaleIn , see TargetTrackingScalingPolicyConfiguration  in\\nthe Application Auto Scaling API Reference.\\nExample\\nThe following is an example of a target-tracking conﬁguration for a scaling policy. In this conﬁguration,\\nthe SageMakerVariantInvocationsPerInstance  predeﬁned metric adjusts a variant based on an\\naverage of 70 across all instances of that variant. The conﬁguration disables scale-in activity for the\\nscaling policy.\\n{\\n    \"TargetValue\": 70.0,\\n    \"PredefinedMetricSpecification\":\\n    {\\n        \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"\\n    },\\n373Amazon SageMaker Developer Guide\\nConﬁgure Automatic Scaling for a Production Variant\\n    \"DisableScaleIn\": true\\n}\\nApply a Scaling Policy to a Production Variant\\nAfter registering your variant and deﬁning a scaling policy, apply the scaling policy to the registered\\nvariant. To apply a scaling policy to a variant, you can use the AWS CLI or the Application Auto Scaling\\nAPI.\\nApply a Scaling Policy to a Production Variant (AWS CLI)\\nTo apply a scaling policy to your variant, use the put-scaling-policy  AWS CLI command with the\\nfollowing parameters:\\n•--policy-name —The name of the scaling policy.\\n•--policy-type —Set this value to TargetTrackingScaling .\\n•--resource-id —The resource identiﬁer for the variant. For this parameter, the resource type is\\nendpoint  and the unique identiﬁer is the name of the variant. For example endpoint/MyEndpoint/\\nvariant/MyVariant .\\n•--service-namespace —Set this value to sagemaker .\\n•--scalable-dimension —Set this value to sagemaker:variant:DesiredInstanceCount .\\n•--target-tracking-scaling-policy-configuration —The target-tracking scaling policy\\nconﬁguration to use for the variant.\\nExample\\nThe following example uses with Application Auto Scaling to apply a target-tracking scaling policy\\nnamed myscalablepolicy  to a variant named myscalablevariant . The policy conﬁguration is saved\\nin a ﬁle named config.json .\\naws application-autoscaling put-scaling-policy \\\\\\n    --policy-name myscalablepolicy \\\\\\n    --policy-type TargetTrackingScaling \\\\\\n    --resource-id endpoint/MyEndpoint/variant/MyVariant \\\\\\n    --service-namespace sagemaker \\\\\\n    --scalable-dimension sagemaker:variant:DesiredInstanceCount \\\\\\n    --target-tracking-scaling-policy-configuration file://config.json\\nApply a Scaling Policy to a Production Variant (Application Auto Scaling API)\\nTo apply a scaling policy to a variant with the Application Auto Scaling API, use the PutScalingPolicy\\nApplication Auto Scaling API action with the following parameters:\\n•PolicyName —The name of the scaling policy.\\n•ServiceNamespace —Set this value to sagemaker .\\n•ResourceID —The resource identiﬁer for the variant. For this parameter, the resource type\\nis endpoint  and the unique identiﬁer is the name of the variant. For example, endpoint/\\nMyEndpoint/variant/MyVariant .\\n•ScalableDimension —Set this value to sagemaker:variant:DesiredInstanceCount .\\n•PolicyType —Set this value to TargetTrackingScaling .\\n•TargetTrackingScalingPolicyConfiguration —The target-tracking scaling policy conﬁguration\\nto use for the variant.\\n374Amazon SageMaker Developer Guide\\nEdit a Scaling Policy\\nExample\\nThe following example uses Application Auto Scaling to apply a target-tracking scaling policy named\\nmyscalablepolicy  to a variant named myscalablevariant . It uses a policy conﬁguration based on\\nthe SageMakerVariantInvocationsPerInstance  predeﬁned metric.\\nPOST / HTTP/1.1\\nHost: autoscaling.us-east-2.amazonaws.com\\nAccept-Encoding: identity\\nX-Amz-Target: AnyScaleFrontendService.\\nX-Amz-Date: 20160506T182145Z\\nUser-Agent: aws-cli/1.10.23 Python/2.7.11 Darwin/15.4.0 botocore/1.4.8\\nContent-Type: application/x-amz-json-1.1\\nAuthorization: AUTHPARAMS\\n{\\n    \"PolicyName\": \"myscalablepolicy\",\\n    \"ServiceNamespace\": \"sagemaker\",\\n    \"ResourceId\": \"endpoint/MyEndpoint/variant/MyVariant\",\\n    \"ScalableDimension\": \"sagemaker:variant:DesiredInstanceCount\",\\n    \"PolicyType\": \"TargetTrackingScaling\",\\n    \"TargetTrackingScalingPolicyConfiguration\": {\\n        \"TargetValue\": 70.0,\\n        \"PredefinedMetricSpecification\":\\n        {\\n            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"\\n        }\\n    }\\n}\\nEdit a Scaling Policy\\nYou can edit a variant scaling policy with the AWS Management Console, the AWS CLI, or the Application\\nAuto Scaling API.\\nEdit a Scaling Policy (Console)\\nTo edit a scaling policy with the AWS Management Console, use the same procedure that you used to\\nConﬁgure Automatic Scaling for a Production Variant (Console) (p. 369).\\nEdit a Scaling Policy (AWS CLI or Application Auto Scaling API)\\nYou can use the AWS CLI or the Application Auto Scaling API to edit a scaling policy in the same way that\\nyou apply a scaling policy:\\n•With the AWS CLI, specify the name of the policy that you want to edit in the --policy-name\\nparameter. Specify new values for the parameters that you want to change.\\n•With the Application Auto Scaling API, specify the name of the policy that you want to edit in the\\nPolicyName  parameter. Specify new values for the parameters that you want to change.\\nFor more information, see Apply a Scaling Policy to a Production Variant (p. 374).\\nDelete a Scaling Policy\\nYou can delete a scaling policy with the AWS Management Console, the AWS CLI, or the Application Auto\\nScaling API.\\n375Amazon SageMaker Developer Guide\\nDelete a Scaling Policy\\nDelete a Scaling Policy (Console)\\nTo delete an automatic scaling policy for a variant (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. In the navigation pane, choose Endpoints .\\n3. Choose the endpoint for which you want to delete automatic scaling.\\n4. For Endpoint runtime settings, choose the variant that you want to conﬁgure.\\n5. Choose Conﬁgure auto scaling .\\n6. Choose Deregister auto scaling .\\nDelete a Scaling Policy (AWS CLI or Application Auto Scaling\\nAPI)\\nYou can use the AWS CLI or the Application Auto Scaling API to delete a scaling policy from a variant.\\nDelete a Scaling Policy (AWS CLI)\\nTo delete a scaling policy from a variant, use the delete-scaling-policy  AWS CLI command with the\\nfollowing parameters:\\n•--policy-name —The name of the scaling policy.\\n•--resource-id —The resource identiﬁer for the variant. For this parameter, the resource type\\nis endpoint  and the unique identiﬁer is the name of the variant. For example, endpoint/\\nMyEndpoint/variant/MyVariant .\\n•--service-namespace —Set this value to sagemaker .\\n•--scalable-dimension —Set this value to sagemaker:variant:DesiredInstanceCount .\\nExample\\nThe following example deletes a target-tracking scaling policy named myscalablepolicy  from a\\nvariant named myscalablevariant .\\naws application-autoscaling delete-scaling-policy \\\\\\n    --policy-name myscalablepolicy \\\\\\n    --resource-id endpoint/MyEndpoint/variant/MyVariant \\\\\\n    --service-namespace sagemaker \\\\\\n    --scalable-dimension sagemaker:variant:DesiredInstanceCount\\n                    \\nDelete a Scaling Policy (Application Auto Scaling API)\\nTo delete a scaling policy from your variant, use the DeleteScalingPolicy  Application Auto Scaling\\nAPI action with the following parameters:\\n•PolicyName —The name of the scaling policy.\\n•ServiceNamespace —Set this value to sagemaker .\\n•ResourceID —The resource identiﬁer for the variant. For this parameter, the resource type\\nis endpoint  and the unique identiﬁer is the name of the variant,. For example, endpoint/\\nMyEndpoint/variant/MyVariant .\\n•ScalableDimension —Set this value to sagemaker:variant:DesiredInstanceCount .\\n376Amazon SageMaker Developer Guide\\nUpdate Endpoints that Use Automatic Scaling\\nExample\\nThe following example uses the Application Auto Scaling API to delete a target-tracking scaling policy\\nnamed myscalablepolicy  from a variant named myscalablevariant .\\nPOST / HTTP/1.1\\nHost: autoscaling.us-east-2.amazonaws.com\\nAccept-Encoding: identity\\nX-Amz-Target: AnyScaleFrontendService.DeleteScalingPolicy\\nX-Amz-Date: 20160506T182145Z\\nUser-Agent: aws-cli/1.10.23 Python/2.7.11 Darwin/15.4.0 botocore/1.4.8\\nContent-Type: application/x-amz-json-1.1\\nAuthorization: AUTHPARAMS\\n{\\n    \"PolicyName\": \"myscalablepolicy\",\\n    \"ServiceNamespace\": \"sagemaker\",\\n    \"ResourceId\": \"endpoint/MyEndpoint/variant/MyVariant\",\\n    \"ScalableDimension\": \"sagemaker:variant:DesiredInstanceCount\"\\n}\\n                    \\nUpdate Endpoints that Use Automatic Scaling\\nWhen you update Amazon SageMaker endpoints that have automatic scaling applied, complete the\\nfollowing steps:\\nTo update an endpoint that has automatic scaling applied\\n1. Deregister the endpoint as a scalable target by calling DeregisterScalableTarget.\\n2. Because you turn oﬀ automatic scaling before you update the endpoint, you might want to take the\\nadditional precaution of increasing the number of instances for your endpoint during the update.\\nTo do this, update the instance counts for the production variants hosted at the endpoint by calling\\nUpdateEndpointWeightsAndCapacities (p. 842).\\n3. Call DescribeEndpoint  (p. 709) repeatedly until the value of the EndpointStatus  ﬁeld of the\\nresponse is InService .\\n4. Call DescribeEndpointConﬁg  (p. 712) to get the values of the current endpoint conﬁg.\\n5. Create a new endpoint conﬁg by calling CreateEndpointConﬁg (p. 635). For the\\nInitialInstanceCount  ﬁeld of each production variant, specify the corresponding value of\\nDesiredInstanceCount  from the response to the previous call to DescribeEndpoint  (p. 709).\\nFor all other values, use the values that you got as the response when you called\\nDescribeEndpointConﬁg  (p. 712) in the previous step.\\n6. Update the endpoint by calling UpdateEndpoint  (p. 840). Specify the endpoint conﬁg you created\\nin the previous step as the EndpointConfig  ﬁeld.\\n7. Re-enable automatic scaling by calling RegisterScalableTarget.\\nLoad Testing for Production Variant Automatic\\nScaling\\nPerform load tests to choose an automatic scaling conﬁguration that works the way you want.\\nFor an example of load testing to optimize automatic scaling for a Amazon SageMaker endpoint, see\\nLoad test and optimize an Amazon SageMaker endpoint using automatic scaling.\\n377Amazon SageMaker Developer Guide\\nAdditional Considerations\\nThe following guidelines for load testing assume you are using an automatic scaling policy that uses the\\npredeﬁned target metric SageMakerVariantInvocationsPerInstance .\\nTopics\\n•Determine the Performance Characteristics of a Production Variant (p. 378)\\n•Calculate the Target SageMakerVariantInvocationsPerInstance (p. 378)\\nDetermine the Performance Characteristics of a Production\\nVariant\\nPerform load testing to ﬁnd the peak InvocationsPerInstance  that your variant instance can\\nhandle, and the latency of requests, as concurrency increases.\\nThis value depends on the instance type chosen, payloads that clients of your variant typically send, and\\nthe performance of any external dependencies your variant has.\\nTo ﬁnd the peak requests-per-second (RPS) your variant can handle and latency of requests\\n1. Set up an endpoint with your variant using a single instance. For information about how to set up an\\nendpoint, see Step 6.1: Deploy the Model to Amazon SageMaker Hosting Services  (p. 26).\\n2. Use a load testing tool to generate an increasing number of parallel requests, and monitor the RPS\\nand model latency in the out put of the load testing tool.\\nNote\\nYou can also monitor requests-per-minute instead of RPS. In that case don\\'t multiply by\\n60 in the equation to calculate SageMakerVariantInvocationsPerInstance  shown\\nbelow.\\nWhen the model latency increases or the proportion of successful transactions decreases, this is the\\npeak RPS that your variant can handle.\\nCalculate the Target SageMakerVariantInvocationsPerInstance\\nAfter you ﬁnd the performance characteristics of the variant, you can determine the maximum RPS we\\nshould allow to be sent to an instance. The threshold used for scaling must be less than this maximum\\nvalue. Use the following equation in combination with load testing to determine the correct value for the\\nSageMakerVariantInvocationsPerInstance  target metric in your automatic scaling conﬁguration.\\nSageMakerVariantInvocationsPerInstance = (MAX_RPS * SAFETY_FACTOR) * 60\\nWhere MAX_RPS is the maximum RPS that you determined previously, and SAFETY_FACTOR  is the safety\\nfactor that you chose to ensure that your clients don\\'t exceed the maximum RPS. Multiply by 60 to\\nconvert from RPS to invocations-per-minute to match the per-minute CloudWatch metric that Amazon\\nSageMaker uses to implement automatic scaling (you don\\'t need to do this if you measured requests-\\nper-minute instead of requests-per-second).\\nNote\\nAmazon SageMaker recommends that you start testing with a SAFETY_FACTOR  of 0.5. Test your\\nautomatic scaling conﬁguration to ensure it operates in the way you expect with your model for\\nboth increasing and decreasing customer traﬃc on your endpoint.\\nBest Practices for Conﬁguring Automatic Scaling\\nWhen conﬁguring automatic scaling, consider the following general guidelines.\\n378Amazon SageMaker Developer Guide\\nAdditional Considerations\\nTesting Your Automatic Scaling Conﬁguration\\nIt is important that you test your automatic scaling conﬁguration to conﬁrm that it works with your\\nmodel the way you expect it to.\\nUpdating Endpoints Conﬁgured for Automatic Scaling\\nWhen you update an endpoint, Application Auto Scaling checks to see whether any of the variants on\\nthat endpoint are targets for automatic scaling. If the update would change the instance type for any\\nvariant that is a target for automatic scaling, the update fails.\\nIn the AWS Management Console, you see a warning that you must deregister the variant from\\nautomatic scaling before you can update it. If you are trying to update the endpoint by calling the\\nUpdateEndpoint  (p. 840) API, the call fails. Before you update the endpoint, delete any scaling policies\\nconﬁgured for it by calling the DeleteScalingPolicy Application Auto Scaling API action, then call\\nDeregisterScalableTarget to deregister the variant as a scalable target. After you update the endpoint,\\nyou can register the variant as a scalable target and attach an automatic scaling policy to the updated\\nvariant.\\nThere is one exception. If you change the model for a variant that is conﬁgured for automatic scaling,\\nAmazon SageMaker automatic scaling allows the update. This is because changing the model doesn\\'t\\ntypically aﬀect performance enough to change automatic scaling behavior. If you do update a model\\nfor a variant conﬁgured for automatic scaling, ensure that the change to the model doesn\\'t signiﬁcantly\\naﬀect performance and automatic scaling behavior.\\nFor instructions on how to update an endpoint that uses automatic scaling, see Update Endpoints that\\nUse Automatic Scaling  (p. 377).\\nDeleting Endpoints Conﬁgured for Automatic Scaling\\nIf you delete an endpoint, Application Auto Scaling checks to see whether any of the variants on\\nthat endpoint are targets for automatic scaling. If any are and you have permission to deregister the\\nvariant, Application Auto Scaling deregisters those variants as scalable targets without notifying you.\\nIf you use a custom permission policy that doesn\\'t provide permission for the DeleteScalingPolicy and\\nDeregisterScalableTarget actions, you must delete automatic scaling policies and deregister scalable\\ntargets and before deleting the endpoint.\\nNote\\nYou, as an IAM user, might not have suﬃcient permission to delete an endpoint if another IAM\\nuser conﬁgured automatic scaling for a variant on that endpoint.\\nUsing Step Scaling Policies\\nAlthough Amazon SageMaker automatic scaling supports using Application Auto Scaling step scaling\\npolicies, we recommend using target tracking policies, instead. For information about using Application\\nAuto Scaling step scaling policies, see Step Scaling Policies.\\nScaling In When There Is No Traﬃc\\nIf a variant’s traﬃc becomes zero, Amazon SageMaker automatic scaling doesn\\'t scale down. This is\\nbecause Amazon SageMaker doesn\\'t emit metrics with a value of zero.\\nAs a workaround, do either of the following:\\n•Send requests to the variant until automatic scaling scales down to the minimum capacity\\n379Amazon SageMaker Developer Guide\\nTroubleshoot\\n•Change the policy to reduce the maximum provisioned capacity to match the minimum provisioned\\ncapacity\\nTroubleshoot Amazon SageMaker Model\\nDeployments\\nIf you encounter an issue when deploying machine learning models in Amazon SageMaker, see the\\nfollowing guidance.\\nTopics\\n•Detection Errors in the Active CPU Count  (p. 380)\\nDetection Errors in the Active CPU Count\\nIf you deploy an Amazon SageMaker model with a Linux Java Virtual Machine (JVM), you might\\nencounter detection errors that prevent using available CPU resources. This issue aﬀects some JVMs\\nthat support Java 8 and Java 9, and most that support Java 10 and Java 11. These JVMs implement a\\nmechanism that detects and handles the CPU count and the maximum memory available when running\\na model in a Docker container, and, more generally, within Linux taskset commands or control groups\\n(cgroups). Amazon SageMaker deployments take advantage of some of the settings that the JVM uses\\nfor managing these resources. Currently, this causes the container to incorrectly detect the number of\\navailable CPUs.\\nAmazon SageMaker doesn\\'t limit access to CPUs on an instance. However, the JVM might detect the CPU\\ncount as 1 when more CPUs are available for the container. As a result, the JVM adjusts all of its internal\\nsettings to run as if only 1 CPU core is available. These settings aﬀect garbage collection, locks, compiler\\nthreads, and other JVM internals that negatively aﬀect the concurrency, throughput, and latency of the\\ncontainer.\\nFor an example of the misdetection, in a container conﬁgured for Amazon SageMaker that is deployed\\nwith a JVM that is based on Java8_191 and that has four available CPUs on the instance, run the\\nfollowing command to start your JVM:\\njava -XX:+UnlockDiagnosticVMOptions -XX:+PrintActiveCpus -version\\nThis generates the following output:\\nactive_processor_count: sched_getaffinity processor count: 4\\nactive_processor_count: determined by OSContainer: 1\\nactive_processor_count: sched_getaffinity processor count: 4\\nactive_processor_count: determined by OSContainer: 1\\nactive_processor_count: sched_getaffinity processor count: 4\\nactive_processor_count: determined by OSContainer: 1\\nactive_processor_count: sched_getaffinity processor count: 4\\nactive_processor_count: determined by OSContainer: 1\\nopenjdk version \"1.8.0_191\"\\nOpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12)\\nOpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)\\nMany of the JVMs aﬀected by this issue have an option to disable this behavior and reestablish full\\naccess to all of the CPUs on the instance. Disable the unwanted behaviour and establish full access\\nto all instance CPUs by including the -XX:-UseContainerSupport  parameter when starting Java\\napplications. For example, run the java command to start your JVM as follows:\\n380Amazon SageMaker Developer Guide\\nBest Practices\\njava -XX:-UseContainerSupport -XX:+UnlockDiagnosticVMOptions -XX:+PrintActiveCpus -version\\nThis generates the following output:\\nactive_processor_count: sched_getaffinity processor count: 4\\nactive_processor_count: sched_getaffinity processor count: 4\\nactive_processor_count: sched_getaffinity processor count: 4\\nactive_processor_count: sched_getaffinity processor count: 4\\nopenjdk version \"1.8.0_191\"\\nOpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12)\\nOpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)\\nCheck whether the JVM used in your container supports the -XX:-UseContainerSupport  parameter.\\nIf it does, always pass the parameter when you start your JVM. This provides access to all of the CPUs in\\nyour instances.\\nYou might also encounter this issue when indirectly using a JVM in Amazon SageMaker containers. For\\nexample, when using a JVM to support SparkML Scala. The -XX:-UseContainerSupport  parameter\\nalso aﬀects the output returned by the Java Runtime.getRuntime().availableProcessors()  API .\\nBest Practices for Deploying Amazon SageMaker\\nModels\\nThis topic provides guidance on best practices for deploying machine learning models in Amazon\\nSageMaker.\\nTopics\\n•Deploy Multiple Instances Across Avalibility Zones (p. 381)\\nDeploy Multiple Instances Across Avalibility Zones\\nCreate robust endpoints when hosting your model. Amazon SageMaker endpoints can help protect\\nyour application from Availability Zone outages and instance failures. If an outage occurs or an instance\\nfails, Amazon SageMaker automatically attempts to distribute your instances across Availability Zones.\\nFor this reason, we strongly recommended that you deploy multiple instances for each production\\nendpoint.\\nIf you are using an Amazon Virtual Private Cloud (VPC), conﬁgure the VPC with at least two  Subnets ,\\neach in a diﬀerent Availability Zone. If an outage occurs or an instance fails, Amazon SageMaker\\nautomatically attempts to distribute your instances across Availability Zones.\\nIn general, to achieve more reliable performance, use more small Instance Types in diﬀerent Availability\\nZones to host your endpoints.\\nHosting Instance Storage Volumes\\nWhen you create an endpoint, Amazon SageMaker attaches an Amazon EBS storage volume to each ML\\ncompute instance that hosts the endpoint. The size of the storage volume depends on the instance type.\\nThe following table shows the size of the storage volume that Amazon SageMaker attaches for each\\ninstance type.\\n381Amazon SageMaker Developer Guide\\nHosting Instance Storage Volumes\\nInstance\\nTypeStorage\\nVolume\\nin\\nGB\\nml.t2.medium 2\\nml.t2.large 4\\nml.t2.xlarge 8\\nml.t2.2xlarge 16\\nml.m4.xlarge 8\\nml.m4.2xlarge 16\\nml.m4.4xlarge 30\\nml.m4.10xlarge 30\\nml.m4.16xlarge 30\\nml.m5.large 4\\nml.m5.xlarge 8\\nml.m5.2xlarge 16\\nml.m5.4xlarge 30\\nml.m5.12xlarge 30\\nml.m5.24xlarge 30\\nml.c4.large 4\\nml.c4.xlarge 4\\nml.c4.2xlarge 8\\nml.c4.4xlarge 15\\nml.c4.8xlarge 30\\nml.c5.large 2\\nml.c5.xlarge 4\\nml.c5.2xlarge 8\\nml.c5.4xlarge 16\\nml.c5.9xlarge 30\\nml.c5.18xlarge 30\\nml.p2.xlarge 30\\nml.p2.8xlarge 30\\nml.p2.16xlarge 30\\n382Amazon SageMaker Developer Guide\\nHosting Instance Storage Volumes\\nInstance\\nTypeStorage\\nVolume\\nin\\nGB\\nml.p3.2xlarge 30\\nml.p3.8xlarge 30\\nml.p3.16xlarge 30\\n383Amazon SageMaker Developer Guide\\nScenarios and Guidance\\nUse Your Own Algorithms or Models\\nwith Amazon SageMaker\\nAmazon SageMaker makes extensive use of Docker containers  for build and runtime tasks. Before using\\nyour own algorithm or model with Amazon SageMaker, you need to understand how Amazon SageMaker\\nmanages and runs them. Amazon SageMaker provides pre-built Docker images for its built-in algorithms\\nand the deep learning frameworks supported used for training and inference. By using containers, you\\ncan train machine learning algorithms and deploy models quickly and reliably at any scale. Docker is a\\nprogram that performs operating-system-level virtualization for installing, distributing, and managing\\nsoftware. It packages applications and their dependencies into virtual containers that provide isolation,\\nportability, and security.\\nYou can put scripts, algorithms, and inference code for your machine learning models into containers.\\nThe container includes the runtime, system tools, system libraries, and other code required to train your\\nalgorithms or deploy your models. This gives you the ﬂexibility to use almost any script or algorithm\\ncode with Amazon SageMaker, regardless of runtime or implementation language. The code that runs\\nin containers is eﬀectively isolated from its surroundings, ensuring a consistent runtime, regardless\\nof where the container is deployed. After packaging your training code, inference code, or both into\\nDocker containers, you can create algorithm resources and model package resources for use in Amazon\\nSageMaker or to publish on AWS Marketplace. With Docker, you can ship code faster, standardize\\napplication operations, seamlessly move code, and economize by improving resource utilization.\\nYou create Docker containers from images  that are saved in a repository. You build the images from\\nscripted instructions provided in a Dockerﬁle. To use Docker containers in Amazon SageMaker, the scripts\\nthat you use must satisfy certain requirements. For information about the requirements, see Use Your\\nOwn Training Algorithms (p. 404) and Use Your Own Inference Code (p. 408).\\nScenarios for Running Scripts, Training Algorithms,\\nor Deploying Models with Amazon SageMaker\\nAmazon SageMaker always uses Docker containers when running scripts, training algorithms or\\ndeploying models. However, your level of engagement with containers varies depending on whether\\nyou are using a built-in algorithm provided by Amazon SageMaker or a script or model that you have\\ndeveloped yourself. If you\\'re using your own code, it also depends on the language and framework\\nor environment used to develop it, and any other the dependencies it requires to run. In particular, it\\ndepends on whether you use the Amazon SageMaker Python SDK or AWS SDK for Python (Boto3) or\\nsome other SDK. Amazon SageMaker provides containers for its built-in algorithms and pre-built Docker\\nimages for some of the most common machine learning frameworks. You can use the containers and\\nimages as provided or extend them to cover more complicated use cases. You can also create your own\\ncontainer images to manage more advanced use cases not addressed by the containers provided by\\nAmazon SageMaker.\\nThere are four main scenarios for running scripts, algorithms, and models in the Amazon SageMaker\\nenvironment. The last three describe the scenarios covered here: the ways you can use containers to bring\\nyour own script, algorithm or model .\\n•Use a built-in algorithm. Containers are used behind the scenes when you use one of the Amazon\\nSageMaker built-in algorithms, but you do not deal with them directly. You can train and deploy\\n384Amazon SageMaker Developer Guide\\nDocker Container Basics\\nthese algorithms from the Amazon SageMaker console, the AWS Command Line Interface (AWS\\nCLI), a Python notebook, or the Amazon SageMaker Python SDK. The built-in algorithms available\\nare itemized and described in the Use Amazon SageMaker Built-in Algorithms  (p. 56) topic. For an\\nexample of how to train and deploy a built-in algorithm using Jupyter Notebook running in an Amazon\\nSageMaker notebook instance, see the Get Started (p. 16) topic.\\n•Use pre-built container images.Amazon SageMaker provides pre-built containers to supports deep\\nlearning frameworks such as Apache MXNet, TensorFlow, PyTorch, and Chainer. It also supports\\nmachine learning libraries such a scikit-learn and SparkML by providing pre-built Docker images. If you\\nuse the Amazon SageMaker Python SDK, they are deployed using their respective Amazon SageMaker\\nSDK Estimator  class. In this case, you can supply the Python code that implements your algorithm\\nand conﬁgure the pre-built image to access your code as an entry point. For a list of deep learning\\nframeworks currently supported by Amazon SageMaker and samples that show how to use their\\npre-build container images, see Prebuilt Amazon SageMaker Docker Images for TensorFlow, MXNet,\\nChainer, and PyTorch (p. 398). For information on the scikit-learn and SparkML pre-built container\\nimages, see Prebuilt Amazon SageMaker Docker Images for Scikit-learn and Spark ML  (p. 401).\\nFor more information about using frameworks with the Amazon SageMaker Python SDK, see their\\nrespective topics in Use Machine Learning Frameworks with Amazon SageMaker (p. 440).\\n•Extend a pre-built container image. If you have additional functional requirements for an algorithm\\nor model that you developed in a framework that a pre-built Amazon SageMaker Docker image doesn\\'t\\nsupport, you can modify an Amazon SageMaker image to satisfy your needs. For an example, see\\nExtending our PyTorch containers.\\n•Build your own custom container image: If there is no pre-built Amazon SageMaker container image\\nthat you can use or modify for an advanced scenario, you can package your own script or algorithm to\\nuse with Amazon SageMaker.You can use any programming language or framework to develop your\\ncontainer. For an example that shows how to build your own containers to train and host an algorithm,\\nsee Bring Your Own R Algorithm.\\nThe next topic provides a brief introduction to Docker containers. Amazon SageMaker has certain\\ncontractual requirements that a container must satisfy to be used with it. The following topic describes\\nthe Amazon SageMaker Containers library that can be used to create Amazon SageMaker-compatible\\ncontainers, including a list of the environmental variables it deﬁnes and may require. Then a tutorial\\nthat shows how to get started by using Amazon SageMaker Containers to train a Python script. After the\\ntutorial, topics:\\n•Describe the pre-built Docker containers provided by Amazon SageMaker for deep learning\\nframeworks and other libraries.\\n•Provide examples of how to deploy containers for the various scenarios.\\nSubsequent sections describe in more detail the contractual requirements to use Docker with Amazon\\nSageMaker to train your custom algorithms and to deploy your inference code to make predictions.\\nThere are two ways to make predictions when deploying a model. First, to get individual, real-time\\npredictions, you can make inferences with a hosting services. Second, to get predictions for an entire\\ndataset, you can use a batch transform. The ﬁnal sections describe how to create algorithm and model\\npackage resources for use in your Amazon SageMaker account or to publish on AWS Marketplace.\\nDocker Container Basics\\nDocker containers provide isolation, portability, and security. They simplify the creation of highly\\ndistributed systems and save money by improving resource utilization. Docker relies on Linux kernel\\nfunctionality to provide a lightweight virtualization to package applications into an image that is totally\\nself-contained. Docker uses a ﬁle, called a Dockerﬁle, to specify how the image is assembled. When you\\nhave an image, you use Docker to build and run a container based on that image.\\n385Amazon SageMaker Developer Guide\\nAmazon SageMaker Containers\\nYou can build your Docker images from scratch or base them on other Docker images that you or others\\nhave built. Images are stored in repositories that are indexed and maintained by registries. An image can\\nbe pushed into or pulled out of a repository using its registry address, which is similar to a URL. Docker\\nHub is a registry hosted by Docker, Inc. that provides publicly available repositories. AWS provides the\\nAmazon Elastic Container Service (Amazon ECS), a highly scalable, fast container management service.\\nWith Amazon ECS, you can deploy any kind of code in Amazon SageMaker. You can also create a logical\\ndivision of labor by creating a deployment team that handles DevOps and infrastructure, and that\\nmaintains the container, and a data science team that creates the algorithms and models that are later\\nadded to a container.\\nDocker builds images by reading the instructions from a Dockerﬁle text ﬁle that contains all of the\\ncommands, in order, that are needed to build the image. A Dockerﬁle adheres to a speciﬁc format\\nand set of instructions. For move information, see Dockerﬁle reference. Dockerﬁles used in Amazon\\nSageMaker must also satisfy additional requirements regarding the environmental variables, directory\\nstructure, timeouts, and other common functionality. For information, see Use Your Own Training\\nAlgorithms  (p. 404) and Use Your Own Inference Code (p. 408).\\nFor general information about Docker containers managed by Amazon ECS, see Docker Basics for\\nAmazon ECS in the Amazon Elastic Container Service Developer Guide.\\nFor more information about writing Dockerﬁles to build images, see Best practices for writing\\nDockerﬁles.\\nFor general information about Docker, see the following:\\n•Docker home page\\n•Docker overview\\n•Getting Started with Docker\\n•Dockerﬁle reference\\nAmazon SageMaker Containers: a Library to Create\\nDocker Containers\\nAmazon SageMaker Containers is a library that implements the functionality that you need to create\\ncontainers to run scripts, train algorithms, or deploy models that are compatible with Amazon\\nSageMaker. To install this library, use a RUN pip install sagemaker-containers  command in\\nyour Dockerﬁle. The library deﬁnes the locations for storing code and other resources when you install it.\\nYour Dockerﬁle must also copy the code to be run into the location expected by an Amazon SageMaker-\\ncompatible container and deﬁne the entry point containing the code to run when the container is\\nstarted. The library also deﬁnes other information that a container needs to manage deployments for\\ntraining and inference. After you build a Docker image, you can push it to the Amazon Elastic Container\\nRegistry (Amazon ECR). To create a container, you can pull the image from Amazon ECR and build the\\ncontainer using the docker build  command.\\nThe following high-level schematic shows how the ﬁles are organized in an Amazon SageMaker-\\ncompatible container created with the Amazon SageMaker Containers library.\\n386Amazon SageMaker Developer Guide\\nAmazon SageMaker Containers\\nWhen Amazon SageMaker trains a model, it creates a number of ﬁles in the container\\'s /opt/ml\\ndirectory.\\n/opt/ml\\n### input\\n#   ### config\\n#   #   ### hyperparameters.json\\n#   #   ### resourceConfig.json\\n#   ### data\\n#       ### <channel_name>\\n#           ### <input data>\\n### model\\n# \\n### code\\n#   ### <script files>\\n#\\n### output\\n    ### failure\\nWhen you run a model training  job, the Amazon SageMaker container has a /opt/ml/input/  directory\\nthat contains JSON ﬁles that conﬁgure the hyperparameters for the algorithm and the network layout\\nused for distributed training. The directory also contains ﬁles that specify the channels through which\\nAmazon SageMaker accesses the data in Amazon Simple Storage Service (Amazon S3). Place scripts to\\nrun in the /opt/ml/code/  directory. The /opt/ml/model/  directory contains the model generated\\nby your algorithm in a singe ﬁle or an entire directory tree in any format. You can also send information\\nabout why a training job failed to the /opt/ml/output/  directory. Amazon SageMaker packages ﬁles in\\nthis directory into a compressed tar archive ﬁle.\\nWhen you host a trained model on Amazon SageMaker to make inferences, you deploy the model\\nto an HTTP endpoint. The model makes realtime predictions in response to inference requests. The\\ncontainer must contain a serving stack to process these requests. The ﬁve ﬁles used in the standard\\nPython serving stack by Amazon SageMaker are installed in the container\\'s WORKDIR. You can choose\\na diﬀerent toolset to deploy an HTTP endpoint and, therefore, could have a diﬀerent layout. If you\\'re\\nwriting in a programming language other than Python, you will have a diﬀerent layout, the nature\\nof which will depend on the frameworks and tools that you choose. The Python serving stack in the\\nWORKDIR directory contains the following ﬁles:\\n•nginx.conf– The conﬁguration ﬁle for the nginx front end.\\n387Amazon SageMaker Developer Guide\\nEnvironmental Variables - Entrypoints\\n•predictor.py– The program that implements the Flask  web server and the decision tree predictions for\\nthis application. You need to customize the code that performs prediction for your application.\\n•serve – The program started when the container is started for hosting. This ﬁle simply launches the\\nGunicorn server, which runs multiple instances of the Flask application deﬁned in predictor.py .\\n•train  – The program that is invoked when you run the container for training. To implement your\\ntraining algorithm, you modify this program.\\n•wsgi.py – A small wrapper used to invoke the Flask application.\\nIn the container, the model ﬁles are in the same place that they were written to during training.\\n/opt/ml\\n### model\\n    ### <model files>\\nFor more information, see Use Your Own Inference Code (p. 408)\\nYou can provide separate Docker images for the training algorithm and inference code, as shown in the\\nﬁgure. Or you can use a single Docker image for both. When creating Docker images for use with Amazon\\nSageMaker, consider the following:\\n•Providing two Docker images can increase storage requirements and cost because common libraries\\nmight be duplicated.\\n•In general, smaller containers start faster for both training and hosting. Models train faster and the\\nhosting service can react to increases in traﬃc by automatically scaling more quickly.\\n•You might be able to write an inference container that is signiﬁcantly smaller than the training\\ncontainer. This is especially common when you use GPUs for training, but your inference code is\\noptimized for CPUs.\\n•Amazon SageMaker requires that Docker containers run without privileged access.\\n•Docker containers might send messages to the Stdout  and Stderr ﬁles. Amazon SageMaker sends\\nthese messages to Amazon CloudWatch logs in your AWS account.\\nEnvironmental Variables used by Amazon SageMaker\\nContainers to Deﬁne Entry Points\\nWhen creating a Dockerﬁle, you must deﬁne an entry point that speciﬁes the location of the code to\\nrun when the container starts. Amazon SageMaker Containers does this by setting an ENV environment\\nvariable. The environment variable that you need to set depends on the job you want to do:\\n•To run a script,specify the SAGEMAKER_PROGRAM  ENV variable.\\n•To train an algorithm, specify the SAGEMAKER_TRAINING_MODULE  ENV variable.\\n•To host a model, specify the SAGEMAKER_SERVING_MODULE  ENV variable.\\nYou can use the Amazon SageMaker containers SDK package to set environment variables.\\nSAGEMAKER_PROGRAM\\nTrain scripts similar to those you would use outside Amazon SageMaker using Amazon SageMaker Script\\nMode. It supports Python and Shell scripts: Amazon SageMaker uses the Python interpreter for any script\\nwith the .py suﬃx.Amazon SageMaker uses the Shell interpreter to execute any other script.\\nWhen running a program to specify the entry point for Script Mode, set the SAGEMAKER_PROGRAM\\nenvironmental variable. The script must be located in the /opt/ml/code  folder.\\n388Amazon SageMaker Developer Guide\\nEnvironmental Variables - User Scripts\\nFor example, the container used in the example in Get Started: Use Amazon SageMaker Containers to\\nRun a Python Script (p. 396) sets this ENV as follows.\\nENV SAGEMAKER_PROGRAM train.py\\nThe Amazon SageMaker PyTorch container sets the ENV variable as follows.\\nENV SAGEMAKER_PROGRAM cifar10.py\\nIn the example, cifar10.py is the program that implements the training algorithm and handles loading\\nthe model for inferences. For more information, see the Extending our PyTorch containers notebook.\\nSAGEMAKER_TRAINING_MODULE\\nWhen training an algorithm, specify the location of the module that contains the training logic by setting\\nthe SAGEMAKER_TRAINING_MODULE  environment variable. An Amazon SageMaker container invokes\\nthis module when the container starts training. For example, you set this environment variable in MXNet\\nas follows.\\nENV SAGEMAKER_TRAINING_MODULE sagemaker_mxnet_container.training:main\\nFor TensorFlow, set this environmant variable  as follows.\\nENV SAGEMAKER_TRAINING_MODULE sagemaker_tensorflow_container.training:main\\nThe code that implements this logic is in Amazon SageMaker Containers.\\nSAGEMAKER_SERVING_MODULE\\nTo locate the module that contains the hosting logic when deploying a model, set the\\nSAGEMAKER_SERVING_MODULE  environmental variable. An Amazon SageMaker container invokes this\\nmodule when it starts hosting.\\nENV SAGEMAKER_SERVING_MODULE sagemaker_mxnet_container.serving:main\\nThe code that implements this logic is in the: Amazon SageMaker Containers.\\nEnvironmental Variables used by Amazon SageMaker\\nContainers Important for Running User Scripts\\nWhen you write a script to run in a container, you are likely to use the following build-time environment\\nvariables. Amazon SageMaker Containers sets some of these variable values by default.\\n•SM_MODEL_DIR\\nSM_MODEL_DIR=/opt/ml/model\\nWhen the training job ﬁnishes, Amazon SageMaker deletes the container, including its ﬁle system,\\nexcept for the ﬁles in the /opt/ml/model  and /opt/ml/output  folders. Use /opt/ml/mode l to\\nsave the model checkpoints. Amazon SageMaker uploads these checkpoints to the default S3 bucket.\\nExamples:\\n# Using it in argparse\\n389Amazon SageMaker Developer Guide\\nEnvironmental Variables - User Scripts\\nparser.add_argument(\\'model_dir\\', type=str, default=os.environ[\\'SM_MODEL_DIR\\'])\\n# Using it as a variable\\nmodel_dir = os.environ[\\'SM_MODEL_DIR\\']\\n# Saving checkpoints to the model directory in Chainer\\nserializers.save_npz(os.path.join(os.environ[\\'SM_MODEL_DIR\\'], \\'model.npz\\'), model)\\nFor more information, see How Amazon SageMaker Processes Training Output.\\n•SM_CHANNELS\\nSM_CHANNELS=\\'[\"testing\",\"training\"]\\'\\nThe SM_CHANNELS  environmental variable contains the list of input data channels for the container.\\nWhen you train a model, you can partition your training data into diﬀerent logical \"channels\". Common\\nchannels are: training, testing,and evaluation, or images and labels. SM_CHANNELS  includes the name\\nof the channels that are in the container as a JSON encoded list.\\nExamples:\\nimport json\\n# Using it in argparse\\nparser.add_argument(\\'channel_names\\', type=int,\\n default=json.loads(os.environ[\\'SM_CHANNELS\\'])))\\n# Using it as a variable\\nchannel_names = json.loads(os.environ[\\'SM_CHANNELS\\']))\\n•SM_CHANNEL_{channel_name}\\nSM_CHANNEL_TRAINING=\\'/opt/ml/input/data/training\\'\\nSM_CHANNEL_TESTING=\\'/opt/ml/input/data/testing\\'\\nThe SM_CHANNEL_{channel_name}  environmental variable contains the directory where the channel\\nnamed channel_name  is located in the container.\\nExamples:\\nimport json\\nparser.add_argument(\\'--train\\', type=str, default=os.environ[\\'SM_CHANNEL_TRAINING\\'])\\nparser.add_argument(\\'--test\\', type=str, default=os.environ[\\'SM_CHANNEL_TESTING\\'])\\nargs = parser.parse_args()\\ntrain_file = np.load(os.path.join(args.train, \\'train.npz\\'))\\ntest_file = np.load(os.path.join(args.test, \\'test.npz\\'))\\n•SM_HPS\\nSM_HPS=\\'{\"batch-size\": \"256\", \"learning-rate\": \"0.0001\",\"communicator\": \"pure_nccl\"}\\'\\nThe SM_HPS environmental variable contains a JSON encoded dictionary with the hyperparameters\\nthat you have provided.\\nExample:\\n390Amazon SageMaker Developer Guide\\nEnvironmental Variables - User Scripts\\nimport json\\nhyperparameters = json.loads(os.environ[\\'SM_HPS\\']))\\n# {\"batch-size\": 256, \"learning-rate\": 0.0001, \"communicator\": \"pure_nccl\"}\\n•SM_HP_ {hyperparameter_name}\\nSM_HP_LEARNING-RATE=0.0001\\nSM_HP_BATCH-SIZE=10000\\nSM_HP_COMMUNICATOR=pure_nccl\\nThe SM_HP_ {hyperparameter_name  environmental variable contains the value of the\\nhyperparameter named hyperparameter_name .\\nExamples:\\nlearning_rate = float(os.environ[\\'SM_HP_LEARNING-RATE\\'])\\nbatch_size = int(os.environ[\\'SM_HP_BATCH-SIZE\\'])\\ncomminicator = os.environ[\\'SM_HP_COMMUNICATOR\\']\\n•SM_CURRENT_HOST\\nSM_CURRENT_HOST=algo-1\\nThe SM_CURRENT HOST  contains the name of the current container on the container network.\\nExamples:\\n# Using it in argparse\\nparser.add_argument(\\'current_host\\', type=str, default=os.environ[\\'SM_CURRENT_HOST\\'])\\n# Using it as a variable\\ncurrent_host = os.environ[\\'SM_CURRENT_HOST\\']\\n•SM_HOSTS\\nSM_HOSTS=\\'[\"algo-1\",\"algo-2\"]\\'\\nThe SM_HOSTS  environmental variable contains a JSON-encoded list of all of the hosts.\\nExample:\\nimport json\\n# Using it in argparse\\nparser.add_argument(\\'hosts\\', type=nargs, default=json.loads(os.environ[\\'SM_HOSTS\\']))\\n# Using it as variable\\nhosts = json.loads(os.environ[\\'SM_HOSTS\\'])\\n•SM_NUM_GPUS\\nSM_NUM_GPUS=1\\nThe SM_NUM_GPUS  environmental variable contains the number of GPUs available in the current\\ncontainer.\\n391Amazon SageMaker Developer Guide\\nEnvironmental Variable - Reference\\nExamples:\\n# Using it in argparse\\nparser.add_argument(\\'num_gpus\\', type=int, default=os.environ[\\'SM_NUM_GPUS\\'])\\n# Using it as a variable\\nnum_gpus = int(os.environ[\\'SM_NUM_GPUS\\'])\\nReference: Amazon SageMaker Containers\\nEnvironmental Variables\\nThe following build-time environment  variables are also deﬁned by default when you use the Amazon\\nSageMaker Containers.\\n•SM_NUM_CPUS\\nSM_NUM_CPUS=32\\nThe SM_NUM_CPUS  environment variable contains the number of CPUs available in the current\\ncontainer.\\nExample:\\n# Using it in argparse\\nparser.add_argument(\\'num_cpus\\', type=int, default=os.environ[\\'SM_NUM_CPUS\\'])\\n# Using it as a variable\\nnum_cpus = int(os.environ[\\'SM_NUM_CPUS\\'])\\n•SM_LOG_LEVEL\\nSM_LOG_LEVEL=20\\nThe SM_LOG_LEVEL  environment variable contains the current log level in the container.\\nExample:\\nimport logging\\nlogger = logging.getLogger(__name__)\\nlogger.setLevel(int(os.environ.get(\\'SM_LOG_LEVEL\\', logging.INFO)))\\n•SM_NETWORK_INTERFACE_NAME\\nSM_NETWORK_INTERFACE_NAME=ethwe\\nThe SM_NETWORK_INTERFACE_NAME  environment variable contains the name of the network\\ninterface, which is used for distributed training.\\nExample:\\n# Using it in argparse\\n392Amazon SageMaker Developer Guide\\nEnvironmental Variable - Reference\\nparser.add_argument(\\'network_interface\\', type=str,\\n default=os.environ[\\'SM_NETWORK_INTERFACE_NAME\\'])\\n# Using it as a variable\\nnetwork_interface = os.environ[\\'SM_NETWORK_INTERFACE_NAME\\']\\n•SM_USER_ARGS\\nSM_USER_ARGS=\\'[\"--batch-size\",\"256\",\"--learning_rate\",\"0.0001\",\"--\\ncommunicator\",\"pure_nccl\"]\\'\\nThe SM_INPUT_DIR  environment variable contains a JSON-encoded list of the script arguments\\nprovided for training.\\n•SM_INPUT_DIR\\nSM_INPUT_DIR=/opt/ml/input/\\nThe SM_INPUT_DIR  environment variable contains the path of the input directory, /opt/ml/input/ .\\nThis is the directory where Amazon SageMaker saves input data and conﬁguration ﬁles before and\\nduring training.\\n•SM_INPUT_CONFIG_DIR\\nSM_INPUT_DIR=/opt/ml/input/config\\nThe SM_INPUT_CONFIG_DIR  environment variable contains the path of the input conﬁg directory, /\\nopt/ml/input/config/ . This is the directory where standard Amazon SageMaker conﬁguration ﬁles\\nare located.\\nWhen training starts, Amazon SageMaker creates the following ﬁles in this directory:\\n•hyperparameters.json  – Contains the hyperparameters speciﬁed in the CreateTrainingJob\\nrequest.\\n•inputdataconfig.json  – Contains the data channel information that you speciﬁed in the\\nInputDataConfig  parameter in a CreateTrainingJob  request.\\n•resourceconfig.json  – Contains the name of the current host and all host containers used in the\\ntraining.\\nFor more information, see: Using Your Own Training Algorithms.\\n•SM_OUTPUT_DATA_DIR\\nSM_OUTPUT_DATA_DIR=/opt/ml/output/data/algo-1\\nThe SM_OUTPUT_DATA_DIR  environment variable contains the directory where the algorithm writes\\nnon-model training artifacts, such as evaluation results. Amazon SageMaker retains these artifacts.\\nAs it runs in a container, your algorithm generates output, including the status of the training job and\\nmodel, and the output artifacts. Your algorithm should write this information to this directory.\\n•SM_RESOURCE_CONFIG\\nSM_RESOURCE_CONFIG=\\'{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"]}\\'\\nThe SM_RESOURCE_CONFIG  environment variable contains the contents of the\\nresourceconfig.json  ﬁle located in the /opt/ml/input/config/  directory. It has the following\\nkeys:\\n393Amazon SageMaker Developer Guide\\nEnvironmental Variable - Reference\\n•current_host  – The name of the current container on the container network. For example,\\n\"algo-1\" .\\n•hosts – The list of names of all of the containers on the container network, sorted lexicographically.\\nFor example, [\"algo-1\", \"algo-2\", \"algo-3\"]  for a three-node cluster.\\nFor more information about the resourceconfig.json  ﬁle, see: Distributed Training Conﬁguration.\\n•SM_INPUT_DATA_CONFIG\\nSM_INPUT_DATA_CONFIG=\\'{\\n    \"testing\": {\\n        \"RecordWrapperType\": \"None\",\\n        \"S3DistributionType\": \"FullyReplicated\",\\n        \"TrainingInputMode\": \"File\"\\n    },\\n    \"training\": {\\n        \"RecordWrapperType\": \"None\",\\n        \"S3DistributionType\": \"FullyReplicated\",\\n        \"TrainingInputMode\": \"File\"\\n    }\\n}\\'\\nThe SM_INPUT_DATA_CONFIG  environment variable contains the input data conﬁguration of the\\ninputdataconfig.json  ﬁle located in the /opt/ml/input/config/  directory.\\nFor more information about the resourceconfig.json  ﬁle, see Distributed Training Conﬁguration.\\n•SM_TRAINING_ENV\\nSM_TRAINING_ENV=\\'\\n{\\n    \"channel_input_dirs\": {\\n        \"test\": \"/opt/ml/input/data/testing\",\\n        \"train\": \"/opt/ml/input/data/training\"\\n    },\\n    \"current_host\": \"algo-1\",\\n    \"framework_module\": \"sagemaker_chainer_container.training:main\",\\n    \"hosts\": [\\n        \"algo-1\",\\n        \"algo-2\"\\n    ],\\n    \"hyperparameters\": {\\n        \"batch-size\": 10000,\\n        \"epochs\": 1\\n    },\\n    \"input_config_dir\": \"/opt/ml/input/config\",\\n    \"input_data_config\": {\\n        \"test\": {\\n            \"RecordWrapperType\": \"None\",\\n            \"S3DistributionType\": \"FullyReplicated\",\\n            \"TrainingInputMode\": \"File\"\\n        },\\n        \"train\": {\\n            \"RecordWrapperType\": \"None\",\\n            \"S3DistributionType\": \"FullyReplicated\",\\n            \"TrainingInputMode\": \"File\"\\n        }\\n    },\\n    \"input_dir\": \"/opt/ml/input\",\\n    \"job_name\": \"preprod-chainer-2018-05-31-06-27-15-511\",\\n    \"log_level\": 20,\\n    \"model_dir\": \"/opt/ml/model\",\\n394Amazon SageMaker Developer Guide\\nGet Information for a Script\\n    \"module_dir\": \"s3://sagemaker-{aws-region}-{aws-id}/{training-job-name}/source/\\nsourcedir.tar.gz\",\\n    \"module_name\": \"user_script\",\\n    \"network_interface_name\": \"ethwe\",\\n    \"num_cpus\": 4,\\n    \"num_gpus\": 1,\\n    \"output_data_dir\": \"/opt/ml/output/data/algo-1\",\\n    \"output_dir\": \"/opt/ml/output\",\\n    \"resource_config\": {\\n        \"current_host\": \"algo-1\",\\n        \"hosts\": [\\n            \"algo-1\",\\n            \"algo-2\"\\n        ]\\n    }\\n}\\'\\nThe SM_TRAINING_ENV  environment variable provides all of the training information as a JSON-\\nencoded dictionary.\\nAdditional Information for Scripts\\nScripts can assign values for the hyperparameters of an algorithm. The interpreter passes all\\nhyperparameters speciﬁed in the training job to the entry point as script arguments. For example, it\\npasses the training job hyperparameters as follow.:\\n{\"HyperParameters\": {\"batch-size\": 256, \"learning-rate\": 0.0001, \"communicator\":\\n \"pure_nccl\"}}\\nWhen an entry point needs additional information from the container that isn\\'t available in\\nhyperparameters, Amazon SageMaker Containers writes this information as environment variables that\\nare available in the script. For example, the following training job includes the training  and testing\\nchannels.\\nfrom sagemaker.pytorch import PyTorch\\nestimator = PyTorch(entry_point=\\'train.py\\', ...)\\nestimator.fit({\\'training\\': \\'s3://bucket/path/to/training/data\\',\\n               \\'testing\\': \\'s3://bucket/path/to/testing/data\\'})\\nThe environment variable SM\\\\_CHANNEL\\\\_{channel_name}  provides the path where the channel is\\nlocated.\\nimport argparse\\nimport os\\nif __name__ == \\'__main__\\':\\n  parser = argparse.ArgumentParser()\\n  ...\\n  # reads input channels training and testing from the environment variables\\n  parser.add_argument(\\'--training\\', type=str, default=os.environ[\\'SM_CHANNEL_TRAINING\\'])\\n  parser.add_argument(\\'--testing\\', type=str, default=os.environ[\\'SM_CHANNEL_TESTING\\'])\\n  args = parser.parse_args()\\n  ...\\n395Amazon SageMaker Developer Guide\\nGet Started with Containers\\nGet Started: Use Amazon SageMaker Containers to\\nRun a Python Script\\nTo run an arbitrary script-based program in a Docker container using the Amazon SageMaker Containers,\\nbuild a Docker container with an Amazon SageMaker notebook instance, as follows:\\n1.Create the notebook instance.\\n2.Create and upload the Dockerﬁle and Python scripts.\\n3.Build the container.\\n4.Test the container locally.\\n5.Clean up the resources.\\nTo create an Amazon SageMaker notebook instance\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebook  , Notebook instances, and Create notebook instance.\\n3. On the Create notebook instance page, provide the following information:\\na. For Notebook instance name, enter RunScriptNotebookInstance .\\nb. For Notebook Instance type, choose ml.t2.medium .\\nc. For IAM role, choose Create a new role.\\ni. Choose Create a new role.\\nii. On the Create an IAM role page, choose Speciﬁc S3 buckets, specify an S3 bucket named\\nsagemaker-run-script ,. and then choose Create role.\\nAmazon SageMaker creates an IAM role named AmazonSageMaker-\\nExecutionRole- YYYYMMDD THHmmSS. For example, AmazonSageMaker-\\nExecutionRole-20190429T110788 . Record the role name because you\\'ll need it later.\\nd. For Root Access, accept the default, Enabled.\\ne. Choose Create notebook instance.\\nIt takes a few minutes for Amazon SageMaker to launch an ML compute instance—in this case,\\na notebook instance—and attach an ML storage volume to it. The notebook instance has a\\npreconﬁgured Jupyter notebook server and a set of Anaconda libraries. For more information,\\nsee the CreateNotebookInstance (p. 656) API.\\n4. When the status of the notebook instance is InService , from Actions, choose Open Jupyter.\\nFor New , choose conda_tensorflw_p36 . This is the kernel you need.\\n5. To name the notebook, choose File, Rename, enter tRun-Python-Script , and then choose\\nRename.\\nTo create and upload the Dockerﬁle and Python scripts\\n1. In the editor of your choice, create the following Dockerﬁle text ﬁle locally and save it with the ﬁle\\nname \"Dockerﬁle\" without an extension. The docker build  command expects by default to ﬁnd a\\nﬁle with precisely this name in the dockerﬁle directory. For example, in Notepad, you can save a text\\nﬁle without an extension by choosing File, Save As and choosing All types(*.*) .\\nFROM tensorflow/tensorflow:2.0.0a0\\n396Amazon SageMaker Developer Guide\\nGet Started with Containers\\nRUN pip install sagemaker-containers\\n# Copies the training code inside the container\\nCOPY train.py /opt/ml/code/train.py\\n# Defines train.py as script entrypoint\\nENV SAGEMAKER_PROGRAM train.py\\nThe Dockerﬁle script performs the following tasks:\\n•FROM tensorflow/tensorflow:2.0.0a0  downloads the TensorFlow library used to run the\\nPython script.\\n•RUN pip install sagemaker-containers Amazon SageMaker Containers contains the\\ncommon functionality necessary to create a container compatible with Amazon SageMaker.\\n•COPY train.py /opt/ml/code/train.py  copies the script to the location inside the\\ncontainer that is expected by Amazon SageMaker. The script must be located in this folder.\\n•ENV SAGEMAKER_PROGRAM train.py  deﬁnes train.py as the name of the entrypoint script that\\nis located in the /opt/ml/code folder for the container. This is the only environmental variable\\nthat you must specify when, you are using your own container.\\n2. In the editor of your choice, create and save the following train.py  text ﬁle locally.\\nimport tensorflow as tf\\nmnist = tf.keras.datasets.mnist\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\nmodel = tf.keras.models.Sequential([\\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\\n    tf.keras.layers.Dense(128, activation=\\'relu\\'),\\n    tf.keras.layers.Dropout(0.2),\\n    tf.keras.layers.Dense(10, activation=\\'softmax\\')\\n])\\nmodel.compile(optimizer=\\'adam\\',\\n  loss=\\'sparse_categorical_crossentropy\\',\\n  metrics=[\\'accuracy\\'])\\n     \\nmodel.fit(x_train, y_train, epochs=1)\\nmodel.evaluate(x_test, y_test)\\n3. To upload the Dockerﬁle to a dockerﬁle directory, choose Open JupyterLab, choose the File\\nBrowser icon, and then choose the New Folder icon. This creates a new directory named dockerﬁle.\\n4. Double-click the new dockerfile  folder, choose the Upload Files icon, navigate to where you\\nsaved your Dockerﬁle and train.py  script ﬁles, and upload them to the dockerfile  folder.\\nTo build the container\\n1. The Jupyter Notebook opens in the SageMaker directory. The Docker build command must be run\\nfrom the dockerfile  directory you created. Run the following command to change into the\\ndockerfile  directory:\\ncd dockerfile\\nThis returns your current directory: /home/ec2-user/SageMaker/dockerfile\\n397Amazon SageMaker Developer Guide\\nPre-built Docker Images - Deep Learning\\n2. To build the Docker container, run the following Docker build command, including the ﬁnal period.\\n!docker build -t tf-2.0 .\\nTo test the container locally\\n1. Use Local Mode the test the container locally. Replace the \\'SageMakerRole\\'  value with the\\nARN for the role with the IAM role you created when conﬁguring the notebook instance. The ARN\\nshould look like: \\'arn:aws:iam::109225375568:role/service-role/AmazonSageMaker-\\nExecutionRole-20190429T110788\\' .\\nfrom sagemaker.estimator import Estimator \\nestimator = Estimator(image_name=\\'tf-2.0\\',\\n     role=\\'SageMakerRole\\',\\n     train_instance_count=1,\\n     train_instance_type=\\'local\\')\\n \\nestimator.fit()\\nThis test outputs the training environment conﬁguration, the values used for the environmental\\nvariables, the source of the data, and the loss and accuracy obtained during training.\\n2. After using Local Mode, you can push the image to Amazon Elastic Container Registry and use it to\\nrun training jobs. For an example that shows how to complete these tasks, see Building Your Own\\nTensorFlow Container\\nTo clean up resources when done with the get started example\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/, stop and\\nthen delete the notebook instance.\\n2. Open the Amazon S3console at https://console.aws.amazon.com/s3 and delete the bucket that you\\ncreated for storing model artifacts and the training dataset.\\n3. Open the IAM console at https://console.aws.amazon.com/iam/ and delete the IAM role. If you\\ncreated permission policies, you can delete them, too.\\nNote\\nThe Docker container shuts down automatically after it has run. You don\\'t need to delete it.\\nPrebuilt Amazon SageMaker Docker Images for\\nTensorFlow, MXNet, Chainer, and PyTorch\\nAmazon SageMaker provides prebuilt Docker images that include deep learning framework libraries and\\nother dependencies needed for training and inference. With the SageMaker Python SDK, you can train\\nand deploy models using one of these popular deep learning frameworks. For instructions on installing\\nand using the SDK, see Amazon SageMaker Python SDK.\\nThe following table provides links to the GitHub repositories that contain the source code and\\nDockerﬁles for each framework and for TensorFlow and MXNet Serving. The instructions linked are for\\nusing the Python SDK estimators to run your own training algorithms on Amazon SageMaker and your\\nown models on Amazon SageMaker hosting.\\n398Amazon SageMaker Developer Guide\\nPre-built Docker Images - Deep Learning\\nFrameworkPrebuilt Docker Image Source CodeInstructions\\nTensorFlowAmazon SageMaker TensorFlow\\nContainers\\nAmazon SageMaker TensorFlow Serving\\nContainerUsing TensorFlow with the SageMaker\\nPython SDK\\nMXNetAmazon SageMaker MXNet Containers\\nAmazon SageMaker MXNet Serving\\nContainerUsing MXNet with the SageMaker\\nPython SDK\\nChainerAmazon SageMaker Chainer SageMaker\\nContainersChainer SageMaker Estimators and\\nModels\\nPyTorchAmazon SageMaker PyTorch ContainersSageMaker PyTorch Estimators and\\nModels\\nIf you are not using the Amazon SageMaker Python SDK and one of its estimators to manage the\\ncontainer, you have to retrieve the relevant pre-built container. The Amazon SageMaker prebuilt Docker\\nimages are stored in Amazon Elastic Container Registry (Amazon ECR). To pull an image from an Amazon\\nECR repo or to push an image to an Amazon ECR repo, use the fullname registry address of the image.\\nAmazon SageMaker uses the following URL patterns for the container image registery addresses:\\n<account_id> .dkr.ecr. <region> .amazonaws.com/ <ECR repo name> :<framework\\nversion> -<processing unit type> -<python version>\\nThe following table itemizes the supported values for each of the components in the URL registery\\naddresses and how they are associated.\\nHere, for example, are some of the most common use cases for the deep learning frameworks supported\\nthe Amazon SageMaker:\\n•If you want to use TensorFlow 1.13 or later to train  a model with Python 3:\\n763104351884.dkr.ecr. <region> .amazonaws.com/tensorflow-training::1.14-gpu-py3\\n•If you want to use TensorFlow 1.14  or later to train  a model with Python 2:\\n763104351884.dkr.ecr. <region> .amazonaws.com/tensorflow-training::1.14-gpu-py2\\n•If you want to use TensorFlow 1.14  or later for inference with Python 3:\\n763104351884.dkr.ecr. <region> .amazonaws.com/tensorflow-inference::1.14-gpu-\\npy3\\n•If you want to use MxNet 1.4.1  or later to train  a model or for inference with Python 3:\\n763104351884.dkr.ecr. <region> .amazonaws.com/mxnet-training:1.4.1-gpu-py3\\n763104351884.dkr.ecr. <region> .amazonaws.com/ mxnet-inference:1.4.1-gpu-py3\\n•If you want to use Chainer  or PyTorch to train  a model or for inference with Python 2 or 3:\\n520713654638.dkr.ecr. <region> .amazonaws.com/sagemaker-chainer:5.0.0-\\ngpu-<python version>\\n520713654638.dkr.ecr. <region> .amazonaws.com/sagemaker-pytorch:1.1.0-\\ngpu-<python version>\\n399Amazon SageMaker Developer Guide\\nPre-built Docker Images - Deep Learning\\nURL Component Description Supported Values\\n<account_id>Speciﬁes the ID for Amazon\\nSageMaker accounts that contain\\nthe pre-built containers.•763104351884\\n•871362719292\\n•520713654638\\n•057415533634\\n<region>Speciﬁes the AWS regions that\\ncontain the Amazon SageMaker\\naccounts.•Accounts 763104351884  and\\n871362719292  are located in:\\nus-west-1, us-west-2, us-east-1, us-east-2,\\nap-northeast-1, ap-northeast-2, ap-\\nsoutheast-1, ap-southeast-2, ap-south-1,\\neu-west-1, eu-west-2, eu-central-1, ca-\\ncentral-1\\n•Accounts 520713654638  and\\n057415533634  are located in:\\nap-east-1\\n<ECR repo\\nname>Speciﬁes the name of the public\\nrepository owned by Amazon\\nSageMaker in the Amazon ECR.Python 3 containers for TensorFlow-1.13\\nand later and for MXNet-1.4.1 and later in\\naccounts 763104351884  and 871362719292 :\\n•tensorflow-training  (also for Python 2)\\n•tensorflow-inference\\n•mxnet-training\\n•mxnet-inference\\nOther Python 2 and Python 3 containers in\\naccounts 520713654638  and 057415533634 :\\n•sagemaker-tensorflow-scriptmode\\n(for Python 2 only)\\n•sagemaker-tensorflow-serving-eia\\n•sagemaker-mxnet  (for Python 2 only)\\n•sagemaker-mxnet-serving  (for Python 2\\nonly)\\n•sagemaker-mxnet-serving-eia\\n•sagemaker-chainer\\n•sagemaker-pytorch\\n<framework\\nversion>Speciﬁes the framework and\\nlinks to documentation for\\nthe estimators for each of the\\nframeworks that explains how to\\nspecify the supported versions.•TensorFlow: TensorFlow SageMaker\\nEstimators\\n•MXNet: MXNet SageMaker Estimators\\n•Chainer: Chainer SageMaker Estimators\\n•PyTorch: PyTorch SageMaker Estimators\\n<processing\\nunit type>Speciﬁes whether to use a GPU or\\nCPU for training or hosting.•cpu\\n•gpu\\n<python\\nversion>Speciﬁes the version of Python\\nused. (Optional if you are using•py2\\n•py3\\n400Amazon SageMaker Developer Guide\\nPre-built Docker Images - Scikit-learn and Spark ML\\nURL Component Description Supported Values\\nthe tensorflow-inference\\ncontainer for serving.)\\n•\\nAmazon SageMaker also provides prebuilt Docker images for scikit-learn and Spark ML. For information\\nabout Docker images that enable using scikit-learn and Spark ML solutions in Amazon SageMaker, see\\nPrebuilt Amazon SageMaker Docker Images for Scikit-learn and Spark ML  (p. 401).\\nYou can use prebuilt containers to deploy your custom models or models that you have purchased on\\nAWS Marketplace that have been trained in a framework other than Amazon SageMaker. For an overview\\nof the process of bringing the trained model artifacts into Amazon SageMaker and hosting them at an\\nendpoint, see Bring Your Own Pretrained MXNet or TensorFlow Models into Amazon SageMaker.\\nYou can customize these prebuilt containers or extend them to handle any additional functional\\nrequirements for your algorithm or model that the prebuilt Amazon SageMaker Docker image doesn\\'t\\nsupport. For an example, see Extending Our PyTorch Containers.\\nPrebuilt Amazon SageMaker Docker Images for\\nScikit-learn and Spark ML\\nAmazon SageMaker provides prebuilt Docker images that install the scikit-learn and Spark ML libraries\\nand the dependencies they need to build Docker images that are compatible with Amazon SageMaker\\nusing the Amazon SageMaker Python SDK. With the SDK, you can use scikit-learn for machine learning\\ntasks and use Spark ML to create and tune machine learning pipelines. For instructions on installing\\nand using the SDK, see SageMaker Python SDK. The following table contains links to the GitHub\\nrepositories with the source code and the Dockerﬁles for scikit-learn and Spark ML frameworks and\\nto instructions that show how use the Python SDK estimators to run your own training algorithms on\\nAmazon SageMaker Learner and your own models on Amazon SageMaker Hosting.\\nLibrary Prebuilt Docker Image Source Code Instructions\\nscikit-learn SageMaker Scikit-learn Containers Using Scikit-learn with the Amazon\\nSageMaker Python SDK\\nSpark ML SageMaker Spark ML Serving\\nContainersSparkML Serving\\nIf you are not using the SM Python SDK and one of its estimators to manage the container, you have to\\nretrieve the relevant pre-build container. The Amazon SageMaker prebuilt Docker images are stored in\\nAmazon Elastic Container Registry (Amazon ECR). You can push or pull them using their fullname registry\\naddresses. Amazon SageMaker uses the following Docker Image URL patterns for scikit-learn and Spark\\nM:\\n•<ACCOUNT_ID> .dkr.ecr. <REGION_NAME> .amazonaws.com/sagemaker-scikit-learn\\nFor example, 746614075791.dkr.ecr.us-west-1.amazonaws.com/sagemaker-scikit-learn\\n•<ACCOUNT_ID> .dkr.ecr. <REGION_NAME> .amazonaws.com/sagemaker-sparkml-serving\\n401Amazon SageMaker Developer Guide\\nExample Notebooks\\nFor example, 341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-sparkml-\\nserving\\nThe following table lists the supported values for account IDs and corresponding AWS Region names.\\nACCOUNT_ID REGION_NAME\\n746614075791 us-west-1\\n246618743249 us-west-2\\n683313688378 us-east-1\\n257758044811 us-east-2\\n354813040037 ap-northeast-1\\n366743142698 ap-northeast-2\\n121021644041 ap-southeast-1\\n783357654285 ap-southeast-2\\n720646828776 ap-south-1\\n141502667606 eu-west-1\\n764974769150 eu-west-2\\n492215442770 eu-central-1\\n341280168497 ca-central-1\\n414596584902 us-gov-west-1\\nThe supported values listed in the table are also available on the fw_registry.py page of the Amazon\\nSageMaker Python SDK GitHub repository.\\nAmazon SageMaker also provides prebuilt Docker images for popular deep learning frameworks. For\\ninformation about Docker images that enable using deep learning frameworks in Amazon SageMaker,\\nsee Prebuilt Amazon SageMaker Docker Images for TensorFlow, MXNet, Chainer, and PyTorch (p. 398).\\nFor information on Docker images for developing reinforcement learning (RL) solutions in Amazon\\nSageMaker, see Amazon SageMaker RL Containers.\\nExample Notebooks: Use Your Own Algorithm or\\nModel\\nThe following sample notebooks show how to use your own algorithms or pretrained models from an\\nAmazon SageMaker notebook instance. . After you have created a notebook instance and opened it,\\nchoose the SageMaker Examples tab for a list of all Amazon SageMaker example notebooks. You can\\nopen the sample notebooks from the Advanced Functionality section in your notebook instance or in\\nGitHub at the provided links. To open a notebook, choose its Use tab, then choose Create copy.\\n402Amazon SageMaker Developer Guide\\nExample Notebooks\\nFor instructions on how to create and access Jupyter notebook instances, see Use Notebook\\nInstances (p. 36)\\nTo learn how to host models trained in scikit-learn for making predictions in Amazon SageMaker by\\ninjecting them ﬁrst-party k-means and XGBoost containers, see the following sample notebooks.\\n•kmeans_bring_your_own_model - https://github.com/awslabs/amazon-sagemaker-examples/tree/\\nmaster/advanced_functionality/kmeans_bring_your_own_model\\n•xgboost_bring_your_own_model - https://github.com/awslabs/amazon-sagemaker-examples/tree/\\nmaster/advanced_functionality/xgboost_bring_your_own_model\\nTo learn how to package algorithms that you have developed in TensorFlow and scikit-learn\\nframeworks for training and deployment in the Amazon SageMaker environment, see the following\\nnotebooks. They show you how to build, register, and deploy you own Docker containers using\\nDockerﬁles.\\n•tensorﬂow_bring_your_own - https://github.com/awslabs/amazon-sagemaker-examples/tree/\\nmaster/advanced_functionality/tensorﬂow_bring_your_own\\n•scikit_bring_your_own - https://github.com/awslabs/amazon-sagemaker-examples/tree/master/\\nadvanced_functionality/scikit_bring_your_own\\nTo learn how to train a neural network locally using MXNet or TensorFlow, and then create an\\nendpoint from the trained model and deploy it on Amazon SageMaker, see the following notebooks.\\nThe MXNet model is trained to recognize handwritten numbers from the MNIST dataset. The TensorFlow\\nmodel is trained to classify irises.\\n•mxnet_mnist_byom - https://github.com/awslabs/amazon-sagemaker-examples/tree/master/\\nadvanced_functionality/mxnet_mnist_byom\\n•tensorﬂow_iris_byom - https://github.com/awslabs/amazon-sagemaker-examples/tree/master/\\nadvanced_functionality/tensorﬂow_iris_byom\\nTo learn how to use a Dockerﬁle to build a container that calls the train.py script  and uses\\npipe mode to custom train an algorithm, see the following notebook. In pipe mode, the input data is\\ntransferred to the algorithm while it is training. This can decrease training time compared to using ﬁle-\\nmode.\\n•pipe_bring_your_own - https://github.com/awslabs/amazon-sagemaker-examples/tree/master/\\nadvanced_functionality/pipe_bring_your_own\\nTo learn how to use an R container to train and host a model with the R kernel installed in a notebook ,\\nsee the following notebook. To take advantage of the AWS SDK for Python (Boto 3), we use Python\\nwithin the notebook. You can achieve the same results completely in R by invoking command line\\narguments.\\n•r_bring_your_own - https://github.com/awslabs/amazon-sagemaker-examples/tree/master/\\nadvanced_functionality/r_bring_your_own\\nTo learn how to extend a prebuilt Amazon SageMaker PyTorch container image when you have\\nadditional functional requirements for your algorithm or model that the pre-built Docker image doesn\\'t\\nsupport, see the following notebook.\\n•pytorch_extending_our_containers - https://github.com/awslabs/amazon-sagemaker-examples/tree/\\nmaster/advanced_functionality/pytorch_extending_our_containers\\n403Amazon SageMaker Developer Guide\\nUse Your Own Training Algorithms\\nFor links to the GitHub repositories with the prebuilt Dockerﬁles for the TensorFlow, MXNet, Chainer,\\nand PyTorch frameworks and instructions on use the AWS SDK for Python (Boto 3) estimators to\\nrun your own training algorithms on Amazon SageMaker Learner and your own models on Amazon\\nSageMaker hosting, see Prebuilt Amazon SageMaker Docker Images for TensorFlow, MXNet, Chainer, and\\nPyTorch (p. 398)\\nUse Your Own Training Algorithms\\nThis section explains how Amazon SageMaker interacts with a Docker container that runs your custom\\ntraining algorithm. Use this information to write training code and create a Docker image for your\\ntraining algorithms.\\nTopics\\n•How Amazon SageMaker Runs Your Training Image (p. 404)\\n•How Amazon SageMaker Provides Training Information  (p. 405)\\n•How Amazon SageMaker Signals Algorithm Success and Failure (p. 407)\\n•How Amazon SageMaker Processes Training Output  (p. 408)\\nHow Amazon SageMaker Runs Your Training Image\\nTo conﬁgure a Docker container to run as an executable, use an ENTRYPOINT  instruction in a Dockerﬁle.\\nNote the following:\\n•For model training, Amazon SageMaker runs the container as follows:\\ndocker run image train\\nAmazon SageMaker overrides any default CMD statement in a container by specifying the train\\nargument after the image name. The train argument also overrides arguments that you provide\\nusing CMD in the Dockerﬁle.\\n\\xa0\\n•Use the exec  form of the ENTRYPOINT  instruction:\\nENTRYPOINT [\"executable\", \"param1\", \"param2\", ...]\\nFor example:\\nENTRYPOINT [\"python\", \"k-means-algorithm.py\"]\\nThe exec  form of the ENTRYPOINT  instruction starts the executable directly, not as a child of /bin/\\nsh. This enables it to receive signals like SIGTERM  and SIGKILL from Amazon SageMaker APIs. Note\\nthe following:\\n\\xa0\\n•The CreateTrainingJob (p. 667) API has a stopping condition that directs Amazon SageMaker to\\nstop model training after a speciﬁc time.\\n\\xa0\\n•The StopTrainingJob (p. 834) API issues the equivalent of the docker stop , with a 2 minute\\ntimeout, command to gracefully stop the speciﬁed container:\\n404Amazon SageMaker Developer Guide\\nProvide Training Information\\ndocker stop -t120\\nThe command attempts to stop the running container by sending a SIGTERM signal. After the 2\\nminute timeout, SIGKILL is sent and the containers are forcibly stopped. If the container handles the\\nSIGTERM gracefully and exits within 120 seconds from receiving it, no SIGKILL is sent.\\nNote\\nIf you want access to the intermediate model artifacts after Amazon SageMaker stops the\\ntraining, add code to handle saving artifacts in your SIGTERM handler.\\n•If you plan to use GPU devices for model training, make sure that your containers are nvidia-docker\\ncompatible. Only the CUDA toolkit should be included on containers; don\\'t bundle NVIDIA drivers with\\nthe image. For more information about nvidia-docker , see NVIDIA/nvidia-docker.\\n•You can\\'t use the tini initializer as your entry point in Amazon SageMaker containers because it gets\\nconfused by the train and serve arguments.\\n•/opt/ml and all sub-directories are reserved by Amazon SageMaker training. When building your\\nalgorithm’s docker image, please ensure you don\\'t place any data required by your algorithm under\\nthem as the data may no longer be visible during training.\\nHow Amazon SageMaker Provides Training\\nInformation\\nThis section explains how Amazon SageMaker makes training information, such as training data,\\nhyperparameters, and other conﬁguration information, available to your Docker container.\\nWhen you send a CreateTrainingJob (p. 667) request to Amazon SageMaker to start model training,\\nyou specify the Amazon Elastic Container Registry path of the Docker image that contains the training\\nalgorithm. You also specify the Amazon Simple Storage Service (Amazon S3) location where training\\ndata is stored and algorithm-speciﬁc parameters. Amazon SageMaker makes this information available\\nto the Docker container so that your training algorithm can use it. This section explains how we make\\nthis information available to your Docker container. For information about creating a training job, see\\nCreateTrainingJob .\\nTopics\\n•Hyperparameters  (p. 405)\\n•Environment Variables (p. 405)\\n•Input Data Conﬁguration  (p. 406)\\n•Training Data (p. 406)\\n•Distributed Training Conﬁguration (p. 407)\\nHyperparameters\\nAmazon SageMaker makes the hyperparameters in a CreateTrainingJob  request available in the\\nDocker container in the /opt/ml/input/config/hyperparameters.json  ﬁle.\\nEnvironment Variables\\n•TRAINING_JOB_NAME—The training job name stored in the TrainingJobName  parameter in a\\nCreateTrainingJob (p. 667) request.\\n•TRAINING_JOB_ARN—The Amazon Resource Name (ARN) of the training job returned as the\\nTrainingJobArn  response element for CreateTrainingJob (p. 667).\\n405Amazon SageMaker Developer Guide\\nProvide Training Information\\nInput Data Conﬁguration\\nYou specify data channel information in the InputDataConfig  parameter in a CreateTrainingJob\\nrequest. Amazon SageMaker makes this information available in the /opt/ml/input/config/\\ninputdataconfig.json  ﬁle in the Docker container.\\nFor example, suppose that you specify three data channels (train , evaluation , and validation ) in\\nyour request. Amazon SageMaker provides the following JSON:\\n{\\n\"train\" : {\"ContentType\":  \"trainingContentType\", \\n           \"TrainingInputMode\": \"File\", \\n           \"S3DistributionType\": \"FullyReplicated\", \\n           \"RecordWrapperType\": \"None\"},\\n\"evaluation\" : {\"ContentType\":  \"evalContentType\", \\n                \"TrainingInputMode\": \"File\", \\n                \"S3DistributionType\": \"FullyReplicated\", \\n                \"RecordWrapperType\": \"None\"},\\n\"validation\" : {\"TrainingInputMode\": \"File\", \\n                \"S3DistributionType\": \"FullyReplicated\", \\n                \"RecordWrapperType\": \"None\"}\\n} \\nNote\\nAmazon SageMaker provides only relevant information about each data channel (for example,\\nthe channel name and the content type) to the container, as shown. S3DistributionType  will\\nbe set as FullyReplicated  if specify EFS or FSxLustre as input data sources.\\nTraining Data\\nThe TrainingInputMode  parameter in a CreateTrainingJob  request speciﬁes how to make data\\navailable for model training: in FILE  mode or PIPE  mode. Depending on the speciﬁed input mode,\\nAmazon SageMaker does the following:\\n•FILE mode—Amazon SageMaker makes the data for the channel available in the /opt/ml/input/\\ndata/channel_name  directory in the Docker container. For example, if you have three channels\\nnamed training , validation , and testing, Amazon SageMaker makes three directories in the\\nDocker container:\\n•/opt/ml/input/data/training\\n•/opt/ml/input/data/validation\\n•/opt/ml/input/data/testing\\n\\xa0\\n•PIPE mode—Amazon SageMaker makes data for the channel available from the named pipe: /opt/\\nml/input/data/ channel_name_epoch_number . For example, if you have three channels named\\ntraining , validation , and testing, you will need to read from the following pipes:\\n•/opt/ml/input/data/training_0,/opt/ml/input/data/training_1, ...\\n•/opt/ml/input/data/validation_0, /opt/ml/input/data/validation_1, ...\\n•/opt/ml/input/data/testing_0, /opt/ml/input/data/testing_1, ...\\nRead the pipes sequentially. For example, if you have a channel called training , read the pipes in this\\nsequence:\\n1.Open /opt/ml/input/data/training_0  in read mode and read it to EOF (or if you are done\\nwith the ﬁrst epoch, close the ﬁle early).\\n2.After closing the ﬁrst pipe ﬁle, look for /opt/ml/input/data/training_1  and read it to go\\nthrough the second epoch, and so on.\\n406Amazon SageMaker Developer Guide\\nSignal Success or Failure\\nIf the ﬁle for a given epoch doesn\\'t exist yet, your code may need to retry until the pipe is created.\\nThere is no sequencing restriction across channel types. That is, you can read multiple epochs for the\\ntraining  channel, for example, and only start reading the validation  channel when you are ready.\\nOr, you can read them simultaneously if your algorithm requires that.\\nDistributed Training Conﬁguration\\nIf you\\'re performing distributed training with multiple containers, Amazon SageMaker makes\\ninformation about all containers available in the /opt/ml/input/config/resourceconfig.json\\nﬁle.\\nTo enable inter-container communication, this JSON ﬁle contains information for all containers. Amazon\\nSageMaker makes this ﬁle available for both FILE and PIPE mode algorithms. The ﬁle provides the\\nfollowing information:\\n•current_host —The name of the current container on the container network. For example, algo-1 .\\nHost values can change at any time. Don\\'t write code with speciﬁc values for this variable.\\n•hosts—The list of names of all containers on the container network, sorted lexicographically. For\\nexample, [\"algo-1\", \"algo-2\", \"algo-3\"]  for a three-node cluster. Containers can use these\\nnames to address other containers on the container network. Host values can change at any time.\\nDon\\'t write code with speciﬁc values for these variables.\\n•network_interface_name —The name of the network interface that is exposed to your container.\\nFor example, containers running the Message Passing Interface (MPI) can use this information to set\\nthe network interface name.\\n•Do not use the information in /etc/hostname  or /etc/hosts  because it might be inaccurate.\\n•Hostname information may not be immediately available to the algorithm container. We recommend\\nadding a retry policy on hostname resolution operations as nodes become available in the cluster.\\nThe following is an example ﬁle on node 1 in a three-node cluster:\\n{\\n\"current_host\": \"algo-1\",\\n\"hosts\": [\"algo-1\",\"algo-2\",\"algo-3\"],\\n\"network_interface_name\":\"eth1\"\\n}\\nHow Amazon SageMaker Signals Algorithm Success\\nand Failure\\nA training algorithm indicates whether it succeeded or failed using the exit code of its process.\\nA successful training execution should exit with an exit code of 0 and an unsuccessful training execution\\nshould exit with a non-zero exit code. These will be converted to \"Completed\" and \"Failed\" in the\\nTrainingJobStatus  returned by DescribeTrainingJob . This exit code convention is standard and\\nis easily implemented in all languages. For example, in Python, you can use sys.exit(1)  to signal a\\nfailure exit and simply running to the end of the main routine will cause Python to exit with code 0.\\nIn the case of failure, the algorithm can write a description of the failure to the failure ﬁle. See next\\nsection for details.\\n407Amazon SageMaker Developer Guide\\nTraining Output\\nHow Amazon SageMaker Processes Training Output\\nAs your algorithm runs in a container, it generates output including the status of the training job and\\nmodel and output artifacts. Your algorithm should write this information to the following ﬁles, which are\\nlocated in the container\\'s /output directory. Amazon SageMaker processes the information contained in\\nthis directory as follows:\\n•/opt/ml/output/failure —If training fails, after all algorithm output (for example,\\nlogging) completes, your algorithm should write the failure description to this ﬁle. In a\\nDescribeTrainingJob  response, Amazon SageMaker returns the ﬁrst 1024 characters from this ﬁle\\nas FailureReason .\\n\\xa0\\n•/opt/ml/model —Your algorithm should write all ﬁnal model artifacts to this directory. Amazon\\nSageMaker copies this data as a single object in compressed tar format to the S3 location that you\\nspeciﬁed in the CreateTrainingJob  request. If multiple containers in a single training job write to\\nthis directory they should ensure no file/directory  names clash. Amazon SageMaker aggregates\\nthe result in a tar ﬁle and uploads to s3.\\nUse Your Own Inference Code\\nYou can use Amazon SageMaker to interact with Docker containers and run your own inference code in\\none of two ways:\\n•To use your own inference code with a persistent endpoint to get one prediction at a time, use Amazon\\nSageMaker hosting services.\\n•To use your own inference code to get predictions for an entire dataset, use Amazon SageMaker batch\\ntransform.\\nTopics\\n•Use Your Own Inference Code with Hosting Services (p. 408)\\n•Use Your Own Inference Code with Batch Transform (p. 411)\\nUse Your Own Inference Code with Hosting Services\\nThis section explains how Amazon SageMaker interacts with a Docker container that runs your own\\ninference code for hosting services. Use this information to write inference code and create a Docker\\nimage.\\nTopics\\n•How Amazon SageMaker Runs Your Inference Image (p. 408)\\n•How Amazon SageMaker Loads Your Model Artifacts (p. 410)\\n•How Containers Serve Requests (p. 410)\\n•How Your Container Should Respond to Inference Requests (p. 410)\\n•How Your Container Should Respond to Health Check (Ping) Requests (p. 410)\\nHow Amazon SageMaker Runs Your Inference Image\\nTo conﬁgure a container to run as an executable, use an ENTRYPOINT  instruction in a Dockerﬁle. Note\\nthe following:\\n408Amazon SageMaker Developer Guide\\nWith Hosting Services\\n•For model inference, Amazon SageMaker runs the container as:\\ndocker run image serve\\nAmazon SageMaker overrides default CMD statements in a container by specifying the serve\\nargument after the image name. The serve argument overrides arguments that you provide with the\\nCMD command in the Dockerﬁle.\\n\\xa0\\n•We recommend that you use the exec  form of the ENTRYPOINT  instruction:\\nENTRYPOINT [\"executable\", \"param1\", \"param2\"]\\nFor example:\\nENTRYPOINT [\"python\", \"k_means_inference.py\"]\\nThe exec  form of the ENTRYPOINT  instruction starts the executable directly, not as a child of /bin/\\nsh. This enables it to receive signals like SIGTERM  and SIGKILL from the Amazon SageMaker APIs,\\nwhich is a requirement.\\n\\xa0\\nFor example, when you use the CreateEndpoint (p. 632) API to create an endpoint, Amazon\\nSageMaker provisions the number of ML compute instances required by the endpoint conﬁguration,\\nwhich you specify in the request. Amazon SageMaker runs the Docker container on those instances.\\n\\xa0\\nIf you reduce the number of instances backing the endpoint (by calling the\\nUpdateEndpointWeightsAndCapacities (p. 842) APIs), Amazon SageMaker runs a command to stop\\nthe Docker container on the instances being terminated. The command sends the SIGTERM  signal,\\nthen it sends the SIGKILL signal thirty seconds later.\\n\\xa0\\nIf you update the endpoint (by calling the UpdateEndpoint  (p. 840) API), Amazon SageMaker\\nlaunches another set of ML compute instances and runs the Docker containers that contain your\\ninference code on them. Then it runs a command to stop the previous Docker containers. To stop\\na Docker container, command sends the SIGTERM  signal, then it sends the SIGKILL signal thirty\\nseconds later.\\n\\xa0\\n•Amazon SageMaker uses the container deﬁnition that you provided in your CreateModel (p. 648)\\nrequest to set environment variables and the DNS hostname for the container as follows:\\n\\xa0\\n•It sets environment variables using the ContainerDefinition.Environment  string-to-string\\nmap.\\n•It sets the DNS hostname using the ContainerDefinition.ContainerHostname .\\n\\xa0\\n•If you plan to use GPU devices for model inferences (by specifying GPU-based ML compute instances\\nin your CreateEndpointConfig  request), make sure that your containers are nvidia-docker\\n409Amazon SageMaker Developer Guide\\nWith Hosting Services\\ncompatible. Don\\'t bundle NVIDIA drivers with the image. For more information about nvidia-\\ndocker , see NVIDIA/nvidia-docker.\\n\\xa0\\n•You can\\'t use the tini initializer as your entry point in Amazon SageMaker containers because it gets\\nconfused by the train and serve arguments.\\nHow Amazon SageMaker Loads Your Model Artifacts\\nIn your CreateModel (p. 648) request, the container deﬁnition includes the ModelDataUrl  parameter,\\nwhich identiﬁes the S3 location where model artifacts are stored. Amazon SageMaker uses this\\ninformation to determine where to copy the model artifacts from. It copies the artifacts to the /opt/\\nml/model  directory for use by your inference code.\\nThe ModelDataUrl  must point to a tar.gz ﬁle. Otherwise, Amazon SageMaker won\\'t download the ﬁle.\\nIf you trained your model in Amazon SageMaker, the model artifacts are saved as a single compressed tar\\nﬁle in Amazon S3. If you trained your model outside Amazon SageMaker, you need to create this single\\ncompressed tar ﬁle and save it in a S3 location. Amazon SageMaker decompresses this tar ﬁle into /opt/\\nml/model directory before your container starts.\\nHow Containers Serve Requests\\nContainers need to implement a web server that responds to /invocations  and /ping on port 8080.\\nHow Your Container Should Respond to Inference Requests\\nTo obtain inferences, the client application sends a POST request to the Amazon SageMaker endpoint.\\nFor more information, see the InvokeEndpoint (p. 853) API. Amazon SageMaker passes the request to\\nthe container, and returns the inference result from the container to the client. Note the following:\\n•Amazon SageMaker strips all POST headers except those supported by InvokeEndpoint . Amazon\\nSageMaker might add additional headers. Inference containers must be able to safely ignore these\\nadditional headers.\\n•To receive inference requests, the container must have a web server listening on port 8080 and must\\naccept POST requests to the /invocations  endpoint.\\n•A customer\\'s model containers must accept socket connection requests within 250 ms.\\n•A customer\\'s model containers must respond to requests within 60 seconds. The model itself can\\nhave a maximum processing time of 60 seconds before responding to the /invocations. If your model\\nis going to take 50-60 seconds of processing time, the SDK socket timeout should be set to be 70\\nseconds.\\nHow Your Container Should Respond to Health Check (Ping)\\nRequests\\nThe CreateEndpoint  and UpdateEndpoint  API calls result in Amazon SageMaker starting new\\ninference containers. Soon after container startup, Amazon SageMaker starts sending periodic GET\\nrequests to the /ping endpoint.\\nThe simplest requirement on the container is to respond with an HTTP 200 status code and an empty\\nbody. This indicates to Amazon SageMaker that the container is ready to accept inference requests at\\nthe /invocations endpoint.\\n410Amazon SageMaker Developer Guide\\nWith Batch Transform\\nIf the container does not begin to pass health checks, by consistently responding with 200s, during the\\n4 minutes after startup, CreateEndPoint  will fail, leaving Endpoint in a failed state, and the update\\nrequested by UpdateEndpoint  will not be completed.\\nWhile the minimum bar is for the container to return a static 200, a container developer can use this\\nfunctionality to perform deeper checks. The request timeout on /ping attempts is 2 seconds.\\nUse Your Own Inference Code with Batch Transform\\nThis section explains how Amazon SageMaker interacts with a Docker container that runs your own\\ninference code for batch transform. Use this information to write inference code and create a Docker\\nimage.\\nTopics\\n•How Amazon SageMaker Runs Your Inference Image  (p. 411)\\n•How Amazon SageMaker Loads Your Model Artifacts (p. 412)\\n•How Containers Serve Requests (p. 412)\\n•How Your Container Should Respond to Health Check (Ping) Requests (p. 413)\\nHow Amazon SageMaker Runs Your Inference Image\\nTo conﬁgure a container to run as an executable, use an ENTRYPOINT  instruction in a Dockerﬁle. Note\\nthe following:\\n•For batch transforms, Amazon SageMaker runs the container as:\\ndocker run image serve\\nAmazon SageMaker overrides default CMD statements in a container by specifying the serve\\nargument after the image name. The serve argument overrides arguments that you provide with the\\nCMD command in the Dockerﬁle.\\n\\xa0\\n•We recommend that you use the exec  form of the ENTRYPOINT  instruction:\\nENTRYPOINT [\"executable\", \"param1\", \"param2\"]\\nFor example:\\nENTRYPOINT [\"python\", \"k_means_inference.py\"]\\n\\xa0\\n•Amazon SageMaker sets environment variables speciﬁed in CreateModel (p. 648) and\\nCreateTransformJob (p. 673) on your container. Additionally, the following environment variables will\\nbe populated:\\n•SAGEMAKER_BATCH  is always set to true when the container runs in Batch Transform.\\n•SAGEMAKER_MAX_PAYLOAD_IN_MB  is set to the largest size payload that will be sent to the\\ncontainer via HTTP.\\n•SAGEMAKER_BATCH_STRATEGY  will be set to SINGLE_RECORD  when the container will be sent a\\nsingle record per call to invocations and MULTI_RECORD  when the container will get as many records\\nas will ﬁt in the payload.\\n411Amazon SageMaker Developer Guide\\nWith Batch Transform\\n•SAGEMAKER_MAX_CONCURRENT_TRANSFORMS  is set to the maximum number of /invocations\\nrequests that can be opened simultaneously.\\nNote\\nThe last three environment variables come from the API call made by the user. If the user\\ndoesn’t set values for them, they aren\\'t passed. In that case, either the default values or the\\nvalues requested by the algorithm (in response to the /execution-parameters ) are used.\\n•If you plan to use GPU devices for model inferences (by specifying GPU-based ML compute instances\\nin your CreateTransformJob  request), make sure that your containers are nvidia-docker compatible.\\nDon\\'t bundle NVIDIA drivers with the image. For more information about nvidia-docker, see NVIDIA/\\nnvidia-docker.\\n\\xa0\\n•You can\\'t use the init initializer as your entry point in Amazon SageMaker containers because it gets\\nconfused by the train and serve arguments.\\nHow Amazon SageMaker Loads Your Model Artifacts\\nIn a CreateModel (p. 648) request, container deﬁnitions includes the ModelDataUrl  parameter, which\\nidentiﬁes the location in Amazon S3 where model artifacts are stored. When you use Amazon SageMaker\\nto run inferences, it uses this information to determine where to copy the model artifacts from. It copies\\nthe artifacts to the /opt/ml/model  directory in the Docker container for use by your inference code.\\nThe ModelDataUrl  parameter must point to a tar.gz ﬁle. Otherwise, Amazon SageMaker can\\'t\\ndownload the ﬁle. If you train a model in Amazon SageMaker, it saves the artifacts as a single\\ncompressed tar ﬁle in Amazon S3. If you train a model in another framework, you need to store the\\nmodel artifacts in Amazon S3 as a compressed tar ﬁle. Amazon SageMaker decompresses this tar ﬁle and\\nsaves it in the /opt/ml/model  directory in the container before the batch transform job starts.\\nHow Containers Serve Requests\\nContainers must implement a web server that responds to invocations and ping requests on port\\n8080. For batch transforms,you have the option to set algorithms to implement execution-parameters\\nrequests to provide a dynamic runtime conﬁguration to Amazon SageMaker. Amazon SageMaker uses\\nthe following endpoints:\\n•ping—Used to periodically check the health of the container. Amazon SageMaker waits for an HTTP\\n200 status code and an empty body for a successful ping request before sending an invocations\\nrequest. You might use a ping request to load a model into memory to generate inference when\\ninvocations requests are sent.\\n•(Optional) execution-parameters —Allows the algorithm to provide the optimal tuning parameters\\nfor a job during runtime. Based on the memory and CPUs available for a container, the algorithm\\nchooses the appropriate MaxConcurrentTransforms , BatchStrategy , and MaxPayloadInMB\\nvalues for the job.\\nBefore calling the invocations request, Amazon SageMaker attempts to invoke the execution-\\nparameters request. When you create a batch transform job, you can provide values for the\\nMaxConcurrentTransforms , BatchStrategy , and MaxPayloadInMB  parameters. Amazon\\nSageMaker determines the values for these parameters using this order of precedence:\\n1.The parameter values that you provide when you create the CreateTransformJob  request,\\n2.The values that the model container returns when Amazon SageMaker invokes the execution-\\nparameters endpoint\\n3.The parameters default values, listed in the following table.\\n412Amazon SageMaker Developer Guide\\nCreate Algorithm and Model Package Resources\\nParameter Default Values\\nMaxConcurrentTransforms 1\\nBatchStrategy MULTI_RECORD\\nMaxPayloadInMB 6\\nThe response for a GET execution-parameters request is a JSON object with keys for\\nMaxConcurrentTransforms , BatchStrategy , and MaxPayloadInMB  parameters. This is an example\\nof a valid response:\\n{\\n  “MaxConcurrentTransforms”: 8,\\n  “BatchStrategy\": \"MULTI_RECORD\",\\n  \"MaxPayloadInMB\": 6\\n}\\nHow Your Container Should Respond to Health Check (Ping)\\nRequests\\nThe simplest requirement on the container is to respond with an HTTP 200 status code and an empty\\nbody. This indicates to Amazon SageMaker that the container is ready to accept inference requests at the\\n/invocations  endpoint.\\nWhile the minimum bar is for the container to return a static 200, a container developer can use this\\nfunctionality to perform deeper checks. The request timeout on /ping attempts is 2 seconds.\\nCreate Algorithm and Model Package Resources\\nAfter your training and/or inference code is packaged in Docker containers, create algorithm and model\\npackage resources that you can use in your Amazon SageMaker account and, optionally, publish on AWS\\nMarketplace.\\nTopics\\n•Create an Algorithm Resource (p. 413)\\n•Create a Model Package Resource (p. 417)\\nCreate an Algorithm Resource\\nTo create an algorithm resource that you can use to run training jobs in Amazon SageMaker and publish\\non AWS Marketplace specify the following information:\\n•The Docker containers that contains the training and, optionally, inference code.\\n•The conﬁguration of the input data that your algorithm expects for training.\\n•The hyperparameters that your algorithm supports.\\n•Metrics that your algorithm sends to Amazon CloudWatch during training jobs.\\n•The instance types that your algorithm supports for training and inference, and whether it supports\\ndistributed training across multiple instances.\\n413Amazon SageMaker Developer Guide\\nCreate an Algorithm Resource\\n•Validation proﬁles, which are training jobs that Amazon SageMaker uses to test your algorithm\\'s\\ntraining code and batch transform jobs that Amazon SageMaker runs to test your algorithm\\'s inference\\ncode.\\nTo ensure that buyers and sellers can be conﬁdent that products work in Amazon SageMaker, we\\nrequire that you validate your algorithms before listing them on AWS Marketplace. You can list\\nproducts in the AWS Marketplace only if validation succeeds. To validate your algorithms, Amazon\\nSageMaker uses your validation proﬁle and sample data to run the following validations tasks:\\n1.Create a training job in your account to verify that your training image works with Amazon\\nSageMaker.\\n2.If you included inference code in your algorithm, create a model in your account using the\\nalgorithm\\'s inference image and the model artifacts produced by the training job.\\n3.If you included inference code in your algorithm, create a transform job in your account using the\\nmodel to verify that your inference image works with Amazon SageMaker.\\nWhen you list your product on AWS Marketplace, the inputs and outputs of this validation process\\npersist as part of your product and are made available to your buyers. This helps buyers understand\\nand evaluate the product before they buy it. For example, buyers can inspect the input data that you\\nused, the outputs generated, and the logs and metrics emitted by your code. The more comprehensive\\nyour validation speciﬁcation, the easier it is for customers to evaluate your product.\\nNote\\nIn your validation proﬁle, provide only data that you want to expose publicly.\\nValidation can take up to a few hours. To see the status of the jobs in your account, in the Amazon\\nSageMaker console, see the Training jobs and Transform jobs pages. If validation fails, you can access\\nthe scan and validation reports from the Amazon SageMaker console. If any issues are found, you will\\nhave to create the algorithm again.\\nNote\\nTo publish your algorithm on AWS Marketplace, at least one validation proﬁle is required.\\nYou can create an algorithm by using either the Amazon SageMaker console or the Amazon SageMaker\\nAPI.\\nTopics\\n•Create an Algorithm Resource (Console) (p. 414)\\n•Create an Algorithm Resource (API) (p. 417)\\nCreate an Algorithm Resource (Console)\\nTo create an algorithm resource (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Algorithms, then choose Create algorithm.\\n3. On the Training speciﬁcations page, provide the following information:\\na. For Algorithm name, type a name for your algorithm. The algorithm name must be unique in\\nyour account and in the AWS region. The name must have 1 to 64 characters. Valid characters\\nare a-z, A-Z, 0-9, and - (hyphen).\\nb. Type a description for your algorithm. This description appears in the Amazon SageMaker\\nconsole and in the AWS Marketplace.\\nc. For Training image, type the path in Amazon ECR where your training container is stored.\\nd. For Support distributed training, Choose Yes if your algorithm supports training on multiple\\ninstances. Otherwise, choose No.\\n414Amazon SageMaker Developer Guide\\nCreate an Algorithm Resource\\ne. For Support instance types for training, choose the instance types that your algorithm\\nsupports.\\nf.For Channel speciﬁcation , specify up to 8 channels of input data for your algorithm. For\\nexample, you might specify 3 input channels named train , validation , and test. For each\\nchannel, specify the following information:\\ni. For Channel name , type a name for the channel. The name must have 1 to 64 characters.\\nValid characters are a-z, A-Z, 0-9, and - (hyphen).\\nii. To require the channel for your algorithm, choose Channel required .\\niii. Type a description for the channel.\\niv.For Supported input modes, choose Pipe mode  if your algorithm supports streaming the\\ninput data, and File mode if your algorithm supports downloading the input data as a ﬁle.\\nYou can choose both.\\nv.For Supported content types, type the MIME type that your algorithm expects for input\\ndata.\\nvi. For Supported compression type, choose Gzip  if your algorithm supports Gzip\\ncompression. Otherwise, choose None .\\nvii. Choose Add channel  to add another data input channel, or choose Next if you are done\\nadding channels.\\n4. On the Tuning speciﬁcations page, provide the following information:\\na. For Hyperparameter speciﬁcation , specify the hyperparameters that your algorithm supports\\nby editing the JSON object. For each hyperparameter that your algorithm supports, construct a\\nJSON block similar to the following:\\n{\\n  \"DefaultValue\": \"5\",\\n  \"Description\": \"The first hyperparameter\",\\n  \"IsRequired\": true,\\n  \"IsTunable\": false,\\n  \"Name\": \"intRange\",\\n  \"Range\": {\\n   \"IntegerParameterRangeSpecification\": {\\n    \"MaxValue\": \"10\",\\n    \"MinValue\": \"1\"\\n   }\\n  },\\n  \"Type\": \"Integer\"\\nIn the JSON, supply the following:\\ni. For DefaultValue , specify a default value for the hyperparameter, if there is one.\\nii. For Description , specify a description for the hyperparameter.\\niii. For IsRequired , specify whether the hyperparameter is required.\\niv.For IsTunable , specify true if this hyperparameter can be tuned when a user runs a\\nhyperparameter tuning job that uses this algorithm. For information, see Automatic Model\\nTuning (p. 288).\\nv.For Name, specify a name for the hyperparameter.\\nvi. For Range, specify one of the following:\\n•IntegerParameterRangeSpecification  - the values of the hyperparameter are\\nintegers. Specify minimum and maximum values for the hyperparameter.\\n•\\n•ContinuousParameterRangeSpecification  - the values of the hyperparameter are\\nﬂoating-point values. Specify minimum and maximum values for the hyperparameter.\\n415Amazon SageMaker Developer Guide\\nCreate an Algorithm Resource\\n•CategoricalParameterRangeSpecification  - the values of the hyperparameter are\\ncategorical values. Specify a list of all of the possible values.\\nvii. For Type, specify Integer , Continuous , or Categorical . The value must correspond to\\nthe type of Range that you speciﬁed.\\nb. For Metric deﬁnitions , specify any training metrics that you want your algorithm to emit.\\nAmazon SageMaker uses the regular expression that you specify to ﬁnd the metrics by parsing\\nthe logs from your training container during training. Users can view these metrics when they\\nrun training jobs with your algorithm, and they can monitor and plot the metrics in Amazon\\nCloudWatch. For information, see Monitor and Analyze Training Jobs Using Metrics (p. 276). For\\neach metric, provide the following information:\\ni. For Metric name , type a name for the metric.\\nii. For Regex, type the regular expression that Amazon SageMaker uses to parse training logs\\nso that it can ﬁnd the metric value.\\niii. For Objective metric support choose Yes if this metric can be used as the objective metric\\nfor a hyperparameter tuning job. For information, see Automatic Model Tuning (p. 288).\\niv.Choose Add metric  to add another metric, or choose Next if you are done adding metrics.\\n5. On the Inference speciﬁcations page, provide the following information if your algorithm supports\\ninference:\\na. For Container deﬁnition , type path in Amazon ECR where your inference container is stored.\\nb. For Container DNS host name , type the name of a DNS host for your image.\\nc. For Supported instance types for real-time inference, choose the instance types that your\\nalgorithm supports for models deployed as hosted endpoints in Amazon SageMaker. For\\ninformation, see Deploy a Model on Amazon SageMaker Hosting Services (p. 7).\\nd. For Supported instance types for batch transform jobs, choose the instance types that your\\nalgorithm supports for batch transform jobs. For information, see Get Inferences for an Entire\\nDataset with Batch Transform (p. 10).\\ne. For Supported content types, type the type of input data that your algorithm expects for\\ninference requests.\\nf.For Supported response MIME types, type the MIME types that your algorithm supports for\\ninference responses.\\ng. Choose Next.\\n6. On the Validation speciﬁcations page, provide the following information:\\na. For Publish this algorithm on AWS Marketplace, choose Yes to publish the algorithm on AWS\\nMarketplace.\\nb. For Validate this algorithm, choose Yes if you want Amazon SageMaker to run training jobs\\nand/or batch transform jobs that you specify to test the training and/or inference code of your\\nalgorithm.\\nNote\\nTo publish your algorithm on AWS Marketplace, your algorithm must be validated.\\nc. For IAM role, choose an IAM role that has the required permissions to run training jobs and\\nbatch transform jobs in Amazon SageMaker, or choose Create a new role to allow Amazon\\nSageMaker to create a role that has the AmazonSageMakerFullAccess  managed policy\\nattached. For information, see Amazon SageMaker Roles  (p. 496).\\nd. For Validation proﬁle, specify the following:\\n•A name for the validation proﬁle.\\n•A Training job deﬁnition. This is a JSON block that describes a training job. This is\\nin the same format as the TrainingJobDeﬁnition (p. 1015 ) input parameter of the\\nCreateAlgorithm (p. 622) API.\\n416Amazon SageMaker Developer Guide\\nCreate a Model Package Resource\\n•A Transform job deﬁnition. This is a JSON block that describes a batch transform job.\\nThis is in the same format as the TransformJobDeﬁnition (p. 1026 )input parameter of the\\nCreateAlgorithm (p. 622) API.\\ne. Choose Create algorithm.\\nCreate an Algorithm Resource (API)\\nTo create an algorithm resource by using the Amazon SageMaker API, call the CreateAlgorithm (p. 622)\\nAPI.\\nCreate a Model Package Resource\\nTo create a model package resource that you can use to create deployable models in Amazon SageMaker\\nand publish on AWS Marketplace specify the following information:\\n•The Docker container that contains the inference code, or the algorithm resource that was used to\\ntrain the model.\\n•The location of the model artifacts. Model artifacts can either be packaged in the same Docker\\ncontainer as the inference code or stored in Amazon S3.\\n•The instance types that your model package supports for both real-time inference and batch\\ntransform jobs.\\n•Validation proﬁles, which are batch transform jobs that Amazon SageMaker runs to test your model\\npackage\\'s inference code.\\nBefore listing model packages on AWS Marketplace, you must validate them. This ensures that buyers\\nand sellers can be conﬁdent that products work in Amazon SageMaker. You can list products on AWS\\nMarketplace only if validation succeeds.\\nThe validation procedure uses your validation proﬁle and sample data to run the following validations\\ntasks:\\n1.Create a model in your account using the model package\\'s inference image and the optional model\\nartifacts that are stored in Amazon S3.\\nNote\\nA model package is speciﬁc to the region in which you create it. The S3 bucket where\\nthe model artifacts are stored must be in the same region where your created the model\\npackage.\\n2.Create a transform job in your account using the model to verify that your inference image works\\nwith Amazon SageMaker.\\n3.Create a validation proﬁle.\\nNote\\nIn your validation proﬁle, provide only data that you want to expose publicly.\\nValidation can take up to a few hours. To see the status of the jobs in your account, in the Amazon\\nSageMaker console, see the Transform jobs pages. If validation fails, you can access the scan and\\nvalidation reports from the Amazon SageMaker console. After ﬁxing issues, recreate the algorithm.\\nWhen the status of the algorithm is COMPLETED , ﬁnd it in the Amazon SageMaker console and start\\nthe listing process\\nNote\\nTo publish your model package on AWS Marketplace, at least one validation proﬁle is\\nrequired.\\n417Amazon SageMaker Developer Guide\\nCreate a Model Package Resource\\nYou can create an model package either by using the Amazon SageMaker console or by using the\\nAmazon SageMaker API.\\nTopics\\n•Create a Model Package Resource (Console)  (p. 418)\\n•Create a Model Package Resource (API)  (p. 419)\\nCreate a Model Package Resource (Console)\\nTo create a model package in the Amazon SageMaker console:\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Model packages , then choose Create model package .\\n3. On the Inference speciﬁcations page, provide the following information:\\na. For Model package name , type a name for your model package. The model package name must\\nbe unique in your account and in the AWS region. The name must have 1 to 64 characters. Valid\\ncharacters are a-z, A-Z, 0-9, and - (hyphen).\\nb. Type a description for your model package. This description appears in the Amazon SageMaker\\nconsole and in the AWS Marketplace.\\nc. For Inference speciﬁcation options, choose Provide the location of the inference image and\\nmodel artifacts to create a model package by using an inference container and model artifacts.\\nChoose Provide the algorithm used for training and its model artifacts to create a model\\npackage from an algorithm resource that you created or subscribe to from AWS Marketplace.\\nd. If you chose Provide the location of the inference image and model artifacts for Inference\\nspeciﬁcation options , provide the following information for Container deﬁnition  and\\nSupported resources:\\ni. For Location of inference image, type the path to the image that contains your inference\\ncode. The image must be stored as a Docker container in Amazon ECR.\\nii. For Location of model data artifacts, type the location in S3 where your model artifacts\\nare stored.\\niii. For Container DNS host name , type the name of the DNS host to use for your container.\\niv.For Supported instance types for real-time inference, choose the instance types that\\nyour model package supports for real-time inference from Amazon SageMaker hosted\\nendpoints.\\nv.For Supported instance types for batch transform jobs, choose the instance types that\\nyour model package supports for batch transform jobs.\\nvi. Supported content types, type the content types that your model package expects for\\ninference requests.\\nvii. For Supported response MIME types, type the MIME types that your model package uses\\nto provide inferences.\\ne. If you chose Provide the algorithm used for training and its model artifacts for Inference\\nspeciﬁcation options , provide the following information:\\ni. For Algorithm ARN, type the Amazon Resource Name (ARN) of the algorithm resource to\\nuse to create the model package.\\nii. For Location of model data artifacts, type the location in S3 where your model artifacts\\nare stored.\\nf.Choose Next.\\n4. On the Validation and scanning page, provide the following information:\\n418Amazon SageMaker Developer Guide\\nUse Algorithm and Model Package Resources\\na. For Publish this model package on AWS Marketplace, choose Yes to publish the model\\npackage on AWS Marketplace.\\nb. For Validate this model package, choose Yes if you want Amazon SageMaker to run batch\\ntransform jobs that you specify to test the inference code of your model package.\\nNote\\nTo publish your model package on AWS Marketplace, your model package must be\\nvalidated.\\nc. For IAM role, choose an IAM role that has the required permissions to run batch transform jobs\\nin Amazon SageMaker, or choose Create a new role to allow Amazon SageMaker to create a role\\nthat has the AmazonSageMakerFullAccess  managed policy attached. For information, see\\nAmazon SageMaker Roles  (p. 496).\\nd. For Validation proﬁle, specify the following:\\n•A name for the validation proﬁle.\\n•A Transform job deﬁnition. This is a JSON block that describes a batch transform job.\\nThis is in the same format as the TransformJobDeﬁnition (p. 1026 )input parameter of the\\nCreateAlgorithm (p. 622) API.\\n5. Choose Create model package .\\nCreate a Model Package Resource (API)\\nTo create a model package by using the Amazon SageMaker API, call the CreateModelPackage (p. 652)\\nAPI.\\nUse Algorithm and Model Package Resources\\nYou can create algorithms and model packages as resources in your Amazon SageMaker account, and you\\ncan ﬁnd and subscribe to algorithms and model packages on AWS Marketplace.\\nUse algorithms to:\\n•Run training jobs. For information, see Use an Algorithm to Run a Training Job (p. 420).\\n•Run hyperparameter tuning jobs. For information, see Use an Algorithm to Run a Hyperparameter\\nTuning Job (p. 423).\\n•Create model packages. After you use an algorithm resource to run a training job or a hyperparameter\\ntuning job, you can use the model artifacts that these jobs output along with the algorithm to create a\\nmodel package. For information, see Create a Model Package Resource (p. 417).\\nNote\\nIf you subscribe to an algorithm on AWS Marketplace, you must create a model package\\nbefore you can use it to get inferences by creating hosted endpoint or running a batch\\ntransform job.\\n419Amazon SageMaker Developer Guide\\nUse an Algorithm to Run a Training Job\\nUse model packages to:\\n•Create models that you can use to get real-time inference or run batch transform jobs. For\\ninformation, see Use a Model Package to Create a Model (p. 425).\\n•Create hosted endpoints to get real-time inference. For information, see Step 6.1: Deploy the Model to\\nAmazon SageMaker Hosting Services  (p. 26).\\n•Create batch transform jobs. For information, see Step 6.2: Deploy the Model with Batch\\nTransform (p. 28).\\nTopics\\n•Use an Algorithm to Run a Training Job (p. 420)\\n•Use an Algorithm to Run a Hyperparameter Tuning Job (p. 423)\\n•Use a Model Package to Create a Model (p. 425)\\nUse an Algorithm to Run a Training Job\\nYou can create use an algorithm resource to create a training job by using the Amazon SageMaker\\nconsole, the low-level Amazon SageMaker API, or the Amazon SageMaker Python SDK.\\nTopics\\n•Use an Algorithm to Run a Training Job (Console) (p. 421)\\n420Amazon SageMaker Developer Guide\\nUse an Algorithm to Run a Training Job\\n•Use an Algorithm to Run a Training Job (API) (p. 422)\\n•Use an Algorithm to Run a Training Job (Amazon SageMaker Python SDK) (p. 422)\\nUse an Algorithm to Run a Training Job (Console)\\nTo use an algorithm to run a training job (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Algorithms.\\n3. Choose an algorithm that you created from the list on the My algorithms tab or choose an\\nalgorithm that you subscribed to on the AWS Marketplace subscriptions tab.\\n4. Choose Create training job .\\nThe algorithm you chose will automatically be selected.\\n5. On the Create training job  page, provide the following information:\\na. For Job name , type a name for the training job.\\nb. For IAM role, choose an IAM role that has the required permissions to run training jobs in\\nAmazon SageMaker, or choose Create a new role to allow Amazon SageMaker to create a role\\nthat has the AmazonSageMakerFullAccess  managed policy attached. For information, see\\nAmazon SageMaker Roles  (p. 496).\\nc. For Resource conﬁguration, provide the following information:\\ni. For Instance type, choose the instance type to use for training.\\nii. For Instance count, type the number of ML instances to use for the training job.\\niii. For Additional volume per instance (GB), type the size of the ML storage volume that you\\nwant to provision. ML storage volumes store model artifacts and incremental states.\\niv.For Encryption key, if you want Amazon SageMaker to use an AWS Key Management\\nService key to encrypt data in the ML storage volume attached to the training instance,\\nspecify the key.\\nv.For Stopping condition, specify the maximum amount of time in seconds, minutes, hours,\\nor days, that you want the training job to run.\\nd. For VPC, choose a Amazon VPC that you want to allow your training container to access. For\\nmore information, see Give Amazon SageMaker Training Jobs Access to Resources in Your\\nAmazon VPC (p. 522).\\ne. For Hyperparameters , specify the values of the hyperparameters to use for the training job.\\nf.For Input data conﬁguration, specify the following values for each channel of input data to\\nuse for the training job. You can see what channels the algorithm you\\'re using for training\\nsports, and the content type, supported compression type, and supported input modes for\\neach channel, under Channel speciﬁcation  section of the Algorithm summary page for the\\nalgorithm.\\ni. For Channel name , type the name of the input channel.\\nii. For Content type, type the content type of the data that the algorithm expects for the\\nchannel.\\niii. For Compression type, choose the data compression type to use, if any.\\niv.For Record wrapper, choose RecordIO  if the algorithm expects data in the RecordIO\\nformat.\\nv.For S3 data type, S3 data distribution type, and S3 location, specify the appropriate\\nvalues. For information about what these values mean, see S3DataSource (p. 994).\\n421Amazon SageMaker Developer Guide\\nUse an Algorithm to Run a Training Job\\nvi. For Input mode , choose File to download the data from to the provisioned ML storage\\nvolume, and mount the directory to a Docker volume. Choose Pipe To stream data directly\\nfrom Amazon S3 to the container.\\nvii. To add another input channel, choose Add channel . If you are ﬁnished adding input\\nchannels, choose Done .\\ng. For Output  location, specify the following values:\\ni. For S3 output path , choose the S3 location where the training job stores output, such as\\nmodel artifacts.\\nNote\\nYou use the model artifacts stored at this location to create a model or model\\npackage from this training job.\\nii. For Encryption key, if you want Amazon SageMaker to use a AWS KMS key to encrypt\\noutput data at rest in the S3 location.\\nh. For Tags, specify one or more tags to manage the training job. Each tag consists of a key and an\\noptional value. Tag keys must be unique per resource. For more information about tags, see For\\nmore information, see AWS Tagging Strategies.\\ni. Choose Create training job  to run the training job.\\nUse an Algorithm to Run a Training Job (API)\\nTo use an algorithm to run a training job by using the Amazon SageMaker API, specify either the name or\\nthe Amazon Resource Name (ARN) as the AlgorithmName  ﬁeld of the AlgorithmSpeciﬁcation  (p. 863)\\nobject that you pass to CreateTrainingJob (p. 667). For information about training models in Amazon\\nSageMaker, see Train a Model with Amazon SageMaker  (p. 4).\\nUse an Algorithm to Run a Training Job (Amazon SageMaker\\nPython SDK)\\nUse an algorithm that you created or subscribed to on AWS Marketplace to create a training job, create\\nan AlgorithmEstimator  object and specify either the Amazon Resource Name (ARN) or the name\\nof the algorithm as the value of the algorithm_arn  argument. Then call the fit method of the\\nestimator. For example:\\nfrom sagemaker import AlgorithmEstimator\\ndata_path = os.path.join(DATA_DIR, \\'marketplace\\', \\'training\\')\\nalgo = AlgorithmEstimator(\\n            algorithm_arn=\\'arn:aws:sagemaker:us-east-2:012345678901:algorithm/my-\\nalgorithm\\',\\n            role=\\'SageMakerRole\\',\\n            train_instance_count=1,\\n            train_instance_type=\\'ml.c4.xlarge\\',\\n            sagemaker_session=sagemaker_session,\\n            base_job_name=\\'test-marketplace\\')\\ntrain_input = algo.sagemaker_session.upload_data(\\n    path=data_path, key_prefix=\\'integ-test-data/marketplace/train\\')\\nalgo.fit({\\'training\\': train_input})\\n422Amazon SageMaker Developer Guide\\nUse an Algorithm to Run a Hyperparameter Tuning Job\\nUse an Algorithm to Run a Hyperparameter Tuning\\nJob\\nA hyperparameter tuning job ﬁnds the best version of a model by running many training jobs on your\\ndataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the\\nhyperparameter values that result in a model that performs the best, as measured by a metric that you\\nchoose. For more information, see Automatic Model Tuning (p. 288).\\nYou can create use an algorithm resource to create a hyperparameter tuning job by using the Amazon\\nSageMaker console, the low-level Amazon SageMaker API, or the Amazon SageMaker Python SDK.\\nTopics\\n•Use an Algorithm to Run a Hyperparameter Tuning Job (Console) (p. 423)\\n•Use an Algorithm to Run a Hyperparameter Tuning Job (API) (p. 425)\\n•Use an Algorithm to Run a Hyperparameter Tuning Job (Amazon SageMaker Python SDK) (p. 425)\\nUse an Algorithm to Run a Hyperparameter Tuning Job\\n(Console)\\nTo use an algorithm to run a hyperparameter tuning job (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Algorithms.\\n3. Choose an algorithm that you created from the list on the My algorithms tab or choose an\\nalgorithm that you subscribed to on the AWS Marketplace subscriptions tab.\\n4. Choose Create hyperparameter tuning job.\\nThe algorithm you chose will automatically be selected.\\n5. On the Create hyperparameter tuning job page, provide the following information:\\na. For Warm start, choose Enable warm start to use the information from previous\\nhyperparameter tuning jobs as a starting point for this hyperparameter tuning job. For more\\ninformation, see Run a Warm Start Hyperparameter Tuning Job (p. 303).\\ni. Choose Identical data and algorithm if your input data is the same as the input data for\\nthe parent jobs of this hyperparameter tuning job, or choose Transfer learning to use\\nadditional or diﬀerent input data for this hyperparameter tuning job.\\nii. For Parent hyperparameter tuning job(s), choose up to 5 hyperparameter tuning jobs to\\nuse as parents to this hyperparameter tuning job.\\nb. For Hyperparameter tuning job name , type a name for the tuning job.\\nc. For IAM role, choose an IAM role that has the required permissions to run hyperparameter\\ntuning jobs in Amazon SageMaker, or choose Create a new role to allow Amazon SageMaker\\nto create a role that has the AmazonSageMakerFullAccess  managed policy attached. For\\ninformation, see Amazon SageMaker Roles  (p. 496).\\nd. For VPC, choose a Amazon VPC that you want to allow the training jobs that the tuning job\\nlaunches to access. For more information, see Give Amazon SageMaker Training Jobs Access to\\nResources in Your Amazon VPC (p. 522).\\ne. Choose Next.\\nf.For Objective metric, choose the metric that the hyperparameter tuning job uses to determine\\nthe best combination of hyperparameters, and choose whether to minimize or maximize this\\nmetric. For more information, see View the Best Training Job (p. 301).\\n423Amazon SageMaker Developer Guide\\nUse an Algorithm to Run a Hyperparameter Tuning Job\\ng. For Hyperparameter conﬁguration, choose ranges for the tunable hyperparameters that you\\nwant the tuning job to search, and set static values for hyperparameters that you want to\\nremain constant in all training jobs that the hyperparameter tuning job launches. For more\\ninformation, see Deﬁne Hyperparameter Ranges  (p. 292).\\nh. Choose Next.\\ni. For Input data conﬁguration, specify the following values for each channel of input data to\\nuse for the hyperparameter tuning job. You can see what channels the algorithm you\\'re using\\nfor hyperparameter tuning supports, and the content type, supported compression type, and\\nsupported input modes for each channel, under Channel speciﬁcation  section of the Algorithm\\nsummary page for the algorithm.\\ni. For Channel name , type the name of the input channel.\\nii. For Content type, type the content type of the data that the algorithm expects for the\\nchannel.\\niii. For Compression type, choose the data compression type to use, if any.\\niv.For Record wrapper, choose RecordIO  if the algorithm expects data in the RecordIO\\nformat.\\nv.For S3 data type, S3 data distribution type, and S3 location, specify the appropriate\\nvalues. For information about what these values mean, see S3DataSource (p. 994).\\nvi. For Input mode , choose File to download the data from to the provisioned ML storage\\nvolume, and mount the directory to a Docker volume. Choose Pipe To stream data directly\\nfrom Amazon S3 to the container.\\nvii. To add another input channel, choose Add channel . If you are ﬁnished adding input\\nchannels, choose Done .\\nj. For Output  location, specify the following values:\\ni. For S3 output path , choose the S3 location where the training jobs that this\\nhyperparameter tuning job launches store output, such as model artifacts.\\nNote\\nYou use the model artifacts stored at this location to create a model or model\\npackage from this hyperparameter tuning job.\\nii. For Encryption key, if you want Amazon SageMaker to use a AWS KMS key to encrypt\\noutput data at rest in the S3 location.\\nk. For Resource conﬁguration, provide the following information:\\ni. For Instance type, choose the instance type to use for each training job that the\\nhyperparameter tuning job launches.\\nii. For Instance count, type the number of ML instances to use for each training job that the\\nhyperparameter tuning job launches.\\niii. For Additional volume per instance (GB), type the size of the ML storage volume that\\nyou want to provision each training job that the hyperparameter tuning job launches. ML\\nstorage volumes store model artifacts and incremental states.\\niv.For Encryption key, if you want Amazon SageMaker to use an AWS Key Management\\nService key to encrypt data in the ML storage volume attached to the training instances,\\nspecify the key.\\nl. For Resource limits, provide the following information:\\ni. For Maximum training jobs , specify the maximum number of training jobs that you want\\nthe hyperparameter tuning job to launch. A hyperparameter tuning job can launch a\\nmaximum of 500 training jobs.\\nii. For Maximum parallel training jobs, specify the maximum number of concurrent training\\njobs that the hyperparameter tuning job can launch. A hyperparameter tuning job can\\nlaunch a maximum of 10 concurrent training jobs.\\n424Amazon SageMaker Developer Guide\\nUse a Model Package to Create a Model\\niii. For Stopping condition, specify the maximum amount of time in seconds, minutes, hours,\\nor days, that you want each training job that the hyperparameter tuning job launches to\\nrun.\\nm. For Tags, specify one or more tags to manage the hyperparameter tuning job. Each tag consists\\nof a key and an optional value. Tag keys must be unique per resource. For more information\\nabout tags, see For more information, see AWS Tagging Strategies.\\nn. Choose Create jobs  to run the hyperparameter tuning job.\\nUse an Algorithm to Run a Hyperparameter Tuning Job (API)\\nTo use an algorithm to run a hyperparameter tuning job by using the Amazon SageMaker API, specify\\neither the name or the Amazon Resource Name (ARN) of the algorithm as the AlgorithmName  ﬁeld of\\nthe AlgorithmSpeciﬁcation  (p. 863) object that you pass to CreateHyperParameterTuningJob (p. 638).\\nFor information about hyperparameter tuning in Amazon SageMaker, see Automatic Model\\nTuning (p. 288).\\nUse an Algorithm to Run a Hyperparameter Tuning Job (Amazon\\nSageMaker Python SDK)\\nUse an algorithm that you created or subscribed to on AWS Marketplace to create a hyperparameter\\ntuning job, create an AlgorithmEstimator  object and specify either the Amazon Resource Name\\n(ARN) or the name of the algorithm as the value of the algorithm_arn  argument. Then initialize\\na HyperparameterTuner  object with the AlgorithmEstimator  you created as the value of the\\nestimator  argument. Finally, call the fit method of the AlgorithmEstimator . For example:\\nfrom sagemaker import AlgorithmEstimator\\nfrom sagemaker.tuner import HyperparameterTuner\\ndata_path = os.path.join(DATA_DIR, \\'marketplace\\', \\'training\\')\\nalgo = AlgorithmEstimator(\\n            algorithm_arn=\\'arn:aws:sagemaker:us-east-2:764419575721:algorithm/scikit-\\ndecision-trees-1542410022\\',\\n            role=\\'SageMakerRole\\',\\n            train_instance_count=1,\\n            train_instance_type=\\'ml.c4.xlarge\\',\\n            sagemaker_session=sagemaker_session,\\n            base_job_name=\\'test-marketplace\\')\\ntrain_input = algo.sagemaker_session.upload_data(\\n    path=data_path, key_prefix=\\'integ-test-data/marketplace/train\\')\\nalgo.set_hyperparameters(max_leaf_nodes=10)\\ntuner = HyperparameterTuner(estimator=algo, base_tuning_job_name=\\'some-name\\',\\n                                objective_metric_name=\\'validation:accuracy\\',\\n                                hyperparameter_ranges=hyperparameter_ranges,\\n                                max_jobs=2, max_parallel_jobs=2)\\ntuner.fit({\\'training\\': train_input}, include_cls_metadata=False)\\ntuner.wait()\\nUse a Model Package to Create a Model\\nUse a model package to create a deployable model that you can use to get real-time inferences by\\ncreating a hosted endpoint or to run batch transform jobs. You can create a deployable model from a\\n425Amazon SageMaker Developer Guide\\nUse a Model Package to Create a Model\\nmodel package by using the Amazon SageMaker console, the low-level Amazon SageMaker API), or the\\nAmazon SageMaker Python SDK.\\nTopics\\n•Use a Model Package to Create a Model (Console) (p. 426)\\n•Use a Model Package to Create a Model (API) (p. 426)\\n•Use a Model Package to Create a Model (Amazon SageMaker Python SDK) (p. 427)\\nUse a Model Package to Create a Model (Console)\\nTo create a deployable model from a model package (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Model packages .\\n3. Choose a model package that you created from the list on the My model packages  tab or choose a\\nmodel package that you subscribed to on the AWS Marketplace subscriptions tab.\\n4. Choose Create model .\\n5. For Model name , type a name for the model.\\n6. For IAM role, choose an IAM role that has the required permissions to call other services on your\\nbehalf, or choose Create a new role to allow Amazon SageMaker to create a role that has the\\nAmazonSageMakerFullAccess  managed policy attached. For information, see Amazon SageMaker\\nRoles  (p. 496).\\n7. For VPC, choose a Amazon VPC that you want to allow the model to access. For more information,\\nsee Give Amazon SageMaker Hosted Endpoints Access to Resources in Your Amazon VPC (p. 525).\\n8. Leave the default values for Container input options  and Choose model package .\\n9. For environment variables, provide the names and values of environment variables you want to pass\\nto the model container.\\n10. For Tags, specify one or more tags to manage the model. Each tag consists of a key and an optional\\nvalue. Tag keys must be unique per resource. For more information about tags, see For more\\ninformation, see AWS Tagging Strategies.\\n11. Choose Create model .\\nAfter you create a deployable model, you can use it to set up an endpoint for real-time inference\\nor create a batch transform job to get inferences on entire datasets. For information about hosted\\nendpoints in Amazon SageMaker, see Step 6.1: Deploy the Model to Amazon SageMaker Hosting\\nServices  (p. 26). For information about batch transform jobs, see Step 6.2: Deploy the Model with Batch\\nTransform (p. 28).\\nUse a Model Package to Create a Model (API)\\nTo use a model package to create a deployable model by using the Amazon SageMaker API, specify the\\nname or the Amazon Resource Name (ARN) of the model package as the ModelPackageName  ﬁeld of\\nthe ContainerDeﬁnition  (p. 886) object that you pass to the CreateModel (p. 648) API.\\nAfter you create a deployable model, you can use it to set up an endpoint for real-time inference\\nor create a batch transform job to get inferences on entire datasets. For information about hosted\\nendpoints in Amazon SageMaker, see Step 6.1: Deploy the Model to Amazon SageMaker Hosting\\nServices  (p. 26). For information about batch transform jobs, see Step 6.2: Deploy the Model with Batch\\nTransform (p. 28).\\n426Amazon SageMaker Developer Guide\\nUse a Model Package to Create a Model\\nUse a Model Package to Create a Model (Amazon SageMaker\\nPython SDK)\\nTo use a model package to create a deployable model by using the Amazon SageMaker Python SDK,\\ninitialize a ModelPackage  object, and pass the Amazon Resource Name (ARN) of the model package as\\nthe model_package_arn  argument. For example:\\nfrom sagemaker import ModelPackage\\nmodel = ModelPackage(role=\\'SageMakerRole\\',\\n                     model_package_arn=\\'training-job-scikit-decision-\\ntrees-1542660466-6f92\\',\\n                     sagemaker_session=sagemaker_session)\\nAfter you create a deployable model, you can use it to set up an endpoint for real-time inference\\nor create a batch transform job to get inferences on entire datasets. For information about hosted\\nendpoints in Amazon SageMaker, see Step 6.1: Deploy the Model to Amazon SageMaker Hosting\\nServices  (p. 26). For information about batch transform jobs, see Step 6.2: Deploy the Model with Batch\\nTransform (p. 28).\\n427Amazon SageMaker Developer Guide\\nTopics\\nAmazon SageMaker Resources in\\nAWS Marketplace\\nAmazon SageMaker integrates with AWS Marketplace, enabling developers to charge other Amazon\\nSageMaker users for the use of their algorithms and model packages. AWS Marketplace is a curated\\ndigital catalog that makes it easy for customers to ﬁnd, buy, deploy, and manage third-party software\\nand services that customers need to build solutions and run their businesses. AWS Marketplace includes\\nthousands of software listings in popular categories, such as security, networking, storage, machine\\nlearning, business intelligence, database, and DevOps. It simpliﬁes software licensing and procurement\\nwith ﬂexible pricing options and multiple deployment methods. For information, see AWS Marketplace\\nDocumentation .\\nTopics\\n•Amazon SageMaker Algorithms (p. 428)\\n•Amazon SageMaker Model Packages (p. 428)\\n•Sell Amazon SageMaker Algorithms and Model Packages (p. 429)\\n•Find and Subscribe to Algorithms and Model Packages on AWS Marketplace (p. 431)\\n•Use Algorithm and Model Package Resources (p. 419)\\nAmazon SageMaker Algorithms\\nAn algorithm enables you to perform end-to-end machine learning. It has two logical components:\\ntraining and inference. Buyers can use the training component to create training jobs in Amazon\\nSageMaker and build a machine learning model. Amazon SageMaker saves the model artifacts generated\\nby the algorithm during training to an Amazon S3 bucket. For more information, see Train a Model with\\nAmazon SageMaker  (p. 4).\\nBuyers use the inference component with the model artifacts generated during a training job to create a\\ndeployable model in their Amazon SageMaker account. They can use the deployable model for real-time\\ninference by using Amazon SageMaker hosting services. Or, they can get inferences for an entire dataset\\nby running batch transform jobs. For more information, see Deploy a Model in Amazon SageMaker (p. 7).\\nAmazon SageMaker Model Packages\\nBuyers use a model package to build a deployable model in Amazon SageMaker. They can use the\\ndeployable model for real-time inference by using Amazon SageMaker hosting services. Or, they can get\\ninferences for an entire dataset by running batch transform jobs. For more information, see Deploy a\\nModel in Amazon SageMaker (p. 7). As a seller, you can build your model artifacts by training in Amazon\\nSageMaker, or you can use your own model artifacts from a model that you trained outside of Amazon\\nSageMaker. You can charge buyers for inference.\\n428Amazon SageMaker Developer Guide\\nSell Amazon SageMaker Algorithms and Model Packages\\nSell Amazon SageMaker Algorithms and Model\\nPackages\\nSelling Amazon SageMaker algorithms and model packages is a three-step process:\\n1.Develop your algorithm or model, and package it in a Docker container. For information, see Develop\\nAlgorithms and Models in Amazon SageMaker (p. 429).\\n2.Create an algorithm or model package resource in Amazon SageMaker. For information, see Create\\nAlgorithm and Model Package Resources (p. 413).\\n3.Register as a seller on AWS Marketplace and list your algorithm or model package on AWS\\nMarketplace. For information about registering as a seller, see Getting Started as a Seller in the User\\nGuide for AWS Marketplace Providers. For information about listing and monetizing your algorithms\\nand model packages, see Listing Algorithms and Model Packages in AWS Marketplace for Machine\\nLearning  in the User Guide for AWS Marketplace Providers.\\nTopics\\n•Develop Algorithms and Models in Amazon SageMaker (p. 429)\\n•Create Algorithm and Model Package Resources (p. 413)\\n•List Your Algorithm or Model Package on AWS Marketplace (p. 431)\\nDevelop Algorithms and Models in Amazon\\nSageMaker\\nBefore you can create algorithm and model package resources to use in Amazon SageMaker or list on\\nAWS Marketplace, you have to develop them and package them in Docker containers.\\n429Amazon SageMaker Developer Guide\\nDevelop Algorithms and Models in Amazon SageMaker\\nNote\\nWhen algorithms and model packages are created for listing on AWS Marketplace, Amazon\\nSageMaker scans the containers for security vulnerabilities on supported operating systems.\\nOnly the following operating system versions are supported:\\n•Debian: 6.0, 7, 8, 9, 10\\n•Ubuntu: 12.04, 12.10, 13.04, 14.04, 14.10, 15.04, 15.10, 16.04, 16.10, 17.04, 17.10, 18.04,\\n18.10\\n•CentOS: 5, 6, 7\\n•Oracle Linux: 5, 6, 7\\n•Alpine: 3.3, 3.4, 3.5\\n•Amazon Linux\\nTopics\\n•Develop Algorithms in Amazon SageMaker (p. 430)\\n•Develop Models in Amazon SageMaker (p. 430)\\nDevelop Algorithms in Amazon SageMaker\\nAn algorithm should be packaged as a docker container and stored in Amazon ECR to use it in Amazon\\nSageMaker. The Docker container contains the training code used to run training jobs and, optionally, the\\ninference code used to get inferences from models trained by using the algorithm.\\nFor information about developing algorithms in Amazon SageMaker and packaging them as containers,\\nsee Use Your Own Algorithms or Models with Amazon SageMaker  (p. 384). For a complete example\\nof how to create an algorithm container, see the sample notebook at https://github.com/awslabs/\\namazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/\\nscikit_bring_your_own.ipynb. You can also ﬁnd the sample notebook in an Amazon SageMaker\\nnotebook instance. The notebook is in the Advanced Functionality section, and is named\\nscikit_bring_your_own.ipynb . For information about using the sample notebooks in a notebook\\ninstance, see Use Example Notebooks  (p. 42).\\nAlways thoroughly test your algorithms before you create algorithm resources to publish on AWS\\nMarketplace.\\nNote\\nWhen a buyer subscribes to your containerized product, the Docker containers run in an isolated\\n(internet-free) environment. When you create your containers, do not rely on making outgoing\\ncalls over the internet. Calls to AWS services are also not allowed.\\nDevelop Models in Amazon SageMaker\\nA deployable model in Amazon SageMaker consists of inference code, model artifacts, an IAM role that\\nis used to access resources, and other information required to deploy the model in Amazon SageMaker.\\nModel artifacts are the results of training a model by using a machine learning algorithm. The inference\\ncode must be packaged in a Docker container and stored in Amazon ECR. You can either package the\\nmodel artifacts in the same container as the inference code, or store them in Amazon S3.\\nYou create a model by running a training job in Amazon SageMaker, or by training a machine\\nlearning algorithm outside of Amazon SageMaker. If you run a training job in Amazon SageMaker, the\\nresulting model artifacts are available in the ModelArtifacts  ﬁeld in the response to a call to the\\nDescribeTrainingJob (p. 744) operation. For information about how to develop an Amazon SageMaker\\nmodel container, see Use Your Own Inference Code (p. 408). For a complete example of how to create\\n430Amazon SageMaker Developer Guide\\nList Your Algorithm or Model Package on AWS Marketplace\\na model container from a model trained outside of Amazon SageMaker, see the sample notebook at\\nhttps://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/\\nxgboost_bring_your_own_model/xgboost_bring_your_own_model.ipynb. You can also ﬁnd the sample\\nnotebook in an Amazon SageMaker notebook instance. The notebook is in the Advanced Functionality\\nsection, and is named xgboost_bring_your_own_model.ipynb . For information about using the\\nsample notebooks in a notebook instance, see Use Example Notebooks  (p. 42).\\nAlways thoroughly test your models before you create model packages to publish on AWS Marketplace.\\nNote\\nWhen a buyer subscribes to your containerized product, the Docker containers run in an isolated\\n(internet-free) environment. When you create your containers, do not rely on making outgoing\\ncalls over the internet. Calls to AWS services are also not allowed.\\nList Your Algorithm or Model Package on AWS\\nMarketplace\\nAfter creating and validating your algorithm or model in Amazon SageMaker, list your product on AWS\\nMarketplace. The listing process makes your products available in the AWS Marketplace and the Amazon\\nSageMaker console.\\nTo list products on AWS Marketplace, you must be a registered seller. To register, use the self-registration\\nprocess from the AWS Marketplace Management Portal (AMMP). For information, see Getting Started as\\na Seller  in the User Guide for AWS Marketplace Providers. When you start the product listing process from\\nthe Amazon SageMaker console, we check your seller registration status. If you have not registered, we\\ndirect you to do so.\\nTo start the listing process, do one of the following:\\n•From the Amazon SageMaker console, choose the product, choose Actions, and choose Publish new\\nML Marketplace listing. This carries over your product reference, the Amazon Resource Name (ARN),\\nand directs you to the AMMP to create the listing.\\n•Go to ML listing process, manually enter the Amazon Resource Name (ARN), and start your product\\nlisting. This process carries over the product metadata that you entered when creating the product in\\nAmazon SageMaker. For an algorithm listing, the information includes the supported instance types\\nand hyperparameters. In addition, you can enter a product description, promotional information, and\\nsupport information as you would with other AWS Marketplace products.\\nFind and Subscribe to Algorithms and Model\\nPackages on AWS Marketplace\\nWith AWS Marketplace, you can browse and search for hundreds of machine learning algorithms and\\nmodels in a broad range of categories, such as computer vision, natural language processing, speech\\nrecognition, text, data, voice, image, video analysis, fraud detection, predictive analysis, and more.\\n431Amazon SageMaker Developer Guide\\nUse Algorithms and Model Packages\\nTo ﬁnd algorithms on AWS Marketplace\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Algorithms, then choose Find algorithms.\\nThis takes you to the AWS Marketplace algorithms page. For information about ﬁnding and\\nsubscribing to algorithms on AWS Marketplace, see Machine Learning Products in the AWS\\nMarketplace User Guide for AWS Consumers.\\nTo ﬁnd model packages on AWS Marketplace\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Model packages , then choose Find model packages .\\nThis takes you to the AWS Marketplace model packages page. For information about ﬁnding and\\nsubscribing to model packages on AWS Marketplace, see Machine Learning Products in the AWS\\nMarketplace User Guide for AWS Consumers.\\nUse Algorithms and Model Packages\\nFor information about using algorithms and model packages that you subscribe to in Amazon\\nSageMaker, see Use Algorithm and Model Package Resources (p. 419).\\nNote\\nWhen you create a training job, inference endpoint, and batch transform job from an algorithm\\nor model package that you subscribe to on AWS Marketplace, the training and inference\\ncontainers do not have access to the internet. Because the containers do not have access to the\\ninternet, the seller of the algorithm or model package does not have access to your data.\\n432Amazon SageMaker Developer Guide\\nSample Notebooks\\nManage Machine Learning\\nExperiments with Amazon\\nSageMaker Model Tracking\\nCapability\\nTo organize, ﬁnd, and evaluate machine leaning model experiments, use Amazon SageMaker model\\ntracking capabilities. Developing models typically requires extensive experimenting with diﬀerent\\ndatasets, algorithms, and parameter values. Using the model tracking capability, you can search, ﬁlter\\nand sort through hundreds and possibly thousands of experiments using model attributes such as\\nparameters, metrics and tags. This helps you ﬁnd the best model for your use case quickly.\\nAmazon SageMaker model tracking capability can be used to:\\n•Find, organize, or evaluate training jobs using properties, hyperparameters, performance metrics, or\\nany other metadata.\\n•Find the best performing model by ranking the results of training jobs and models based on metrics,\\nsuch as training loss or validation accuracy.\\n•Trace the lineage of a model back to the training job and its related resources, such as the training\\ndatasets.\\nSample Notebooks that Manage ML Experiments\\nwith Amazon SageMaker Model Tracking\\nCapability\\nFor a sample notebook that uses Amazon SageMaker model tracking capability to manage ML\\nexperiments, see Managing ML Experimentation using Amazon SageMaker Model Tracking Capability. For\\ninstructions on how to create and access Jupyter notebook instances that you can use to run the example\\nin Amazon SageMaker, see Use Notebook Instances (p. 36). After you have created a notebook instance\\nand opened it, choose the SageMaker Examples tab to see a list of all of the Amazon SageMaker\\nsamples. The notebook managing ML experiments is located in the Advanced Functionality section. To\\nopen a notebook, choose its Use tab and choose Create copy. If you have questions, post them on our\\ndeveloper forum.\\nTopics\\n•Use Model Tracking to Find, Organize, and Evaluate Training Jobs (Console) (p. 434)\\n•Use Model Tracking to Find and Evaluate Training Jobs (API) (p. 436)\\n•Verify the Contents of Your Training Jobs (p. 438)\\n•Trace the Lineage of your Models (p. 438)\\n433Amazon SageMaker Developer Guide\\nUse Model Tracking to Find, Organize,\\nand Evaluate Training Jobs (Console)\\nUse Model Tracking to Find, Organize, and\\nEvaluate Training Jobs (Console)\\nTo create and test a model, you need to conduct experiments. You can perform an experiment to test\\ndiﬀerent algorithms, tune hyperparameters, or use diﬀerent datasets. Typically, you study the eﬀect\\nof the changes made in these experiments on the performance of a model. You can organize these\\nexperiments by tagging them with key/ value pairs that are seaerchable.\\nTo ﬁnd a speciﬁc training job, model, or resource, use Amazon SageMaker model tracking to search\\non keywords in any items that are searchable. Searchable items include training jobs, models,\\nhyperparameters, metadata, tags, and URLs. You can use model tracking with tags to help organize your\\ntraining jobs. To reﬁne your tracking results, you can search using multiple criteria.\\nTo choose the optimal model for deployment, you need to evaluate how they performed against one\\nor more metrics. You can use model tracking results to list, sort, and evaluate the performance of the\\nmodels in your experiments.\\nTopics\\n•Use Tags to Track Training Jobs (Console) (p. 434)\\n•Find Training Jobs (Console) (p. 435)\\n•Evaluate Models Returned by a Search (Console) (p. 435)\\nUse Tags to Track Training Jobs (Console)\\nYou can use tags as search criteria. To group training jobs, create tags with descriptive keys and value. For\\nexample, create tag keys for: project, owner, customer, and industry.\\nAdd tags to training job and search for taged jobs (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker.\\n2. In the left navigation pane, choose Training jobs and select Create training job .\\n3. Scroll down to the bottom of the page to enter the Key and Value for the tag.\\n4. To add more tags to the search, choose Add tag  and add a another tag key-value pair for each new\\ntag that you want to add.\\n5. After you have trained models that have been tagged, you can search for the models that had them\\nadded. In the left navigation pane, choose Search .\\n6. For Property, enter a tag key and a tag value.\\n434Amazon SageMaker Developer Guide\\nFind Training Jobs (Console)\\nWhen you use tags in a search, in the results, the key is a column name and the values are entries in rows.\\nFind Training Jobs (Console)\\nTo use Amazon SageMaker model tracking capability (console)\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker.\\n2. In the left navigation pane, choose Search .\\n3. For Resource type, choose Training jobs.\\n4. To add a parameter, for Parameters, provide the following:\\na. Enter a parameter in the search box and choose a parameter type, for example\\nTrainingJobName.\\nb. Choose the conditional operation to use. This sets the condition that values must satisfy to be\\nincluded in a search result. For numeral values, use operators such as is equals to , lesser than,\\nor or greater than . For text-based values use operators, such as equals to  or contains.\\nc. Enter the value for the parameter.\\n5. (optional) To reﬁne your search, add additional search criteria, choose Add parameter  and enter\\nthe parameter values. When you provide multiple parameters, Amazon SageMaker includes all\\nparameters in the search.\\n6. Choose Search .\\nEvaluate Models Returned by a Search (Console)\\nTo evaluate diﬀerent models, ﬁnd their metrics with a search. To highlight metrics, adjust the view to\\nshow only metrics and important hyperparameters.\\nTo change the viewable metadata, hyperparameters, and metrics:\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker.\\n2. In the left navigation pane, choose Search  and run a search on training jobs for relevant parameters.\\nThe results are displayed in a table.\\n435Amazon SageMaker Developer Guide\\nUse Model Tracking to Find and\\nEvaluate Training Jobs (API)\\n3. After performing a search, choose the cog icon at the search results table to show the preferences\\nwindow.\\n4. To show or hide a Hyperparameter  or Metric , use its toggle switch.\\n5. To update the view after making changes, choose Update view .\\nAfter viewing metrics and important hyperparameters, you can compare and contrast the result. From\\nthere, you can choose the best model to host or investigate the models that are performing poorly.\\nUse Model Tracking to Find and Evaluate Training\\nJobs (API)\\nYou can also use Search (p. 819) to the ﬁnd and evaluate training jobs or to get suggestions for items\\nused in experiments that are searchable.\\nTopics\\n•Use Search to Find Training Jobs Tagged with Speciﬁc Values (API) (p. 436)\\n•Evaluate Models (API)  (p. 436)\\n•Get Suggestions for a Search (API) (p. 437)\\nUse Search to Find Training Jobs Tagged with Speciﬁc\\nValues (API)\\nTo use Amazon SageMaker model tracking capability, create a search parameter, search_params , then\\nuse the search function found in the smclient  of the AWS SDK for Python (Boto 3).\\nThe following example shows how to use search using the API:\\n436Amazon SageMaker Developer Guide\\nEvaluate Models (API)\\nimport boto3\\nsearch_params={\\n   \"MaxResults\": 10,\\n   \"Resource\": \"TrainingJob\",\\n   \"SearchExpression\": { \\n      \"Filters\": [{ \\n            \"Name\": \"Tags.Project\",\\n            \"Operator\": \"Equals\",\\n            \"Value\": \"Project_Binary_Classifier\"\\n         }]},\\n  \"SortBy\": \"Metrics.train:binary_classification_accuracy\",\\n  \"SortOrder\": \"Descending\"\\n}\\nsmclient = boto3.client(service_name=\\'sagemaker\\')\\nresults = smclient.search(**search_params)\\nEvaluate Models (API)\\nTo evaluate diﬀerent models, see the metrics in a search result. To evaluate models using the AWS SDK\\nfor Python (Boto 3), create a table and plot it.\\nThe following example shows how to use model tracking capability to evaluate models and to display\\nthe results in a table:\\nimport pandas\\nheaders=[\"Training Job Name\", \"Training Job Status\", \"Batch Size\", \"Binary Classification\\n Accuracy\"]\\nrows=[]\\nfor result in results[\\'Results\\']: \\n    trainingJob = result[\\'TrainingJob\\']\\n    metrics = trainingJob[\\'FinalMetricDataList\\']\\n    rows.append([trainingJob[\\'TrainingJobName\\'],\\n     trainingJob[\\'TrainingJobStatus\\'],\\n     trainingJob[\\'HyperParameters\\'][\\'mini_batch_size\\'],\\n     metrics[[x[\\'MetricName\\'] for x in  \\n     metrics].index(\\'train:binary_classification_accuracy\\')][\\'Value\\']\\n    ])\\ndf = pandas.DataFrame(data=rows,columns=headers)\\nfrom IPython.display import display, HTMLdisplay(HTML(df.to_html()))\\nGet Suggestions for a Search (API)\\nTo get suggestions for a search, use GetSearchSuggestions (p. 759) in the API.\\nThe following code example for AWS SDK for Python (Boto 3) shows a get_search_suggestions\\nrequest for items containing \"linear\":\\nsearch_suggestion_params={\\n   \"Resource\": \"TrainingJob\",\\n   \"SuggestionQuery\": { \\n      \"PropertyNameQuery\": { \\n         \"PropertyNameHint\": \"linear\"\\n      }\\n   }\\n437Amazon SageMaker Developer Guide\\nVerify the Contents of Your Training Jobs\\n}\\nThe following code shows an example of an expected response for get_search_suggestions :\\n{\\n        \\'PropertyNameSuggestions\\': [{\\'PropertyName\\': \\'hyperparameters.linear_init_method\\'},\\n                    {\\'PropertyName\\': \\'hyperparameters.linear_init_value\\'},\\n                    {\\'PropertyName\\': \\'hyperparameters.linear_init_sigma\\'},\\n                    {\\'PropertyName\\': \\'hyperparameters.linear_lr\\'},\\n                    {\\'PropertyName\\': \\'hyperparameters.linear_wd\\'}]\\n}\\nAfter you get the search suggestions, you can use one of the property names in a search.\\nVerify the Contents of Your Training Jobs\\nYou can use Amazon SageMaker model tracking capability to verify which datasets were used in training,\\nwhere the holdout datasets were used, and other details about training jobs. Use it, for example, if you\\nneed to verify that a dataset was used in a training job for an audit or to verify compliance.\\nTo check if a holdout dataset or any other dataset was used in a training job, search for its Amazon S3\\nURL. Amazon SageMaker model tracking uses the dataset as a search parameter and lists the training\\njobs that used the dataset. If your search result is empty, it means that the dataset was not used in a\\ntraining job.\\nTrace the Lineage of your Models\\nYou can use Amazon SageMaker model tracking to trace information about the lineage of training jobs\\nand model resources related to it, including the dataset, algorithm, hyperparameters, and metrics used.\\nFor example, if you ﬁnd that the performance of a hosted model has declined, you can review its training\\njob and the resources it used to determine what is causing the problem. This investigation can be done\\nfrom the console or by using the API.\\nUse Single-click on the Amazon SageMaker Console\\nto Trace the Lineage of Your Models (Console)\\nIn the left navigation pane of the Amazon SageMaker, choose Endpoints , and select the relevant\\nendpoint from the list of your deployed endpoints. Scroll to Endpoint Conﬁguration Settings, which\\nlists all the model versions deployed at the endpoint. Here you have access to a hyperlink to the Model\\nTraining Job that created that model in the ﬁrst place. For an example that used a linear-learner model,\\nyou would see:\\n438Amazon SageMaker Developer Guide\\nUse Code to Trace the Lineage of Your Models (API)\\nUse Code to Trace the Lineage of Your Models (API)\\nTo trace a model\\'s lineage, you need to obtain the model\\'s name, then use it to search for training jobs.\\nThe following example shows how to use model tracking capability to trace a model\\'s lineage using the\\nAPI:\\n# Get the name of model deployed at endpoint\\nendpoint_config = smclient.describe_endpoint_config(EndpointConfigName=endpointName)\\nmodel_name = endpoint_config[\\'ProductionVariants\\'][0][\\'ModelName\\']\\n# Get the model\\'s name\\nmodel = smclient.describe_model(ModelName=model_name)\\n# Search the training job by Amazon S3 location of model artifacts\\nsearch_params={\\n   \"MaxResults\": 1,\\n   \"Resource\": \"TrainingJob\",\\n   \"SearchExpression\": { \\n      \"Filters\": [ \\n         { \\n            \"Name\": \"ModelArtifacts.S3ModelArtifacts\",\\n            \"Operator\": \"Equals\",\\n            \"Value\": model[\\'PrimaryContainer\\'][\\'ModelDataUrl\\']\\n         }]},\\n}\\nresults = smclient.search(**search_params)\\nAfter you ﬁnd your training job, you can investigate the resources used to train the model.\\n439Amazon SageMaker Developer Guide\\nUsing Apache Spark\\nUse Machine Learning Frameworks\\nwith Amazon SageMaker\\nThe Amazon SageMaker Python SDK provides open source APIs and containers that make it easy to\\ntrain and deploy models in Amazon SageMaker with several diﬀerent machine learning and deep\\nlearning frameworks. For general information about the Amazon SageMaker Python SDK, see https://\\ngithub.com/aws/sagemaker-python-sdk. For information about using speciﬁc frameworks in Amazon\\nSageMaker, see the following topics:\\nTopics\\n•Use Apache Spark with Amazon SageMaker (p. 440)\\n•Use TensorFlow with Amazon SageMaker (p. 449)\\n•Use Apache MXNet with Amazon SageMaker (p. 450)\\n•Use Scikit-learn with Amazon SageMaker (p. 451)\\n•Use PyTorch with Amazon SageMaker (p. 451)\\n•Use Chainer with Amazon SageMaker (p. 452)\\n•Use SparkML Serving with Amazon SageMaker (p. 453)\\nUse Apache Spark with Amazon SageMaker\\nThis section provides information for developers who want to use Apache Spark for preprocessing data\\nand Amazon SageMaker for model training and hosting. For information about supported versions of\\nApache Spark, see https://github.com/aws/sagemaker-spark#getting-sagemaker-spark.\\nAmazon SageMaker provides an Apache Spark library, in both Python and Scala, that you can use to\\neasily train models in Amazon SageMaker using org.apache.spark.sql.DataFrame  data frames in\\nyour Spark clusters. After model training, you can also host the model using Amazon SageMaker hosting\\nservices.\\nThe Amazon SageMaker Spark library, com.amazonaws.services.sagemaker.sparksdk , provides\\nthe following classes, among others:\\n•SageMakerEstimator —Extends the org.apache.spark.ml.Estimator  interface. You can use\\nthis estimator for model training in Amazon SageMaker.\\n•KMeansSageMakerEstimator , PCASageMakerEstimator , and XGBoostSageMakerEstimator —\\nExtend the SageMakerEstimator  class.\\n•SageMakerModel —Extends the org.apache.spark.ml.Model  class. You can use this\\nSageMakerModel  for model hosting and obtaining inferences in Amazon SageMaker.\\nDownload the Amazon SageMaker Spark Library\\nYou have the following options for downloading the Spark library provided by Amazon SageMaker:\\n440Amazon SageMaker Developer Guide\\nIntegrate Your Apache Spark\\nApplication with Amazon SageMaker\\n•You can download the source code for both PySpark and Scala libraries from GitHub at https://\\ngithub.com/aws/sagemaker-spark.\\n\\xa0\\n•For the Python Spark library, you have the following additional options:\\n•Use pip install:\\n$ pip install sagemaker_pyspark\\n•In a notebook instance, create a new notebook that uses either the Sparkmagic (PySpark)  or\\nthe Sparkmagic (PySpark3)  kernel and connect to a remote Amazon EMR cluster. For more\\ninformation, see Build Amazon SageMaker Notebooks Backed by Spark in Amazon EMR.\\nNote\\nThe EMR cluster must be conﬁgured with an IAM role that has the\\nAmazonSageMakerFullAccess  policy attached. For information about conﬁguring roles\\nfor an EMR cluster, see Conﬁgure IAM Roles for Amazon EMR Permissions to AWS Services\\nin the Amazon EMR Management Guide .\\n\\xa0\\n•You can get the Scala library from Maven. Add the Spark library to your project by adding the\\nfollowing dependency to your pom.xml  ﬁle:\\n<dependency>\\n    <groupId>com.amazonaws</groupId>\\n    <artifactId>sagemaker-spark_2.11</artifactId>\\n    <version>spark_2.2.0-1.0</version>\\n</dependency>\\nIntegrate Your Apache Spark Application with\\nAmazon SageMaker\\nThe following is high-level summary of the steps for integrating your Apache Spark application with\\nAmazon SageMaker.\\n1. Continue data preprocessing using the Apache Spark library that you are familiar with. Your dataset\\nremains a DataFrame  in your Spark cluster.\\nNote\\nLoad your data into a DataFrame  and preprocess it so that you have a features  column\\nwith org.apache.spark.ml.linalg.Vector  of Doubles , and an optional label\\ncolumn with values of Double type.\\n2. Use the estimator in the Amazon SageMaker Spark library to train your model. For example, if you\\nchoose the k-means algorithm provided by Amazon SageMaker for model training, you call the\\nKMeansSageMakerEstimator.fit  method.\\nProvide your DataFrame  as input. The estimator returns a SageMakerModel  object.\\nNote\\nSageMakerModel  extends the org.apache.spark.ml.Model .\\nThe fit method does the following:\\na. Converts the input DataFrame  to the protobuf format by selecting the features  and label\\ncolumns from the input DataFrame  and uploading the protobuf data to an Amazon S3 bucket.\\nThe protobuf format is eﬃcient for model training in Amazon SageMaker.\\n441Amazon SageMaker Developer Guide\\nExample 1: Amazon SageMaker with Apache Spark \\nb. Starts model training in Amazon SageMaker by sending an Amazon SageMaker\\nCreateTrainingJob (p. 667) request. After model training has completed, Amazon SageMaker\\nsaves the model artifacts to an S3 bucket.\\nAmazon SageMaker assumes the IAM role that you speciﬁed for model training to perform tasks\\non your behalf. For example, it uses the role to read training data from an S3 bucket and to\\nwrite model artifacts to a bucket.\\nc. Creates and returns a SageMakerModel  object. The constructor does the following tasks, which\\nare related to deploying your model to Amazon SageMaker.\\ni. Sends a CreateModel (p. 648) request to Amazon SageMaker.\\nii. Sends a CreateEndpointConﬁg (p. 635) request to Amazon SageMaker.\\niii. Sends a CreateEndpoint (p. 632) request to Amazon SageMaker, which then launches the\\nspeciﬁed resources, and hosts the model on them.\\n3. You can get inferences from your model hosted in Amazon SageMaker with the\\nSageMakerModel.transform .\\nProvide an input DataFrame  with features as input. The transform  method transforms it to\\na DataFrame  containing inferences. Internally, the transform  method sends a request to the\\nInvokeEndpoint (p. 853) Amazon SageMaker API to get inferences. The transform  method\\nappends the inferences to the input DataFrame .\\nExample 1: Use Amazon SageMaker for Training and\\nInference with Apache Spark\\nTopics\\n•Use Custom Algorithms for Model Training and Hosting on Amazon SageMaker with Apache\\nSpark  (p. 446)\\n•Use the SageMakerEstimator in a Spark Pipeline (p. 447)\\nAmazon SageMaker provides an Apache Spark library (in both Python and Scala) that you can use\\nto integrate your Apache Spark applications with Amazon SageMaker. For example, you might use\\nApache Spark for data preprocessing and Amazon SageMaker for model training and hosting. For more\\ninformation, see Use Apache Spark with Amazon SageMaker (p. 440). This section provides example\\ncode that uses the Apache Spark Scala library provided by Amazon SageMaker to train a model in\\nAmazon SageMaker using DataFrame s in your Spark cluster. The example also hosts the resulting model\\nartifacts using Amazon SageMaker hosting services. Speciﬁcally, this example does the following:\\n•Uses the KMeansSageMakerEstimator  to ﬁt (or train) a model on data\\n\\xa0\\nBecause the example uses the k-means algorithm provided by Amazon SageMaker to train a model,\\nyou use the KMeansSageMakerEstimator . You train the model using images of handwritten single-\\ndigit numbers (from the MNIST dataset). You provide the images as an input DataFrame . For your\\nconvenience, Amazon SageMaker provides this dataset in an S3 bucket.\\n\\xa0\\nIn response, the estimator returns a SageMakerModel  object.\\n\\xa0\\n•Obtains inferences using the trained SageMakerModel\\n442Amazon SageMaker Developer Guide\\nExample 1: Amazon SageMaker with Apache Spark \\n\\xa0\\nTo get inferences from a model hosted in Amazon SageMaker, you call the\\nSageMakerModel.transform  method. You pass a DataFrame  as input. The method transforms the\\ninput DataFrame  to another DataFrame  containing inferences obtained from the model.\\n\\xa0\\nFor a given input image of a handwritten single-digit number, the inference identiﬁes a cluster that the\\nimage belongs to. For more information, see K-Means Algorithm (p. 141).\\nThis is the example code:\\nimport org.apache.spark.sql.SparkSession\\nimport com.amazonaws.services.sagemaker.sparksdk.IAMRole\\nimport com.amazonaws.services.sagemaker.sparksdk.algorithms\\nimport com.amazonaws.services.sagemaker.sparksdk.algorithms.KMeansSageMakerEstimator\\nval spark = SparkSession.builder.getOrCreate\\n// load mnist data as a dataframe from libsvm\\nval region = \"us-east-1\"\\nval trainingData = spark.read.format(\"libsvm\")\\n  .option(\"numFeatures\", \"784\")\\n  .load(s\"s3://sagemaker-sample-data-$region/spark/mnist/train/\")\\nval testData = spark.read.format(\"libsvm\")\\n  .option(\"numFeatures\", \"784\")\\n  .load(s\"s3://sagemaker-sample-data-$region/spark/mnist/test/\")\\nval roleArn = \"arn:aws:iam:: account-id :role/rolename \"\\nval estimator = new KMeansSageMakerEstimator(\\n  sagemakerRole = IAMRole(roleArn),\\n  trainingInstanceType = \"ml.p2.xlarge\",\\n  trainingInstanceCount = 1,\\n  endpointInstanceType = \"ml.c4.xlarge\",\\n  endpointInitialInstanceCount = 1)\\n  .setK(10).setFeatureDim(784)\\n// train\\nval model = estimator.fit(trainingData)\\nval transformedData = model.transform(testData)\\ntransformedData.show\\nThe code does the following:\\n•Loads the MNIST dataset from an S3 bucket provided by Amazon SageMaker (awsai-sparksdk-\\ndataset ) into a Spark DataFrame  (mnistTrainingDataFrame ):\\n// Get a Spark session.\\nval spark = SparkSession.builder.getOrCreate\\n// load mnist data as a dataframe from libsvm\\nval region = \"us-east-1\"\\nval trainingData = spark.read.format(\"libsvm\")\\n  .option(\"numFeatures\", \"784\")\\n  .load(s\"s3://sagemaker-sample-data-$region/spark/mnist/train/\")\\nval testData = spark.read.format(\"libsvm\")\\n  .option(\"numFeatures\", \"784\")\\n443Amazon SageMaker Developer Guide\\nExample 1: Amazon SageMaker with Apache Spark \\n  .load(s\"s3://sagemaker-sample-data-$region/spark/mnist/test/\")\\nval roleArn = \"arn:aws:iam:: account-id :role/rolename \"\\ntrainingData.show()\\nThe show method displays the ﬁrst 20 rows in the data frame:\\n+-----+--------------------+\\n|label|            features|\\n+-----+--------------------+\\n|  5.0|(784,[152,153,154...|\\n|  0.0|(784,[127,128,129...|\\n|  4.0|(784,[160,161,162...|\\n|  1.0|(784,[158,159,160...|\\n|  9.0|(784,[208,209,210...|\\n|  2.0|(784,[155,156,157...|\\n|  1.0|(784,[124,125,126...|\\n|  3.0|(784,[151,152,153...|\\n|  1.0|(784,[152,153,154...|\\n|  4.0|(784,[134,135,161...|\\n|  3.0|(784,[123,124,125...|\\n|  5.0|(784,[216,217,218...|\\n|  3.0|(784,[143,144,145...|\\n|  6.0|(784,[72,73,74,99...|\\n|  1.0|(784,[151,152,153...|\\n|  7.0|(784,[211,212,213...|\\n|  2.0|(784,[151,152,153...|\\n|  8.0|(784,[159,160,161...|\\n|  6.0|(784,[100,101,102...|\\n|  9.0|(784,[209,210,211...|\\n+-----+--------------------+\\nonly showing top 20 rows\\nIn each row:\\n•The label column identiﬁes the image\\'s label. For example, if the image of the handwritten number\\nis the digit 5, the label value is 5.\\n•The features  column stores a vector (org.apache.spark.ml.linalg.Vector ) of Double\\nvalues. These are the 784 features of the handwritten number. (Each handwritten number is a 28 x\\n28-pixel image, making 784 features.)\\n\\xa0\\n•Creates an Amazon SageMaker estimator (KMeansSageMakerEstimator )\\nThe fit method of this estimator uses the k-means algorithm provided by Amazon SageMaker to train\\nmodels using an input DataFrame . In response, it returns a SageMakerModel  object that you can use\\nto get inferences.\\nNote\\nThe KMeansSageMakerEstimator  extends the Amazon SageMaker SageMakerEstimator ,\\nwhich extends the Apache Spark Estimator .\\nval estimator = new KMeansSageMakerEstimator(\\n  sagemakerRole = IAMRole(roleArn),\\n  trainingInstanceType = \"ml.p2.xlarge\",\\n  trainingInstanceCount = 1,\\n  endpointInstanceType = \"ml.c4.xlarge\",\\n  endpointInitialInstanceCount = 1)\\n  .setK(10).setFeatureDim(784)\\n444Amazon SageMaker Developer Guide\\nExample 1: Amazon SageMaker with Apache Spark \\nThe constructor parameters provide information that is used for training a model and deploying it on\\nAmazon SageMaker:\\n•trainingInstanceType  and trainingInstanceCount —Identify the type and number of ML\\ncompute instances to use for model training.\\n\\xa0\\n•endpointInstanceType —Identiﬁes the ML compute instance type to use when hosting the model\\nin Amazon SageMaker. By default, one ML compute instance is assumed.\\n\\xa0\\n•endpointInitialInstanceCount —Identiﬁes the number of ML compute instances initially\\nbacking the endpoint hosting the model in Amazon SageMaker.\\n\\xa0\\n•sagemakerRole —Amazon SageMaker assumes this IAM role to perform tasks on your behalf. For\\nexample, for model training, it reads data from S3 and writes training results (model artifacts) to S3.\\nNote\\nThis example implicitly creates an Amazon SageMaker client. To create this client, you must\\nprovide your credentials. The API uses these credentials to authenticate requests to Amazon\\nSageMaker. For example, it uses the credentials to authenticate requests to create a training\\njob and API calls for deploying the model using Amazon SageMaker hosting services.\\n•After the KMeansSageMakerEstimator  object has been created, you set the following parameters,\\nare used in model training:\\n•The number of clusters that the k-means algorithm should create during model training. You\\nspecify 10 clusters, one for each digit, 0 through 9.\\n•Identiﬁes that each input image has 784 features (each handwritten number is a 28 x 28-pixel\\nimage, making 784 features).\\n\\xa0\\n•Calls the estimator fit method\\n// train\\nval model = estimator.fit(trainingData)\\nYou pass the input DataFrame  as a parameter. The model does all the work of training the model\\nand deploying it to Amazon SageMaker. For more information see, Integrate Your Apache Spark\\nApplication with Amazon SageMaker (p. 441). In response, you get a SageMakerModel  object, which\\nyou can use to get inferences from your model deployed in Amazon SageMaker.\\n\\xa0\\nYou provide only the input DataFrame . You don\\'t need to specify the registry path to the k-means\\nalgorithm used for model training because the KMeansSageMakerEstimator  knows it.\\n\\xa0\\n•Calls the SageMakerModel.transform  method to get inferences from the model deployed in\\nAmazon SageMaker.\\nThe transform  method takes a DataFrame  as input, transforms it, and returns another DataFrame\\ncontaining inferences obtained from the model.\\nval transformedData = model.transform(testData)\\ntransformedData.show\\n445Amazon SageMaker Developer Guide\\nExample 1: Amazon SageMaker with Apache Spark \\nFor simplicity, we use the same DataFrame  as input to the transform  method that we used for\\nmodel training in this example. The transform  method does the following:\\n•Serializes the features  column in the input DataFrame  to protobuf and sends it to the Amazon\\nSageMaker endpoint for inference.\\n•Deserializes the protobuf response into the two additional columns (distance_to_cluster  and\\nclosest_cluster ) in the transformed DataFrame .\\nThe show method gets inferences to the ﬁrst 20 rows in the input DataFrame :\\n+-----+--------------------+-------------------+---------------+\\n|label|            features|distance_to_cluster|closest_cluster|\\n+-----+--------------------+-------------------+---------------+\\n|  5.0|(784,[152,153,154...|  1767.897705078125|            4.0|\\n|  0.0|(784,[127,128,129...|  1392.157470703125|            5.0|\\n|  4.0|(784,[160,161,162...| 1671.5711669921875|            9.0|\\n|  1.0|(784,[158,159,160...| 1182.6082763671875|            6.0|\\n|  9.0|(784,[208,209,210...| 1390.4002685546875|            0.0|\\n|  2.0|(784,[155,156,157...|  1713.988037109375|            1.0|\\n|  1.0|(784,[124,125,126...| 1246.3016357421875|            2.0|\\n|  3.0|(784,[151,152,153...|  1753.229248046875|            4.0|\\n|  1.0|(784,[152,153,154...|  978.8394165039062|            2.0|\\n|  4.0|(784,[134,135,161...|  1623.176513671875|            3.0|\\n|  3.0|(784,[123,124,125...|  1533.863525390625|            4.0|\\n|  5.0|(784,[216,217,218...|  1469.357177734375|            6.0|\\n|  3.0|(784,[143,144,145...|  1736.765869140625|            4.0|\\n|  6.0|(784,[72,73,74,99...|   1473.69384765625|            8.0|\\n|  1.0|(784,[151,152,153...|    944.88720703125|            2.0|\\n|  7.0|(784,[211,212,213...| 1285.9071044921875|            3.0|\\n|  2.0|(784,[151,152,153...| 1635.0125732421875|            1.0|\\n|  8.0|(784,[159,160,161...| 1436.3162841796875|            6.0|\\n|  6.0|(784,[100,101,102...| 1499.7366943359375|            7.0|\\n|  9.0|(784,[209,210,211...| 1364.6319580078125|            6.0|\\n+-----+--------------------+-------------------+---------------+\\nYou can interpret the data, as follows:\\n•A handwritten number with the label  5 belongs to cluster 5 ( closest_cluster ).\\n•A handwritten number with the label  0 belongs to cluster 2.\\n•A handwritten number with the label  4 belongs to cluster 4.\\n•A handwritten number with the label  1 belongs to cluster 1.\\nFor more information on how to run these examples, see https://github.com/aws/sagemaker-spark/\\nblob/master/README.md on GitHub.\\nUse Custom Algorithms for Model Training and Hosting on\\nAmazon SageMaker with Apache Spark\\nIn Example 1: Use Amazon SageMaker for Training and Inference with Apache Spark (p. 442), you\\nuse the kMeansSageMakerEstimator  because the example uses the k-means algorithm provided by\\nAmazon SageMaker for model training. You might choose to use your own custom algorithm for model\\ntraining instead. Assuming that you have already created a Docker image, you can create your own\\nSageMakerEstimator  and specify the Amazon Elastic Container Registry path for your custom image.\\nThe following example shows how to create a KMeansSageMakerEstimator  from the\\nSageMakerEstimator . In the new estimator, you explicitly specify the Docker registry path to your\\ntraining and inference code images.\\n446Amazon SageMaker Developer Guide\\nExample 1: Amazon SageMaker with Apache Spark \\nimport com.amazonaws.services.sagemaker.sparksdk.IAMRole\\nimport com.amazonaws.services.sagemaker.sparksdk.SageMakerEstimator\\nimport\\n com.amazonaws.services.sagemaker.sparksdk.transformation.serializers.ProtobufRequestRowSerializer\\nimport\\n com.amazonaws.services.sagemaker.sparksdk.transformation.deserializers.KMeansProtobufResponseRowDeserializer\\nval estimator = new SageMakerEstimator(\\n  trainingImage =\\n    \"811284229777.dkr.ecr.us-east-1.amazonaws.com/kmeans:1\",\\n  modelImage =\\n    \"811284229777.dkr.ecr.us-east-1.amazonaws.com/kmeans:1\",\\n  requestRowSerializer = new ProtobufRequestRowSerializer(),\\n  responseRowDeserializer = new KMeansProtobufResponseRowDeserializer(),\\n  hyperParameters = Map(\"k\" -> \"10\", \"feature_dim\" -> \"784\"),\\n  sagemakerRole = IAMRole(roleArn),\\n  trainingInstanceType = \"ml.p2.xlarge\",\\n  trainingInstanceCount = 1,\\n  endpointInstanceType = \"ml.c4.xlarge\",\\n  endpointInitialInstanceCount = 1,\\n  trainingSparkDataFormat = \"sagemaker\")\\nIn the code, the parameters in the SageMakerEstimator  constructor include:\\n•trainingImage  —Identiﬁes the Docker registry path to the training image containing your custom\\ncode.\\n•modelImage  —Identiﬁes the Docker registry path to the image containing inference code.\\n•requestRowSerializer  —Implements\\ncom.amazonaws.services.sagemaker.sparksdk.transformation.RequestRowSerializer .\\nThis parameter serializes rows in the input DataFrame  to send them to the model hosted in Amazon\\nSageMaker for inference.\\n•responseRowDeserializer  —Implements\\ncom.amazonaws.services.sagemaker.sparksdk.transformation.ResponseRowDeserializer .\\nThis parameter deserializes responses from the model, hosted in Amazon SageMaker, back into a\\nDataFrame .\\n•trainingSparkDataFormat  —Speciﬁes the data format that Spark uses when uploading training\\ndata from a DataFrame  to S3. For example, \"sagemaker\"  for protobuf format, \"csv\" for comma-\\nseparated values, and \"libsvm\"  for LibSVM format.\\nYou can implement your own RequestRowSerializer  and ResponseRowDeserializer  to serialize\\nand deserialize rows from a data format that your inference code supports, such as .libsvm or ..csv.\\nUse the SageMakerEstimator in a Spark Pipeline\\nYou can use org.apache.spark.ml.Estimator  estimators and org.apache.spark.ml.Model\\nmodels, and SageMakerEstimator  estimators and SageMakerModel  models in\\norg.apache.spark.ml.Pipeline  pipelines, as shown in the following example:\\nimport org.apache.spark.ml.Pipeline\\nimport org.apache.spark.ml.feature.PCA\\nimport org.apache.spark.sql.SparkSession\\nimport com.amazonaws.services.sagemaker.sparksdk.IAMRole\\nimport com.amazonaws.services.sagemaker.sparksdk.algorithms\\nimport com.amazonaws.services.sagemaker.sparksdk.algorithms.KMeansSageMakerEstimator\\n447Amazon SageMaker Developer Guide\\nExample 1: Amazon SageMaker with Apache Spark \\nval spark = SparkSession.builder.getOrCreate\\n// load mnist data as a dataframe from libsvm \\nval region = \"us-east-1\"\\nval trainingData = spark.read.format(\"libsvm\")\\n  .option(\"numFeatures\", \"784\")\\n  .load(s\"s3://sagemaker-sample-data-$region/spark/mnist/train/\")\\nval testData = spark.read.format(\"libsvm\")\\n  .option(\"numFeatures\", \"784\")\\n  .load(s\"s3://sagemaker-sample-data-$region/spark/mnist/test/\")\\n// substitute your SageMaker IAM role here\\nval roleArn = \"arn:aws:iam:: account-id :role/rolename \"\\nval pcaEstimator = new PCA()\\n  .setInputCol(\"features\")\\n  .setOutputCol(\"projectedFeatures\")\\n  .setK(50)\\nval kMeansSageMakerEstimator = new KMeansSageMakerEstimator(\\n  sagemakerRole = IAMRole(integTestingRole),\\n  requestRowSerializer =\\n    new ProtobufRequestRowSerializer(featuresColumnName = \"projectedFeatures\"),\\n  trainingSparkDataFormatOptions = Map(\"featuresColumnName\" -> \"projectedFeatures\"),\\n  trainingInstanceType = \"ml.p2.xlarge\",\\n  trainingInstanceCount = 1,\\n  endpointInstanceType = \"ml.c4.xlarge\",\\n  endpointInitialInstanceCount = 1)\\n  .setK(10).setFeatureDim(50)\\nval pipeline = new Pipeline().setStages(Array(pcaEstimator, kMeansSageMakerEstimator))\\n// train\\nval pipelineModel = pipeline.fit(trainingData)\\nval transformedData = pipelineModel.transform(testData)\\ntransformedData.show()\\nThe parameter trainingSparkDataFormatOptions  conﬁgures Spark to serialize to protobuf the\\n\"projectedFeatures\" column for model training. Additionally, Spark serializes to protobuf the \"label\"\\ncolumn by default.\\nBecause we want to make inferences using the \"projectedFeatures\" column, we pass the column name\\ninto the ProtobufRequestRowSerializer .\\nThe following example shows a transformed DataFrame :\\n+-----+--------------------+--------------------+-------------------+---------------+\\n|label|            features|   projectedFeatures|distance_to_cluster|closest_cluster|\\n+-----+--------------------+--------------------+-------------------+---------------+\\n|  5.0|(784,[152,153,154...|[880.731433034386...|     1500.470703125|            0.0|\\n|  0.0|(784,[127,128,129...|[1768.51722024166...|      1142.18359375|            4.0|\\n|  4.0|(784,[160,161,162...|[704.949236329314...|  1386.246826171875|            9.0|\\n|  1.0|(784,[158,159,160...|[-42.328192193771...| 1277.0736083984375|            5.0|\\n|  9.0|(784,[208,209,210...|[374.043902028333...|   1211.00927734375|            3.0|\\n|  2.0|(784,[155,156,157...|[941.267714528850...|  1496.157958984375|            8.0|\\n|  1.0|(784,[124,125,126...|[30.2848596410594...| 1327.6766357421875|            5.0|\\n|  3.0|(784,[151,152,153...|[1270.14374062052...| 1570.7674560546875|            0.0|\\n|  1.0|(784,[152,153,154...|[-112.10792566485...|     1037.568359375|            5.0|\\n|  4.0|(784,[134,135,161...|[452.068280676606...| 1165.1236572265625|            3.0|\\n|  3.0|(784,[123,124,125...|[610.596447285397...|  1325.953369140625|            7.0|\\n|  5.0|(784,[216,217,218...|[142.959601818422...| 1353.4930419921875|            5.0|\\n|  3.0|(784,[143,144,145...|[1036.71862533658...| 1460.4315185546875|            7.0|\\n|  6.0|(784,[72,73,74,99...|[996.740157435754...| 1159.8631591796875|            2.0|\\n448Amazon SageMaker Developer Guide\\nAdditional Examples: Amazon\\nSageMaker with Apache Spark\\n|  1.0|(784,[151,152,153...|[-107.26076167417...|   960.963623046875|            5.0|\\n|  7.0|(784,[211,212,213...|[619.771820430940...|   1245.13623046875|            6.0|\\n|  2.0|(784,[151,152,153...|[850.152101817161...|  1304.437744140625|            8.0|\\n|  8.0|(784,[159,160,161...|[370.041887230547...| 1192.4781494140625|            0.0|\\n|  6.0|(784,[100,101,102...|[546.674328209335...|    1277.0908203125|            2.0|\\n|  9.0|(784,[209,210,211...|[-29.259112927426...| 1245.8182373046875|            6.0|\\n+-----+--------------------+--------------------+-------------------+---------------+\\nAdditional Examples: Use Amazon SageMaker with\\nApache Spark\\nAdditional examples of using Amazon SageMaker with Apache Spark are available at https://\\ngithub.com/aws/sagemaker-spark/tree/master/examples.\\nUse TensorFlow with Amazon SageMaker\\nYou can use Amazon SageMaker to train and deploy a model using custom TensorFlow code. The\\nAmazon SageMaker Python SDK TensorFlow estimators and models and the Amazon SageMaker open-\\nsource TensorFlow containers make writing a TensorFlow script and running it in Amazon SageMaker\\neasier.\\nUse TensorFlow Version 1.11 and Later\\nFor TensorFlow versions 1.11 and later, the Amazon SageMaker Python SDK supports script mode\\ntraining scripts.\\nWhat do you want to do?\\nI want to train a custom TensorFlow model in Amazon SageMaker.\\nFor a sample Jupyter notebook, see https://github.com/awslabs/amazon-sagemaker-examples/\\ntree/master/sagemaker-python-sdk/tensorﬂow_distributed_mnist.\\nFor documentation, see Train a Model with TensorFlow.\\nI have a TensorFlow model that I trained in Amazon SageMaker, and I want to deploy it to a hosted\\nendpoint.\\nDeploy TensorFlow Serving models.\\nI have a TensorFlow model that I trained outside of Amazon SageMaker, and I want to deploy it to an\\nAmazon SageMaker endpoint\\nDeploying directly from model artifacts.\\nI want to see the API documentation for Amazon SageMaker Python SDK TensorFlow classes.\\nTensorFlow Estimator\\nI want to see information about Amazon SageMaker TensorFlow containers.\\nhttps://github.com/aws/sagemaker-tensorﬂow-container.\\nFor general information about writing TensorFlow script mode training scripts and using TensorFlow\\nscript mode estimators and models with Amazon SageMaker, see Using TensorFlow with the SageMaker\\nPython SDK.\\n449Amazon SageMaker Developer Guide\\nUse TensorFlow Legacy Mode for Versions 1.11 and Earlier\\nFor information about TensorFlow versions supported by the Amazon SageMaker TensorFlow container,\\nsee https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorﬂow/\\nREADME.rst .\\nUse TensorFlow Legacy Mode for Versions 1.11 and\\nEarlier\\nThe Amazon SageMaker Python SDK provides a legacy mode that supports TensorFlow versions 1.11 and\\nearlier. Use legacy mode TensorFlow training scripts to run TensorFlow jobs in Amazon SageMaker if:\\n•You have existing legacy mode scripts that you do not want to convert to script mode.\\n•You want to use a TensorFlow version earlier than 1.11.\\nFor information about writing legacy mode TensorFlow scipts to use with the Amazon SageMaker\\nPython SDK, see https://github.com/aws/sagemaker-python-sdk/tree/v1.12.0/src/sagemaker/\\ntensorﬂow#tensorﬂow-sagemaker-estimators-and-models.\\nUse Apache MXNet with Amazon SageMaker\\nYou can use Amazon SageMaker to train and deploy a model using custom MXNet code. The Amazon\\nSageMaker Python SDK MXNet estimators and models and the Amazon SageMaker open-source MXNet\\ncontainer make writing a MXNet script and running it in Amazon SageMaker easier.\\nWhat do you want to do?\\nI want to train a custom MXNet model in Amazon SageMaker.\\nFor a sample Jupyter notebook, see https://github.com/awslabs/amazon-sagemaker-examples/\\ntree/master/sagemaker-python-sdk/mxnet_mnist.\\nFor documentation, see Train a Model with MXNet.\\nI have an MXNet model that I trained in Amazon SageMaker, and I want to deploy it to a hosted\\nendpoint.\\nDeploy MXNet models.\\nI have an MXNet model that I trained outside of Amazon SageMaker, and I want to deploy it to an\\nAmazon SageMaker endpoint\\nDeploy Endpoints from Model Data.\\nI want to see the API documentation for Amazon SageMaker Python SDK MXNet classes.\\nMXNet Classes\\nI want to see information about Amazon SageMaker MXNet containers.\\nhttps://github.com/aws/sagemaker-mxnet-container.\\nFor general information about writing MXNet script mode training scripts and using MXNet script mode\\nestimators and models with Amazon SageMaker, see Using MXNet with the SageMaker Python SDK.\\nFor information about MXNet versions supported by the Amazon SageMaker MXNet container, see\\nhttps://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/mxnet/README.rst.\\n450Amazon SageMaker Developer Guide\\nUsing Scikit-learn\\nUse Scikit-learn with Amazon SageMaker\\nYou can use Amazon SageMaker to train and deploy a model using custom Scikit-learn code. The\\nAmazon SageMaker Python SDK Scikit-learn estimators and models and the Amazon SageMaker open-\\nsource Scikit-learn container make writing a Scikit-learn script and running it in Amazon SageMaker\\neasier.\\nWhat do you want to do?\\nI want to train a custom Scikit-learn model in Amazon SageMaker.\\nFor a sample Jupyter notebook, see https://github.com/awslabs/amazon-sagemaker-examples/\\ntree/master/sagemaker-python-sdk/scikit_learn_iris.\\nFor documentation, see Train a Model with Scikit-learn.\\nI have a Scikit-learn model that I trained in Amazon SageMaker, and I want to deploy it to a hosted\\nendpoint.\\nDeploy Scikit-learn models.\\nI have a Scikit-learn model that I trained outside of Amazon SageMaker, and I want to deploy it to an\\nAmazon SageMaker endpoint\\nDeploy Endpoints from Model Data.\\nI want to see the API documentation for Amazon SageMaker Python SDK Scikit-learn classes.\\nScikit-learn Classes\\nI want to see information about Amazon SageMaker Scikit-learn containers.\\nhttps://github.com/aws/sagemaker-scikit-learn-container.\\nFor general information about writing Scikit-learn training scripts and using Scikit-learn estimators and\\nmodels with Amazon SageMaker, see Using Scikit-learn with the SageMaker Python SDK.\\nFor information about Scikit-learn versions supported by the Amazon SageMaker Scikit-learn container,\\nsee https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/sklearn/README.rst.\\nUse PyTorch with Amazon SageMaker\\nYou can use Amazon SageMaker to train and deploy a model using custom PyTorch code. The Amazon\\nSageMaker Python SDK PyTorch estimators and models and the Amazon SageMaker open-source\\nPyTorch container make writing a PyTorch script and running it in Amazon SageMaker easier.\\nWhat do you want to do?\\nI want to train a custom PyTorch model in Amazon SageMaker.\\nFor a sample Jupyter notebook, see https://github.com/awslabs/amazon-sagemaker-examples/\\ntree/master/sagemaker-python-sdk/pytorch_mnist.\\nFor documentation, see Train a Model with PyTorch.\\n451Amazon SageMaker Developer Guide\\nUsing Chainer\\nI have a PyTorch model that I trained in Amazon SageMaker, and I want to deploy it to a hosted\\nendpoint.\\nDeploy PyTorch models.\\nI have a PyTorch model that I trained outside of Amazon SageMaker, and I want to deploy it to an\\nAmazon SageMaker endpoint\\nDeploy Endpoints from Model Data.\\nI want to see the API documentation for Amazon SageMaker Python SDK PyTorch classes.\\nPyTorch Classes\\nI want to see information about Amazon SageMaker PyTorch containers.\\nhttps://github.com/aws/sagemaker-pytorch-container.\\nFor general information about writing PyTorch training scripts and using PyTorch estimators and models\\nwith Amazon SageMaker, see Using PyTorch with the SageMaker Python SDK.\\nFor information about PyTorch versions supported by the Amazon SageMaker PyTorch container, see\\nhttps://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/pytorch/README.rst.\\nUse Chainer with Amazon SageMaker\\nYou can use Amazon SageMaker to train and deploy a model using custom Chainer code. The Amazon\\nSageMaker Python SDK Chainer estimators and models and the Amazon SageMaker open-source Chainer\\ncontainer make writing a Chainer script and running it in Amazon SageMaker easier.\\nWhat do you want to do?\\nI want to train a custom Chainer model in Amazon SageMaker.\\nFor a sample Jupyter notebook, see https://github.com/awslabs/amazon-sagemaker-examples/\\ntree/master/sagemaker-python-sdk/chainer_mnist.\\nFor documentation, see Train a Model with Chainer.\\nI have a Chainer model that I trained in Amazon SageMaker, and I want to deploy it to a hosted endpoint.\\nDeploy Chainer models.\\nI have a Chainer model that I trained outside of Amazon SageMaker, and I want to deploy it to an\\nAmazon SageMaker endpoint\\nDeploy Endpoints from Model Data.\\nI want to see the API documentation for Amazon SageMaker Python SDK Chainer classes.\\nChainer Classes\\nI want to see information about Amazon SageMaker Chainer containers.\\nhttps://github.com/aws/sagemaker-chainer-container.\\nFor general information about writing Chainer training scripts and using Chainer estimators and models\\nwith Amazon SageMaker, see Using Chainer with the SageMaker Python SDK.\\nFor information about Chainer versions supported by the Amazon SageMaker Chainer container, see\\nhttps://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/chainer/README.rst.\\n452Amazon SageMaker Developer Guide\\nUse SparkML Serving\\nUse SparkML Serving with Amazon SageMaker\\nThe Amazon SageMaker Python SDK SparkML Serving model and predictor and the Amazon SageMaker\\nopen-source SparkML Serving container support deploying Apache Spark ML pipelines serialized with\\nMLeap in Amazon SageMaker to get inferences.\\nFor information about using the SparkML Serving container to deploy models to Amazon SageMaker,\\nsee https://github.com/aws/sagemaker-sparkml-serving-container. For information about the Amazon\\nSageMaker Python SDK SparkML Serving model and predictors, see https://sagemaker.readthedocs.io/\\nen/stable/sagemaker.sparkml.html.\\n453Amazon SageMaker Developer Guide\\nWhy is Reinforcement Learning Important?\\nReinforcement Learning with\\nAmazon SageMaker RL\\nReinforcement learning (RL) is a machine learning technique that attempts to learn a strategy, called\\na policy, that optimizes an objective for an agent acting in an environment. For example, the agent\\nmight be a robot, the environment might be a maze, and the goal might be to successfully navigate\\nthe maze in the smallest amount of time. In RL, the agent takes an action, observes the state of the\\nenvironment, and gets a reward based on the value of the current state of the environment. The goal is\\nto maximize the long-term reward that the agent receives as a result of its actions. RL is well-suited for\\nsolving problems where an agent can make autonomous decisions.\\nTopics\\n•Why is Reinforcement Learning Important? (p. 454)\\n•Markov Decision Process (MDP) (p. 454)\\n•Key Features of Amazon SageMaker RL  (p. 455)\\n•Sample RL Workﬂow Using Amazon SageMaker RL (p. 457)\\n•RL Environments in Amazon SageMaker (p. 458)\\n•Distributed Training with Amazon SageMaker RL (p. 459)\\n•Hyperparameter Tuning with Amazon SageMaker RL (p. 460)\\nWhy is Reinforcement Learning Important?\\nRL is well-suited for solving large, complex problems. For example, supply chain management, HVAC\\nsystems, industrial robotics, game artiﬁcial intelligence, dialog systems, and autonomous vehicles.\\nBecause RL models learn by a continuous process of receiving rewards and punishments for every action\\ntaken by the agent, it is possible to train systems to make decisions under uncertainty and in dynamic\\nenvironments.\\nMarkov Decision Process (MDP)\\nRL is based on models called Markov Decision Processes (MDPs). An MDP consists of a series of time\\nsteps. Each time step consists of the following:\\nEnvironment\\nDeﬁnes the space in which the RL model operates. This can be either a real-world environment or\\na simulator. For example, if you train a physical autonomous vehicle on a physical road, that would\\nbe a real-world environment. If you train a computer program that models an autonomous vehicle\\ndriving on a road, that would be a simulator.\\nState\\nSpeciﬁes all information about the environment and past steps that is relevant to the future. For\\nexample, in an RL model in which a robot can move in any direction at any time step, then the\\n454Amazon SageMaker Developer Guide\\nKey Features of Amazon SageMaker RL \\nposition of the robot at the current time step is the state, because if we know where the robot is, it\\nisn\\'t necessary to know the steps it took to get there.\\nAction\\nWhat the agent does. For example, the robot takes a step forward.\\nReward\\nA number that represents the value of the state that resulted from the last action that the agent\\ntook. For example, if the goal is for a robot to ﬁnd treasure, the reward for ﬁnding treasure might be\\n5, and the reward for not ﬁnding treasure might be 0. The RL model attempts to ﬁnd a strategy that\\noptimizes the cumulative reward over the long term. This strategy is called a policy.\\nObservation\\nInformation about the state of the environment that is available to the agent at each step. This\\nmight be the entire state, or it might be just a part of the state. For example, the agent in a chess-\\nplaying model would be able to observe the entire state of the board at any step, but a robot in a\\nmaze might only be able to observe a small portion of the maze that it currently occupies.\\nTypically, training in RL consists of many episodes . An episode consists of all of the time steps in an MDP\\nfrom the initial state until the environment reaches the terminal state.\\nKey Features of Amazon SageMaker RL\\nTo train RL models in Amazon SageMaker RL, use the following components:\\n•A deep learning (DL) framework. Currently, Amazon SageMaker supports RL in TensorFlow and Apache\\nMXNet.\\n•An RL toolkit. An RL toolkit manages the interaction between the agent and the environment,\\nand provides a wide selection of state of the art RL algorithms. Amazon SageMaker supports\\nthe Intel Coach and Ray RLlib toolkits. For information about Intel Coach, see https://\\nnervanasystems.github.io/coach/. For information about Ray RLlib, see https://ray.readthedocs.io/en/\\nlatest/rllib.html .\\n•An RL environment. You can use custom environments, open-source environments, or commercial\\nenvironments. For information, see RL Environments in Amazon SageMaker (p. 458).\\nThe following diagram shows the RL components that are supported in Amazon SageMaker RL.\\n455Amazon SageMaker Developer Guide\\nKey Features of Amazon SageMaker RL \\n456Amazon SageMaker Developer Guide\\nSample RL Workﬂow Using Amazon SageMaker RL\\nSample RL Workﬂow Using Amazon SageMaker RL\\nThe following example describes the steps for developing RL models using Amazon SageMaker RL.\\nFor complete code examples, see the sample notebooks at https://github.com/awslabs/amazon-\\nsagemaker-examples/tree/master/reinforcement-learning.\\n1. Formulate the RL problem—First, formulate the business problem into an RL problem. For example,\\nauto scaling enables services to dynamically increase or decrease capacity depending on conditions\\nthat you deﬁne. Currently, this requires setting up alarms, scaling policies, and thresholds, and other\\nmanual steps. To solve this with RL, we deﬁne the components of the Markov Decision Process:\\na. Objective—Scale instance capacity so that it matches the desired load proﬁle.\\nb. Environment—A custom environment that includes the load proﬁle. It generates a simulated\\nload with daily and weekly variations and occasional spikes. The simulated system has a delay\\nbetween when new resources are requested and when they become available for serving\\nrequests.\\nc. State —The current load, number of failed jobs, and number of active machines\\nd. Action—Remove, add, or keep the same number of instances.\\ne. Reward—A positive reward for successful transactions, a high penalty for failing transactions\\nbeyond a speciﬁed threshold.\\n2. Deﬁne the RL environment—The RL environment can be the real world where the RL agent\\ninteracts or a simulation of the real world. You can connect open source and custom environments\\ndeveloped using Gym interfaces, and commercial simulation environments such as MATLAB and\\nSimulink.\\n3. Deﬁne the presets —The presets conﬁgure the RL training jobs and deﬁne the hyperparameters for\\nthe RL algorithms.\\n4. Write the training code—Write training code as a Python script and pass the script to an Amazon\\nSageMaker training job. In your training code, import the environment ﬁles and the preset ﬁles, and\\nthen deﬁne the main() function.\\n5. Train the RL Model— Use the Amazon SageMaker RLEstimator  in the Amazon SageMaker Python\\nSDK to start an RL training job. If you are using local mode, the training job runs on the notebook\\ninstance. When you use Amazon SageMaker for training, you can select GPU or CPU instances. Store\\nthe output from the training job in a local directory if you train in local mode, or on Amazon S3 if\\nyou use Amazon SageMaker training.\\nFor information about using the Amazon SageMaker Python SDK for RL, see https://github.com/\\naws/sagemaker-python-sdk/blob/master/src/sagemaker/rl/README.rst .\\nThe RLEstimator  requires the following information as parameters.\\na. The source directory where the environment, presets, and training code are uploaded.\\nb. The path to the training script.\\nc. The RL toolkit and deep learning framework you want to use. This automatically resolves to the\\nAmazon ECR path for the RL container.\\nd. The training parameters, such as the instance count, job name, and S3 path for output.\\ne. Metric deﬁnitions that you want to capture in your logs. These can also be visualized in\\nCloudWatch and in Amazon SageMaker notebooks.\\n6. Visualize training metrics and output—After a training job that uses an RL model completes, you\\ncan view the metrics you deﬁned in the training jobs in CloudWatch,. You can also plot the metrics in\\na notebook by using the Amazon SageMaker Python SDK analytics library. Visualizing metrics helps\\nyou understand how the performance of the model as measured by the reward improves over time.\\n457Amazon SageMaker Developer Guide\\nRL Environments in Amazon SageMaker\\nNote\\nIf you train in local mode, you can\\'t visualize metrics in CloudWatch.\\n7. Evaluate the model —Checkpointed data from the previously trained models can be passed on for\\nevaluation and inference in the checkpoint channel. In local mode, use the local directory. In Amazon\\nSageMaker training mode, you need to upload the data to S3 ﬁrst.\\n8. Deploy RL models—Finally, deploy the trained model on an endpoint hosted on Amazon SageMaker\\nor on an Edge device by using AWS IoT Greengrass.\\nRL Environments in Amazon SageMaker\\nAmazon SageMaker RL uses environments to mimic real-world scenarios. Given the current state of the\\nenvironment and an action taken by the agent or agents, the simulator processes the impact of the\\naction, and returns the next state and a reward. Simulators are useful in cases where it is not safe to\\ntrain an agent in the real world (for example, ﬂying a drone) or if the RL algorithm takes a long time to\\nconverge (for example, when playing chess).\\nThe following diagram shows an example of the interactions with a simulator for a car racing game.\\nThe simulation environment consists of an agent and a simulator. Here, a convolutional neural network\\n(CNN) consumes images from the simulator and generates actions to control the game controller. With\\nmultiple simulations, this environment generates training data of the form state_t , action , state_t\\n+1, and reward_t+1 . Deﬁning the reward is not trivial and impacts the RL model quality. We want to\\nprovide a few examples of reward functions, but would like to make it user-conﬁgurable.\\nTopics\\n•Use OpenAI Gym Interface for Environments in Amazon SageMaker RL (p. 459)\\n•Use Open Source Environments (p. 459)\\n•Use Commercial Environments (p. 459)\\n458Amazon SageMaker Developer Guide\\nUse OpenAI Gym Interface for\\nEnvironments in Amazon SageMaker RL\\nUse OpenAI Gym Interface for Environments in\\nAmazon SageMaker RL\\nTo use OpenAI Gym environments in Amazon SageMaker RL, use the following API elements. For more\\ninformation about OpenAI Gym, see https://gym.openai.com/docs/.\\n•env.action_space —Deﬁnes the actions the agent can take, speciﬁes whether each action is\\ncontinuous or discrete, and speciﬁes the minimum and maximum if the action is continuous.\\n•env.observation_space —Deﬁnes the observations the agent receives from the environment, as\\nwell as minimum and maximum for continuous observations.\\n•env.reset() —Initializes a training episode. The reset() function returns the initial state of the\\nenvironment, and the agent uses the initial state to take its ﬁrst action. The action is then sent to the\\nstep() repeatedly until the episode reaches a terminal state. When step() returns done = True ,\\nthe episode ends. The RL toolkit re-initializes the environment by calling reset() .\\n•step()—Takes the agent action as input and outputs the next state of the environment, the reward,\\nwhether the episode has terminated, and an info dictionary to communicate debugging information.\\nIt is the responsibility of the environment to validate the inputs.\\n•env.render() Used for environments that have visualization. The RL toolkit calls this function to\\ncapture visualizations of the environment after each call to the step() function.\\nUse Open Source Environments\\nYou can use open source environments, such as EnergyPlus and RoboSchool, in Amazon SageMaker RL\\nby building your own container. For more information about EnergyPlus, see https://energyplus.net/.\\nFor more information about RoboSchool, see https://github.com/openai/roboschool. The HVAC and\\nRoboSchool examples in the samples repository at https://github.com/awslabs/amazon-sagemaker-\\nexamples/tree/master/reinforcement_learning show how to build a custom container to use with\\nAmazon SageMaker RL:\\nUse Commercial Environments\\nYou can use commercial environments, such as MATLAB and Simulink, in Amazon SageMaker RL by\\nbuilding your own container. You need to manage your own licenses.\\nDistributed Training with Amazon SageMaker RL\\nAmazon SageMaker RL supports multi-core and multi-instance distributed training. Depending on your\\nuse case, training and/or environment rollout can be distributed. For example, Amazon SageMaker RL\\nworks for the following distributed scenarios:\\n•Single training instance and multiple rollout instances of the same instance type. For an example, see\\nthe Neural Network Compression example in the Amazon SageMaker examples repository at https://\\ngithub.com/awslabs/amazon-sagemaker-examples/tree/master/reinforcement_learning.\\n•Single trainer instance and multiple rollout instances, where diﬀerent instance types for training\\nand rollouts. For an example, see the AWS DeepRacer / AWS RoboMaker example in the Amazon\\nSageMaker examples repository at https://github.com/awslabs/amazon-sagemaker-examples/tree/\\nmaster/reinforcement_learning.\\n•Single trainer instance that uses multiple cores for rollout. For an example, see the Roboschool\\nexample in the Amazon SageMaker examples repository at https://github.com/awslabs/amazon-\\nsagemaker-examples/tree/master/reinforcement_learning. This is useful if the simulation environment\\nis light-weight and can run on a single thread.\\n459Amazon SageMaker Developer Guide\\nHyperparameter Tuning with Amazon SageMaker RL\\n•Multiple instances for training and rollouts. For an example, see the Roboschool example in the\\nAmazon SageMaker examples repository at https://github.com/awslabs/amazon-sagemaker-\\nexamples/tree/master/reinforcement_learning.\\nHyperparameter Tuning with Amazon SageMaker\\nRL\\nYou can run a hyperparameter tuning job to optimize hyperparameters for Amazon SageMaker RL. The\\nRoboschool example in the sample notebooks at https://github.com/awslabs/amazon-sagemaker-\\nexamples/tree/master/\\'reinforcement-learning shows how you can do this with RL Coach. The launcher\\nscript shows how you can abstract parameters from the Coach preset ﬁle and optimize them.\\n460Amazon SageMaker Developer Guide\\nMonitoring with CloudWatch\\nMonitor Amazon SageMaker\\nMonitoring is an important part of maintaining the reliability, availability, and performance of Amazon\\nSageMaker and your other AWS solutions. AWS provides the following monitoring tools to watch\\nAmazon SageMaker, report when something is wrong, and take automatic actions when appropriate:\\n•Amazon CloudWatch monitors your AWS resources and the applications that you run on AWS in real\\ntime. You can collect and track metrics, create customized dashboards, and set alarms that notify you\\nor take actions when a speciﬁed metric reaches a threshold that you specify. For example, you can have\\nCloudWatch track CPU usage or other metrics of your Amazon EC2 instances and automatically launch\\nnew instances when needed. For more information, see the Amazon CloudWatch User Guide.\\n•Amazon CloudWatch Logs enables you to monitor, store, and access your log ﬁles from EC2 instances,\\nAWS CloudTrail, and other sources. CloudWatch Logs can monitor information in the log ﬁles and\\nnotify you when certain thresholds are met. You can also archive your log data in highly durable\\nstorage. For more information, see the Amazon CloudWatch Logs User Guide.\\n•AWS CloudTrail captures API calls and related events made by or on behalf of your AWS account\\nand delivers the log ﬁles to an Amazon S3 bucket that you specify. You can identify which users\\nand accounts called AWS, the source IP address from which the calls were made, and when the calls\\noccurred. For more information, see the AWS CloudTrail User Guide.\\n•CloudWatch Events delivers a near real-time stream of system events that describe changes in AWS\\nresources. Create CloudWatch Events rules react to a status change in a Amazon SageMaker training,\\nhyperparameter tuning, or batch transform job\\nTopics\\n•Monitor Amazon SageMaker with Amazon CloudWatch (p. 461)\\n•Log Amazon SageMaker Events with Amazon CloudWatch (p. 466)\\n•Log Amazon SageMaker API Calls with AWS CloudTrail (p. 467)\\n•React to Amazon SageMaker Job Status Changes with CloudWatch Events (p. 470)\\nMonitor Amazon SageMaker with Amazon\\nCloudWatch\\nYou can monitor Amazon SageMaker using Amazon CloudWatch, which collects raw data and processes\\nit into readable, near real-time metrics. These statistics are kept for 15 months, so that you can\\naccess historical information and gain a better perspective on how your web application or service is\\nperforming. However, the Amazon CloudWatch console limits the search to metrics that were updated\\nin the last 2 weeks. This limitation ensures that the most current jobs are shown in your namespace. To\\ngraph metrics without using a search, specify its exact name in the source view. You can also set alarms\\nthat watch for certain thresholds, and send notiﬁcations or take actions when those thresholds are met.\\nFor more information, see the Amazon CloudWatch User Guide.\\nAmazon SageMaker model training jobs and endpoints write CloudWatch metrics and logs. The following\\ntables list the metrics and dimensions for Amazon SageMaker.\\nEndpoint Invocation Metrics\\n461Amazon SageMaker Developer Guide\\nMonitoring with CloudWatch\\nThe AWS/SageMaker  namespace includes the following request metrics from calls to\\nInvokeEndpoint (p. 853) .\\nMetrics are available at a 1-minute frequency.\\nFor information about how long CloudWatch metrics are retained for, see GetMetricStatistics  in the\\nAmazon CloudWatch API Reference.\\nMetric Description\\nInvocation4XXErrors The number of InvokeEndpoint  requests where the model returned a 4xx\\nHTTP response code. For each 4xx response, 1 is sent; otherwise, 0 is sent.\\nUnits: None\\nValid statistics: Average, Sum\\nInvocation5XXErrors The number of InvokeEndpoint  requests where the model returned a 5xx\\nHTTP response code. For each 5xx response, 1 is sent; otherwise, 0 is sent.\\nUnits: None\\nValid statistics: Average, Sum\\nInvocations The number of InvokeEndpoint  requests sent to a model endpoint.\\nTo get the total number of requests sent to a model endpoint, use the Sum\\nstatistic.\\nUnits: None\\nValid statistics: Sum, Sample Count\\nInvocationsPerInstance The number of invocations sent to a model, normalized by InstanceCount\\nin each ProductionVariant. 1/numberOfInstances  is sent as the value on\\neach request, where numberOfInstances  is the number of active instances\\nfor the ProductionVariant behind the endpoint at the time of the request.\\nUnits: None\\nValid statistics: Sum\\nModelLatency The interval of time taken by a model to respond as viewed from Amazon\\nSageMaker. This interval includes the local communication times taken to\\nsend the request and to fetch the response from the container of a model\\nand the time taken to complete the inference in the container.\\nUnits: Microseconds\\nValid statistics: Average, Sum, Min, Max, Sample Count\\nOverheadLatency The interval of time added to the time taken to respond to a client request\\nby Amazon SageMaker overheads. This interval is measured from the time\\nAmazon SageMaker receives the request until it returns a response to the\\nclient, minus the ModelLatency . Overhead latency can vary depending\\non multiple factors, including request and response payload sizes, request\\nfrequency, and authentication/authorization of the request.\\nUnits: Microseconds\\n462Amazon SageMaker Developer Guide\\nMonitoring with CloudWatch\\nMetric Description\\nValid statistics: Average, Sum, Min, Max, Sample Count\\nDimensions for Endpoint Invocation Metrics\\nDimension Description\\nEndpointName,\\nVariantNameFilters endpoint invocation metrics for a ProductionVariant  of the\\nspeciﬁed endpoint and variant.\\nTraining Job, Batch Transform Job, and Endpoint Instance Metrics\\nThe /aws/sagemaker/TrainingJobs , /aws/sagemaker/TransformJobs  and /aws/sagemaker/\\nEndpoints  namespaces include the following metrics for the training jobs and endpoint instances.\\nMetrics are available at a 1-minute frequency.\\nMetric Description\\nCPUUtilization The percentage of CPU units that are used by the containers on an instance.\\nThe value can range between 0 and 100, and is multiplied by the number of\\nCPUs. For example, if there are four CPUs, CPUUtilization  can range from\\n0% to 400%.\\nFor training jobs, the value is the CPU utilization of the algorithm container\\non the instance.\\nFor batch transform jobs, the value is the CPU utilization of the transform\\ncontainer on the instance.\\nFor endpoint variants, the value is the sum of the CPU utilization of the\\nprimary and supplementary containers on the instance.\\nNote\\nFor multi-instance, each instance reports CPU utilization metrics.\\nHowever, the default view in CloudWatch shows the average CPU\\nutilization across all instances.\\nUnits: Percent\\nMemoryUtilization The percentage of memory that is used by the containers on an instance.\\nThis value can range between 0% and 100%.\\nFor training jobs, the value is the memory utilization of the algorithm\\ncontainer on the instance.\\nFor batch transform jobs, the value is the memory utilization of the\\ntransform container on the instance.\\nFor endpoint variants, the value is the sum of the memory utilization of the\\nprimary and supplementary containers on the instance.\\nUnits: Percent\\n463Amazon SageMaker Developer Guide\\nMonitoring with CloudWatch\\nMetric Description\\nNote\\nFor multi-instance, each instance reports memory utilization\\nmetrics. However, the default view in CloudWatch shows the\\naverage memory utilization across all instances.\\nGPUUtilization The percentage of GPU units that are used by the containers on an instance.\\nThe value can range between 0 and 100 and is multiplied by the number\\nof GPUs. For example, if there are four GPUs, GPUUtilization  can range\\nfrom 0% to 400%.\\nFor training jobs, the value is the GPU utilization of the algorithm container\\non the instance.\\nFor batch transform jobs, the value is the GPU utilization of the transform\\ncontainer on the instance.\\nFor endpoint variants, the value is the sum of the GPU utilization of the\\nprimary and supplementary containers on the instance.\\nNote\\nFor multi-instance, each instance reports GPU utilization metrics.\\nHowever, the default view in CloudWatch shows the average GPU\\nutilization across all instances.\\nUnits: Percent\\nGPUMemoryUtilization The percentage of GPU memory used by the containers on an instance. The\\nvalue can range between 0 and 100 and is multiplied by the number of\\nGPUs. For example, if there are four GPUs, GPUMemoryUtilization  can\\nrange from 0% to 400%.\\nFor training jobs, the value is the GPU memory utilization of the algorithm\\ncontainer on the instance.\\nFor batch transform jobs, the value is the GPU memory utilization of the\\ntransform container on the instance.\\nFor endpoint variants, the value is the sum of the GPU memory utilization of\\nthe primary and supplementary containers on the instance.\\nNote\\nFor multi-instance, each instance reports GPU memory utilization\\nmetrics. However, the default view in CloudWatch shows the\\naverage GPU memory utilization across all instances.\\nUnits: Percent\\n464Amazon SageMaker Developer Guide\\nMonitoring with CloudWatch\\nMetric Description\\nDiskUtilization The percentage of disk space used by the containers on an instance uses.\\nThis value can range between 0% and 100%. This metric is not supported\\nfor batch transform jobs.\\nFor training jobs, the value is the disk space utilization of the algorithm\\ncontainer on the instance.\\nFor endpoint variants, the value is the sum of the disk space utilization of\\nthe primary and supplementary containers on the instance.\\nUnits: Percent\\nNote\\nFor multi-instance, each instance reports disk utilization metrics.\\nHowever, the default view in CloudWatch shows the average disk\\nutilization across all instances.\\nDimensions for Training Job, Batch Transform Job, and Endpoint Instance Metrics\\nDimension Description\\nHost For training jobs, the value for this dimension has the format [training-\\njob-name]/algo-[instance-number-in-cluster] . Use this\\ndimension to ﬁlter instance metrics for the speciﬁed training job and\\ninstance. This dimension format is present only in the /aws/sagemaker/\\nTrainingJobs  namespace.\\nFor batch transform jobs, the value for this dimension has the format\\n[transform-job-name]/[instance-id] . Use this dimension to\\nﬁlter instance metrics for the speciﬁed batch transform job and instance.\\nThis dimension format is present only in the /aws/sagemaker/\\nTransformJobs  namespace.\\nFor endpoints, the value for this dimension has the format [endpoint-\\nname]/[ production-variant-name ]/[instance-id] . Use this\\ndimension to ﬁlter instance metrics for the speciﬁed endpoint, variant, and\\ninstance. This dimension format is present only in the /aws/sagemaker/\\nEndpoints  namespace.\\nAmazon SageMaker Ground Truth Metrics\\nMetric Description\\nDatasetObjectsAutoAnnotated The number of dataset objects auto-annotated in a labeling job. This metric\\nis only emitted when automated labeling is enabled. To view the labeling job\\nprogress, use the Max metric.\\nUnits: None\\nValid statistics: Max\\nDatasetObjectsHumanAnnotated The number of dataset objects annotated by a human in a labeling job. To\\nview the labeling job progress, use the Max metric.\\n465Amazon SageMaker Developer Guide\\nLogging with CloudWatch\\nMetric Description\\nUnits: None\\nValid statistics: Max\\nDatasetObjectsLabelingFailed The number of dataset objects that failed labeling in a labeling job. To view\\nthe labeling job progress, use the Max metric.\\nUnits: None\\nValid statistics: Max\\nJobsFailed The number of labeling jobs that failed. To get the total number of labeling\\njobs that failed, use the Sum statistic.\\nUnits: None\\nValid statistics: Sum, Sample Count\\nJobsSucceeded The number of labeling jobs that succeeded. To get the total number of\\nlabeling jobs that succeeded, use the Sum statistic.\\nUnits: None\\nValid statistics: Sum, Sample Count\\nJobsStopped The number of labeling jobs that were stopped. To get the total number of\\nlabeling jobs that were stopped, use the Sum statistic.\\nUnits: None\\nValid statistics: Sum, Sample Count\\nTotalDatasetObjectsLabeled The number of dataset objects labeled successfully in a labeling job. To view\\nthe labeling job progress, use the Max metric.\\nUnits: None\\nValid statistics: Max\\nDimensions for Dataset Object Metrics\\nDimension Description\\nLabelingJobName Filters dataset object count metrics for a labeling job.\\nLog Amazon SageMaker Events with Amazon\\nCloudWatch\\nTo help you debug your training jobs, endpoints, transform jobs, notebook instances, and notebook\\ninstance lifecycle conﬁgurations, anything an algorithm container, a model container, or a notebook\\ninstance lifecycle conﬁguration sends to stdout  or stderr is also sent to Amazon CloudWatch Logs. In\\naddition to debugging, you can use these for progress analysis.\\nLogs\\n466Amazon SageMaker Developer Guide\\nLog Amazon SageMaker API Calls with AWS CloudTrail\\nThe following table lists all of the logs provided by Amazon SageMaker.\\nLogs\\nLog Group Name Log Stream Name\\n/aws/sagemaker/\\nTrainingJobs[training-job-name]/algo-[instance-number-in-cluster]-\\n[epoch_timestamp]\\n[production-variant-name]/[instance-id] /aws/sagemaker/\\nEndpoints/\\n[EndpointName] [production-variant-name]/[instance-id]/[container-name\\nprovided in SageMaker model] (For Inference Pipelines)\\n[notebook-instance-name]/[LifecycleConfigHook] /aws/sagemaker/\\nNotebookInstances\\n[notebook-instance-name]/jupyter.log\\n[transform-job-name]/[instance-id]-[epoch_timestamp]\\n[transform-job-name]/[instance-id]-[epoch_timestamp]/data-\\nlog/aws/sagemaker/\\nTransformJobs\\n[transform-job-name]/[instance-id]-[epoch_timestamp]/\\n[container-name provided in SageMaker model] (For\\nInference Pipelines)\\nNote\\n1. The /aws/sagemaker/NotebookInstances/[LifecycleConfigHook]  log stream\\nis created when you create a notebook instance with a lifecycle conﬁguration. For more\\ninformation, see Customize a Notebook Instance  (p. 40).\\n2. For Inference Pipelines, if you don\\'t provide container names, the platform uses **container-1,\\ncontainer-2**, and so on, corresponding to the order provided in the Amazon SageMaker model.\\nFor more information about logging events with CloudWatch logging, see What is Amazon CloudWatch\\nLogs?  in the Amazon CloudWatch User Guide.\\nLog Amazon SageMaker API Calls with AWS\\nCloudTrail\\nAmazon SageMaker is integrated with AWS CloudTrail, a service that provides a record of actions taken\\nby a user, role, or an AWS service in Amazon SageMaker. CloudTrail captures all API calls for Amazon\\nSageMaker, with the exception of InvokeEndpoint (p. 853), as events. The calls captured include\\ncalls from the Amazon SageMaker console and code calls to the Amazon SageMaker API operations.\\nIf you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket,\\nincluding events for Amazon SageMaker. If you don\\'t conﬁgure a trail, you can still view the most recent\\nevents in the CloudTrail console in Event history. Using the information collected by CloudTrail, you can\\ndetermine the request that was made to Amazon SageMaker, the IP address from which the request was\\nmade, who made the request, when it was made, and additional details.\\nTo learn more about CloudTrail, see the AWS CloudTrail User Guide.\\nBy default, log data is stored in CloudWatch Logs indeﬁnitely. Howerver, you can conﬁgure how long to\\nstore log data in a log group. For information, see Change Log Data Retention in CloudWatch Logs in the\\nAmazon CloudWatch Logs User Guide.\\n467Amazon SageMaker Developer Guide\\nAmazon SageMaker Information in CloudTrail\\nAmazon SageMaker Information in CloudTrail\\nCloudTrail is enabled on your AWS account when you create the account. When activity occurs in Amazon\\nSageMaker, that activity is recorded in a CloudTrail event along with other AWS service events in Event\\nhistory. You can view, search, and download recent events in your AWS account. For more information,\\nsee Viewing Events with CloudTrail Event History.\\nFor an ongoing record of events in your AWS account, including events for Amazon SageMaker, create a\\ntrail. A trail enables CloudTrail to deliver log ﬁles to an Amazon S3 bucket. By default, when you create\\na trail in the console, the trail applies to all AWS Regions. The trail logs events from all Regions in the\\nAWS partition and delivers the log ﬁles to the Amazon S3 bucket that you specify. Additionally, you can\\nconﬁgure other AWS services to further analyze and act upon the event data collected in CloudTrail logs.\\nFor more information, see the following:\\n•Overview for Creating a Trail\\n•CloudTrail Supported Services and Integrations\\n•Conﬁguring Amazon SNS Notiﬁcations for CloudTrail\\n•Receiving CloudTrail Log Files from Multiple Regions and Receiving CloudTrail Log Files from Multiple\\nAccounts\\nAll Amazon SageMaker actions, with the exception of InvokeEndpoint (p. 853), are logged by CloudTrail\\nand are documented in the Actions (p. 616). For example, calls to the CreateTrainingJob ,\\nCreateEndpoint  and CreateNotebookInstance  actions generate entries in the CloudTrail log ﬁles.\\nEvery event or log entry contains information about who generated the request. The identity\\ninformation helps you determine the following:\\n•Whether the request was made with root or AWS Identity and Access Management (IAM) user\\ncredentials.\\n•Whether the request was made with temporary security credentials for a role or federated user.\\n•Whether the request was made by another AWS service.\\nFor more information, see the CloudTrail userIdentity Element.\\nOperations Performed by Automatic Model Tuning\\nAmazon SageMaker supports logging non-API service events to your CloudTrail log ﬁles,for automatic\\nmodel tuning jobs. These events are related to your tuning jobs but, are not the direct result of a\\ncustomer request to the public AWS API. For example, when you create a hyperparameter tuning job\\nby calling CreateHyperParameterTuningJob (p. 638), Amazon SageMaker creates training jobs to\\nevaluate various combinations of hyperparameters to ﬁnd the best result. Similarly, when you call\\nStopHyperParameterTuningJob (p. 828) to stop a hyperparameter tuning job, Amazon SageMaker\\nmight stop any of the associated running training jobs. Non-API events for your tuning jobs are logged to\\nCloudTrail to help you improve governance, compliance, and operational and risk auditing of your AWS\\naccount.\\nLog entries that result from non-API service events have an eventType  of AwsServiceEvent  instead\\nof AwsApiCall .\\nUnderstanding Amazon SageMaker Log File Entries\\nA trail is a conﬁguration that enables delivery of events as log ﬁles to an S3 bucket that you specify.\\nCloudTrail log ﬁles contain one or more log entries. An event represents a single request from any\\n468Amazon SageMaker Developer Guide\\nUnderstanding Amazon SageMaker Log File Entries\\nsource and includes information about the requested action, the date and time of the action, request\\nparameters, and so on. CloudTrail log ﬁles are not an ordered stack trace of the public API calls, so they\\ndo not appear in any speciﬁc order.\\nThe following examples a log entry for the CreateEndpoint  action, which creates an endpoint to\\ndeploy a trained model.\\n{\\n    \"eventVersion\":\"1.05\",\\n    \"userIdentity\": {\\n        \"type\":\"IAMUser\",\\n        \"principalId\":\"AIXDAYQEXAMPLEUMLYNGL\",\\n        \"arn\":\"arn:aws:iam::123456789012:user/intern\",\\n        \"accountId\":\"123456789012\",\\n        \"accessKeyId\":\"ASXIAGXEXAMPLEQULKNXV\",\\n        \"userName\":\"intern\"\\n    },\\n    \"eventTime\":\"2018-01-02T13:39:06Z\",\\n    \"eventSource\":\"sagemaker.amazonaws.com\",\\n    \"eventName\":\"CreateEndpoint\",\\n    \"awsRegion\":\"us-west-2\",\\n    \"sourceIPAddress\":\"127.0.0.1\",\\n    \"userAgent\":\"USER_AGENT\",\\n    \"requestParameters\": {\\n        \"endpointName\":\"ExampleEndpoint\",\\n        \"endpointConfigName\":\"ExampleEndpointConfig\"\\n    },\\n    \"responseElements\": {\\n        \"endpointArn\":\"arn:aws:sagemaker:us-west-2:123456789012:endpoint/exampleendpoint\"\\n    },\\n    \"requestID\":\"6b1b42b9-EXAMPLE\",\\n    \"eventID\":\"a6f85b21-EXAMPLE\",\\n    \"eventType\":\"AwsApiCall\",\\n    \"recipientAccountId\":\"444455556666\"\\n}\\nThe following example is a log entry for the CreateModel  action, which creates one or more containers\\nto host a previously trained model.\\n{\\n    \"eventVersion\":\"1.05\",\\n    \"userIdentity\": {\\n        \"type\":\"IAMUser\",\\n        \"principalId\":\"AIXDAYQEXAMPLEUMLYNGL\",\\n        \"arn\":\"arn:aws:iam::123456789012:user/intern\",\\n        \"accountId\":\"123456789012\",\\n        \"accessKeyId\":\"ASXIAGXEXAMPLEQULKNXV\",\\n        \"userName\":\"intern\"\\n    },\\n    \"eventTime\":\"2018-01-02T15:23:46Z\",\\n    \"eventSource\":\"sagemaker.amazonaws.com\",\\n    \"eventName\":\"CreateModel\",\\n    \"awsRegion\":\"us-west-2\",\\n    \"sourceIPAddress\":\"127.0.0.1\",\\n    \"userAgent\":\"USER_AGENT\",\\n    \"requestParameters\": {\\n        \"modelName\":\"ExampleModel\",\\n        \"primaryContainer\": {\\n            \"image\":\"174872318107.dkr.ecr.us-west-2.amazonaws.com/kmeans:latest\"\\n        },\\n        \"executionRoleArn\":\"arn:aws:iam::123456789012:role/EXAMPLEARN\"\\n    },\\n    \"responseElements\": {\\n469Amazon SageMaker Developer Guide\\nReact to Amazon SageMaker Job Status\\nChanges with CloudWatch Events\\n        \"modelArn\":\"arn:aws:sagemaker:us-west-2:123456789012:model/\\nbarkinghappy2018-01-02t15-23-32-275z-ivrdog\"\\n    },\\n    \"requestID\":\"417b8dab-EXAMPLE\",\\n    \"eventID\":\"0f2b3e81-EXAMPLE\",\\n    \"eventType\":\"AwsApiCall\",\\n    \"recipientAccountId\":\"444455556666\"\\n}\\nReact to Amazon SageMaker Job Status Changes\\nwith CloudWatch Events\\nTo react to a status change in a Amazon SageMaker training, hyperparameter tuning, or batch transform\\njob, create a rule in CloudWatch Events that use the SageMaker Training Job State Change, SageMaker\\nHyperparameter Tuning Job State Change, or SageMaker Transform Job State Change event type as\\nthe event source for the rule.\\nEvery time the status of a Amazon SageMaker job changes, it triggers an event that CloudWatch Events\\nmonitors, and you can create a rule that calls a AWS Lambda function when the status changes. For\\ninformation about the status values and meanings for Amazon SageMaker jobs, see the following:\\n•TrainingJobStatus\\n•HyperParameterTuningJobStatus\\n•TransformJobStatus\\nFor information about creating CloudWatch Events rules, see Creating a CloudWatch Events Rule That\\nTriggers on an Event  in the CloudWatch Events User Guide. For detailed information about the format of\\nthe Amazon SageMaker events that CloudWatch Events monitors, see Amazon SageMaker Events.\\n470Amazon SageMaker Developer Guide\\nData Protection\\nSecurity in Amazon SageMaker\\nCloud security at AWS is the highest priority. As an AWS customer, you beneﬁt from a data center and\\nnetwork architecture that is built to meet the requirements of the most security-sensitive organizations.\\nSecurity is a shared responsibility between AWS and you. The shared responsibility model describes this\\nas security of the cloud and security in the cloud:\\n•Security of the cloud – AWS is responsible for protecting the infrastructure that runs AWS services in\\nthe AWS Cloud. AWS also provides you with services that you can use securely. Third-party auditors\\nregularly test and verify the eﬀectiveness of our security as part of the AWS compliance programs. To\\nlearn about the compliance programs that apply to Amazon SageMaker, see AWS Services in Scope by\\nCompliance Program.\\n•Security in the cloud – Your responsibility is determined by the AWS service that you use. You are also\\nresponsible for other factors including the sensitivity of your data, your company’s requirements, and\\napplicable laws and regulations.\\nThis documentation helps you understand how to apply the shared responsibility model when using\\nAmazon SageMaker. The following topics show you how to conﬁgure Amazon SageMaker to meet your\\nsecurity and compliance objectives. You also learn how to use other AWS services that help you to\\nmonitor and secure your Amazon SageMaker resources.\\nTopics\\n•Data Protection in Amazon SageMaker (p. 471)\\n•Identity and Access Management for Amazon SageMaker (p. 475)\\n•Logging and Monitoring  (p. 514)\\n•Compliance Validation for Amazon SageMaker (p. 514)\\n•Resilience in Amazon SageMaker (p. 515)\\n•Infrastructure Security in Amazon SageMaker (p. 515)\\nData Protection in Amazon SageMaker\\nAmazon SageMaker conforms to the AWS shared responsibility model, which includes regulations and\\nguidelines for data protection. AWS is responsible for protecting the global infrastructure that runs all\\nthe AWS services. AWS maintains control over data hosted on this infrastructure, including the security\\nconﬁguration controls for handling customer content and personal data. AWS customers and APN\\npartners, acting either as data controllers or data processors, are responsible for any personal data that\\nthey put in the AWS Cloud.\\nFor data protection purposes, we recommend that you protect AWS account credentials and set up\\nindividual user accounts with AWS Identity and Access Management (IAM), so that each user is given only\\nthe permissions necessary to fulﬁll their job duties. We also recommend that you secure your data in the\\nfollowing ways:\\n•Use multi-factor authentication (MFA) with each account.\\n•Use SSL/TLS to communicate with AWS resources.\\n471Amazon SageMaker Developer Guide\\nProtecting Data at Rest Using Encryption\\n•Set up API and user activity logging with AWS CloudTrail.\\n•Use AWS encryption solutions, along with all default security controls within AWS services.\\n•Use advanced managed security services such as Amazon Macie, which assists in discovering and\\nsecuring personal data that is stored in Amazon S3.\\nWe strongly recommend that you never put sensitive identifying information, such as your customers\\'\\naccount numbers, into free-form ﬁelds such as a Name  ﬁeld. This includes when you work with Amazon\\nSageMaker or other AWS services using the console, API, AWS CLI, or AWS SDKs. Any data that you enter\\ninto Amazon SageMaker or other services might get picked up for inclusion in diagnostic logs. When you\\nprovide a URL to an external server, don\\'t include credentials information in the URL to validate your\\nrequest to that server.\\nFor more information about data protection, see the AWS Shared Responsibility Model and GDPR blog\\npost on the AWS Security Blog.\\nTopics\\n•Protecting Data at Rest Using Encryption (p. 472)\\n•Protecting Data in Transit with Encryption (p. 473)\\n•Key Management (p. 475)\\n•Internetwork Traﬃc Privacy (p. 475)\\nProtecting Data at Rest Using Encryption\\nYou can use encrypted Amazon Simple Storage Service buckets for model artifacts and data, as\\nwell as pass a AWS Key Management Service key to Amazon SageMaker notebooks, training jobs,\\nhyperparameter tuning jobs, batch transform jobs, and endpoints, to encrypt the attached machine\\nlearning (ML) storage volume. If you do not specify a AWS KMS key, Amazon SageMaker encrypts storage\\nvolumes with a transient key. A transient key is discarded immediately after it is used to encrypt the\\nstorage volume.\\nAll instance OS volumes are encrypted with an AWS-managed AWS KMS key.\\nAll ML data volumes for all Amazon SageMaker instances may be encrypted with customer speciﬁed AWS\\nKMS keys. ML data volumes are mounted as follows:\\n•Notebooks - /home/ec2-user/SageMaker\\n•Training - /opt/ml/  and /tmp/\\n•Batch - /opt/ml/  and /tmp/\\n•Endpoints - /opt/ml/  and /tmp/\\nBatch and training job containers and their storage are ephemeral in nature. When the job completes,\\noutput is uploaded to Amazon S3 (with optional AWS KMS encryption) and the instance is torn down.\\nData of a sensitive nature that needs to be encrypted with a customer owned AWS KMS key for\\ncompliance reasons should be stored in the ML Amazon EBS volume or Amazon S3, both of which can\\nbe KMS encrypted with customer managed keys. Notebook instances mount all default folders used by\\nJupyter or the algorithm containers onto the ML volume.\\nThe Amazon SageMaker folder in the ML Amazon EBS volume is the default storage location when\\nyou open a notebook instance. Amazon SageMaker saves any ﬁles within the SageMaker folder. The /\\nsample-notebooks subfolder is located on the OS volume but that location is read only. When you stop\\na Notebook instance any customizations to the OS (like custom libraries installed or OS level settings)\\n472Amazon SageMaker Developer Guide\\nProtecting Data in Transit with Encryption\\nare lost. Consider utilizing lifecycle options to automate any customizations to the default image. If\\na Notebook instance is stopped, a snapshot of the ML volume is retained by Amazon in the service\\nplatform to support resumption. This snapshot is deleted on termination as well as the ML volume, so\\nany data to be persisted beyond the notebook lifecycle should be transferred to customer Amazon S3\\nbuckets.\\nProtecting Data in Transit with Encryption\\nAll inter-network data in transit supports TLS 1.2 encryption.\\nAmazon SageMaker ensures that machine learning (ML) model artifacts and other system artifacts are\\nencrypted in transit and at rest. Requests to the Amazon SageMaker API and console are made over a\\nsecure (SSL) connection. You pass AWS Identity and Access Management roles to Amazon SageMaker\\nto provide permissions to access resources on your behalf for training and deployment. You can use\\nencrypted Amazon S3 buckets for model artifacts and data, as well as pass a AWS KMS key to Amazon\\nSageMaker instances to encrypt the attached ML storage volumes.\\nSome intra-network data in-transit (inside the service platform) is unencrypted. This includes:\\n•Command and control communications between the service control plane and training job instances\\n(not customer data).\\n•Communications between nodes in distributed training jobs (intra-network).\\nThere are no inter-node communications for batch processing.\\nYou can choose to encrypt internode training communications. Enabling inter-container traﬃc\\nencryption can increase training time, especially if you are using distributed deep learning algorithms.\\nFor aﬀected algorithms, adding this additional level of security also increases cost. The training time\\nfor most Amazon SageMaker built-in algorithms, such as XGBoost, DeepAR, and linear learner, typically\\naren\\'t aﬀected.\\nFIPS validated endpoints are available for the Amazon SageMaker API and request router for hosted\\nmodels (runtime). For information about FIPS compliant endpoints, see Federal Information Processing\\nStandard (FIPS) 140-2.\\nProtect Communications Between ML Compute Instances in a\\nDistributed Training Job\\nBy default, Amazon SageMaker runs training jobs in an Amazon Virtual Private Cloud (Amazon VPC) to\\nhelp keep your data secure. You can add another level of security to protect your training containers\\nand data by conﬁguring a private  VPC. Distributed ML frameworks and algorithms usually transmit\\ninformation that is directly related to the model such as weights, not the training dataset. When\\nperforming distributed training, you can further protect data that is transmitted between instances. This\\ncan help you to comply with regulatory requirements. To do this, use inter-container traﬃc encryption.\\nEnabling inter-container traﬃc encryption can increase training time, especially if you are using\\ndistributed deep learning algorithms. Enabling inter-container traﬃc encryption doesn\\'t aﬀect training\\njobs with a single compute instance. However, for training jobs with several compute instances, the\\neﬀect on training time depends on the amount of communication between compute instances. For\\naﬀected algorithms, adding this additional level of security also increases cost. The training time for\\nmost Amazon SageMaker built-in algorithms, such as XGBoost, DeepAR, and linear learner, typically\\naren\\'t aﬀected.\\nYou can enable inter-container traﬃc encryption for training jobs or hyperparameter tuning jobs. You\\ncan use Amazon SageMaker APIs or console to enable inter-container traﬃc encryption.\\n473Amazon SageMaker Developer Guide\\nProtecting Data in Transit with Encryption\\nFor information about running training jobs in a private VPC, see Give Amazon SageMaker Training Jobs\\nAccess to Resources in Your Amazon VPC (p. 522).\\nEnable Inter-Container Traﬃc Encryption (API)\\nBefore enabling inter-container traﬃc encryption on training or hyperparameter tuning jobs with APIs,\\nyou need to add inbound and outbound rules to your private VPC\\'s security group.\\nTo enable inter-container traﬃc encryption (API)\\n1. Add the following inbound and outbound rules in the security group for your private VPC:\\nProtocol Port Range Source\\nUDP 500 Self Security Group ID\\n50 N/A Self Security Group ID\\n2. When you send a request to the CreateTrainingJob (p. 667) or\\nCreateHyperParameterTuningJob (p. 638) API, specify True  for the\\nEnableInterContainerTrafficEncryption  parameter.\\nNote\\nThe AWS Security Group Console might show display ports range as \"All\", however EC2 ignores\\nthe speciﬁed port range because it is not applicable for the ESP 50 IP protocol.\\nEnable Inter-Container Traﬃc Encryption (Console)\\nEnable Inter-container Traﬃc Encryption in a Training Job\\nTo enable inter-container traﬃc encryption in a training job\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker\\n2. In the navigation pane, choose Training, then choose Training jobs.\\n3. Choose Create training job .\\n4. Under Network, choose a VPC. You can use the default VPC or one that you have created.\\n5. Choose Enable inter-container traﬃc encryption.\\nAfter you enable inter-container traﬃc encryption, ﬁnish creating the training job. For more information,\\nsee Step 5: Train a Model (p. 21).\\nEnable Inter-container Traﬃc Encryption in a Hyperparameter Tuning Job\\nTo enable inter-container traﬃc encryption in a hyperparameter tuning job\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker.\\n2. In the navigation pane, choose Training, then choose Hyperparameter tuning jobs .\\n3. Choose Create hyperparameter tuning job.\\n4. Under Network, choose a VPC. You can use the default VPC or one that you created.\\n5. Choose Enable inter-container traﬃc encryption.\\nAfter enabling inter-container traﬃc encryption, ﬁnish creating the hyperparameter tuning job. For more\\ninformation, see Conﬁgure and Launch a Hyperparameter Tuning Job (p. 296).\\n474Amazon SageMaker Developer Guide\\nKey Management\\nKey Management\\nCustomers can specify AWS KMS keys, including bring your own keys (BYOK), to use for envelope\\nencryption with Amazon S3 input/output buckets and machine learning (ML) Amazon EBS volumes. ML\\nvolumes for notebook instances and training and hosted model Docker containers can be optionally\\nencrypted by using AWS KMS customer-owned keys. All instance OS volumes are encrypted with an\\nAWS-managed AWS KMS key.\\nFor information about AWS KMS keys see What is AWS Key Management Service? in the AWS Key\\nManagement Service Developer Guide.\\nInternetwork Traﬃc Privacy\\nThis topic describes how Amazon SageMaker secures connections from the service to other locations.\\nInternetwork communications support TLS 1.2 encryption between all components and clients.\\nInstances can be connected to Customer VPC, providing access to S3 VPC endpoints or customer\\nrepositories. Internet egress can be managed through this interface by the customer if service platform\\ninternet egress is disabled for notebooks. For training and hosting, egress through the service platform is\\nnot available when connected to the customer\\'s VPC.\\nBy default, API calls made to published endpoints traverse the public network to the request router.\\nAmazon SageMaker supports Amazon Virtual Private Cloud interface endpoints powered by AWS\\nPrivateLink for private connectivity between the customer\\'s VPC and the request router to access hosted\\nmodel endpoints. For information about Amazon VPC, see Connect to Amazon SageMaker Through a\\nVPC Interface Endpoint (p. 517)\\nIdentity and Access Management for Amazon\\nSageMaker\\nAWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely\\ncontrol access to AWS resources. IAM administrators control who can be authenticated  (signed in) and\\nauthorized  (have permissions) to use Amazon SageMaker resources. IAM is an AWS service that you can\\nuse with no additional charge.\\nTopics\\n•Audience (p. 475)\\n•Authenticating With Identities  (p. 476)\\n•Managing Access Using Policies (p. 478)\\n•How Amazon SageMaker Works with IAM (p. 479)\\n•Amazon SageMaker Identity-Based Policy Examples (p. 481)\\n•Amazon SageMaker Roles  (p. 496)\\n•AWS Managed (Predeﬁned) Policies for Amazon SageMaker (p. 507)\\n•Amazon SageMaker API Permissions: Actions, Permissions, and Resources Reference (p. 508)\\n•Troubleshooting Amazon SageMaker Identity and Access (p. 512)\\nAudience\\nHow you use AWS Identity and Access Management (IAM) diﬀers, depending on the work you do in\\nAmazon SageMaker.\\n475Amazon SageMaker Developer Guide\\nAuthenticating With Identities\\nService user – If you use the Amazon SageMaker service to do your job, then your administrator provides\\nyou with the credentials and permissions that you need. As you use more Amazon SageMaker features\\nto do your work, you might need additional permissions. Understanding how access is managed can help\\nyou request the right permissions from your administrator. If you cannot access a feature in Amazon\\nSageMaker, see Troubleshooting Amazon SageMaker Identity and Access (p. 512).\\nService administrator – If you\\'re in charge of Amazon SageMaker resources at your company, you\\nprobably have full access to Amazon SageMaker. It\\'s your job to determine which Amazon SageMaker\\nfeatures and resources your employees should access. You must then submit requests to your IAM\\nadministrator to change the permissions of your service users. Review the information on this page to\\nunderstand the basic concepts of IAM. To learn more about how your company can use IAM with Amazon\\nSageMaker, see How Amazon SageMaker Works with IAM (p. 479).\\nIAM administrator  – If you\\'re an IAM administrator, you might want to learn details about how you can\\nwrite policies to manage access to Amazon SageMaker. To view example Amazon SageMaker identity-\\nbased policies that you can use in IAM, see Amazon SageMaker Identity-Based Policy Examples (p. 481).\\nAuthenticating With Identities\\nAuthentication is how you sign in to AWS using your identity credentials. For more information about\\nsigning in using the AWS Management Console, see The IAM Console and Sign-in Page in the IAM User\\nGuide .\\nYou must be authenticated  (signed in to AWS) as the AWS account root user, an IAM user, or by assuming\\nan IAM role. You can also use your company\\'s single sign-on authentication, or even sign in using Google\\nor Facebook. In these cases, your administrator previously set up identity federation using IAM roles.\\nWhen you access AWS using credentials from another company, you are assuming a role indirectly.\\nTo sign in directly to the AWS Management Console, use your password with your root user email or your\\nIAM user name. You can access AWS programmatically using your root user or IAM user access keys. AWS\\nprovides SDK and command line tools to cryptographically sign your request using your credentials. If\\nyou don’t use AWS tools, you must sign the request yourself. Do this using Signature Version 4, a protocol\\nfor authenticating inbound API requests. For more information about authenticating requests, see\\nSignature Version 4 Signing Process in the AWS General Reference.\\nRegardless of the authentication method that you use, you might also be required to provide additional\\nsecurity information. For example, AWS recommends that you use multi-factor authentication (MFA) to\\nincrease the security of your account. To learn more, see Using Multi-Factor Authentication (MFA) in AWS\\nin the IAM User Guide .\\nAWS Account Root User\\nWhen you ﬁrst create an AWS account, you begin with a single sign-in identity that has complete access\\nto all AWS services and resources in the account. This identity is called the AWS account root user  and\\nis accessed by signing in with the email address and password that you used to create the account. We\\nstrongly recommend that you do not use the root user for your everyday tasks, even the administrative\\nones. Instead, adhere to the best practice of using the root user only to create your ﬁrst IAM user. Then\\nsecurely lock away the root user credentials and use them to perform only a few account and service\\nmanagement tasks.\\nIAM Users and Groups\\nAn IAM user  is an identity within your AWS account that has speciﬁc permissions for a single person or\\napplication. An IAM user can have long-term credentials such as a user name and password or a set of\\naccess keys. To learn how to generate access keys, see Managing Access Keys for IAM Users in the IAM\\nUser Guide . When you generate access keys for an IAM user, make sure you view and securely save the key\\n476Amazon SageMaker Developer Guide\\nAuthenticating With Identities\\npair. You cannot recover the secret access key in the future. Instead, you must generate a new access key\\npair.\\nAn IAM group  is an identity that speciﬁes a collection of IAM users. You can\\'t sign in as a group. You\\ncan use groups to specify permissions for multiple users at a time. Groups make permissions easier to\\nmanage for large sets of users. For example, you could have a group named IAMAdmins  and give that\\ngroup permissions to administer IAM resources.\\nUsers are diﬀerent from roles. A user is uniquely associated with one person or application, but a role\\nis intended to be assumable by anyone who needs it. Users have permanent long-term credentials, but\\nroles provide temporary credentials. To learn more, see When to Create an IAM User (Instead of a Role) in\\nthe IAM User Guide .\\nIAM Roles\\nAn IAM role  is an identity within your AWS account that has speciﬁc permissions. It is similar to an IAM\\nuser, but is not associated with a speciﬁc person. You can temporarily assume an IAM role in the AWS\\nManagement Console by switching roles. You can assume a role by calling an AWS CLI or AWS API\\noperation or by using a custom URL. For more information about methods for using roles, see Using IAM\\nRoles in the IAM User Guide .\\nIAM roles with temporary credentials are useful in the following situations:\\n•Temporary IAM user permissions – An IAM user can assume an IAM role to temporarily take on\\ndiﬀerent permissions for a speciﬁc task.\\n•Federated user access – Instead of creating an IAM user, you can use existing identities from AWS\\nDirectory Service, your enterprise user directory, or a web identity provider. These are known as\\nfederated users . AWS assigns a role to a federated user when access is requested through an identity\\nprovider. For more information about federated users, see Federated Users and Roles in the IAM User\\nGuide .\\n•Cross-account access – You can use an IAM role to allow someone (a trusted principal) in a diﬀerent\\naccount to access resources in your account. Roles are the primary way to grant cross-account access.\\nHowever, with some AWS services, you can attach a policy directly to a resource (instead of using a role\\nas a proxy). To learn the diﬀerence between roles and resource-based policies for cross-account access,\\nsee How IAM Roles Diﬀer from Resource-based Policies in the IAM User Guide .\\n•AWS service access – A service role is an IAM role that a service assumes to perform actions in your\\naccount on your behalf. When you set up some AWS service environments, you must deﬁne a role\\nfor the service to assume. This service role must include all the permissions that are required for the\\nservice to access the AWS resources that it needs. Service roles vary from service to service, but many\\nallow you to choose your permissions as long as you meet the documented requirements for that\\nservice. Service roles provide access only within your account and cannot be used to grant access\\nto services in other accounts. You can create, modify, and delete a service role from within IAM. For\\nexample, you can create a role that allows Amazon Redshift to access an Amazon S3 bucket on your\\nbehalf and then load data from that bucket into an Amazon Redshift cluster. For more information, see\\nCreating a Role to Delegate Permissions to an AWS Service in the IAM User Guide .\\n•Applications running on Amazon EC2 – You can use an IAM role to manage temporary credentials\\nfor applications that are running on an EC2 instance and making AWS CLI or AWS API requests.\\nThis is preferable to storing access keys within the EC2 instance. To assign an AWS role to an EC2\\ninstance and make it available to all of its applications, you create an instance proﬁle that is attached\\nto the instance. An instance proﬁle contains the role and enables programs that are running on the\\nEC2 instance to get temporary credentials. For more information, see Using an IAM Role to Grant\\nPermissions to Applications Running on Amazon EC2 Instances in the IAM User Guide .\\nTo learn whether to use IAM roles, see When to Create an IAM Role (Instead of a User) in the IAM User\\nGuide .\\n477Amazon SageMaker Developer Guide\\nManaging Access Using Policies\\nManaging Access Using Policies\\nYou control access in AWS by creating policies and attaching them to IAM identities or AWS resources. A\\npolicy is an object in AWS that, when associated with an identity or resource, deﬁnes their permissions.\\nAWS evaluates these policies when an entity (root user, IAM user, or IAM role) makes a request.\\nPermissions in the policies determine whether the request is allowed or denied. Most policies are stored\\nin AWS as JSON documents. For more information about the structure and contents of JSON policy\\ndocuments, see Overview of JSON Policies in the IAM User Guide .\\nAn IAM administrator can use policies to specify who has access to AWS resources, and what actions\\nthey can perform on those resources. Every IAM entity (user or role) starts with no permissions. In other\\nwords, by default, users can do nothing, not even change their own password. To give a user permission\\nto do something, an administrator must attach a permissions policy to a user. Or the administrator can\\nadd the user to a group that has the intended permissions. When an administrator gives permissions to a\\ngroup, all users in that group are granted those permissions.\\nIAM policies deﬁne permissions for an action regardless of the method that you use to perform the\\noperation. For example, suppose that you have a policy that allows the iam:GetRole  action. A user with\\nthat policy can get role information from the AWS Management Console, the AWS CLI, or the AWS API.\\nIdentity-Based Policies\\nIdentity-based policies are JSON permissions policy documents that you can attach to an identity, such\\nas an IAM user, role, or group. These policies control what actions that identity can perform, on which\\nresources, and under what conditions. To learn how to create an identity-based policy, see Creating IAM\\nPolicies in the IAM User Guide .\\nIdentity-based policies can be further categorized as inline policies  or managed policies . Inline policies\\nare embedded directly into a single user, group, or role. Managed policies are standalone policies that\\nyou can attach to multiple users, groups, and roles in your AWS account. Managed policies include AWS\\nmanaged policies and customer managed policies. To learn how to choose between a managed policy or\\nan inline policy, see Choosing Between Managed Policies and Inline Policies in the IAM User Guide .\\nResource-Based Policies\\nResource-based policies are JSON policy documents that you attach to a resource such as an Amazon S3\\nbucket. Service administrators can use these policies to deﬁne what actions a speciﬁed principal (account\\nmember, user, or role) can perform on that resource and under what conditions. Resource-based policies\\nare inline policies. There are no managed resource-based policies.\\nAccess Control Lists (ACLs)\\nAccess control policies (ACLs) control which principals (account members, users, or roles) have\\npermissions to access a resource. ACLs are similar to resource-based policies, although they are the only\\npolicy type that does not use the JSON policy document format. Amazon S3, AWS WAF, and Amazon\\nVPC are examples of services that support ACLs. To learn more about ACLs, see Access Control List (ACL)\\nOverview in the Amazon Simple Storage Service Developer Guide.\\nOther Policy Types\\nAWS supports additional, less-common policy types. These policy types can set the maximum\\npermissions granted to you by the more common policy types.\\n•Permissions boundaries – A permissions boundary is an advanced feature in which you set the\\nmaximum permissions that an identity-based policy can grant to an IAM entity (IAM user or role).\\nYou can set a permissions boundary for an entity. The resulting permissions are the intersection of\\nentity\\'s identity-based policies and its permissions boundaries. Resource-based policies that specify\\n478Amazon SageMaker Developer Guide\\nHow Amazon SageMaker Works with IAM\\nthe user or role in the Principal  ﬁeld are not limited by the permissions boundary. An explicit deny\\nin any of these policies overrides the allow. For more information about permissions boundaries, see\\nPermissions Boundaries for IAM Entities in the IAM User Guide .\\n•Service control policies (SCPs) – SCPs are JSON policies that specify the maximum permissions for\\nan organization or organizational unit (OU) in AWS Organizations. AWS Organizations is a service for\\ngrouping and centrally managing multiple AWS accounts that your business owns. If you enable all\\nfeatures in an organization, then you can apply service control policies (SCPs) to any or all of your\\naccounts. The SCP limits permissions for entities in member accounts, including each AWS account\\nroot user. For more information about Organizations and SCPs, see How SCPs Work in the AWS\\nOrganizations User Guide .\\n•Session policies  – Session policies are advanced policies that you pass as a parameter when you\\nprogrammatically create a temporary session for a role or federated user. The resulting session\\'s\\npermissions are the intersection of the user or role\\'s identity-based policies and the session policies.\\nPermissions can also come from a resource-based policy. An explicit deny in any of these policies\\noverrides the allow. For more information, see Session Policies in the IAM User Guide .\\nMultiple Policy Types\\nWhen multiple types of policies apply to a request, the resulting permissions are more complicated to\\nunderstand. To learn how AWS determines whether to allow a request when multiple policy types are\\ninvolved, see Policy Evaluation Logic in the IAM User Guide .\\nHow Amazon SageMaker Works with IAM\\nBefore you use IAM to manage access to Amazon SageMaker, you should understand what IAM features\\nare available to use with Amazon SageMaker. To get a high-level view of how Amazon SageMaker and\\nother AWS services work with IAM, see AWS Services That Work with IAM in the IAM User Guide .\\nTopics\\n•Amazon SageMaker Identity-Based Policies (p. 479)\\nAmazon SageMaker Identity-Based Policies\\nWith IAM identity-based policies, you can specify allowed or denied actions and resources as well as the\\nconditions under which actions are allowed or denied. Amazon SageMaker supports speciﬁc actions,\\nresources, and condition keys. To learn about all of the elements that you use in a JSON policy, see IAM\\nJSON Policy Elements Reference in the IAM User Guide .\\nActions\\nThe Action element of an IAM identity-based policy describes the speciﬁc action or actions that will be\\nallowed or denied by the policy. Policy actions usually have the same name as the associated AWS API\\noperation. The action is used in a policy to grant permissions to perform the associated operation.\\nPolicy actions in Amazon SageMaker use the following preﬁx before the action: sagemaker: . For\\nexample, to grant someone permission to run an Amazon SageMaker training job with the Amazon\\nSageMaker CreateTrainingJob  API operation, you include the sagemaker:CreateTrainingJob\\naction in their policy. Policy statements must include either an Action  or NotAction  element. Amazon\\nSageMaker deﬁnes its own set of actions that describe tasks that you can perform with this service.\\nTo specify multiple actions in a single statement, separate them with commas as follows:\\n\"Action\": [\\n      \"sagemaker: action1\",\\n479Amazon SageMaker Developer Guide\\nHow Amazon SageMaker Works with IAM\\n      \"sagemaker: action2\"\\nYou can specify multiple actions using wildcards (*). For example, to specify all actions that begin with\\nthe word Describe , include the following action:\\n\"Action\": \"sagemaker:Describe*\"\\nTo see a list of Amazon SageMaker actions, see Actions Deﬁned by Amazon SageMaker in the IAM User\\nGuide .\\nResources\\nAmazon SageMaker does not support specifying resource ARNs in a policy.\\nCondition Keys\\nThe Condition  element (or Condition  block ) lets you specify conditions in which a statement is in\\neﬀect. The Condition  element is optional. You can build conditional expressions that use condition\\noperators , such as equals or less than, to match the condition in the policy with values in the request.\\nIf you specify multiple Condition  elements in a statement, or multiple keys in a single Condition\\nelement, AWS evaluates them using a logical AND operation. If you specify multiple values for a single\\ncondition key, AWS evaluates the condition using a logical OR operation. All of the conditions must be\\nmet before the statement\\'s permissions are granted.\\nYou can also use placeholder variables when you specify conditions. For example, you can grant an IAM\\nuser permission to access a resource only if it is tagged with their IAM user name. For more information,\\nsee IAM Policy Elements: Variables and Tags in the IAM User Guide .\\nAmazon SageMaker deﬁnes its own set of condition keys and also supports using some global condition\\nkeys. To see all AWS global condition keys, see AWS Global Condition Context Keys in the IAM User Guide .\\nAmazon SageMaker supports a number of service-speciﬁc condition keys that you can use for ﬁne-\\ngrained access control for the following operations:\\n•the section called “CreateTrainingJob” (p. 667)\\n•the section called “CreateModel” (p. 648)\\n•the section called “CreateEndpointConﬁg” (p. 635)\\n•the section called “CreateTransformJob” (p. 673)\\n•the section called “CreateHyperParameterTuningJob” (p. 638)\\n•the section called “CreateNotebookInstance” (p. 656)\\n•the section called “UpdateNotebookInstance” (p. 844)\\nTo see a list of Amazon SageMaker condition keys, see Condition Keys for Amazon SageMaker in the IAM\\nUser Guide . To learn with which actions and resources you can use a condition key, see Actions Deﬁned by\\nAmazon SageMaker.\\nFor examples of using Amazon SageMaker condition keys, see the following:\\nExamples\\nTo view examples of Amazon SageMaker identity-based policies, see Amazon SageMaker Identity-Based\\nPolicy Examples (p. 481).\\n480Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\nAmazon SageMaker Resource-Based Policies\\nAmazon SageMaker does not support resource-based policies.\\nAuthorization Based on Amazon SageMaker Tags\\nYou can attach tags to Amazon SageMaker resources or pass tags in a request to Amazon SageMaker.\\nTo control access based on tags, you provide tag information in the condition element of a policy using\\nthe sagemaker:ResourceTag/ key-name , aws:RequestTag/ key-name , or aws:TagKeys  condition\\nkeys. For more information about tagging Amazon SageMaker resources, see Control Access to Amazon\\nSageMaker Resources by Using Tags (p. 493).\\nTo view an example identity-based policy for limiting access to a resource based on the tags on that\\nresource, see Control Access to Amazon SageMaker Resources by Using Tags (p. 493).\\nAmazon SageMaker IAM Roles\\nAn IAM role is an entity within your AWS account that has speciﬁc permissions.\\nUsing Temporary Credentials with Amazon SageMaker\\nYou can use temporary credentials to sign in with federation, assume an IAM role, or to assume a cross-\\naccount role. You obtain temporary security credentials by calling AWS STS API operations such as\\nAssumeRole or GetFederationToken.\\nAmazon SageMaker supports using temporary credentials.\\nService-Linked Roles\\nAmazon SageMaker doesn\\'t support service-linked roles.\\nService Roles\\nThis feature allows a service to assume a service role on your behalf. This role allows the service to\\naccess resources in other services to complete an action on your behalf. Service roles appear in your\\nIAM account and are owned by the account. This means that an IAM administrator can change the\\npermissions for this role. However, doing so might break the functionality of the service.\\nAmazon SageMaker supports service roles.\\nChoosing an IAM Role in Amazon SageMaker\\nWhen you create a notebook instance, training job, hosted endpoint, or batch transform job resource in\\nAmazon SageMaker, you must choose a role to allow Amazon SageMaker to access Amazon SageMaker\\non your behalf. If you have previously created a service role or service-linked role, then Amazon\\nSageMaker provides you with a list of roles to choose from. It\\'s important to choose a role that allows\\naccess to the AWS operations and resources you need. For more information, see Amazon SageMaker\\nRoles  (p. 496).\\nAmazon SageMaker Identity-Based Policy Examples\\nBy default, IAM users and roles don\\'t have permission to create or modify Amazon SageMaker resources.\\nThey also can\\'t perform tasks using the AWS Management Console, AWS CLI, or AWS API. An IAM\\nadministrator must create IAM policies that grant users and roles permission to perform speciﬁc API\\noperations on the speciﬁed resources they need. The administrator must then attach those policies to\\nthe IAM users or groups that require those permissions.\\nTo learn how to create an IAM identity-based policy using these example JSON policy documents, see\\nCreating Policies on the JSON Tab in the IAM User Guide .\\n481Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\nTopics\\n•Policy Best Practices (p. 482)\\n•Using the Amazon SageMaker Console (p. 482)\\n•Allow Users to View Their Own Permissions (p. 485)\\n•Control Creation of Amazon SageMaker Resources with Condition Keys (p. 486)\\n•Control Access to the Amazon SageMaker API by Using Identity-based Policies (p. 491)\\n•Limit Access to Amazon SageMaker API and Runtime Calls by IP Address (p. 492)\\n•Limit Access to a Notebook Instance by IP Address (p. 492)\\n•Control Access to Amazon SageMaker Resources by Using Tags (p. 493)\\nPolicy Best Practices\\nIdentity-based policies are very powerful. They determine whether someone can create, access, or delete\\nAmazon SageMaker resources in your account. These actions can incur costs for your AWS account. When\\nyou create or edit identity-based policies, follow these guidelines and recommendations:\\n•Get Started Using AWS Managed Policies – To start using Amazon SageMaker quickly, use AWS\\nmanaged policies to give your employees the permissions they need. These policies are already\\navailable in your account and are maintained and updated by AWS. For more information, see Get\\nStarted Using Permissions With AWS Managed Policies in the IAM User Guide .\\n•Grant Least Privilege – When you create custom policies, grant only the permissions required\\nto perform a task. Start with a minimum set of permissions and grant additional permissions as\\nnecessary. Doing so is more secure than starting with permissions that are too lenient and then trying\\nto tighten them later. For more information, see Grant Least Privilege  in the IAM User Guide .\\n•Enable MFA for Sensitive Operations – For extra security, require IAM users to use multi-factor\\nauthentication (MFA) to access sensitive resources or API operations. For more information, see Using\\nMulti-Factor Authentication (MFA) in AWS in the IAM User Guide .\\n•Use Policy Conditions for Extra Security – To the extent that it\\'s practical, deﬁne the conditions under\\nwhich your identity-based policies allow access to a resource. For example, you can write conditions to\\nspecify a range of allowable IP addresses that a request must come from. You can also write conditions\\nto allow requests only within a speciﬁed date or time range, or to require the use of SSL or MFA. For\\nmore information, see IAM JSON Policy Elements: Condition in the IAM User Guide .\\nUsing the Amazon SageMaker Console\\nTo access the Amazon SageMaker console, you must have a minimum set of permissions. These\\npermissions must allow you to list and view details about the Amazon SageMaker resources in your\\nAWS account. If you create an identity-based policy that is more restrictive than the minimum required\\npermissions, the console won\\'t function as intended for entities (IAM users or roles) with that policy.\\nTo ensure that those entities can still use the Amazon SageMaker console, also attach the following AWS\\nmanaged policy to the entities. For more information, see Adding Permissions to a User in the IAM User\\nGuide :\\nYou don\\'t need to allow minimum console permissions for users that are making calls only to the AWS\\nCLI or the AWS API. Instead, allow access to only the actions that match the API operation that you\\'re\\ntrying to perform.\\nTopics\\n•Permissions Required to Use the Amazon SageMaker Console (p. 483)\\n•Permissions Required to Use the Amazon SageMaker Ground Truth Console (p. 484)\\n482Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\nPermissions Required to Use the Amazon SageMaker Console\\nThe permissions reference table lists the Amazon SageMaker API operations and shows the required\\npermissions for each operation. For more information about Amazon SageMaker API operations, see\\nAmazon SageMaker API Permissions: Actions, Permissions, and Resources Reference (p. 508).\\nTo use the Amazon SageMaker console, you need to grant permissions for additional actions. Speciﬁcally,\\nthe console needs permissions that allow the ec2 actions to display subnets, VPCs, and security groups.\\nOptionally, the console needs permission to create execution roles for tasks such as CreateNotebook ,\\nCreateTrainingJob , and CreateModel . Grant these permissions with the following permissions\\npolicy:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n          \"Sid\": \"SageMakerApis\",\\n          \"Effect\": \"Allow\",\\n          \"Action\": [\\n            \"sagemaker:*\"\\n          ],\\n          \"Resource\": \"*\"\\n        },\\n        {\\n          \"Sid\": \"VpcConfigurationForCreateForms\",\\n          \"Effect\": \"Allow\",\\n          \"Action\": [\\n            \"ec2:DescribeVpcs\",\\n            \"ec2:DescribeSubnets\",\\n            \"ec2:DescribeSecurityGroups\"\\n          ],\\n          \"Resource\": \"*\"\\n        },\\n        {\\n            \"Sid\":\"KmsKeysForCreateForms\",\\n            \"Effect\":\"Allow\",\\n            \"Action\":[\\n              \"kms:DescribeKey\",\\n              \"kms:ListAliases\"\\n            ],\\n            \"Resource\":\"*\"\\n        },\\n        {\\n          \"Sid\": \"AccessAwsMarketplaceSubscritions\",\\n          \"Effect\": \"Allow\",\\n          \"Action\": [\\n            \"aws-marketplace:ViewSubscriptions\"\\n          ],\\n          \"Resource\": \"*\"\\n        },\\n        {\\n          \"Effect\": \"Allow\",\\n          \"Action\": [\\n            \"codecommit:BatchGetRepositories\",\\n            \"codecommit:CreateRepository\",\\n            \"codecommit:GetRepository\",\\n            \"codecommit:ListRepositories\",\\n            \"codecommit:ListBranches\",\\n            \"secretsmanager:CreateSecret\",\\n            \"secretsmanager:DescribeSecret\",\\n            \"secretsmanager:ListSecrets\"\\n          ],\\n          \"Resource\": \"*\"\\n        },\\n483Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n        {\\n          \"Sid\":\"ListAndCreateExecutionRoles\",\\n          \"Effect\":\"Allow\",\\n          \"Action\":[\\n            \"iam:ListRoles\",\\n            \"iam:CreateRole\",\\n            \"iam:CreateRole\",\\n            \"iam:CreatePolicy\",\\n            \"iam:AttachRolePolicy\"\\n          ],\\n          \"Resource\":\"*\"\\n        },\\n        {\\n          \"Sid\": \"DescribeECRMetaData\",\\n          \"Effect\": \"Allow\",\\n          \"Action\": [\\n              \"ecr:Describe*\"\\n          ],\\n          \"Resource\": \"*\"\\n        },\\n        {\\n          \"Sid\": \"PassRoleForExecutionRoles\",\\n          \"Effect\": \"Allow\",\\n          \"Action\": [\\n            \"iam:PassRole\"\\n          ],\\n          \"Resource\": \"*\",\\n          \"Condition\": {\\n            \"StringEquals\": {\\n                \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\\n            }\\n          }\\n        }\\n    ]\\n}\\nPermissions Required to Use the Amazon SageMaker Ground Truth Console\\nTo use the Amazon SageMaker Ground Truth console, you need to grant permissions for additional\\nresources. Speciﬁcally, the console needs permissions for the AWS Marketplace to view subscriptions,\\nAmazon Cognito operations to manage your private workforce, Amazon S3 actions for access to your\\ninput and output ﬁles, and AWS Lambda actions to list and invoke functions. Grant these permissions\\nwith the following permissions policy:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"GroundTruthConsole\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"aws-marketplace:DescribeListings\",\\n                \"aws-marketplace:ViewSubscriptions\",\\n                \\n                \"cognito-idp:AdminAddUserToGroup\",\\n                \"cognito-idp:AdminCreateUser\",\\n                \"cognito-idp:AdminDeleteUser\",\\n                \"cognito-idp:AdminDisableUser\",\\n                \"cognito-idp:AdminEnableUser\",\\n                \"cognito-idp:AdminRemoveUserFromGroup\",\\n                \"cognito-idp:CreateGroup\",\\n                \"cognito-idp:CreateUserPool\",\\n                \"cognito-idp:CreateUserPoolClient\",\\n                \"cognito-idp:CreateUserPoolDomain\",\\n484Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n                \"cognito-idp:DescribeUserPool\",\\n                \"cognito-idp:DescribeUserPoolClient\",\\n                \"cognito-idp:ListGroups\",\\n                \"cognito-idp:ListIdentityProviders\",\\n                \"cognito-idp:ListUsers\",\\n                \"cognito-idp:ListUsersInGroup\",\\n                \"cognito-idp:ListUserPoolClients\",\\n                \"cognito-idp:ListUserPools\",\\n                \"cognito-idp:UpdateUserPool\",\\n                \"cognito-idp:UpdateUserPoolClient\",\\n                \\n                \"groundtruthlabeling:DescribeConsoleJob\",\\n                \"groundtruthlabeling:ListDatasetObjects\",\\n                \"groundtruthlabeling:RunFilterOrSampleManifestJob\",\\n                \"groundtruthlabeling:RunGenerateManifestByCrawlingJob\",\\n                \\n                \"lambda:InvokeFunction\",\\n                \"lambda:ListFunctions\",\\n                \\n                \"s3:GetObject\",\\n                \"s3:PutObject\",\\n                \"s3:SelectObjectContent\"\\n            ],\\n            \"Resource\": \"*\"\\n        }\\n    ]\\n}\\nAllow Users to View Their Own Permissions\\nThis example shows how you might create a policy that allows IAM users to view the inline and managed\\npolicies that are attached to their user identity. This policy includes permissions to complete this action\\non the console or programmatically using the AWS CLI or AWS API.\\n{\\n       \"Version\": \"2012-10-17\",\\n       \"Statement\": [\\n           {\\n               \"Sid\": \"ViewOwnUserInfo\",\\n               \"Effect\": \"Allow\",\\n               \"Action\": [\\n                   \"iam:GetUserPolicy\",\\n                   \"iam:ListGroupsForUser\",\\n                   \"iam:ListAttachedUserPolicies\",\\n                   \"iam:ListUserPolicies\",\\n                   \"iam:GetUser\"\\n               ],\\n               \"Resource\": [\\n                   \"arn:aws:iam::*:user/${aws:username}\"\\n               ]\\n           },\\n           {\\n               \"Sid\": \"NavigateInConsole\",\\n               \"Effect\": \"Allow\",\\n               \"Action\": [\\n                   \"iam:GetGroupPolicy\",\\n                   \"iam:GetPolicyVersion\",\\n                   \"iam:GetPolicy\",\\n                   \"iam:ListAttachedGroupPolicies\",\\n                   \"iam:ListGroupPolicies\",\\n                   \"iam:ListPolicyVersions\",\\n                   \"iam:ListPolicies\",\\n                   \"iam:ListUsers\"\\n               ],\\n485Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n               \"Resource\": \"*\"\\n           }\\n       ]\\n   }\\nControl Creation of Amazon SageMaker Resources with\\nCondition Keys\\nControl ﬁne-grained access to creation of Amazon SageMaker resources by using Amazon SageMaker-\\nspeciﬁc condition keys. For information about using condition keys in IAM policies, see IAM JSON Policy\\nElements: Condition  in the IAM User Guide .\\nThe following examples show how to use Amazon SageMaker condition keys to control access.\\nTopics\\n•Control Access to Amazon SageMaker Resources by Using File System Condition Keys (p. 486)\\n•Restrict Training to a Speciﬁc VPC (p. 488)\\n•Enforcing Encryption of Input Data (p. 488)\\n•Enforcing Encryption of Notebook Instance Storage Volume (p. 489)\\n•Enforcing Network Isolation for Training Jobs (p. 489)\\n•Enforcing a Speciﬁc Instance Type for Training Jobs (p. 490)\\n•Enforce Disabling Internet Access and Root Access for Creating Notebook Instances (p. 490)\\nControl Access to Amazon SageMaker Resources by Using File System Condition\\nKeys\\nAmazon SageMaker training provides a secure infrastructure for the training algorithm to run in, but for\\nsome cases you may want increased defense in depth. For example, you minimize the risk of running\\nuntrusted code in your algorithm, or you have speciﬁc security mandates in your organization. For these\\nscenarios, you can use the following service-speciﬁc condition keys in the Condition element of an IAM\\npolicy to scope down the user to speciﬁc ﬁle systems, directories, access modes (read-write, read-only)\\nand security groups:\\nTopics\\n•Restrict an IAM User to Speciﬁc Directories and Access Modes (p. 486)\\n•Restrict an IAM User to Speciﬁc File System (p. 487)\\nRestrict an IAM User to Speciﬁc Directories and Access Modes\\nThe policy below restricts an IAM user to the /sagemaker/xgboost-dm/train  and /sagemaker/\\nxgboost-dm/validation  directories of an EFS ﬁle system to ro (read-only) AccessMode:\\nNote\\nWhen a directory is allowed, all of its subdirectories are also accessible by the training\\nalgorithm. POSIX permissions are ignored.\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"AccessToElasticFileSystem\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateTrainingJob\",\\n486Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n                \"sagemaker:CreateHyperParameterTuningJob\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"sagemaker:FileSystemId\": \"fs-12345678\",\\n                    \"sagemaker:FileSystemAccessMode\": \"ro\",\\n                    \"sagemaker:FileSystemType\": \"EFS\",\\n                    \"sagemaker:FileSystemDirectoryPath\": \"/sagemaker/xgboost-dm/train\"\\n                }\\n            }\\n        },\\n        {\\n            \"Sid\": \"AccessToElasticFileSystemValidation\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateTrainingJob\",\\n                \"sagemaker:CreateHyperParameterTuningJob\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"sagemaker:FileSystemId\": \"fs-12345678\",\\n                    \"sagemaker:FileSystemAccessMode\": \"ro\",\\n                    \"sagemaker:FileSystemType\": \"EFS\",\\n                    \"sagemaker:FileSystemDirectoryPath\": \"/sagemaker/xgboost-dm/validation\"\\n                }\\n            }\\n        }\\n     ]\\n}\\nRestrict an IAM User to Speciﬁc File System\\nTo prevent a malicious algorithm using a user space client from accessing any ﬁle system directly in your\\naccount, you can restrict networking traﬃc by allowing ingress from a speciﬁc security group. In the\\nfollowing example, the IAM user can only use the speciﬁed security group to access the ﬁle system:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"AccessToLustreFileSystem\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateTrainingJob\",\\n                \"sagemaker:CreateHyperParameterTuningJob\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"sagemaker:FileSystemId\": \"fs-12345678\",\\n                    \"sagemaker:FileSystemAccessMode\": \"ro\",\\n                    \"sagemaker:FileSystemType\": \"FSxLustre\",\\n                    \"sagemaker:FileSystemDirectoryPath\": \"/fsx/sagemaker/xgboost/train\"\\n                },\\n                \"ForAllValues:StringEquals\": {\\n                    \"sagemaker:VpcSecurityGroupIds\": [\\n                        \"sg-12345678\"\\n                    ]\\n                }\\n            }\\n        }\\n    ]\\n487Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n}\\nAlthough the above example can restrict an algorithm to a speciﬁc ﬁle system, it does not prevent an\\nalgorithm from accessing any directory within that ﬁle system using the user space client. To mitigate\\nthis, you can:\\n•Ensure that the ﬁle system only contains data that you trust your IAM users to access\\n•Create an IAM role that restricts your IAM users to launching training jobs with algorithms from\\napproved ECR repositories\\nFor more information on how to use roles with Amazon SageMaker, see Amazon SageMaker Roles.\\nRestrict Training to a Speciﬁc VPC\\nRestrict an AWS user to creating training jobs from within a Amazon VPC. When a training job is created\\nwithin a VPC, you can use VPC ﬂow logs to monitor all traﬃc to and from the training cluster. For\\ninformation about using VPC ﬂow logs, see VPC Flow Logs in the Amazon Virtual Private Cloud User\\nGuide .\\nThe following policy enforces that a training job is created by an IAM user calling the section called\\n“CreateTrainingJob” (p. 667) from within a VPC:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"AllowFromVpc\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateTrainingJob\",\\n                \"sagemaker:CreateHyperParameterTuningJob\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"sagemaker:VpcSubnets\": [\"10.24.34.0/23\"],\\n                    \"sagemaker:VpcSecurityGroupIds\": [\"vpc-12345678\"]\\n                }\\n            }\\n        }\\n        \\n     ]\\n}\\nEnforcing Encryption of Input Data\\nThe following policy restricts an IAM user to specify a AWS KMS key to encrypt input data when creating\\ntraining and hyperparameter tuning jobs by using the sagemaker:VolumeKmsKey  condition key:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"EnforceEncryption\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateTrainingJob\",\\n                \"sagemaker:CreateHyperParameterTuningJob\"\\n            ],\\n            \"Resource\": \"*\",\\n488Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n            \"Condition\": {\\n                \"Null\": {\\n                    \"sagemaker:VolumeKmsKey\": \"false\"\\n                }\\n            }\\n        }\\n        \\n     ]\\n}\\nEnforcing Encryption of Notebook Instance Storage Volume\\nThe following policy restricts an IAM user to specify a AWS KMS key to encrypt the attached storage\\nvolume when creating or updating a notebook instance by using the sagemaker:VolumeKmsKey\\ncondition key:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"EnforceEncryption\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateNotebookInstance\",\\n                \"sagemaker:UpdateNotebookInstance\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"Null\": {\\n                    \"sagemaker:VolumeKmsKey\": \"false\"\\n                }\\n            }\\n        }\\n        \\n     ]\\n}\\nEnforcing Network Isolation for Training Jobs\\nThe following policy restricts an IAM user to enable network isolation when creating training jobs by\\nusing the sagemaker:NetworkIsolation  condition key:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"EnforceIsolation\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateTrainingJob\",\\n                \"sagemaker:CreateHyperParameterTuningJob\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"sagemaker:NetworkIsolation\": \"True\"\\n                }\\n            }\\n        }\\n        \\n     ]\\n}\\n489Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\nEnforcing a Speciﬁc Instance Type for Training Jobs\\nThe following policy restricts an IAM user to use a speciﬁc instance type when creating training jobs by\\nusing the sagemaker:InstanceTypes  condition key:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"EnforceInstanceType\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateTrainingJob\",\\n                \"sagemaker:CreateHyperParameterTuningJob\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringLike\": {\\n                    \"sagemaker:InstanceTypes\": [\"ml.c5dn.*\"]\\n                }\\n            }\\n        }\\n        \\n     ]\\n}\\nEnforce Disabling Internet Access and Root Access for Creating Notebook\\nInstances\\nYou can disable both internet access and root access to notebook instances to help make them more\\nsecure. For information about controling root access to a notebook instance, see Control Root Access to\\na Notebook Instance (p. 40). for information about disabling internet access for a notebook instance, see\\nConnect a Notebook Instance to Resources in a VPC (p. 516).\\nThe following policy requires an IAM user to disable network access and root access when creating or\\nupdating a notebook instance:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"LockdownNotebook\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreateNotebookInstance\",\\n                \"sagemaker:UpdateNotebookInstance\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"sagemaker:RootAccess\": \"False\",\\n                    \"sagemaker:DirectInternetAccess\": \"False\"\\n                }\\n                \"Null\": {\\n                  \"sagemaker:VpcSubnets\": \"false\",\\n                  \"sagemaker:VpcSecurityGroupIds\": \"false\"\\n            }\\n        }\\n        \\n     ]\\n}\\n490Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\nControl Access to the Amazon SageMaker API by Using Identity-\\nbased Policies\\nTo control access to Amazon SageMaker API calls and calls to Amazon SageMaker hosted endpoints, use\\nidentity-based IAM policies.\\nTopics\\n•Restrict Access to Amazon SageMaker API and Runtime to Calls from Within Your VPC (p. 491)\\nRestrict Access to Amazon SageMaker API and Runtime to Calls from Within\\nYour VPC\\nIf you set up an interface endpoint in your VPC, individuals outside the VPC can still connect to\\nthe Amazon SageMaker API and runtime over the internet unless you attach an IAM policy that\\nrestricts access to calls coming from within the VPC to all users and groups that have access to your\\nAmazon SageMaker resources. For information about creating a VPC interface endpoint for the\\nAmazon SageMaker API and runtime, see Connect to Amazon SageMaker Through a VPC Interface\\nEndpoint  (p. 517).\\nImportant\\nIf you apply an IAM policy similar to one of the following, users can\\'t access the speciﬁed\\nAmazon SageMaker APIs through the console.\\nTo restrict access to only connections made from within your VPC, create an AWS Identity and Access\\nManagement policy that restricts access to only calls that come from within your VPC. Then add that\\npolicy to every AWS Identity and Access Management user, group, or role used to access the Amazon\\nSageMaker API or runtime.\\nNote\\nThis policy allows connections only to callers within a subnet where you created an interface\\nendpoint.\\n{\\n    \"Id\": \"api-example-1\",\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"Enable API Access\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:*\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"aws:SourceVpc\": \"vpc-111bbaaa\"\\n                }\\n            }\\n        }\\n    ]\\n}\\nIf you want to restrict access to the API to only calls made using the interface endpoint, use the\\naws:SourceVpce  condition key instead of aws:SourceVpc :\\n{\\n    \"Id\": \"api-example-1\",\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n491Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n        {\\n            \"Sid\": \"Enable API Access\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreatePresignedNotebookInstanceUrl\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"ForAllValues:StringEquals\": {\\n                    \"aws:sourceVpce\": [\\n                        \"vpce-111bbccc\",\\n                        \"vpce-111bbddd\"\\n                    ]\\n                }\\n            }\\n        }\\n    ]\\n}\\nLimit Access to Amazon SageMaker API and Runtime Calls by IP\\nAddress\\nTo allow access to Amazon SageMaker API calls and runtime invocations only from IP addresses in a\\nlist that you specify, attach an IAM policy that denies access to the API unless the call comes from an IP\\naddress in the list to every AWS Identity and Access Management user, group, or role used to access the\\nAPI or runtime. For information about creating IAM policies, see Creating IAM Policies in the AWS Identity\\nand Access Management User Guide . To specify the list of IP addresses that you want to have access to\\nthe API call, use the IpAddress  condition operator and the aws:SourceIP  condition context key. For\\ninformation about IAM condition operators, see IAM JSON Policy Elements: Condition Operators in the\\nAWS Identity and Access Management User Guide. For information about IAM condition context keys, see\\nAWS Global Condition Context Keys.\\nFor example, the following policy allows access to the CreateTrainingJob (p. 667) only from IP\\naddresses in the ranges 192.0.2.0 -192.0.2.255  and 203.0.113.0 -203.0.113.255 :\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        \\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": \"sagemaker:CreateTrainingJob\",\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"IpAddress\": {\\n                    \"aws:SourceIp\": [\\n                        \"192.0.2.0/24\",\\n                        \"203.0.113.0/24\"\\n                    ]\\n                }\\n            }\\n        }\\n    ]\\n}\\nLimit Access to a Notebook Instance by IP Address\\nTo allow access to a notebook instance only from IP addresses in a list that you specify, attach an IAM\\npolicy that denies access to CreatePresignedNotebookInstanceUrl (p. 665) unless the call comes from\\nan IP address in the list to every AWS Identity and Access Management user, group, or role used to access\\n492Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\nthe notebook instance. For information about creating IAM policies, see Creating IAM Policies in the\\nAWS Identity and Access Management User Guide. To specify the list of IP addresses that you want to\\nhave access to the notebook instance, use the IpAddress  condition operator and the aws:SourceIP\\ncondition context key. For information about IAM condition operators, see IAM JSON Policy Elements:\\nCondition Operators  in the AWS Identity and Access Management User Guide. For information about IAM\\ncondition context keys, see AWS Global Condition Context Keys.\\nFor example, the following policy allows access to a notebook instance only from IP addresses in the\\nranges 192.0.2.0 -192.0.2.255  and 203.0.113.0 -203.0.113.255 :\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        \\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": \"sagemaker:CreatePresignedNotebookInstanceUrl\",\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"IpAddress\": {\\n                    \"aws:SourceIp\": [\\n                        \"192.0.2.0/24\",\\n                        \"203.0.113.0/24\"\\n                    ]\\n                }\\n            }\\n        }\\n    ]\\n}\\nThe policy restricts access to both the call to CreatePresignedNotebookInstanceUrl  and to the\\nURL that the call returns. The policy also restricts access to opening a notebook instance in the console\\nand is enforced for every HTTP request and WebSocket frame that attempts to connect to the notebook\\ninstance.\\nNote\\nUsing this method to ﬁlter by IP address is incompatible when connecting to Amazon\\nSageMaker through a VPC interface endpoint.. For information about restricting access to\\na notebook instance when connecting through a VPC interface endpoint, see Connect to a\\nNotebook Instance Through a VPC Interface Endpoint (p. 519).\\nControl Access to Amazon SageMaker Resources by Using Tags\\nControl access to groups of Amazon SageMaker resources by attaching tags to the resources and\\nspecifying ResourceTag  conditions in IAM policies.\\nNote\\nTag-based policies do not work to restrict the following API calls:\\n•ListAlgorithms\\n•ListCodeRepositories\\n•ListCompilationJobs\\n•ListEndpointConﬁgs\\n•ListEndpoints\\n•ListHyperparameterTuningJobs\\n•ListLabelingJobs\\n•ListLabelingJobsForWorkteam\\n•ListModelPackages\\n•ListModels\\n493Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n•ListNotebookInstanceLifecycleConﬁgs\\n•ListNotebookInstances\\n•ListSubscribedWorkteams\\n•ListTags\\n•ListTrainingJobs\\n•ListTrainingJobsForHyperParameterTuningJob\\n•ListTransformJobs\\n•ListWorkteams\\n•Search\\nFor example, suppose you\\'ve deﬁned two diﬀerent IAM groups, named DevTeam1  and DevTeam2 , in\\nyour AWS account. Suppose also that you\\'ve created 10 notebook instances, 5 of which are used for one\\nproject, and 5 of which are used for a second project. You want to allow members of DevTeam1  to make\\nAPI calls on notebook instances used for the ﬁrst project, and members of DevTeam2  to make API calls\\non notebook instances used for the second project.\\nYou can control access to API calls by completing the following steps:\\n1. Add a tag with the key Project  and value A to the notebook instances used for the ﬁrst project. For\\ninformation about adding tags to Amazon SageMaker resources, see AddTags (p. 620).\\n2. Add a tag with the key Project  and value B to the notebook instances used for the second project.\\n3. Create an IAM policy with a ResourceTag  condition that denies access to the notebook instances\\nused for the second project, and attach that policy to DevTeam1 . The following is an example of a\\npolicy that denies all API calls on any notebook instance that has a tag with a key of Project  and a\\nvalue of B:\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Effect\": \"Allow\",\\n      \"Action\": \"sagemaker:*\",\\n      \"Resource\": \"*\"\\n    },\\n    {\\n      \"Effect\": \"Deny\",\\n      \"Action\": \"sagemaker:*\",\\n      \"Resource\": \"*\",\\n      \"Condition\": {\\n        \"StringEquals\": {\\n          \"sagemaker:ResourceTag/Project\": \"B\"\\n        }\\n      }\\n    },\\n    {\\n      \"Effect\": \"Deny\",\\n      \"Action\": [\\n        \"sagemaker:CreateTags\",\\n        \"sagemaker:DeleteTags\"\\n      ],\\n      \"Resource\": \"*\"\\n    }\\n  ]\\n}\\nFor information about creating IAM policies and attaching them to identities, see Controlling Access\\nUsing Policies in the AWS Identity and Access Management User Guide.\\n494Amazon SageMaker Developer Guide\\nIdentity-Based Policy Examples\\n4. Create an IAM policy with a ResourceTag  condition that denies access to the notebook instances\\nused for the ﬁrst project, and attach that policy to DevTeam2 . The following is an example of a\\npolicy that denies all API calls on any notebook instance that has a tag with a key of Project  and a\\nvalue of A:\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Effect\": \"Allow\",\\n      \"Action\": \"*\",\\n      \"Resource\": \"*\"\\n    },\\n    {\\n      \"Effect\": \"Deny\",\\n      \"Action\": \"sagemaker:*\",\\n      \"Resource\": \"*\",\\n      \"Condition\": {\\n        \"StringEquals\": {\\n          \"sagemaker:ResourceTag/Project\": \"A\"\\n        }\\n      }\\n    },\\n    {\\n      \"Effect\": \"Deny\",\\n      \"Action\": [\\n        \"sagemaker:CreateTags\",\\n        \"sagemaker:DeleteTags\"\\n      ],\\n      \"Resource\": \"*\"\\n    }\\n  ]\\n}\\nRequire the Presence or Absence of Tags for API Calls\\nRequire the presence or absence of speciﬁc tags or speciﬁc tag values by using RequestTag  condition\\nkeys in an IAM policy. For example, if you want to require that every endpoint created by any member\\nof an IAM group to be created with a tag with the key environment  and value dev, create a policy as\\nfollows:\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Effect\": \"Allow\",\\n      \"Action\": \"*\",\\n      \"Resource\": \"*\"\\n    },\\n    {\\n      \"Effect\": \"Deny\",\\n      \"Action\": \"sagemaker:CreateEndpoint\",\\n      \"Resource\": [\\n        \"arn:aws:sagemaker:*:*:endpoint/*\"\\n      ]\\n    {\\n      \"Effect\": \"Allow\",\\n      \"Action\": \"sagemaker:CreateEndpoint\",\\n      \"Resource\": [\\n        \"arn:aws:sagemaker:*:*:endpoint/*\"\\n      ],\\n      \"Condition\": {\\n495Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n        \"StringEquals\": {\\n          \"aws:RequestTag/environment\": \"dev\"\\n        }\\n      }\\n    }\\n  ]\\n}\\nUse Tags with Hyperparameter Tuning Jobs\\nYou can add tags to a hyperparameter tuning job when you create the tuning job by specifying the\\ntags as the Tags parameter when you call CreateHyperParameterTuningJob (p. 638). If you do this,\\nthe tags you specify for the hyperparameter tuning job are also added to all training jobs that the\\nhyperparameter tuning job launches.\\nIf you add tags to a hyperparameter tuning job by calling AddTags (p. 620), the tags you add are also\\nadded to any training jobs that the hyperparameter tuning job launches after you call AddTags , but\\nare not added to training jobs the hyperparameter tuning jobs launched before you called AddTags .\\nSimilarly, when you remove tags from a hyperparameter tuning job by calling DeleteTags (p. 693),\\nthose tags are not removed from training jobs that the hyperparameter tuning job launched previously.\\nBecause of this, the tags associated with training jobs can be out of sync with the tags associated with\\nthe hyperparameter tuning job that launched them. If you use tags to control access to a hyperparameter\\ntuning job and the training jobs it launches, you might want to keep the tags in sync. To make sure the\\ntags associated with training jobs stay sync with the tags associated with the hyperparameter tuning\\njob that launched them, ﬁrst call ListTrainingJobsForHyperParameterTuningJob (p. 808) for the\\nhyperparameter tuning job to get a list of the training jobs that the hyperparameter tuning job launched.\\nThen, call AddTags  or DeleteTags  for the hyperparameter tuning job and for each of the training jobs\\nin the list of training jobs to add or delete the same set of tags for all of the jobs. The following Python\\nexample demonstrates this:\\ntuning_job_arn =\\n smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=\\'MyTuningJob\\')\\n[\\'HyperParameterTuningJobArn\\']\\nsmclient.add_tags(ResourceArn=tuning_job_arn, Tags=[{\\'Key\\':\\'Env\\', \\'Value\\':\\'Dev\\'}])\\ntraining_jobs = smclient.list_training_jobs_for_hyper_parameter_tuning_job(\\n    HyperParameterTuningJobName=\\'MyTuningJob\\')[\\'TrainingJobSummaries\\']\\n    for training_job in training_jobs:\\n       time.sleep(1) # Wait for 1 second between calls to avoid being throttled\\n       smclient.add_tags(ResourceArn=training_job[\\'TrainingJobArn\\'], Tags=[{\\'Key\\':\\'Env\\',\\n \\'Value\\':\\'Dev\\'}])\\nAmazon SageMaker Roles\\nAs a managed service, Amazon SageMaker performs operations on your behalf on the AWS hardware\\nthat is managed by Amazon SageMaker. Amazon SageMaker can perform only operations that the user\\npermits.\\nAn Amazon SageMaker user can grant these permissions with an IAM role (referred to as an execution\\nrole). The user passes the role when making these API calls: CreateNotebookInstance (p. 656),\\nCreateHyperParameterTuningJob (p. 638), CreateTrainingJob (p. 667), and CreateModel (p. 648).\\nYou attach the following trust policy to the IAM role which grants Amazon SageMaker principal\\npermissions to assume the role, and is the same for all of the execution roles:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n496Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n            \"Principal\": {\\n                \"Service\": \"sagemaker.amazonaws.com\"\\n            },\\n            \"Action\": \"sts:AssumeRole\"\\n        }\\n    ]\\n}\\nThe permissions that you need to grant to the role vary depending on the API that you call. The\\nfollowing sections explain these permissions.\\nNote\\nInstead of managing permissions by crafting a permission policy, you can use the AWS-managed\\nAmazonSageMakerFullAccess  permission policy. The permissions in this policy are fairly\\nbroad, to allow for any actions you might want to perform in Amazon SageMaker. For a listing\\nof the policy including information about the reasons for adding many of the permisions,\\nsee AmazonSageMakerFullAccess Policy (p. 506). If you prefer to create custom policies and\\nmanage permissions to scope the permissions only to the actions you need to perform with the\\nexecution role, see the following topics.\\nFor more information about IAM roles, see IAM Roles in the IAM User Guide .\\nTopics\\n•CreateNotebookInstance API: Execution Role Permissions (p. 497)\\n•CreateHyperParameterTuningJob API: Execution Role Permissions (p. 500)\\n•CreateTrainingJob API: Execution Role Permissions (p. 502)\\n•CreateModel API: Execution Role Permissions (p. 505)\\n•AmazonSageMakerFullAccess Policy (p. 506)\\nCreateNotebookInstance API: Execution Role Permissions\\nThe permissions that you grant to the execution role for calling the CreateNotebookInstance  API\\ndepend on what you plan to do with the notebook instance. If you plan to use it to invoke Amazon\\nSageMaker APIs and pass the same role when calling the CreateTrainingJob  and CreateModel  APIs,\\nattach the following permissions policy to the role:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:*\",\\n                \"ecr:GetAuthorizationToken\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\",\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:SetRepositoryPolicy\",\\n                \"ecr:CompleteLayerUpload\",\\n                \"ecr:BatchDeleteImage\",\\n                \"ecr:UploadLayerPart\",\\n                \"ecr:DeleteRepositoryPolicy\",\\n                \"ecr:InitiateLayerUpload\",\\n                \"ecr:DeleteRepository\",\\n                \"ecr:PutImage\",\\n                \"ecr:CreateRepository\",\\n                \"cloudwatch:PutMetricData\",\\n                \"cloudwatch:GetMetricData\",\\n                \"cloudwatch:GetMetricStatistics\",\\n497Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n                \"cloudwatch:ListMetrics\",\\n                \"logs:CreateLogGroup\",\\n                \"logs:CreateLogStream\",\\n                \"logs:DescribeLogStreams\",\\n                \"logs:PutLogEvents\",\\n                \"logs:GetLogEvents\",\\n                \"s3:CreateBucket\",\\n                \"s3:ListBucket\",\\n                \"s3:GetBucketLocation\",\\n                \"s3:GetObject\",\\n                \"s3:PutObject\",\\n                \"s3:DeleteObject\",\\n                \"robomaker:CreateSimulationApplication\",\\n                \"robomaker:DescribeSimulationApplication\",\\n                \"robomaker:DeleteSimulationApplication\",\\n                \"robomaker:CreateSimulationJob\",\\n                \"robomaker:DescribeSimulationJob\",\\n                \"robomaker:CancelSimulationJob\",\\n                \"ec2:CreateVpcEndpoint\",\\n                \"ec2:DescribeRouteTables\",\\n                \"fsx:DescribeFileSystem\",\\n                \"elasticfilesystem:DescribeMountTargets\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"codecommit:GitPull\",\\n                \"codecommit:GitPush\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:codecommit:*:*:*sagemaker*\",\\n                \"arn:aws:codecommit:*:*:*SageMaker*\",\\n                \"arn:aws:codecommit:*:*:*Sagemaker*\"\\n            ]\\n        }\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"iam:PassRole\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\\n                }\\n            }\\n        }\\n    ]\\n}\\nTo tighten the permissions, limit them to speciﬁc Amazon S3 and Amazon ECR resources, by replacing\\n\"Resource\": \"*\" , as follows:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:*\",\\n                \"ecr:GetAuthorizationToken\",\\n                \"cloudwatch:PutMetricData\",\\n498Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n                \"logs:CreateLogGroup\",\\n                \"logs:CreateLogStream\",\\n                \"logs:DescribeLogStreams\",\\n                \"logs:PutLogEvents\",\\n                \"logs:GetLogEvents\"\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"iam:PassRole\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\\n                }\\n            }\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:ListBucket\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3:::inputbucket\"\\n            ]\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:GetObject\",\\n                \"s3:PutObject\",\\n                \"s3:DeleteObject\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3::: inputbucket /object1\",\\n                \"arn:aws:s3::: outputbucket /path\",\\n                \"arn:aws:s3::: inputbucket /object2\",\\n                \"arn:aws:s3::: inputbucket /object3\"\\n            ]\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:ecr:::repository/ my-repo1 \",\\n                \"arn:aws:ecr:::repository/ my-repo2 \",\\n                \"arn:aws:ecr:::repository/ my-repo3 \"\\n            ]\\n        }\\n    ]\\n}\\nIf you plan to access other resources, such as Amazon DynamoDB or Amazon Relational Database\\nService, add the relevant permissions to this policy.\\nIn the preceding policy, you scope the policy as follows:\\n499Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n•Scope the s3:ListBucket  permission to the speciﬁc bucket that you specify as\\nInputDataConfig.DataSource.S3DataSource.S3Uri  in a CreateTrainingJob  request.\\n•Scope s3:GetObject , s3:PutObject , and s3:DeleteObject  permissions as follows:\\n•Scope to the following values that you specify in a CreateTrainingJob  request:\\nInputDataConfig.DataSource.S3DataSource.S3Uri\\nOutputDataConfig.S3OutputPath\\n•Scope to the following values that you specify in a CreateModel  request:\\nPrimaryContainer.ModelDataUrl\\nSuplementalContainers.ModelDataUrl\\n•Scope ecr permissions as follows:\\n•Scope to the AlgorithmSpecification.TrainingImage  value that you specify in a\\nCreateTrainingJob  request.\\n•Scope to the PrimaryContainer.Image  value that you specify in a CreateModel  request:\\nThe cloudwatch  and logs actions are applicable for \"*\" resources. For more information, see\\nCloudWatch Resources and Operations in the Amazon CloudWatch User Guide.\\nCreateHyperParameterTuningJob API: Execution Role\\nPermissions\\nFor an execution role that you can pass in a CreateHyperParameterTuningJob  API request, you can\\nattach the following permission policy to the role:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"cloudwatch:PutMetricData\",\\n                \"logs:CreateLogStream\",\\n                \"logs:PutLogEvents\",\\n                \"logs:CreateLogGroup\",\\n                \"logs:DescribeLogStreams\",\\n                \"s3:GetObject\",\\n                \"s3:PutObject\",\\n                \"s3:ListBucket\",\\n                \"ecr:GetAuthorizationToken\",\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\"\\n            ],\\n            \"Resource\": \"*\"\\n        }\\n    ]\\n}\\nInstead of the specifying \"Resource\": \"*\" , you could scope these permissions to speciﬁc Amazon S3\\nand Amazon ECR resources:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n500Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"cloudwatch:PutMetricData\",\\n                \"logs:CreateLogStream\",\\n                \"logs:PutLogEvents\",\\n                \"logs:CreateLogGroup\",\\n                \"logs:DescribeLogStreams\",\\n                \"ecr:GetAuthorizationToken\"\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:ListBucket\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3::: inputbucket \"\\n            ]\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:GetObject\",\\n                \"s3:PutObject\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3::: inputbucket /object\",\\n                \"arn:aws:s3::: outputbucket /path\"\\n            ]\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\"\\n            ],\\n            \"Resource\": \"arn:aws:ecr:::repository/ my-repo\"\\n        }\\n    ]\\n}\\nIf the training container associated with the hyperparameter tuning job needs to access other data\\nsources, such as DynamoDB or Amazon RDS resources, add relevant permissions to this policy.\\nIn the preceding policy, you scope the policy as follows:\\n•Scope the s3:ListBucket  permission to a speciﬁc bucket that you specify as the\\nInputDataConfig.DataSource.S3DataSource.S3Uri  in a CreateTrainingJob  request.\\n•Scope the s3:GetObject and s3:PutObject  permissions to the following objects that you specify\\nin the input and output data conﬁguration in a CreateHyperParameterTuningJob  request:\\nInputDataConfig.DataSource.S3DataSource.S3Uri\\nOutputDataConfig.S3OutputPath\\n•Scope Amazon ECR permissions to the registry path (AlgorithmSpecification.TrainingImage )\\nthat you specify in a CreateHyperParameterTuningJob  request.\\nThe cloudwatch  and logs actions are applicable for \"*\" resources. For more information, see\\nCloudWatch Resources and Operations in the Amazon CloudWatch User Guide.\\n501Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\nIf you specify a private VPC for your hyperparameter tuning job, add the following permissions:\\n{\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n            \"ec2:CreateNetworkInterface\",\\n            \"ec2:CreateNetworkInterfacePermission\",\\n            \"ec2:DeleteNetworkInterface\",\\n            \"ec2:DeleteNetworkInterfacePermission\",\\n            \"ec2:DescribeNetworkInterfaces\",\\n            \"ec2:DescribeVpcs\",\\n            \"ec2:DescribeDhcpOptions\",\\n            \"ec2:DescribeSubnets\",\\n            \"ec2:DescribeSecurityGroups\"\\nIf your input is encrypted using server-side encryption with an AWS KMS–managed key (SSE-KMS), add\\nthe following permissions:\\n{\\n    \"Effect\": \"Allow\",\\n    \"Action\": [\\n    \"kms:Decrypt\"\\n    ]\\n}\\nIf you specify a KMS key in the output conﬁguration of your hyperparameter tuning job, add the\\nfollowing permissions:\\n{\\n    \"Effect\": \"Allow\",\\n    \"Action\": [\\n    \"kms:Encrypt\"\\n    ]\\n}\\nIf you specify a volume KMS key in the resource conﬁguration of your hyperparameter tuning job, add\\nthe following permissions:\\n{\\n    \"Effect\": \"Allow\",\\n    \"Action\": [\\n    \"kms:CreateGrant\"\\n    ]\\n}\\nCreateTrainingJob API: Execution Role Permissions\\nFor an execution role that you can pass in a CreateTrainingJob  API request, you can attach the\\nfollowing permission policy to the role:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"cloudwatch:PutMetricData\",\\n                \"logs:CreateLogStream\",\\n                \"logs:PutLogEvents\",\\n502Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n                \"logs:CreateLogGroup\",\\n                \"logs:DescribeLogStreams\",\\n                \"s3:GetObject\",\\n                \"s3:PutObject\",\\n                \"s3:ListBucket\",\\n                \"ecr:GetAuthorizationToken\",\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\"\\n            ],\\n            \"Resource\": \"*\"\\n        }\\n    ]\\n}\\nInstead of the specifying \"Resource\": \"*\" , you could scope these permissions to speciﬁc Amazon S3\\nand Amazon ECR resources:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"cloudwatch:PutMetricData\",\\n                \"logs:CreateLogStream\",\\n                \"logs:PutLogEvents\",\\n                \"logs:CreateLogGroup\",\\n                \"logs:DescribeLogStreams\",\\n                \"ecr:GetAuthorizationToken\"\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:ListBucket\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3::: inputbucket \"\\n            ]\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:GetObject\",\\n                \"s3:PutObject\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3::: inputbucket /object\",\\n                \"arn:aws:s3::: outputbucket /path\"\\n            ]\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\"\\n            ],\\n            \"Resource\": \"arn:aws:ecr:::repository/ my-repo\"\\n        }\\n    ]\\n}\\n503Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\nIf CreateTrainingJob.AlgorithSpecifications.TrainingImage  needs to access other data\\nsources, such as DynamoDB or Amazon RDS resources, add relevant permissions to this policy.\\nIn the preceding policy, you scope the policy as follows:\\n•Scope the s3:ListBucket  permission to a speciﬁc bucket that you specify as the\\nInputDataConfig.DataSource.S3DataSource.S3Uri  in a CreateTrainingJob  request.\\n•Scope the s3:GetObject and s3:PutObject  permissions to the following objects that you specify\\nin the input and output data conﬁguration in a CreateTrainingJob  request:\\nInputDataConfig.DataSource.S3DataSource.S3Uri\\nOutputDataConfig.S3OutputPath\\n•Scope Amazon ECR permissions to the registry path (AlgorithmSpecification.TrainingImage )\\nthat you specify in a CreateTrainingJob  request.\\nThe cloudwatch  and logs actions are applicable for \"*\" resources. For more information, see\\nCloudWatch Resources and Operations in the Amazon CloudWatch User Guide.\\nIf you specify a private VPC for your training job, add the following permissions:\\n{\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n            \"ec2:CreateNetworkInterface\",\\n            \"ec2:CreateNetworkInterfacePermission\",\\n            \"ec2:DeleteNetworkInterface\",\\n            \"ec2:DeleteNetworkInterfacePermission\",\\n            \"ec2:DescribeNetworkInterfaces\",\\n            \"ec2:DescribeVpcs\",\\n            \"ec2:DescribeDhcpOptions\",\\n            \"ec2:DescribeSubnets\",\\n            \"ec2:DescribeSecurityGroups\"\\nIf your input is encrypted using server-side encryption with an AWS KMS–managed key (SSE-KMS), add\\nthe following permissions:\\n{\\n    \"Effect\": \"Allow\",\\n    \"Action\": [\\n    \"kms:Decrypt\"\\n    ]\\n}\\nIf you specify a KMS key in the output conﬁguration of your training job, add the following permissions:\\n{\\n    \"Effect\": \"Allow\",\\n    \"Action\": [\\n    \"kms:Encrypt\"\\n    ]\\n}\\nIf you specify a volume KMS key in the resource conﬁguration of your training job, add the following\\npermissions:\\n{\\n504Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n    \"Effect\": \"Allow\",\\n    \"Action\": [\\n    \"kms:CreateGrant\"\\n    ]\\n}\\nCreateModel API: Execution Role Permissions\\nFor an execution role that you can pass in a CreateModel  API request, you can attach the following\\npermission policy to the role:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"cloudwatch:PutMetricData\",\\n                \"logs:CreateLogStream\",\\n                \"logs:PutLogEvents\",\\n                \"logs:CreateLogGroup\",\\n                \"logs:DescribeLogStreams\",\\n                \"s3:GetObject\",\\n                \"ecr:GetAuthorizationToken\",\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\"\\n            ],\\n            \"Resource\": \"*\"\\n        }\\n    ]\\n}\\nInstead of the specifying \"Resource\": \"*\" , you can scope these permissions to speciﬁc Amazon S3\\nand Amazon ECR resources:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"cloudwatch:PutMetricData\",\\n                \"logs:CreateLogStream\",\\n                \"logs:PutLogEvents\",\\n                \"logs:CreateLogGroup\",\\n                \"logs:DescribeLogStreams\",\\n                \"ecr:GetAuthorizationToken\"\\n            ],\\n            \"Resource\": \"*\"\\n        },\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"s3:GetObject\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3::: inputbucket /object\",\\n                \"arn:aws:s3::: inputbucket /object\"\\n            ]\\n        },\\n        {\\n505Amazon SageMaker Developer Guide\\nAmazon SageMaker Roles \\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"ecr:BatchCheckLayerAvailability\",\\n                \"ecr:GetDownloadUrlForLayer\",\\n                \"ecr:BatchGetImage\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:ecr:::repository/ my-repo\",\\n                \"arn:aws:ecr:::repository/ my-repo\"\\n             ]\\n        }\\n    ]\\n}\\nIf CreateModel.PrimaryContainer.Image  need to access other data sources, such as Amazon\\nDynamoDB or Amazon RDS resources, add relevant permissions to this policy.\\nIn the preceding policy, you scope the policy as follows:\\n•Scope S3 permissions to objects that you specify in the PrimaryContainer.ModelDataUrl  in a\\nCreateModel (p. 648) request.\\n•Scope Amazon ECR permissions to a speciﬁc registry path that you specify as the\\nPrimaryContainer.Image  and SecondaryContainer.Image  in a CreateModel  request.\\nThe cloudwatch  and logs actions are applicable for \"*\" resources. For more information, see\\nCloudWatch Resources and Operations in the Amazon CloudWatch User Guide.\\nIf you specify a private VPC for your model, add the following permissions:\\n{\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n            \"ec2:CreateNetworkInterface\",\\n            \"ec2:CreateNetworkInterfacePermission\",\\n            \"ec2:DeleteNetworkInterface\",\\n            \"ec2:DeleteNetworkInterfacePermission\",\\n            \"ec2:DescribeNetworkInterfaces\",\\n            \"ec2:DescribeVpcs\",\\n            \"ec2:DescribeDhcpOptions\",\\n            \"ec2:DescribeSubnets\",\\n            \"ec2:DescribeSecurityGroups\"\\nAmazonSageMakerFullAccess Policy\\nThe AmazonSageMakerFullAccess managed policy includes all of the necessary permissions to perform\\nmost actions in Amazon SageMaker. You can use attach this policy to any role that you pass to an\\nAmazon SageMaker execution role. You can also create more narrowly-scoped policies if you want more\\ngranular control of the permissions that you grant to your execution role.\\nThe following list explains why some of the categories of permissions in the\\nAmazonSageMakerFullAccess  policy are needed.\\napplication-autoscaling\\nNeeded for automatically scaling an Amazon SageMaker real-time inference endpoint.\\naws-marketplace\\nNeeded to view AWS AI Marketplace subscriptions.\\n506Amazon SageMaker Developer Guide\\nAWS Managed (Predeﬁned) Policies for Amazon SageMaker\\ncloudwatch\\nNeeded to post CloudWatch metrics, interact with alarms, and upload CloudWatch Logs logs in your\\naccount.\\ncodecommit\\nNeeded for AWS CodeCommit integration with Amazon SageMaker notebook instances.\\ncognito\\nNeeded for Amazon SageMaker Ground Truth to deﬁne your private workforce and work teams.\\nec2\\nNeeded to manage elastic network interfaces when you specify a Amazon VPC for your Amazon\\nSageMaker jobs and notebook instances.\\nec2:DescribeVpcs\\nAll Amazon SageMaker services launch Amazon EC2 instances and require this permission set.\\necr\\nNeeded to pull and store Docker artifacts for training and inference. This is required only if you use\\nyour own container in Amazon SageMaker.\\nelastic-inference\\nNeeded to integrate Amazon Elastic Inference with Amazon SageMaker.\\nglue\\nNeeded for inference pipeline pre-processing from within Amazon SageMaker notebook instances.\\ngroundtruthlabeling\\nNeeded for Amazon SageMaker Ground Truth.\\niam:ListRoles\\nNeeded to give the Amazon SageMaker console access to list available roles.\\nkms\\nNeeded to give the Amazon SageMaker console access to list the avialable AWS KMS keys.\\nlogs\\nNeeded to allow Amazon SageMaker jobs and endpoints to publish log streams.\\nAWS Managed (Predeﬁned) Policies for Amazon\\nSageMaker\\nAWS addresses many common use cases by providing standalone IAM policies that are created and\\nadministered by AWS. These AWS managed policies grant necessary permissions for common use cases\\nso that you can avoid having to investigate which permissions are needed. For more information, see\\nAWS Managed Policies in the IAM User Guide .\\nThe following AWS managed policies, which you can attach to users in your account, are speciﬁc to\\nAmazon SageMaker:\\n•AmazonSageMakerReadOnly – Grants read-only access to Amazon SageMaker resources.\\n•AmazonSageMakerFullAccess – Grants full access to Amazon SageMaker resources and the supported\\noperations. (This does not provide unrestricted S3 access, but supports buckets/objects with speciﬁc\\nsagemaker tags.)\\n507Amazon SageMaker Developer Guide\\nAmazon SageMaker API Permissions Reference\\nThe following AWS managed policies can also be attached to users in your account:\\n•AdministratorAccess – Grants all actions for all AWS services and for all resources in the account.\\n•DataScientist  – Grants a wide range of permissions to cover most of the use cases (primarily for\\nanalytics and business intelligence) encountered by data scientists.\\nYou can review these permissions policies by signing in to the IAM console and searching for them.\\nYou can also create your own custom IAM policies to allow permissions for Amazon SageMaker actions\\nand resources as you need them. You can attach these custom policies to the IAM users or groups that\\nrequire them.\\nAmazon SageMaker API Permissions: Actions,\\nPermissions, and Resources Reference\\nWhen you are setting up access control and writing a permissions policy that you can attach to an IAM\\nidentity (an identity-based policy), use the following as a reference. The each Amazon SageMaker API\\noperation, the corresponding actions for which you can grant permissions to perform the action, and the\\nAWS resource for which you can grant the permissions. You specify the actions in the policy\\'s Action\\nﬁeld, and you specify the resource value in the policy\\'s Resource  ﬁeld.\\nNote\\nExcept for the ListTags  API, resource-level restrictions are not available on List- calls . Any\\nuser calling a List- API will see all resources of that type in the account.\\nTo express conditions in your Amazon SageMaker policies, you can use AWS-wide condition keys. For a\\ncomplete list of AWS-wide keys, see Available Keys in the IAM User Guide .\\nAmazon SageMaker API and Required Permissions for Actions\\nAPI Operation:  AddTags (p. 620)\\nRequired Permissions (API Action): sagemaker:AddTags\\nResources: *\\nAPI Operation:  CreateEndpoint (p. 632)\\nRequired Permissions (API Action): sagemaker:CreateEndpoint\\nResources: arn:aws:sagemaker: region:account-id :endpoint/ endpointName\\nAPI Operation:  CreateEndpointConﬁg (p. 635)\\nRequired Permissions (API Action): sagemaker:CreateEndpointConfig\\nResources: arn:aws:sagemaker: region:account-id :endpoint-\\nconfig/endpointConfigName\\nAPI Operation:  CreateModel (p. 648)\\nRequired Permissions (API Action): sagemaker:CreateModel, iam:PassRole\\nResources: arn:aws:sagemaker: region:account-id :model/modelName\\nAPI Operation:  CreateLabelingJob (p. 643)\\nRequired Permissions (API Action): sagemaker:CreateLabelingJob, iam:PassRole\\nResources: arn:aws:sagemaker: region:account-id :labeling-job/ labelingJobName\\n508Amazon SageMaker Developer Guide\\nAmazon SageMaker API Permissions Reference\\nAPI Operation:  CreateNotebookInstance (p. 656)\\nRequired Permissions (API Action): sagemaker:CreateNotebookInstance,\\niam:PassRole, ec2:CreateNetworkInterface, ec2:AttachNetworkInterface,\\nec2:ModifyNetworkInterfaceAttribute, ec2:DescribeAvailabilityZones,\\nec2:DescribeInternetGateways, ec2:DescribeSecurityGroups,\\nec2:DescribeSubnets, ec2:DescribeVpcs, kms:CreateGrant\\nResources: arn:aws:sagemaker: region:account-id :notebook-\\ninstance/ notebookInstanceName\\nAPI Operation:  CreateTrainingJob (p. 667)\\nRequired Permissions (API Action): sagemaker:CreateTrainingJob, iam:PassRole\\nResources: arn:aws:sagemaker: region:account-id :training-job/ trainingJobName\\nAPI Operation:  CreateWorkteam (p. 678)\\nRequired Permissions (API Action): sagemaker:CreateWorkteam , sagemaker:CreateWorkteam ,\\ncognito-idp:DescribeUserPoolClient , cognito-idp:UpdateUserPool , cognito-\\nidp:DescribeUserPool , cognito-idp:UpdateUserPoolClient\\nResources:arn:aws:sagemaker: region:account-id :workteam/private-crowd/ work team\\nname , arn:aws:sagemaker: region:account-id :workteam/vendor-crowd/ work team\\nname , arn:aws:sagemaker: region:account-id :workteam/public-crowd/ work team\\nname\\nAPI Operation:  DeleteEndpoint  (p. 683)\\nRequired Permissions (API Action): sagemaker:DeleteEndpoint\\nResources: arn:aws:sagemaker: region:account-id :endpoint/ endpointName\\nAPI Operation:  DeleteEndpointConﬁg  (p. 685)\\nRequired Permissions (API Action): sagemaker:DeleteEndpointConfig\\nResources: arn:aws:sagemaker: region:account-id :endpoint-\\nconfig/endpointConfigName\\nAPI Operation:  DeleteModel  (p. 686)\\nRequired Permissions (API Action): sagemaker:DeleteModel\\nResources: arn:aws:sagemaker: region:account-id :model/modelName\\nAPI Operation:  DeleteNotebookInstance (p. 690)\\nRequired Permissions (API Action): sagemaker:DeleteNotebookInstance,\\nec2:DeleteNetworkInterface, ec2:DetachNetworkInterface,\\nec2:DescribeAvailabilityZones, ec2:DescribeInternetGateways,\\nec2:DescribeSecurityGroups, ec2:DescribeSubnets, ec2:DescribeVpcs\\nResources: arn:aws:sagemaker: region:account-id :notebook-\\ninstance/ notebookInstanceName\\nAPI Operation:  DeleteTags (p. 693)\\nRequired Permissions (API Action): sagemaker:DeleteTags\\nResources: *\\nAPI Operation:  DeleteWorkteam (p. 695)\\nRequired Permissions (API Action): sagemaker:DeleteWorkteam\\n509Amazon SageMaker Developer Guide\\nAmazon SageMaker API Permissions Reference\\nResources: arn:aws:sagemaker: region:account-id :workteam/*\\nAPI Operation:  DescribeEndpoint  (p. 709)\\nRequired Permissions (API Action): sagemaker:DescribeEndpoint\\nResources: arn:aws:sagemaker: region:account-id :endpoint/ endpointName\\nAPI Operation:  DescribeEndpointConﬁg  (p. 712)\\nRequired Permissions (API Action): sagemaker:DescribeEndpointConfig\\nResources: arn:aws:sagemaker: region:account-id :endpoint-\\nconfig/endpointConfigName\\nAPI Operation:  DescribeLabelingJob  (p. 721)\\nRequired Permissions (API Action): sagemaker:DescribeLabelingJob\\nResources: arn:aws:sagemaker: region:account-id :labeling-job/ labelingJobName\\nAPI Operation:  DescribeModel  (p. 727)\\nRequired Permissions (API Action): sagemaker:DescribeModel\\nResources: arn:aws:sagemaker: region:account-id :model/modelName\\nAPI Operation:  DescribeNotebookInstance (p. 734)\\nRequired Permissions (API Action): sagemaker:DescribeNotebookInstance\\nResources: arn:aws:sagemaker: region:account-id :notebook-\\ninstance/ notebookInstanceName\\nAPI Operation:  DescribeSubscribedWorkteam (p. 742)\\nRequired Permissions (API Action): sagemaker:DescribeSubscribedWorkteam , aws-\\nmarketplace:ViewSubscriptions\\nResources: arn:aws:sagemaker: region:account-id :workteam/*\\nAPI Operation:  DescribeTrainingJob (p. 744)\\nRequired Permissions (API Action): sagemaker:DescribeTrainingJob\\nResources: arn:aws:sagemaker: region:account-id :training-job/ trainingJobName\\nAPI Operation:  DescribeWorkteam (p. 757)\\nRequired Permissions (API Action): sagemaker:DescribeWorkteam\\nResources: arn:aws:sagemaker: region:account-id :workteam/*\\nAPI Operation:  CreatePresignedNotebookInstanceUrl (p. 665)\\nRequired Permissions (API Action): sagemaker:CreatePresignedNotebookInstanceUrl\\nResources: arn:aws:sagemaker: region:account-id :notebook-\\ninstance/ notebookInstanceName\\nAPI Operation:  InvokeEndpoint (p. 853)\\nRequired Permissions (API Action): sagemaker:InvokeEndpoint\\nResources: arn:aws:sagemaker: region:account-id :endpoint/ endpointName\\nAPI Operation:  ListEndpointConﬁgs  (p. 771)\\nRequired Permissions (API Action): sagemaker:ListEndpointConfigs\\n510Amazon SageMaker Developer Guide\\nAmazon SageMaker API Permissions Reference\\nResources: *\\nAPI Operation:  ListEndpoints  (p. 774)\\nRequired Permissions (API Action): sagemaker:ListEndpoints\\nResources: *\\nAPI Operation:  ListLabelingJobs  (p. 781)\\nRequired Permissions (API Action): sagemaker:ListLabelingJobs\\nResources: *\\nAPI Operation:  ListLabelingJobsForWorkteam (p. 785)\\nRequired Permissions (API Action): sagemaker:ListLabelingJobsForWorkteam\\nResources: *\\nAPI Operation:  ListModels  (p. 791)\\nRequired Permissions (API Action): sagemaker:ListModels\\nResources: *\\nAPI Operation:  ListNotebookInstances (p. 797)\\nRequired Permissions (API Action): sagemaker:ListNotebookInstances\\nResources: *\\nAPI Operation:  ListSubscribedWorkteams (p. 801)\\nRequired Permissions (API Action): sagemaker:ListSubscribedWorkteam , aws-\\nmarketplace:ViewSubscriptions\\nResources: arn:aws:sagemaker: region:account-id :workteam/*\\nAPI Operation:  ListTags (p. 803)\\nRequired Permissions (API Action): sagemaker:ListTags\\nResources: *\\nAPI Operation:  ListTrainingJobs (p. 805)\\nRequired Permissions (API Action): sagemaker:ListTrainingJobs\\nResources: *\\nAPI Operation:  ListWorkteams (p. 814)\\nRequired Permissions (API Action): sagemaker:ListWorkteams\\nResources: arn:aws:sagemaker: region:account-id :workteam/*\\nAPI Operation:  StartNotebookInstance (p. 824)\\nRequired Permissions (API Action): sagemaker:StartNotebookInstance,\\niam:PassRole, ec2:CreateNetworkInterface, ec2:AttachNetworkInterface,\\nec2:ModifyNetworkInterfaceAttribute, ec2:DescribeAvailabilityZones,\\nec2:DescribeInternetGateways, ec2:DescribeSecurityGroups,\\nec2:DescribeSubnets, ec2:DescribeVpcs, kms:CreateGrant\\nResources: arn:aws:sagemaker: region:account-id :notebook-\\ninstance/ notebookInstanceName\\n511Amazon SageMaker Developer Guide\\nTroubleshooting\\nAPI Operation:  StopLabelingJob  (p. 830)\\nRequired Permissions (API Action): sagemaker:StopLabelingJob\\nResources: arn:aws:sagemaker: region:account-id :labeling-job/ labelingJobName\\nAPI Operation:  StopNotebookInstance (p. 832)\\nRequired Permissions (API Action): sagemaker:StopNotebookInstance\\nResources: arn:aws:sagemaker: region:account-id :notebook-\\ninstance/ notebookInstanceName\\nAPI Operation:  StopTrainingJob (p. 834)\\nRequired Permissions (API Action): sagemaker:StopTrainingJob\\nResources: arn:aws:sagemaker: region:account-id :training-job/ trainingJobName\\nAPI Operation:  UpdateEndpoint  (p. 840)\\nRequired Permissions (API Action): sagemaker:UpdateEndpoints\\nResources: arn:aws:sagemaker: region:account-id :endpoint/ endpointName\\nAPI Operation:  UpdateNotebookInstance (p. 844)\\nRequired Permissions (API Action): sagemaker:UpdateNotebookInstance, iam:PassRole\\nResources: arn:aws:sagemaker: region:account-id :notebook-\\ninstance/ notebookInstanceName\\nAPI Operation:  UpdateWorkteam (p. 850)\\nRequired Permissions (API Action): sagemaker:UpdateWorkteam\\nResources: arn:aws:sagemaker: region:account-id :workteam/*\\nTroubleshooting Amazon SageMaker Identity and\\nAccess\\nUse the following information to help you diagnose and ﬁx common issues that you might encounter\\nwhen working with Amazon SageMaker and IAM.\\nTopics\\n•I Am Not Authorized to Perform an Action in Amazon SageMaker (p. 512)\\n•I Am Not Authorized to Perform iam:PassRole (p. 513)\\n•I Want to View My Access Keys (p. 513)\\n•I\\'m an Administrator and Want to Allow Others to Access Amazon SageMaker (p. 513)\\n•I Want to Allow People Outside of My AWS Account to Access My Amazon SageMaker\\nResources (p. 514)\\nI Am Not Authorized to Perform an Action in Amazon\\nSageMaker\\nIf the AWS Management Console tells you that you\\'re not authorized to perform an action, then you\\nmust contact your administrator for assistance. Your administrator is the person that provided you with\\nyour user name and password.\\n512Amazon SageMaker Developer Guide\\nTroubleshooting\\nThe following example error occurs when the mateojackson  IAM user tries to use the console to view\\ndetails about a training job but does not have sagemaker:CreateTrainingJob  permissions.\\nUser: arn:aws:iam::123456789012:user/mateojackson is not\\n            authorized to perform: sagemaker:DescribeTrainingJob on resource: my-example-\\nwidget\\nIn this case, Mateo asks his administrator to update his policies to allow him to access the TrainingJob\\nresource using the sagemaker:DescribeTrainingJob  action.\\nI Am Not Authorized to Perform iam:PassRole\\nIf you receive an error that you\\'re not authorized to perform the iam:PassRole  action, then you must\\ncontact your administrator for assistance. Your administrator is the person that provided you with your\\nuser name and password. Ask that person to update your policies to allow you to pass a role to Amazon\\nSageMaker.\\nSome AWS services allow you to pass an existing role to that service, instead of creating a new service\\nrole or service-linked role. To do this, you must have permissions to pass the role to the service.\\nThe following example error occurs when an IAM user named marymajor  tries to use the console to\\nperform an action in Amazon SageMaker. However, the action requires the service to have permissions\\ngranted by a service role. Mary does not have permissions to pass the role to the service.\\nUser: arn:aws:iam::123456789012:user/ marymajor  is not authorized to perform: iam:PassRole\\nIn this case, Mary asks her administrator to update her policies to allow her to perform the\\niam:PassRole  action.\\nI Want to View My Access Keys\\nAfter you create your IAM user access keys, you can view your access key ID at any time. However, you\\ncan\\'t view your secret access key again. If you lose your secret key, you must create a new access key pair.\\nAccess keys consist of two parts: an access key ID (for example, AKIAIOSFODNN7EXAMPLE ) and a secret\\naccess key (for example, wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY ). Like a user name and\\npassword, you must use both the access key ID and secret access key together to authenticate your\\nrequests. Manage your access keys as securely as you do your user name and password.\\nImportant\\nDo not provide your access keys to a third party, even to help ﬁnd your canonical user ID. By\\ndoing this, you might give someone permanent access to your account.\\nWhen you create an access key pair, you are prompted to save the access key ID and secret access key in\\na secure location. The secret access key is available only at the time you create it. If you lose your secret\\naccess key, you must add new access keys to your IAM user. You can have a maximum of two access keys.\\nIf you already have two, you must delete one key pair before creating a new one. To view instructions,\\nsee Managing Access Keys in the IAM User Guide .\\nI\\'m an Administrator and Want to Allow Others to Access\\nAmazon SageMaker\\nTo allow others to access Amazon SageMaker, you must create an IAM entity (user or role) for the person\\nor application that needs access. They will use the credentials for that entity to access AWS. You must\\nthen attach a policy to the entity that grants them the correct permissions in Amazon SageMaker.\\nTo get started right away, see Creating Your First IAM Delegated User and Group in the IAM User Guide .\\n513Amazon SageMaker Developer Guide\\nLogging and Monitoring\\nI Want to Allow People Outside of My AWS Account to Access\\nMy Amazon SageMaker Resources\\nYou can create a role that users in other accounts or people outside of your organization can use to\\naccess your resources. You can specify who is trusted to assume the role. For services that support\\nresource-based policies or access control lists (ACLs), you can use those policies to grant people access to\\nyour resources.\\nTo learn more, consult the following:\\n•To learn whether Amazon SageMaker supports these features, see How Amazon SageMaker Works\\nwith IAM  (p. 479).\\n•To learn how to provide access to your resources across AWS accounts that you own, see Providing\\nAccess to an IAM User in Another AWS Account That You Own in the IAM User Guide .\\n•To learn how to provide access to your resources to third-party AWS accounts, see Providing Access to\\nAWS Accounts Owned by Third Parties in the IAM User Guide .\\n•To learn how to provide access through identity federation, see Providing Access to Externally\\nAuthenticated Users (Identity Federation) in the IAM User Guide .\\n•To learn the diﬀerence between using roles and resource-based policies for cross-account access, see\\nHow IAM Roles Diﬀer from Resource-based Policies in the IAM User Guide .\\nLogging and Monitoring\\nYou can monitor Amazon SageMaker using Amazon CloudWatch, which collects raw data and processes\\nit into readable, near real-time metrics. These statistics are kept for 15 months, so that you can\\naccess historical information and gain a better perspective on how your web application or service is\\nperforming. You can also set alarms that watch for certain thresholds and send notiﬁcations or take\\nactions when those thresholds are met. For more information, see Monitor Amazon SageMaker with\\nAmazon CloudWatch (p. 461).\\nAmazon CloudWatch Logs enables you to monitor, store, and access your log ﬁles from Amazon EC2\\ninstances, AWS CloudTrail, and other sources. You can collect and track metrics, create customized\\ndashboards, and set alarms that notify you or take actions when a speciﬁed metric reaches a threshold\\nthat you specify. CloudWatch Logs can monitor information in the log ﬁles and notify you when certain\\nthresholds are met. You can also archive your log data in highly durable storage. For more information,\\nsee Log Amazon SageMaker Events with Amazon CloudWatch (p. 466).\\nAWS CloudTrail provides a record of actions taken by a user, role, or an AWS service in Amazon\\nSageMaker. Using the information collected by CloudTrail, you can determine the request that was made\\nto Amazon SageMaker, the IP address from which the request was made, who made the request, when\\nit was made, and additional details. For more information, Log Amazon SageMaker API Calls with AWS\\nCloudTrail (p. 467).\\nNote\\nCloudTrail does not monitor calls to InvokeEndpoint (p. 853).\\nYou can create rules in Amazon CloudWatch Events to react to status changes in status in an Amazon\\nSageMaker training, hyperperparameter tuning, or batch transform job. For more information, see React\\nto Amazon SageMaker Job Status Changes with CloudWatch Events (p. 470).\\nCompliance Validation for Amazon SageMaker\\nThird-party auditors assess the security and compliance of Amazon SageMaker as part of multiple AWS\\ncompliance programs. These include SOC, PCI, FedRAMP, HIPAA, and others.\\n514Amazon SageMaker Developer Guide\\nResilience\\nFor a list of AWS services in scope of speciﬁc compliance programs, see AWS Services in Scope by\\nCompliance Program. For general information, see AWS Compliance Programs.\\nYou can download third-party audit reports using AWS Artifact. For more information, see Downloading\\nReports in AWS Artifact.\\nYour compliance responsibility when using Amazon SageMaker is determined by the sensitivity of your\\ndata, your company\\'s compliance objectives, and applicable laws and regulations. AWS provides the\\nfollowing resources to help with compliance:\\n•Security and Compliance Quick Start Guides – These deployment guides discuss architectural\\nconsiderations and provide steps for deploying security- and compliance-focused baseline\\nenvironments on AWS.\\n•Architecting for HIPAA Security and Compliance Whitepaper  – This whitepaper describes how\\ncompanies can use AWS to create HIPAA-compliant applications.\\n•AWS Compliance Resources – This collection of workbooks and guides might apply to your industry\\nand location.\\n•AWS Conﬁg – This AWS service assesses how well your resource conﬁgurations comply with internal\\npractices, industry guidelines, and regulations.\\n•AWS Security Hub – This AWS service provides a comprehensive view of your security state within AWS\\nthat helps you check your compliance with security industry standards and best practices.\\nResilience in Amazon SageMaker\\nThe AWS global infrastructure is built around AWS Regions and Availability Zones. AWS Regions provide\\nmultiple physically separated and isolated Availability Zones, which are connected with low-latency,\\nhigh-throughput, and highly redundant networking. With Availability Zones, you can design and operate\\napplications and databases that automatically fail over between Availability Zones without interruption.\\nAvailability Zones are more highly available, fault tolerant, and scalable than traditional single or\\nmultiple data center infrastructures.\\nFor more information about AWS Regions and Availability Zones, see AWS Global Infrastructure.\\nIn addition to the AWS global infrastructure, Amazon SageMaker oﬀers several features to help support\\nyour data resiliency and backup needs.\\nInfrastructure Security in Amazon SageMaker\\nAs a managed service, Amazon SageMaker is protected by the AWS global network security procedures\\nthat are described in the Amazon Web Services: Overview of Security Processes whitepaper.\\nYou use AWS published API calls to access Amazon SageMaker through the network. Clients must\\nsupport Transport Layer Security (TLS) 1.0 or later. We recommend TLS 1.2 or later. Clients must also\\nsupport cipher suites with perfect forward secrecy (PFS) such as Ephemeral Diﬃe-Hellman (DHE) or\\nElliptic Curve Ephemeral Diﬃe-Hellman (ECDHE). Most modern systems such as Java 7 and later support\\nthese modes.\\nAdditionally, requests must be signed by using an access key ID and a secret access key that is associated\\nwith an IAM principal. Or you can use the AWS Security Token Service (AWS STS) to generate temporary\\nsecurity credentials to sign requests.\\nTopics\\n•Connect a Notebook Instance to Resources in a VPC (p. 516)\\n•Training and Inference Containers Run in Internet-Free Mode (p. 516)\\n515Amazon SageMaker Developer Guide\\nConnect a Notebook Instance to Resources in a VPC\\n•Amazon SageMaker Scans AWS Marketplace Training and Inference Containers for Security\\nVulnerabilities (p. 517)\\n•Connect to Amazon SageMaker Through a VPC Interface Endpoint (p. 517)\\n•Give Amazon SageMaker Training Jobs Access to Resources in Your Amazon VPC (p. 522)\\n•Give Amazon SageMaker Hosted Endpoints Access to Resources in Your Amazon VPC (p. 525)\\n•Give Batch Transform Jobs Access to Resources in Your Amazon VPC (p. 529)\\nConnect a Notebook Instance to Resources in a VPC\\nAmazon SageMaker notebook instances are internet-enabled by default. This allows you to download\\npopular packages and notebooks, customize your development environment, and work eﬃciently.\\nHowever, if you connect a notebook instance to your VPC, the notebook instance provides an additional\\navenue for unauthorized access to your data. For example, a malicious user or code that you accidentally\\ninstall on the computer (in the form of a publicly available notebook or a publicly available source code\\nlibrary) could access your data. If you do not want Amazon SageMaker to provide internet access to your\\nnotebook instance, you can disable direct internet access when you specify a VPC for your notebook\\ninstance. If you disable direct internet access, the notebook instance won\\'t be able to train or host\\nmodels unless your VPC has an interface endpoint (PrivateLink) or a NAT gateway and your security\\ngroups allow outbound connections. For information about creating a VPC interface endpoint to use\\nPrivateLink for your notebook instance, see Connect to a Notebook Instance Through a VPC Interface\\nEndpoint  (p. 519). For information about setting up a NAT gateway for your VPC, see Scenario 2:\\nVPC with Public and Private Subnets (NAT) in the in the Amazon Virtual Private Cloud User Guide. For\\ninformation about security groups, see Security Groups for Your VPC.\\nNotebook Instances Provide the Best Experience for a Single\\nUser\\nAn Amazon SageMaker notebook instance is designed to work best for an individual user. It is designed\\nto give data scientists and other users the most power for managing their development environment.\\nA notebook instance user has root access for installing packages and other pertinent software. We\\nrecommend that you exercise judgement when granting individuals access to notebook instances that\\nare attached to a VPC that contains sensitive information. For example, you might grant a user access to\\na notebook instance with an IAM policy, as in the following example:\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n   {\\n      \"Effect\": \"Allow\",\\n      \"Action\": \"sagemaker:CreatePresignedNotebookInstanceUrl\",\\n      \"Resource\": \"arn:aws:sagemaker: region:account-id :notebook-instance/\\nmyNotebookInstance\"\\n   }\\n  ]\\n}\\nTraining and Inference Containers Run in Internet-\\nFree Mode\\nAmazon SageMaker training and deployed inference containers are internet-enabled by default.\\nThis allows containers to access external services and resources on the public internet as part of\\nyour training and inference workloads. However, this oﬀers an avenue for unauthorized access to\\nyour data. For example, a malicious user or code that you accidentally install on the container (in the\\n516Amazon SageMaker Developer Guide\\nAmazon SageMaker Scans AWS Marketplace Training\\nand Inference Containers for Security Vulnerabilities\\nform of a publicly available source code library) could access your data and transfer it to a remote\\nhost. If you use an Amazon VPC by specifying a value for the VpcConfig  parameter when you call\\nCreateTrainingJob (p. 667), CreateHyperParameterTuningJob (p. 638), or CreateModel (p. 648),\\nyou can protect your data and resources by managing security groups and restricting internet access\\nfrom your VPC. However, this comes at the cost of additional network conﬁguration, and has the risk\\nof conﬁguring your network incorrectly. If you do not want Amazon SageMaker to provide external\\nnetwork access to your training or inference containers, you can enable network isolation when you\\ncreate your training job or model by setting the value of the EnableNetworkIsolation  parameter\\nto True when you call CreateTrainingJob (p. 667), CreateHyperParameterTuningJob (p. 638),\\nor CreateModel (p. 648). If you enable network isolation, the containers are not able to make any\\noutbound network calls, even to other AWS services such as Amazon S3. Additionally, no AWS credentials\\nare made available to the container runtime environment. In the case of a training job with multiple\\ninstances, network inbound and outbound traﬃc is limited to the peers of each training container.\\nAmazon SageMaker still performs download and upload operations against Amazon S3 using your\\nAmazon SageMaker Execution Role in isolation from the training or inference container. Network\\nisolation is required for training jobs and models run using resources from AWS Marketplace. Network\\nisolation can be used in conjunction with a VPC. In this scenario, download and upload of customer data\\nand model artifacts are routed via your VPC subnet. However, the training and inference containers\\nthemselves continue to be isolated from the network, and do not have access to any resource within your\\nVPC or on the internet.\\nNetwork isolation is not supported by the following managed Amazon SageMaker containers as they\\nrequire access to Amazon S3:\\n•TensorFlow\\n•Chainer\\n•PyTorch\\n•Scikit-learn\\n•Amazon SageMaker Reinforcement Learning\\nAmazon SageMaker Scans AWS Marketplace Training\\nand Inference Containers for Security Vulnerabilities\\nTo meet our security requirements, algorithms and model packages listed in AWS Marketplace are\\nscanned for Common Vulnerabilities and Exposures (CVE). CVE is a list of publicly known information\\nabout security vulnerability and exposure. The National Vulnerability Database (NVD) provides CVE\\ndetails such as severity, impact rating, and ﬁx information. Both CVE and NVD are available for\\npublic consumption and free for security tools and services to use. For more information, see http://\\ncve.mitre.org/about/faqs.html#what_is_cve.\\nConnect to Amazon SageMaker Through a VPC\\nInterface Endpoint\\nYou can connect directly to the Amazon SageMaker API or to the Amazon SageMaker Runtime through\\nan interface endpoint in your Virtual Private Cloud (VPC) instead of connecting over the internet. When\\nyou use a VPC interface endpoint, communication between your VPC and the Amazon SageMaker API or\\nRuntime is conducted entirely and securely within the AWS network.\\nNote\\nPrivateLink for Amazon SageMaker is not supported in the us-gov-west-1  region.\\nThe Amazon SageMaker API and Runtime support Amazon Virtual Private Cloud (Amazon VPC) interface\\nendpoints that are powered by AWS PrivateLink. Each VPC endpoint is represented by one or more\\nElastic Network Interfaces (ENIs) with private IP addresses in your VPC subnets.\\n517Amazon SageMaker Developer Guide\\nConnect to Amazon SageMaker\\nThrough a VPC Interface Endpoint\\nThe VPC interface endpoint connects your VPC directly to the Amazon SageMaker API or Runtime\\nwithout an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. The\\ninstances in your VPC don\\'t need public IP addresses to communicate with the Amazon SageMaker API or\\nRuntime.\\nYou can create an interface endpoint to connect to Amazon SageMaker or to Amazon SageMaker\\nRuntime with either the AWS console or AWS Command Line Interface (AWS CLI) commands. For\\ninstructions, see Creating an Interface Endpoint.\\nAfter you have created a VPC endpoint, you can use the following example CLI commands that use the\\nendpoint-url  parameter to specify interface endpoints to the Amazon SageMaker API or Runtime:\\naws sagemaker list-notebook-instances --endpoint-\\nurl VPC_Endpoint_ID .api.sagemaker. Region.vpce.amazonaws.com\\naws sagemaker list-training-jobs --endpoint-\\nurl VPC_Endpoint_ID.api .sagemaker. Region.vpce.amazonaws.com\\naws sagemaker-runtime invoke-endpoint --endpoint-\\nurl VPC_Endpoint_ID .runtime.sagemaker. Region.vpce.amazonaws.com  \\\\\\n    --endpoint-name Endpoint_Name  \\\\\\n    --body \" Endpoint_Body \" \\\\\\n    --content-type \" Content_Type \" \\\\\\n            Output_File\\nIf you enable private DNS hostnames for your VPC endpoint, you don\\'t need to specify the endpoint URL.\\nThe Amazon SageMaker API DNS hostname that the CLI and Amazon SageMaker SDK use by default\\n(https://api.sagemaker.Region.amazonaws.com) resolves to your VPC endpoint. Similarly, the Amazon\\nSageMaker Runtime DNS hostname that the CLI and Amazon SageMaker Runtime SDK use by default\\n(https://runtime.sagemaker.Region.amazonaws.com) resolves to your VPC endpoint.\\nThe Amazon SageMaker API and Runtime support VPC endpoints in all AWS Regions where\\nboth Amazon VPC and Amazon SageMaker are available. Amazon SageMaker supports making\\ncalls to all of its Actions (p. 616) inside your VPC. The result AuthorizedUrl  from the\\nCreatePresignedNotebookInstanceUrl (p. 665) is not supported by Private Link. For information about\\nhow to enable PrivateLink for the authorized URL that users use to connect to a notebook instance, see\\nConnect to a Notebook Instance Through a VPC Interface Endpoint (p. 519).\\nTo learn more about AWS PrivateLink, see the AWS PrivateLink documentation . Refer to VPC Pricing  for\\nthe price of VPC Endpoints. To learn more about VPC and Endpoints, see Amazon VPC. For information\\nabout how to use identity-based AWS Identity and Access Management policies to restrict access to\\nthe Amazon SageMaker API and runtime, see Control Access to the Amazon SageMaker API by Using\\nIdentity-based Policies (p. 491).\\nCreate a VPC Endpoint Policy for Amazon SageMaker\\nYou can create a policy for Amazon VPC endpoints for Amazon SageMaker to specify the following:\\n•The principal that can perform actions.\\n•The actions that can be performed.\\n•The resources on which actions can be performed.\\nFor more information, see Controlling Access to Services with VPC Endpoints in the Amazon VPC User\\nGuide .\\nNote\\nVPC endpoint policies aren\\'t supported for Federal Information Processing Standard (FIPS)\\nAmazon SageMaker runtime endpoints for InvokeEndpoint (p. 853).\\n518Amazon SageMaker Developer Guide\\nConnect to Amazon SageMaker\\nThrough a VPC Interface Endpoint\\nThe following example VPC endpoint policy speciﬁes that all users who have access to the VPC interface\\nendpoint are allowed to invoke the Amazon SageMaker hosted endpoint named myEndpoint .\\n{\\n  \"Statement\": [\\n      {\\n          \"Action\": \"sagemaker:InvokeEndpoint\",\\n          \"Effect\": \"Allow\",\\n          \"Resource\": \"arn:aws:sagemaker:us-west-2:123456789012:endpoint/myEndpoint\",\\n          \"Principal\": \"*\"\\n      }\\n  ]\\n}\\nIn this example, the following are denied:\\n•Other Amazon SageMaker API actions, such as sagemaker:CreateEndpoint  and\\nsagemaker:CreateTrainingJob .\\n•Invoking Amazon SageMaker hosted endpoints other than myEndpoint .\\nNote\\nIn this example, users can still take other Amazon SageMaker API actions from outside the VPC.\\nFor information about how to restrict API calls to those from within the VPC, see Control Access\\nto the Amazon SageMaker API by Using Identity-based Policies (p. 491).\\nConnect to a Notebook Instance Through a VPC Interface\\nEndpoint\\nYou can connect to your notebook instance from your VPC through an interface endpoint in your Virtual\\nPrivate Cloud (VPC) instead of connecting over the internet. When you use a VPC interface endpoint,\\ncommunication between your VPC and the notebook instance is conducted entirely and securely within\\nthe AWS network.\\nAmazon SageMaker notebook instances support Amazon Virtual Private Cloud (Amazon VPC) interface\\nendpoints that are powered by AWS PrivateLink. Each VPC endpoint is represented by one or more\\nElastic Network Interfaces (ENIs) with private IP addresses in your VPC subnets.\\nNote\\nBefore you create an interface VPC endpoint to connect to a notebook instance, create an\\ninterface VPC endpoint to connect to the Amazon SageMaker API. That way, when users call\\nCreatePresignedNotebookInstanceUrl (p. 665) to get the URL to connect to the notebook\\ninstance, that call also goes through the interface VPC endpoint. For information, see Connect\\nto Amazon SageMaker Through a VPC Interface Endpoint (p. 517).\\nYou can create an interface endpoint to connect to your notebook instance with either the AWS console\\nor AWS Command Line Interface (AWS CLI) commands. For instructions, see Creating an Interface\\nEndpoint . Make sure that you create an interface endpoint for all of the subnets in your VPC from which\\nyou want to connect to the notebook instance.\\nWhen you create the interface endpoint, specify aws.sagemaker.region .notebook  as the service name.\\nAfter you create a VPC endpoint, enable private DNS for your VPC endpoint. Anyone using the Amazon\\nSageMaker API, the AWS CLI, or the console to connect to the notebook instance from within the VPC\\nwill connect to the notebook instance through the VPC endpoint instead of the public internet.\\nAmazon SageMaker notebook instances support VPC endpoints in all AWS Regions where both Amazon\\nVPC and Amazon SageMaker are available.\\nTopics\\n519Amazon SageMaker Developer Guide\\nConnect to Amazon SageMaker\\nThrough a VPC Interface Endpoint\\n•Connect Your Private Network to Your VPC (p. 520)\\n•Create a VPC Endpoint Policy for Amazon SageMaker Notebook Instances (p. 520)\\n•Restrict Access to Connections from Within Your VPC (p. 520)\\nConnect Your Private Network to Your VPC\\nTo connect to your notebook instance through your VPC, you either have to connect from an instance\\nthat is inside the VPC, or connect your private network to your VPC by using an Amazon Virtual Private\\nNetwork (VPN) or AWS Direct Connect. For information about Amazon VPN, see VPN Connections in\\nthe Amazon Virtual Private Cloud User Guide. For information about AWS Direct Connect, see Creating a\\nConnection in the AWS Direct Connect User Guide.\\nCreate a VPC Endpoint Policy for Amazon SageMaker Notebook Instances\\nYou can create a policy for Amazon VPC endpoints for Amazon SageMaker notebook instances to specify\\nthe following:\\n•The principal that can perform actions.\\n•The actions that can be performed.\\n•The resources on which actions can be performed.\\nFor more information, see Controlling Access to Services with VPC Endpoints in the Amazon VPC User\\nGuide .\\nThe following example of a VPC endpoint policy speciﬁes that all users that have access to the endpoint\\nare allowed to access the notebook instance named myNotebookInstance .\\n{\\n  \"Statement\": [\\n      {\\n          \"Action\": \"sagemaker:CreatePresignedNotebookInstanceUrl\",\\n          \"Effect\": \"Allow\",\\n          \"Resource\": \"arn:aws:sagemaker:us-west-2:123456789012:notebook-instance/\\nmyNotebookInstance\",\\n          \"Principal\": \"*\"\\n      }\\n  ]\\n}\\nAccess to other notebook instances is denied.\\nRestrict Access to Connections from Within Your VPC\\nEven if you set up an interface endpoint in your VPC, individuals outside the VPC can connect to the\\nnotebook instance over the internet.\\nImportant\\nIf you apply an IAM policy similar to one of the following, users can\\'t access the speciﬁed\\nAmazon SageMaker APIs or the notebook instance through the console.\\nTo restrict access to only connections made from within your VPC, create an AWS Identity and Access\\nManagement policy that restricts access to only calls that come from within your VPC. Then add that\\npolicy to every AWS Identity and Access Management user, group, or role used to access the notebook\\ninstance.\\nNote\\nThis policy allows connections only to callers within a subnet where you created an interface\\nendpoint.\\n520Amazon SageMaker Developer Guide\\nConnect to Amazon SageMaker\\nThrough a VPC Interface Endpoint\\n{\\n    \"Id\": \"notebook-example-1\",\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"Enable Notebook Access\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreatePresignedNotebookInstanceUrl\",\\n                \"sagemaker:DescribeNotebookInstance\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"StringEquals\": {\\n                    \"aws:SourceVpc\": \"vpc-111bbaaa\"\\n                }\\n            }\\n        }\\n    ]\\n}\\nIf you want to restrict access to the notebook instance to only connections made using the interface\\nendpoint, use the aws:SourceVpce  condition key instead of aws:SourceVpc :\\n{\\n    \"Id\": \"notebook-example-1\",\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"Enable Notebook Access\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"sagemaker:CreatePresignedNotebookInstanceUrl\",\\n                \"sagemaker:DescribeNotebookInstance\"\\n            ],\\n            \"Resource\": \"*\",\\n            \"Condition\": {\\n                \"ForAnyValue:StringEquals\": {\\n                    \"aws:sourceVpce\": [\\n                        \"vpce-111bbccc\",\\n                        \"vpce-111bbddd\"\\n                    ]\\n                }\\n            }\\n        }\\n    ]\\n}\\nBoth of these policy examples assume that you have also created an interface endpoint for the Amazon\\nSageMaker API. For more information, see Connect to Amazon SageMaker Through a VPC Interface\\nEndpoint  (p. 517). In the second example, one of the values for aws:SourceVpce  is the ID of the\\ninterface endpoint for the notebook instance. The other is the ID of the interface endpoint for the\\nAmazon SageMaker API.\\nThe policy examples here include DescribeNotebookInstance (p. 734) because typically you would\\ncall DescribeNotebookInstance  to make sure that the NotebookInstanceStatus  is InService\\nbefore you try to connect to it. For example:\\naws sagemaker describe-notebook-instance \\\\\\n                    --notebook-instance-name myNotebookInstance\\n                    \\n                    \\n521Amazon SageMaker Developer Guide\\nGive Amazon SageMaker Training Jobs\\nAccess to Resources in Your Amazon VPC\\n{\\n   \"NotebookInstanceArn\":\\n   \"arn:aws:sagemaker:us-west-2:1234567890ab:notebook-instance/mynotebookinstance\",\\n   \"NotebookInstanceName\": \"myNotebookInstance\",\\n   \"NotebookInstanceStatus\": \"InService\",\\n   \"Url\": \"mynotebookinstance.notebook.us-west-2.sagemaker.aws\",\\n   \"InstanceType\": \"ml.m4.xlarge\",\\n   \"RoleArn\":\\n   \"arn:aws:iam::1234567890ab:role/service-role/AmazonSageMaker-\\nExecutionRole-12345678T123456\",\\n   \"LastModifiedTime\": 1540334777.501,\\n   \"CreationTime\": 1523050674.078,\\n   \"DirectInternetAccess\": \"Disabled\"\\n}\\naws sagemaker create-presigned-notebook-instance-url --notebook-instance-name\\n myNotebookInstance\\n                \\n                \\n{\\n   \"AuthorizedUrl\": \"https://mynotebookinstance.notebook.us-west-2.sagemaker.aws?\\nauthToken= AuthToken\\n}\\nFor both of these calls, if you did not enable private DNS hostnames for your VPC endpoint, or if you\\nare using a version of the AWS SDK that was released before August 13, 2018, you must specify the\\nendpoint URL in the call. For example, the call to create-presigned-notebook-instance-url\\nwould be:\\naws sagemaker create-presigned-notebook-instance-url\\n    --notebook-instance-name myNotebookInstance  --endpoint-url\\n    VPC_Endpoint_ID .api.sagemaker. Region.vpce.amazonaws.com\\nConnect Your Private Network to Your VPC\\nTo call the Amazon SageMaker API and runtime through your VPC, you have to connect from an instance\\nthat is inside the VPC or connect your private network to your VPC by using an Amazon Virtual Private\\nNetwork (VPN) or AWS Direct Connect. For information about Amazon VPN, see VPN Connections in\\nthe Amazon Virtual Private Cloud User Guide. For information about AWS Direct Connect, see Creating a\\nConnection in the AWS Direct Connect User Guide.\\nGive Amazon SageMaker Training Jobs Access to\\nResources in Your Amazon VPC\\nAmazon SageMaker runs training jobs in an Amazon Virtual Private Cloud by default. However, training\\ncontainers access AWS resources—such as the Amazon S3 buckets where you store training data and\\nmodel artifacts—over the internet.\\nTo control access to your data and training containers, we recommend that you create a private VPC\\nand conﬁgure it so that they aren\\'t accessible over the internet. For information about creating and\\nconﬁguring a VPC, see Getting Started With Amazon VPC in the Amazon VPC User Guide . Using a VPC\\nhelps to protect your training containers and data because you can conﬁgure your VPC so that it is not\\nconnected to the internet. Using a VPC also allows you to monitor all network traﬃc in and out of your\\ntraining containers by using VPC ﬂow logs. For more information, see VPC Flow Logs in the Amazon VPC\\nUser Guide .\\nYou specify your private VPC conﬁguration when you create training jobs by specifying subnets and\\nsecurity groups. When you specify the subnets and security groups, Amazon SageMaker creates elastic\\n522Amazon SageMaker Developer Guide\\nGive Amazon SageMaker Training Jobs\\nAccess to Resources in Your Amazon VPC\\nnetwork interfaces (ENIs) that are associated with your security groups in one of the subnets. ENIs allow\\nyour training containers to connect to resources in your VPC. For information about ENIs, see Elastic\\nNetwork Interfaces in the Amazon VPC User Guide .\\nNote\\nFor training jobs, you can conﬁgure only subnets with a default tenancy VPC in which your\\ninstance runs on shared hardware. For more information on the tenancy attribute for VPCs, see\\nDedicated Instances.\\nConﬁgure a Training Job for Amazon VPC Access\\nTo specify subnets and security groups in your private VPC, use the VpcConfig  request parameter of\\nthe CreateTrainingJob (p. 667) API, or provide this information when you create a training job in the\\nAmazon SageMaker console. Amazon SageMaker uses this information to create ENIs and attach them\\nto your training containers. The ENIs provide your training containers with a network connection within\\nyour VPC that is not connected to the internet. They also enable your training job to connect to resources\\nin your private VPC.\\nThe following is an example of the VpcConfig  parameter that you include in your call to\\nCreateTrainingJob :\\nVpcConfig: {\\n      \"Subnets\": [\\n          \"subnet-0123456789abcdef0\",\\n          \"subnet-0123456789abcdef1\",\\n          \"subnet-0123456789abcdef2\"\\n          ],\\n      \"SecurityGroupIds\": [\\n          \"sg-0123456789abcdef0\"\\n          ]\\n        }\\nConﬁgure Your Private VPC for Amazon SageMaker Training\\nWhen conﬁguring the private VPC for your Amazon SageMaker training jobs, use the following\\nguidelines. For information about setting up a VPC, see Working with VPCs and Subnets in the Amazon\\nVPC User Guide .\\nTopics\\n•Ensure That Subnets Have Enough IP Addresses (p. 523)\\n•Create an Amazon S3 VPC Endpoint (p. 523)\\n•Use a Custom Endpoint Policy to Restrict Access to S3 (p. 524)\\n•Conﬁgure Route Tables (p. 525)\\n•Conﬁgure the VPC Security Group (p. 525)\\n•Connect to Resources Outside Your VPC (p. 525)\\nEnsure That Subnets Have Enough IP Addresses\\nYour VPC subnets should have at least two private IP addresses for each instance in a training job. For\\nmore information, see VPC and Subnet Sizing for IPv4  in the Amazon VPC User Guide .\\nCreate an Amazon S3 VPC Endpoint\\nIf you conﬁgure your VPC so that training containers don\\'t have access to the internet, they can\\'t connect\\nto the Amazon S3 buckets that contain your training data unless you create a VPC endpoint that allows\\n523Amazon SageMaker Developer Guide\\nGive Amazon SageMaker Training Jobs\\nAccess to Resources in Your Amazon VPC\\naccess. By creating a VPC endpoint, you allow your training containers to access the buckets where you\\nstore your data and model artifacts . We recommend that you also create a custom policy that allows\\nonly requests from your private VPC to access to your S3 buckets. For more information, see Endpoints\\nfor Amazon S3.\\nTo create an S3 VPC endpoint:\\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\\n2. In the navigation pane, choose Endpoints , then choose Create Endpoint\\n3. For Service Name, choose com.amazonaws.region .s3, where region is the name of the region\\nwhere your VPC resides.\\n4. For VPC, choose the VPC you want to use for this endpoint.\\n5. For Conﬁgure route tables, select the route tables to be used by the endpoint. The VPC service\\nautomatically adds a route to each route table you select that points any S3 traﬃc to the new\\nendpoint.\\n6. For Policy, choose Full Access to allow full access to the S3 service by any user or service within the\\nVPC. Choose Custom  to restrict access further. For information, see Use a Custom Endpoint Policy to\\nRestrict Access to S3 (p. 524).\\nUse a Custom Endpoint Policy to Restrict Access to S3\\nThe default endpoint policy allows full access to S3 for any user or service in your VPC. To further restrict\\naccess to S3, create a custom endpoint policy. For more information, see Using Endpoint Policies for\\nAmazon S3. You can also use a bucket policy to restrict access to your S3 buckets to only traﬃc that\\ncomes from your Amazon VPC. For information, see Using Amazon S3 Bucket Policies.\\nRestrict Package Installation on the Training Container\\nThe default endpoint policy allows users to install packages from the Amazon Linux and Amazon Linux\\n2 repositories on the training container. If you don\\'t want users to install packages from that repository,\\ncreate a custom endpoint policy that explicitly denies access to the Amazon Linux and Amazon Linux 2\\nrepositories. The following is an example of a policy that denies access to these repositories:\\n{ \\n    \"Statement\": [ \\n      { \\n        \"Sid\": \"AmazonLinuxAMIRepositoryAccess\",\\n        \"Principal\": \"*\",\\n        \"Action\": [ \\n            \"s3:GetObject\" \\n        ],\\n        \"Effect\": \"Deny\",\\n        \"Resource\": [\\n            \"arn:aws:s3:::packages.*.amazonaws.com/*\",\\n            \"arn:aws:s3:::repo.*.amazonaws.com/*\"\\n        ] \\n      } \\n    ] \\n} \\n{ \\n    \"Statement\": [ \\n        { \"Sid\": \"AmazonLinux2AMIRepositoryAccess\",\\n          \"Principal\": \"*\",\\n          \"Action\": [ \\n              \"s3:GetObject\" \\n              ],\\n          \"Effect\": \"Deny\",\\n524Amazon SageMaker Developer Guide\\nGive Amazon SageMaker Hosted Endpoints\\nAccess to Resources in Your Amazon VPC\\n          \"Resource\": [\\n              \"arn:aws:s3:::amazonlinux.*.amazonaws.com/*\" \\n              ] \\n         } \\n    ] \\n} \\nConﬁgure Route Tables\\nUse default DNS settings for your endpoint route table, so that standard Amazon S3 URLs (for example,\\nhttp://s3-aws-region.amazonaws.com/MyBucket ) resolve. If you don\\'t use default DNS settings,\\nensure that the URLs that you use to specify the locations of the data in your training jobs resolve by\\nconﬁguring the endpoint route tables. For information about VPC endpoint route tables, see Routing for\\nGateway Endpoints in the Amazon VPC User Guide .\\nConﬁgure the VPC Security Group\\nIn distributed training, you must allow communication between the diﬀerent containers in the same\\ntraining job. To do that, conﬁgure a rule for your security group that allows inbound connections\\nbetween members of the same security group For information, see Security Group Rules.\\nConnect to Resources Outside Your VPC\\nIf you conﬁgure your VPC so that it doesn\\'t have internet access, training jobs that use that VPC do not\\nhave access to resources outside your VPC. If your training job needs access to resources outside your\\nVPC, provide access with one of the following options:\\n•If your training job needs access to an AWS service that supports interface VPC endpoints, create an\\nendpoint to connect to that service. For a list of services that support interface endpoints, see VPC\\nEndpoints  in the Amazon VPC User Guide . For information about creating an interface VPC endpoint,\\nsee Interface VPC Endpoints (AWS PrivateLink) in the Amazon VPC User Guide .\\n•If your training job needs access to an AWS service that doesn\\'t support interface VPC endpoints\\nor to a resource outside of AWS, create a NAT gateway and conﬁgure your security groups to allow\\noutbound connections. For information about setting up a NAT gateway for your VPC, see Scenario 2:\\nVPC with Public and Private Subnets (NAT) in the Amazon Virtual Private Cloud User Guide.\\nGive Amazon SageMaker Hosted Endpoints Access to\\nResources in Your Amazon VPC\\nAmazon SageMaker hosts models in an Amazon Virtual Private Cloud by default. However, models access\\nAWS resources—such as the Amazon S3 buckets where you store training data and model artifacts—over\\nthe internet.\\nTo avoid making your data and model containers accessible over the internet, we recommend that you\\ncreate a private VPC and conﬁgure it to control access to them. For information about creating and\\nconﬁguring a VPC, see Getting Started With Amazon VPC in the Amazon VPC User Guide . Using a VPC\\nhelps to protect your training containers and data because you can conﬁgure your VPC so that it is not\\nconnected to the internet. Using a VPC also allows you to monitor all network traﬃc in and out of your\\ntraining containers by using VPC ﬂow logs. For more information, see VPC Flow Logs in the Amazon VPC\\nUser Guide .\\nYou specify your private VPC conﬁguration when you create a model by specifying subnets and security\\ngroups. When you specify the subnets and security groups, Amazon SageMaker creates elastic network\\ninterfaces (ENIs) that are associated with your security groups in one of the subnets. ENIs allow your\\n525Amazon SageMaker Developer Guide\\nGive Amazon SageMaker Hosted Endpoints\\nAccess to Resources in Your Amazon VPC\\nmodel containers to connect to resources in your VPC. For information about ENIs, see Elastic Network\\nInterfaces in the Amazon VPC User Guide .\\nConﬁgure a Model for Amazon VPC Access\\nTo specify subnets and security groups in your private VPC, use the VpcConfig  request parameter of\\nthe CreateModel (p. 648) API, or provide this information when you create a model in the Amazon\\nSageMaker console. Amazon SageMaker uses this information to create ENIs and attach them to your\\nmodel containers. The ENIs provide your model containers with a network connection within your VPC\\nthat is not connected to the internet. They also enable your model to connect to resources in your\\nprivate VPC.\\nNote\\nYou must create at least two subnets in diﬀerent availability zones in your private VPC, even if\\nyou have only one hosting instance.\\nThe following is an example of the VpcConfig  parameter that you include in your call to CreateModel :\\nVpcConfig: {\\n      \"Subnets\": [\\n          \"subnet-0123456789abcdef0\",\\n          \"subnet-0123456789abcdef1\",\\n          \"subnet-0123456789abcdef2\"\\n          ],\\n      \"SecurityGroupIds\": [\\n          \"sg-0123456789abcdef0\"\\n          ]\\n       }\\nConﬁgure Your Private VPC for Amazon SageMaker Hosting\\nWhen conﬁguring the private VPC for your Amazon SageMaker models, use the following guidelines. For\\ninformation about setting up a VPC, see Working with VPCs and Subnets in the Amazon VPC User Guide .\\nTopics\\n•Ensure That Subnets Have Enough IP Addresses (p. 526)\\n•Create an Amazon S3 VPC Endpoint (p. 526)\\n•Use a Custom Endpoint Policy to Restrict Access to Amazon S3 (p. 527)\\n•Add Permissions for Endpoint Access for Containers Running in a VPC to Custom IAM Policies\\n (p. 528)\\n•Conﬁgure Route Tables (p. 528)\\n•Connect to Resources Outside Your VPC (p. 528)\\nEnsure That Subnets Have Enough IP Addresses\\nYour VPC subnets should have at least two private IP addresses for each model instance. For more\\ninformation, see VPC and Subnet Sizing for IPv4  in the Amazon VPC User Guide .\\nCreate an Amazon S3 VPC Endpoint\\nIf you conﬁgure your VPC so that model containers don\\'t have access to the internet, they can\\'t connect\\nto the Amazon S3 buckets that contain your data unless you create a VPC endpoint that allows access.\\nBy creating a VPC endpoint, you allow your model containers to access the buckets where you store your\\ndata and model artifacts . We recommend that you also create a custom policy that allows only requests\\nfrom your private VPC to access to your S3 buckets. For more information, see Endpoints for Amazon S3.\\n526Amazon SageMaker Developer Guide\\nGive Amazon SageMaker Hosted Endpoints\\nAccess to Resources in Your Amazon VPC\\nTo create an Amazon S3 VPC endpoint:\\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\\n2. In the navigation pane, choose Endpoints , then choose Create Endpoint\\n3. For Service Name, choose com.amazonaws.region .s3, where region is the name of the AWS\\nRegion where your VPC resides.\\n4. For VPC, choose the VPC that you want to use for this endpoint.\\n5. For Conﬁgure route tables, choose the route tables that the endpoint will use. The VPC service\\nautomatically adds a route to each route table that you choose that points Amazon S3 traﬃc to the\\nnew endpoint.\\n6. For Policy, choose Full Access to allow full access to the Amazon S3 service by any user or service\\nwithin the VPC. To restrict access further, choose Custom . For more information, see Use a Custom\\nEndpoint Policy to Restrict Access to Amazon S3 (p. 527).\\nUse a Custom Endpoint Policy to Restrict Access to Amazon S3\\nThe default endpoint policy allows full access to Amazon Simple Storage Service (Amazon S3) for any\\nuser or service in your VPC. To further restrict access to Amazon S3, create a custom endpoint policy. For\\nmore information, see Using Endpoint Policies for Amazon S3.\\nYou can also use a bucket policy to restrict access to your S3 buckets to only traﬃc that comes from your\\nAmazon VPC. For information, see Using Amazon S3 Bucket Policies.\\nRestrict Package Installation on the Model Container with a Custom Endpoint Policy\\nThe default endpoint policy allows users to install packages from the Amazon Linux and Amazon Linux 2\\nrepositories on the model container. If you don\\'t want users to install packages from those repositories,\\ncreate a custom endpoint policy that explicitly denies access to the Amazon Linux and Amazon Linux 2\\nrepositories. The following is an example of a policy that denies access to these repositories:\\n{ \\n    \"Statement\": [ \\n      { \\n        \"Sid\": \"AmazonLinuxAMIRepositoryAccess\",\\n        \"Principal\": \"*\",\\n        \"Action\": [ \\n            \"s3:GetObject\" \\n        ],\\n        \"Effect\": \"Deny\",\\n        \"Resource\": [\\n            \"arn:aws:s3:::packages.*.amazonaws.com/*\",\\n            \"arn:aws:s3:::repo.*.amazonaws.com/*\"\\n        ] \\n      } \\n    ] \\n} \\n{ \\n    \"Statement\": [ \\n        { \"Sid\": \"AmazonLinux2AMIRepositoryAccess\",\\n          \"Principal\": \"*\",\\n          \"Action\": [ \\n              \"s3:GetObject\" \\n              ],\\n          \"Effect\": \"Deny\",\\n          \"Resource\": [\\n              \"arn:aws:s3:::amazonlinux.*.amazonaws.com/*\" \\n              ] \\n         } \\n527Amazon SageMaker Developer Guide\\nGive Amazon SageMaker Hosted Endpoints\\nAccess to Resources in Your Amazon VPC\\n    ] \\n} \\nAdd Permissions for Endpoint Access for Containers Running in a VPC to Custom\\nIAM Policies\\nThe SageMakerFullAccess  managed policy includes the permissions that you need to use models\\nconﬁgured for Amazon VPC access with an endpoint. These permissions allow Amazon SageMaker to\\ncreate an elastic network interface and attach it to model containers running in a VPC. If you use your\\nown IAM policy, you must add the following permissions to that policy to use models conﬁgured for VPC\\naccess.\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"ec2:DescribeVpcEndpoints\",\\n                \"ec2:DescribeDhcpOptions\",\\n                \"ec2:DescribeVpcs\",\\n                \"ec2:DescribeSubnets\",\\n                \"ec2:DescribeSecurityGroups\",\\n                \"ec2:DescribeNetworkInterfaces\",\\n                \"ec2:DeleteNetworkInterfacePermission\",\\n                \"ec2:DeleteNetworkInterface\",\\n                \"ec2:CreateNetworkInterfacePermission\",\\n                \"ec2:CreateNetworkInterface\"\\n            ],\\n            \"Resource\": \"*\"\\n        }\\n}\\nFor more information about the SageMakerFullAccess  managed policy, see\\nAmazonSageMakerFullAccess Policy (p. 506).\\nConﬁgure Route Tables\\nUse default DNS settings for your endpoint route table, so that standard Amazon S3 URLs (for example,\\nhttp://s3-aws-region.amazonaws.com/MyBucket ) resolve. If you don\\'t use default DNS settings,\\nensure that the URLs that you use to specify the locations of the data in your models resolve by\\nconﬁguring the endpoint route tables. For information about VPC endpoint route tables, see Routing for\\nGateway Endpoints in the Amazon VPC User Guide .\\nConnect to Resources Outside Your VPC\\nIf you conﬁgure your VPC so that it doesn\\'t have internet access, models that use that VPC do not have\\naccess to resources outside your VPC. If your model needs access to resources outside your VPC, provide\\naccess with one of the following options:\\n•If your model needs access to an AWS service that supports interface VPC endpoints, create an\\nendpoint to connect to that service. For a list of services that support interface endpoints, see VPC\\nEndpoints  in the Amazon VPC User Guide . For information about creating an interface VPC endpoint,\\nsee Interface VPC Endpoints (AWS PrivateLink) in the Amazon VPC User Guide .\\n•If your model needs access to an AWS service that doesn\\'t support interface VPC endpoints or to a\\nresource outside of AWS, create a NAT gateway and conﬁgure your security groups to allow outbound\\nconnections. For information about setting up a NAT gateway for your VPC, see Scenario 2: VPC with\\nPublic and Private Subnets (NAT) in the Amazon Virtual Private Cloud User Guide.\\n528Amazon SageMaker Developer Guide\\nGive Batch Transform Jobs Access\\nto Resources in Your Amazon VPC\\nGive Batch Transform Jobs Access to Resources in\\nYour Amazon VPC\\nAmazon SageMaker runs batch transform jobs in an Amazon Virtual Private Cloud by default. However,\\nmodel containers access AWS resources—such as the Amazon S3 buckets where you store your data and\\nmodel artifacts—over the internet.\\nTo control access to your model containers and data, we recommend that you create a private VPC\\nand conﬁgure it so that they aren\\'t accessible over the internet. For information about creating and\\nconﬁguring a VPC, see Getting Started With Amazon VPC in the Amazon VPC User Guide . Using a VPC\\nhelps to protect your model containers and data because you can conﬁgure your VPC so that it is not\\nconnected to the internet. Using a VPC also allows you to monitor all network traﬃc in and out of your\\nmodel containers by using VPC ﬂow logs. For more information, see VPC Flow Logs in the Amazon VPC\\nUser Guide .\\nYou specify your private VPC conﬁguration when you create a model by specifying subnets and security\\ngroups. You then specify the same model when you create a batch transform job. When you specify\\nthe subnets and security groups, Amazon SageMaker creates elastic network interfaces (ENIs) that are\\nassociated with your security groups in one of the subnets. ENIs allow your model containers to connect\\nto resources in your VPC. For information about ENIs, see Elastic Network Interfaces in the Amazon VPC\\nUser Guide .\\nConﬁgure a Batch Transform Job for Amazon VPC Access\\nTo specify subnets and security groups in your private VPC, use the VpcConfig  request parameter\\nof the CreateModel (p. 648) API, or provide this information when you create a transform job in the\\nAmazon SageMaker console. Then specify the same model in the ModelName  request parameter of\\nthe CreateTransformJob (p. 673) API, or when you create a transform job in the Amazon SageMaker\\nconsole. Amazon SageMaker uses this information to create ENIs and attach them to your model\\ncontainers. The ENIs provide your model containers with a network connection within your VPC that\\nis not connected to the internet. They also enable your transform job to connect to resources in your\\nprivate VPC.\\nThe following is an example of the VpcConfig  parameter that you include in your call to CreateModel :\\nVpcConfig: {\\n      \"Subnets\": [\\n          \"subnet-0123456789abcdef0\",\\n          \"subnet-0123456789abcdef1\",\\n          \"subnet-0123456789abcdef2\"\\n          ],\\n      \"SecurityGroupIds\": [\\n          \"sg-0123456789abcdef0\"\\n          ]\\n        }\\nConﬁgure Your Private VPC for Amazon SageMaker Batch\\nTransform\\nWhen conﬁguring the private VPC for your Amazon SageMaker batch transform jobs, use the following\\nguidelines. For information about setting up a VPC, see Working with VPCs and Subnets in the Amazon\\nVPC User Guide .\\nTopics\\n•Ensure That Subnets Have Enough IP Addresses (p. 530)\\n529Amazon SageMaker Developer Guide\\nGive Batch Transform Jobs Access\\nto Resources in Your Amazon VPC\\n•Create an Amazon S3 VPC Endpoint (p. 530)\\n•Use a Custom Endpoint Policy to Restrict Access to S3 (p. 530)\\n•Conﬁgure Route Tables (p. 531)\\n•Conﬁgure the VPC Security Group (p. 531)\\n•Connect to Resources Outside Your VPC (p. 531)\\nEnsure That Subnets Have Enough IP Addresses\\nYour VPC subnets should have at least two private IP addresses for each instance in a transform job. For\\nmore information, see VPC and Subnet Sizing for IPv4  in the Amazon VPC User Guide .\\nCreate an Amazon S3 VPC Endpoint\\nIf you conﬁgure your VPC so that model containers don\\'t have access to the internet, they can\\'t connect\\nto the Amazon S3 buckets that contain your data unless you create a VPC endpoint that allows access.\\nBy creating a VPC endpoint, you allow your model containers to access the buckets where you store your\\ndata and model artifacts . We recommend that you also create a custom policy that allows only requests\\nfrom your private VPC to access to your S3 buckets. For more information, see Endpoints for Amazon S3.\\nTo create an S3 VPC endpoint:\\n1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/.\\n2. In the navigation pane, choose Endpoints , then choose Create Endpoint\\n3. For Service Name, choose com.amazonaws.region .s3, where region is the name of the region\\nwhere your VPC resides.\\n4. For VPC, choose the VPC you want to use for this endpoint.\\n5. For Conﬁgure route tables, select the route tables to be used by the endpoint. The VPC service\\nautomatically adds a route to each route table you select that points any S3 traﬃc to the new\\nendpoint.\\n6. For Policy, choose Full Access to allow full access to the S3 service by any user or service within the\\nVPC. Choose Custom  to restrict access further. For information, see Use a Custom Endpoint Policy to\\nRestrict Access to S3 (p. 530).\\nUse a Custom Endpoint Policy to Restrict Access to S3\\nThe default endpoint policy allows full access to S3 for any user or service in your VPC. To further restrict\\naccess to S3, create a custom endpoint policy. For more information, see Using Endpoint Policies for\\nAmazon S3. You can also use a bucket policy to restrict access to your S3 buckets to only traﬃc that\\ncomes from your Amazon VPC. For information, see Using Amazon S3 Bucket Policies.\\nRestrict Package Installation on the Model Container\\nThe default endpoint policy allows users to install packages from the Amazon Linux and Amazon Linux\\n2 repositories on the training container. If you don\\'t want users to install packages from that repository,\\ncreate a custom endpoint policy that explicitly denies access to the Amazon Linux and Amazon Linux 2\\nrepositories. The following is an example of a policy that denies access to these repositories:\\n{ \\n    \"Statement\": [ \\n      { \\n        \"Sid\": \"AmazonLinuxAMIRepositoryAccess\",\\n        \"Principal\": \"*\",\\n        \"Action\": [ \\n            \"s3:GetObject\" \\n530Amazon SageMaker Developer Guide\\nGive Batch Transform Jobs Access\\nto Resources in Your Amazon VPC\\n        ],\\n        \"Effect\": \"Deny\",\\n        \"Resource\": [\\n            \"arn:aws:s3:::packages.*.amazonaws.com/*\",\\n            \"arn:aws:s3:::repo.*.amazonaws.com/*\"\\n        ] \\n      } \\n    ] \\n} \\n{ \\n    \"Statement\": [ \\n        { \"Sid\": \"AmazonLinux2AMIRepositoryAccess\",\\n          \"Principal\": \"*\",\\n          \"Action\": [ \\n              \"s3:GetObject\" \\n              ],\\n          \"Effect\": \"Deny\",\\n          \"Resource\": [\\n              \"arn:aws:s3:::amazonlinux.*.amazonaws.com/*\" \\n              ] \\n         } \\n    ] \\n} \\nConﬁgure Route Tables\\nUse default DNS settings for your endpoint route table, so that standard Amazon S3 URLs (for example,\\nhttp://s3-aws-region.amazonaws.com/MyBucket ) resolve. If you don\\'t use default DNS settings,\\nensure that the URLs that you use to specify the locations of the data in your batch transform jobs\\nresolve by conﬁguring the endpoint route tables. For information about VPC endpoint route tables, see\\nRouting for Gateway Endpoints in the Amazon VPC User Guide .\\nConﬁgure the VPC Security Group\\nIn distributed batch transform, you must allow communication between the diﬀerent containers in\\nthe same batch transform job. To do that, conﬁgure a rule for your security group that allows inbound\\nconnections between members of the same security group For information, see Security Group Rules.\\nConnect to Resources Outside Your VPC\\nIf you conﬁgure your VPC so that it doesn\\'t have internet access, batch transform jobs that use that VPC\\ndo not have access to resources outside your VPC. If your batch transform job needs access to resources\\noutside your VPC, provide access with one of the following options:\\n•If your batch transform job needs access to an AWS service that supports interface VPC endpoints,\\ncreate an endpoint to connect to that service. For a list of services that support interface endpoints,\\nsee VPC Endpoints  in the Amazon VPC User Guide . For information about creating an interface VPC\\nendpoint, see Interface VPC Endpoints (AWS PrivateLink) in the Amazon VPC User Guide .\\n•If your batch transform job needs access to an AWS service that doesn\\'t support interface VPC\\nendpoints or to a resource outside of AWS, create a NAT gateway and conﬁgure your security groups\\nto allow outbound connections. For information about setting up a NAT gateway for your VPC, see\\nScenario 2: VPC with Public and Private Subnets (NAT) in the Amazon Virtual Private Cloud User Guide.\\n531Amazon SageMaker Developer Guide\\nAre You a First-time User of Ground Truth?\\nAmazon SageMaker Ground Truth\\nTo train a machine learning model, you need a large, high-quality, labeled dataset. Ground Truth helps\\nyou build high-quality training datasets for your machine learning models. With Ground Truth, you can\\nuse workers from either Amazon Mechanical Turk, a vendor company that you choose, or an internal,\\nprivate workforce along with machine learning to enable you to create a labeled dataset. You can use the\\nlabeled dataset output from Ground Truth to train your own models. You can also use the output as a\\ntraining dataset for an Amazon SageMaker model.\\nIn order to automate labeling your training dataset, you can optionally use automated data labeling ,\\na Ground Truth process that uses machine learning to decide which data needs to be labeled by\\nhumans. Automated data labeling may reduce the labeling time and manual eﬀort required. For more\\ninformation, see Using Automated Data Labeling  (p. 539).\\nUse either pre-built or custom tools to assign the labeling tasks for your training dataset. A labeling UI\\ntemplate  is a webpage that Ground Truth uses to present tasks and instructions to your workers. The\\nAmazon SageMaker console provides built-in templates for labeling data. You can use these templates\\nto get started , or you can build your own tasks and instructions by using our HTML 2.0 components. For\\nmore information, see Creating Custom Labeling Workﬂows (p. 557).\\nUse the workforce of your choice to label your dataset. You can choose your workforce from:\\n•The Amazon Mechanical Turk workforce of over 500,000 independent contractors worldwide.\\n•A private workforce that you create from your employees or contractors for handling data within your\\norganization.\\n•A vendor company that you can ﬁnd in the AWS Marketplace that specializes in data labeling services.\\nFor more information, see Managing Your Workforce (p. 551).\\nYou store your datasets in Amazon S3 buckets. The buckets contain three things: The data to be labeled,\\nan input manifest ﬁle that Ground Truth uses to read the data ﬁles, and an output manifest ﬁle. The\\noutput ﬁle contains the results of the labeling job. For more information, see Using Input and Output\\nData  (p. 543).\\nEvents from your labeling jobs appear in Amazon CloudWatch under the /aws/sagemaker/\\nLabelingJobs  group. CloudWatch uses the labeling job name as the name for the log stream.\\nAre You a First-time User of Ground Truth?\\nIf you are a ﬁrst-time user of Ground Truth, we recommend that you do the following:\\n1.Read Getting started (p. 533)—This section walks you through setting up your ﬁrst Ground Truth\\nlabeling job.\\n2.Explore other topics—Depending on your needs, do the following:\\n•Create instruction pages for your labeling jobs—Create a custom instruction page that makes\\nit easier for your workers to understand the requirements of the job. For more information, see\\nCreating Instruction Pages (p. 549).\\n532Amazon SageMaker Developer Guide\\nGetting started\\n•Manage your labeling workforce—Create new work teams and manage your existing workforce.\\nFor more information, see Managing Your Workforce (p. 551).\\n•Create a custom UI —Make it easier for your workers to quickly and correctly label your data\\nby creating a custom UI for them to use. For more information, see Creating Custom Labeling\\nWorkﬂows (p. 557).\\n3.See the API Reference (p. 616)—This section describes operations to automate Ground Truth\\noperations.\\nGetting started\\nTo get started using Amazon SageMaker Ground Truth, follow the instructions in the following sections.\\nThe sections here explain how to use the console to create a labeling job, assign a public or private\\nworkforce, and send the labeling job to your workforce. You can also learn how to monitor the progress\\nof a labeling job.\\nIf you want to create a custom labeling job, see Creating Custom Labeling Workﬂows (p. 557) for\\ninstructions.\\nBefore you create a labeling job, you must upload your dataset to an Amazon S3 bucket. For more\\ninformation, see Using Input and Output Data  (p. 543).\\nTopics\\n•Step 1: Before You Begin (p. 533)\\n•Step 2: Create a Labeling Job (p. 534)\\n•Step 3: Select Workers (p. 535)\\n•Step 4: Conﬁgure the Bounding Box Tool. (p. 535)\\n•Step 5: Monitoring Your Labeling Job (p. 536)\\nStep 1: Before You Begin\\nBefore you begin using the Amazon SageMaker console to create a labeling job, you must set up the\\ndataset for use. Do this:\\n1. Save two images at publicly available HTTP URLs. The images are used when creating instructions\\nfor completing a labeling task. The images should have an aspect ratio of around 2:1. For this\\nexercise, the content of the images is not important.\\n2. Create an Amazon S3 bucket to hold the input and output ﬁles. The bucket must be in the same\\nRegion where you are running Ground Truth. Make a note of the bucket name because you use it\\nduring step\\xa02.\\n3. Place 5–10 PNG images in the bucket.\\n4. Create a manifest ﬁle for the dataset and store it in the S3 bucket. Use these steps:\\na. Using a text editor, create a new text ﬁle.\\nb. Add a line similar to the following for each image ﬁle in your dataset:\\n{\"source-ref\": \"s3://bucket/path/imageFile.png\"}\\nAdd one line for each PNG ﬁle in your S3 bucket.\\nc. Save the ﬁle in the S3 bucket containing your source ﬁles. Record the name because you use it\\nin step\\xa02.\\n533Amazon SageMaker Developer Guide\\nStep 2: Create a Labeling Job\\nNote\\nIt is not necessary to store the manifest ﬁle in the same bucket as the source ﬁle. You\\nuse the same bucket in this exercise because it is easier.\\nFor more information, see Input Data  (p. 543).\\nAssign the following permissions policy to the user that is creating the labeling job:\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"sagemakergroundtruth\",\\n            \"Effect\": \"Allow\",\\n            \"Action\": [\\n                \"cognito-idp:CreateGroup\",\\n                \"cognito-idp:CreateUserPool\",\\n                \"cognito-idp:CreateUserPoolDomain\",\\n                \"cognito-idp:AdminCreateUser\",\\n                \"cognito-idp:CreateUserPoolClient\",\\n                \"cognito-idp:AdminAddUserToGroup\",\\n                \"cognito-idp:DescribeUserPoolClient\",\\n                \"cognito-idp:DescribeUserPool\",\\n                \"cognito-idp:UpdateUserPool\"\\n            ],\\n            \"Resource\": \"*\"\\n        }\\n    ]\\n}\\nNext\\nStep 2: Create a Labeling Job (p. 534)\\nStep 2: Create a Labeling Job\\nIn this step you use the console to create a labeling job. You tell Amazon SageMaker Ground Truth the\\nAmazon S3 bucket where the manifest ﬁle is stored and conﬁgure the parameters for the job. For more\\ninformation about storing data in an Amazon S3 bucket, see Using Input and Output Data  (p. 543).\\nTo create a labeling job\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. From the left navigation, choose Labeling jobs .\\n3. Choose Create labeling job  to start the job creation process.\\n4. In the Job overview section, provide the following information:\\n•Job name  — Give the labeling job a name that describes the job. This name is shown in your job\\nlist. The name must be unique in your account in an AWS Region.\\n•Label attribute name — Leave this unchecked as the default value is the best option for this\\nintroductory job.\\n•Input dataset location — Enter the S3 location of the manifest ﬁle that you created in step\\xa01.\\n•Output dataset location — the location where your output data is written.\\n•IAM role — Create or choose an IAM role with the SageMakerFullAccess IAM policy attached.\\n5. In the Task type section, for the Dataset type ﬁeld, choose Bounding box as the task type.\\n534Amazon SageMaker Developer Guide\\nStep 3: Select Workers\\n6. Choose Next to move on to conﬁguring your labeling job.\\nNext\\nStep 3: Select Workers (p. 535)\\nStep 3: Select Workers\\nIn this step you choose a workforce for labeling your dataset. You can create your own private workforce\\nor you can use the Amazon Mechanical Turk workforce. If you create a private workforce in this step you\\nwon\\'t be able to import your Amazon Cognito user pool later. For more information, see Managing a\\nPrivate Workforce (p. 553). Use the Amazon Mechanical Turk workforce for this exercise instead.\\nYou can create a private workforce to test Amazon SageMaker Ground Truth. Use email addresses to\\ninvite the members of your workforce.\\nTo create a private workforce\\n1. In the Workers section, choose Private .\\n2. If this is your ﬁrst time using a private workforce, in the Email addresses  ﬁeld, enter up to 100\\nemail addresses. The addresses must be separated by a comma. You should include your own email\\naddress so that you are part of the workforce and can see data object labeling tasks.\\n3. In the Organization name  ﬁeld, enter the name of your organization. This information is used to\\ncustomize the email sent to invite a person to your private workforce.\\n4. In the Contact email ﬁeld enter an email address that members of the workforce use to report\\nproblems with the task.\\nIf you choose to use the Amazon Mechanical Turk workforce to label the dataset, you are charged for\\nlabeling tasks completed on the dataset.\\nTo use the Amazon Mechanical Turk workforce\\n1. In the Workers section, choose Public .\\n2. Choose The dataset does not contain PII to acknowledge that the dataset does not contain any\\npersonally identiﬁable information.\\n3. Choose The dataset does not contain adult content. to acknowledge that the sample dataset has\\nno adult content.\\n4. Review and accept the statement that the dataset will be viewed by the public workforce.\\nNext\\nStep 4: Conﬁgure the Bounding Box Tool. (p. 535)\\nStep 4: Conﬁgure the Bounding Box Tool.\\nFinally you conﬁgure the bounding box tool to give instructions to your workers. You can conﬁgure a\\ntask title that describes the task and provides high-level instructions for the workers. You can provide\\nboth quick instructions and full instructions. Quick instructions are displayed next to the image to be\\nlabeled. Full instructions contain detailed instructions for completing the task. In this example, you only\\nprovide quick instructions. You can see an example of full instructions by choosing Full instructions at\\nthe bottom of the section.\\n535Amazon SageMaker Developer Guide\\nStep 5: Monitoring Your Labeling Job\\nTo conﬁgure the bounding box tool\\n1. In the Task description ﬁeld type in brief instructions for the task. For example:\\nDraw a box around any objects in the image.\\nReplace objects with the name of an object that appears in your images.\\n2. In the Labels  ﬁeld, type a category name for the objects that the worker should draw a bounding\\nbox around. For example, if you are asking the worker to draw boxes around football players, you\\ncould use \"FootballPlayer\" in this ﬁeld.\\n3. The Short instructions section enables you to create instructions that are displayed on the page\\nwith the image that your workers are labeling. We suggest that you include an example of a\\ncorrectly drawn bounding box and an example of an incorrectly drawn box. To create your own\\ninstructions, use these steps:\\na. Select the text between GOOD EXAMPLE and the image placeholder. Replace it with the\\nfollowing text:\\nDraw the box around the object with a small border.\\nb. Select the ﬁrst image placeholder and delete it.\\nc. Choose the image button and then enter the HTTPS URL of one of the images that you created\\nin step\\xa01.\\nd. Select the text between BAD EXAMPLE and the image placeholder. Replace it with the following\\ntext:\\nDon\\'t make the bounding box too large or cut into the object.\\ne. Select the second image placeholder and delete it.\\nf.Choose the image button and then enter the HTTPS URL of the other image that you created in\\nstep\\xa01.\\nConﬁguration of your labeling job is complete. To start your job, choose Submit .\\nNext\\nStep 5: Monitoring Your Labeling Job (p. 536)\\nStep 5: Monitoring Your Labeling Job\\nAfter you create your labeling job, you see a list of all the jobs that you have created. You can use this list\\nto monitor that status of your labeling jobs. The list has the following ﬁelds:\\n•Name —The name that you assigned the job when you created it.\\n•Status —The completion status of the job. The status can be one of Complete, Failed, In progress, or\\nStopped.\\n•Labeled objects/total—Shows the total number of objects in the labeling job and how many of them\\nhave been labeled.\\n•Creation time —The date and time that you created the job.\\nYou can also clone, chain, or stop a job. Select a job and then select one of the following from the\\nActions menu:\\n•Clone—Creates a new labeling job with the conﬁguration copied from the selected job. You can clone\\na job when you want to change to the job and run it again. For example, you can clone a job that was\\n536Amazon SageMaker Developer Guide\\nData Labeling\\nsent to a private workforce so that you can send it to the Amazon Mechanical Turk workforce. Or you\\ncan clone a job to rerun it against a new dataset stored in the same location as the original job.\\n•Chain —Creates a new labeling job that can build upon the data and models (if any) of a stopped,\\nfailed, or completed job. For more information about the use cases and how to use it, see Chaining\\nlabeling jobs  (p. 540).\\n•Stop —Stops a running job. You cannot restart a stopped job. You can clone a job to start over or chain\\nthe job to continue from where it left oﬀ. Labels for any already labeled objects are written to the\\noutput ﬁle location. For more information, see Output Data  (p. 545).\\nData Labeling\\nAmazon SageMaker Ground Truth manages sending your data objects to workers to be labeled. Labeling\\neach data object is a task. Workers complete each task until the entire labeling job is complete. Ground\\nTruth divides the total number of tasks into smaller batches  that are sent to workers. A new batch is sent\\nto workers when the previous one is ﬁnished.\\nGround Truth provides two features that help improve the accuracy of your data labels and reduce the\\ntotal cost of labeling your data.\\nThe ﬁrst feature is annotation consolidation . This helps to improve the accuracy of your data object\\'s\\nlabels. It combines the results of multiple worker\\'s annotation tasks into one high-ﬁdelity label.\\nThe second feature is automated data labeling . This uses machine learning to label portions of your data\\nautomatically without having to send them to human workers.\\nTopics\\n•Batches for Labeling Tasks (p. 537)\\n•Annotation Consolidation  (p. 537)\\n•Using Automated Data Labeling  (p. 539)\\n•Chaining labeling jobs  (p. 540)\\nBatches for Labeling Tasks\\nAmazon SageMaker Ground Truth sends data objects to your workers in batches. There are one or more\\ntasks for each data object. For each task, a worker annotates one of your data objects. A batch provides\\nthe following:\\n•It sets the number of data objects that are available to workers. After the objects are annotated\\nanother batch is sent.\\n•It breaks the work into smaller chunks to avoid overloading your workforce.\\n•It provides chunks of data for the iterative training of automated labeling models.\\nGround Truth ﬁrst sends a batch of 10 tasks to your workers. It uses this small batch to set up the\\nlabeling job and to make sure that the job is correctly conﬁgured.\\nAfter the small batch, Ground Truth sends larger batches to your workers. You can conﬁgure the\\nbatch size when you create the job using the CreateLabelingJob (p. 643). When you use the Amazon\\nSageMaker console, your job uses 1,000 tasks in each batch.\\nAnnotation Consolidation\\nAnnotation consolidation combines the annotations of two or more workers into a single label for your\\ndata objects. An annotation  is the result of a single worker. Annotation consolidation  combines multiple\\n537Amazon SageMaker Developer Guide\\nAnnotation Consolidation\\nannotations from diﬀerent workers to come up with a probabilistic estimate of what the true label\\nshould be. The label  is assigned to each object in the dataset. Each object in the dataset typically has\\nmultiple annotations but only one label or set of labels.\\nYou can decide how many workers should annotate each object in your dataset. More workers can\\nincrease the accuracy of your labels but also increases the cost of labeling. Amazon SageMaker\\nGround Truth uses the following defaults in the Amazon SageMaker console. When you use the\\nCreateLabelingJob (p. 643) operation, you set the number of workers that should annotate each data\\nobject using the NumberOfHumanWorkersPerDataObject  parameter.\\n•Text classiﬁcation—3 workers\\n•Image classiﬁcation —3 workers\\n•Bounding boxes—5 workers\\n•Semantic segmentation —3 workers\\n•Named entity recognition—3 workers\\nYou can override the default number of workers that label a data object using the console or the\\nCreateLabelingJob (p. 643) operation.\\nGround Truth provides an annotation consolidation function for each of its predeﬁned labeling tasks:\\nBounding box, image classiﬁcation, semantic segmentation, and text classiﬁcation. These are the\\nfunctions:\\n•Multi-class annotation consolidation for image and text classiﬁcation uses a variant of the Expectation\\nMaximization approach to annotations. It estimates parameters for each worker and uses Bayesian\\ninference to estimate the true class based on the class annotations from individual workers.\\n•Bounding box annotation consolidates bounding boxes from multiple workers. This function ﬁnds the\\nmost similar boxes from diﬀerent workers based on the Jaccard index, or intersection over union, of\\nthe boxes and averages them.\\n•Semantic segmentation annotation consolidation treats each pixel in a single image as a multi-\\nclass classiﬁcation. This function treats the pixel annotations from workers as \"votes,\" with more\\ninformation from surrounding pixels incorporated by applying a smoothing function to the image.\\n•Named entity recognition clusters text selections by Jaccard similarity and calculates selection\\nboundaries based on the mode, or median if the mode isn\\'t clear. The label resolves to the most\\nassigned entity label in the cluster, breaking ties by random selection.\\nNote\\nIf you want to run worker responses through diﬀerent algorithms on your own, that data is\\nstored in the [project-name] /annotations/worker-response  folder of the Amazon S3\\nbucket where you direct the job output.\\nCreating Your Own Annotation Consolidation Function\\nThere are many possible approaches for writing an annotation consolidation function. The approach\\nthat you take depends on the nature of the annotations to consolidate. Broadly, consolidation functions\\nlook at the annotations from workers, measure the similarity between them, and then use some form of\\nprobabilistic judgment to determine what the most probable label should be.\\nAssessing Similarity\\nTo assess the similarity between labels, you can use one of the following strategies or you can use one\\nthat meets your data labeling needs:\\n•For label spaces that consist of discrete, mutually exclusive categories, such as multi-class\\nclassiﬁcation, assessing similarity can be straightforward. Discrete labels either match or not.\\n538Amazon SageMaker Developer Guide\\nUsing Automated Data Labeling\\n•For label spaces that don\\'t have discrete values, such as bounding box annotations, ﬁnd a broad\\nmeasure of similarity. For bounding boxes, one such measure is the Jaccard index. This measures\\nthe ratio of the intersection of two boxes with the union of the boxes to assess how similar they\\nare. For example, if there are three annotations, then there can be a function that determines\\nwhichannotations represent the same object and should be consolidated.\\nAssessing the Most Probable Label\\nWith one of the above strategies in mind, make some sort of probabilistic judgment on what the\\nconsolidated label should be. In the case of discrete, mutually exclusive categories this can be\\nstraightforward. One of the most common ways to do this is to take the results of a majority vote\\nbetween the annotations. This weights the annotations equally.\\nSome approaches attempt to estimate the accuracy of diﬀerent annotators and weight their annotations\\nin proportion to the probability of correctness. An example of this is the Expectation Maximization\\nmethod, which is used in the default Ground Truth consolidation function for multi-class annotations.\\nFor more information about creating an annotation consolidation function, see Step 3: Processing with\\nAWS Lambda (p. 574).\\nUsing Automated Data Labeling\\nGround Truth can use active learning  to automate the labeling of your input data. Active learning is a\\nmachine learning technique that identiﬁes data that should be labeled by your workers.\\nAutomated data labeling is optional. Turn it on when you create a labeling job. Automated data labeling\\nincurs Amazon SageMaker training and inference costs, but it helps to reduce the cost and time that it\\ntakes to label your dataset compared to humans alone.\\nUse automated data labeling on large datasets. The neural networks used with active learning require\\na signiﬁcant amount of data for every new dataset. With larger datasets, there is more potential to\\nautomatically label the data and therefore reduce the total cost of labeling. We recommend that you use\\nthousands of data objects when using automated data labeling. The system minimum for automated\\nlabeling is 1,250 objects, but to get a meaningful amount of your data automatically labeled, we\\nstrongly suggest a minimum with 5,000 or more objects.\\nThe potential beneﬁt of automated data labeling also depends on the accuracy that you require. Higher\\naccuracy levels generally reduce the number of data objects that are automatically labeled.\\nWhen Amazon SageMaker Ground Truth starts an automated data labeling job, it ﬁrst selects a random\\nsample of the input data. Then it sends the sample to human workers. When the labeled data are\\nreturned, Ground Truth uses this set of data as validation data. It is used to validate the machine learning\\nmodels that Ground Truth trains for automated data labeling.\\nNext, Ground Truth runs an Amazon SageMaker batch transform using the validation set. This generates\\na quality metric that Ground Truth uses to estimate the potential quality of auto-labeling the rest of the\\nunlabeled data.\\nGround Truth next runs an Amazon SageMaker batch transform on the unlabeled data in the dataset.\\nAny data where the expected quality of automatically labeling the data is above the requested level of\\naccuracy is considered labeled.\\nAfter performing the auto-labeling step, Ground Truth selects a new sample of the most ambiguous\\nunlabeled data points in the dataset. It sends those to human workers. Ground Truth uses the existing\\nlabeled data and this additional labeled data from human workers to train a new model. The process is\\nrepeated until the dataset is fully labeled.\\n539Amazon SageMaker Developer Guide\\nChaining labeling jobs\\nFor automated semantic segmentation, please note these job limits\\n•Label Categories (max): 20\\n•Dataset Size (max): 20k items\\n•Image Resolution (max): 720p (1280 x 720 pixels)\\nEnsure the automated-labeling model is ready for production use\\nThe model generatphoneed by your labeling job needs ﬁne-tuning and/or testing before\\nyou use it in production. Fine-tune the model generated by Ground Truth (or create and\\ntune another supervised model of your choice) on the dataset produced by your labeling job.\\nOptimize the model’s architecture and hyperparameters. If you decide to use the model for\\ninference without ﬁne-tuning, we strongly recommend making sure its accuracy is evaluated on\\na representative (e.g. randomly selected) subset of the dataset labeled with Ground Truth and\\nmatches your expectations.\\nAmazon EC2 Instances Required for Automated Data Labeling\\nTo run automated data labeling, Ground Truth requires the following Amazon EC2 resources for training\\nand batch inference jobs:\\nAutomated labeling action Training instance type Inference instance type\\nImage classiﬁcation ml.p3.2xlarge* ml.c5.xlarge\\nObject detection ml.p3.2xlarge* ml.c5.4large\\nText classiﬁcation ml.c5.2xlarge ml.m4.xlarge\\nSemantic Segmentation ml.p3.2xlarge* ml.p3.2xlarge*\\n* ml.p2.8xlarge is substituted in the following regions: Mumbai (ap-south-1)\\nA note about pricing\\nAutomated labeling incurs two separate charges: the per item charge (Ground Truth pricing),\\nand the charge for the Amazon EC2 instance required to run the model (Amazon EC2 pricing).\\nThese instances are managed by Ground Truth. They are created, conﬁgured, and destroyed as needed to\\nperform your job. They do not appear in your Amazon EC2 instance dashboard.\\nChaining labeling jobs\\nAmazon SageMaker Ground Truth can reuse datasets from prior jobs in two ways: cloning and chaining.\\nCloning is a relatively straightforward operation. Cloning copies the set-up of a prior labeling job and\\nallows you to make additional changes, before setting it to run.\\nChaining is a more complex operation. Chaining uses not only the setup of the prior job, but the results.\\nThis allows you to continue an incomplete job,and add labels or data objects to a completed job.\\nWhen it comes to the data being processed:\\n•Cloning — uses the prior job\\'s input  manifest as the new job\\'s input manifest.\\n•Chaining  — uses the prior job\\'s output  manifest as the new job\\'s input manifest.\\n540Amazon SageMaker Developer Guide\\nChaining labeling jobs\\nChaining labeling jobs\\nSome situations where chaining is useful include:\\n•Continue a labeling job that was manually stopped.\\n•Continue a labeling job that failed mid-job, with issues ﬁxed..\\n•Switch to automated labeling after manually labeling part of a job (or vice-versa).\\n•Add more data objects to a completed job and start the job from there.\\n•Add another annotation to a completed job. For example, you have a collection of phrases labeled for\\ntopic, then want to run the set again, categorizing them by the topic\\'s implied audience.\\nIn Amazon SageMaker Ground Truth you can conﬁgure a chained labeling job via either the console or\\nAPI.\\nKey Term: Label attribute name\\nThe label attribute name (LabelAttributeName  in the API) is a string used as the key for the key-value\\npair formed with the label that a worker assigns to the data object.\\nThere are a few rules for the label attribute name.\\n•It cannot end with -metadata .\\n•The names source  and source-ref  are reserved and cannot be used.\\n•Semantic-segmentation labeling jobs require it to end with -ref. All other labeling jobs require it to\\nnot end with -ref . The adding of -ref is managed automatically for you in jobs conﬁgured via the\\nconsole.\\n•If you\\'re using the same label attribute name from the originating job and you conﬁgure the chained\\njob to use auto-labeling, then if it had been in auto-labeling mode at any point, the model from the\\noriginating job is used.\\nIn an output manifest, it can appear something like this:\\n  \"source-ref\": \"< S3 URI>\",\\n  \"<label attribute name >\": {\\n    \"annotations\": [{\\n      \"class_id\": 0,\\n      \"width\": 99,\\n      \"top\": 87,\\n      \"height\": 62,\\n      \"left\": 175\\n    }],\\n    \"image_size\": [{\\n      \"width\": 344,\\n      \"depth\": 3,\\n      \"height\": 234\\n    }]\\n  },\\n  \"<label attribute name >-metadata\": {\\n    \"job-name\": \"< job name >\",\\n    \"class-map\": {\\n      \"0\": \"< label attribute name >\"\\n    },\\n    \"human-annotated\": \"yes\",\\n    \"objects\": [{\\n      \"confidence\": 0.09\\n    }],\\n    \"creation-date\": \"< timestamp >\",\\n541Amazon SageMaker Developer Guide\\nChaining labeling jobs\\n    \"type\": \"groundtruth/object-detection\"\\n  }\\nIf you\\'re creating a job in the console, the job name is used as the label attribute name for the job if you\\ndon\\'t explicitly set the label attribute name value.\\nStarting a chained job in the console\\nSelect a stopped, failed, or completed labeling job from the list of your existing jobs. This enables the\\nActions menu.\\nFrom the Actions menu, select Chain .\\nJob overview panel\\nIn the Job overview panel, a new Job name  is set based on the title of the job from which you are\\nchaining this one. You can change it.\\nYou may also specify a label attribute name diﬀerent from the labeling job name.\\nIf you\\'re chaining from a completed job, the label attribute name uses the name of the new job you\\'re\\nconﬁguring. To change the name, select the check box.\\nIf you\\'re chaining from a stopped or failed job, the label attribute name uses to the name of the job from\\nwhich you\\'re chaining. Its easy to see and edit the value because the name check box is checked.\\nAttribute label naming considerations\\n•The default  uses the label attribute name Ground Truth has selected. All data objects without\\ndata connected to that label attribute name are labeled.\\n•Using a label attribute name not present in the manifest causes the job to process all the\\nobjects in the dataset.\\nThe input dataset location in this case is automatically selected as the output manifest of the chained\\njob. The input ﬁeld is not available, so you cannot change it.\\nAdding data objects to a labeling job\\nYou cannot specify an alternate manifest ﬁle. Manually edit the output manifest from the\\nprevious job to add new items before starting a chained job. The S3 URI helps you locate where\\nyou are storing the manifest in your S3 bucket. Download the manifest ﬁle from there, edit\\nit locally on your computer, then upload the new version to replace it. Make sure you are not\\nintroducing errors during editing. We recommend you use JSON linter to check your JSON. Many\\npopular text editors and IDEs have linter plugins available.\\nStarting a chained job with the API\\nThe procedure is almost the same as setting up a new labeling job with CreateLabelingJob , except for\\ntwo primary diﬀerences.\\n•Manifest location: Rather than use your original manifest from the prior job, the value for the\\nManifestS3Uri  in the DataSource  should point to the S3 URI of the output manifest  from the prior\\nlabeling job.\\n•Label attribute name: Setting the correct LabelAttributeName  value is important here. As pointed\\nout, this is the key portion of a key-value pair where labeling data is the value. Sample use cases\\ninclude:\\n•Adding new or more-speciﬁc labels to a completed job — set a new label attribute name.\\n•Labeling the unlabeled items from a prior job — use the label attribute name from the prior job.\\n542Amazon SageMaker Developer Guide\\nUsing Input and Output Data\\nUsing a partially labeled dataset\\nYou can get some chaining beneﬁts if you use an augmented manifest that has already been partially\\nlabeled. Check the Label attribute name check box and set the name so that it matches the name in\\nyour manifest.\\nIf you\\'re using the API, the instructions are the same as starting a chained job. However, be sure to\\nupload your manifest to an S3 bucket and use it instead of using the output manifest from a prior job.\\nThe Label attribute name value in the manifest has to conform to the naming considerations discussed\\nabove.\\nUsing Input and Output Data\\nThe input data that your provide Amazon SageMaker Ground Truth is sent to your workers for labeling.\\nYou can choose the data to send to your workers by creating a manifest ﬁle that deﬁnes the data to\\nlabel.\\nThe output data is the result of your labeling job. The output data ﬁle contains one entry that speciﬁes\\nthe label for each object in the input dataset.\\nTopics\\n•Input Data  (p. 543)\\n•Output Data  (p. 545)\\nInput Data\\nThe input data are the data objects that you send to your workforce to be labeled. Each object in the\\ninput data is described in a manifest ﬁle. Each line in the manifest is an entry containing an object to\\nlabel and may contain labels from previous jobs.\\n•The input data is stored in an Amazon S3 bucket. The bucket must be in the same region as you are\\nrunning Amazon SageMaker Ground Truth. You must give access to Amazon SageMaker for the data\\nto be read. In order to read the data, give access to Amazon SageMaker. For more information about\\nAmazon S3 buckets, see  Working with Amazon S3 buckets.\\n•The manifest ﬁle must be in the same region the data ﬁles but does not need to be in the same\\nlocation as the data ﬁles. It can be in any Amazon S3 bucket accessible to the role that you\\nassigned to Ground Truth when you created the labeling job with either the console or the\\nCreateLabelingJob (p. 643) operation.\\nThe manifest is a UTF-8 encoded ﬁle where each line is a complete and valid JSON object. Each line is\\ndelimited by a standard line break, \\\\n or \\\\r\\\\n. Since each line must be a valid JSON object, you can\\'t have\\nunescaped line break characters. For more information about the data format, see JSON Lines.\\nLimits:  Each JSON object in the manifest ﬁle can be no larger than 100k characters and no single\\nattribute within the object can be larger than 20,000 characters. Attribute names cannot begin with $\\n(dollar sign).\\nEach JSON object in the manifest ﬁle must contain a key, either source-ref  or source . The value of\\nthe keys are interpreted as follows:\\n•source-ref—The source of the object is the S3 object speciﬁed in the value. This can be used when the\\nobject is a binary object, such as an image, or when you have text in individual ﬁles.\\n•source—The source of the object is the value. This can be used when the object is a text value.\\n543Amazon SageMaker Developer Guide\\nInput Data\\nYou use the source-ref  key for image ﬁles for a bounding box or semantic segmentation labeling job.\\nEach image ﬁle must be:\\n•6 Mb or smaller\\n•1920 x 1080 pixels or smaller for semantic segmentation\\nThe following is an example of a manifest ﬁle for ﬁles stored in an S3 bucket:\\n{\"source-ref\": \" S3 bucket location 1 \"} \\n{\"source-ref\": \" S3 bucket location 2 \"} \\n   ... \\n{\"source-ref\": \" S3 bucket location n \"} \\nThe following is an example of a manifest ﬁle with the input data stored in the manifest:\\n{\"source\": \"Lorem ipsum dolor sit amet\"} \\n{\"source\": \"consectetur adipiscing elit\"}\\n   ...\\n{\"source\": \"mollit anim id est laborum\"} \\nYou can include other key-value pairs in the manifest ﬁle. These pairs are passed to the output ﬁle\\nunchanged. This is useful when you want to pass information between your applications. For more\\ninformation, see Output Data  (p. 545).\\nFiltering and Selecting Data (Console)\\nYou can use the Amazon SageMaker console to select a portion of your dataset for labeling. The data\\nmust be stored in an Amazon S3 bucket. You have three options:\\n•Use the full dataset.\\n•Choose a randomly selected sample of the dataset.\\n•Specify a subset of the dataset using a query.\\nUsing the Full Dataset\\nWhen you choose to use the full dataset you must provide a manifest ﬁle for your data objects. You\\ncan provide the S3 bucket location of the manifest ﬁle or you can have the Amazon SageMaker console\\ncreate the ﬁle for you. Choose Create a manifest ﬁle to create the ﬁle. The ﬁle is stored in the S3 bucket\\nspeciﬁed in the Input data location ﬁeld.\\nChoosing a Random Sample\\nUse a random sample of your dataset when you want to label a random subset of your data. The dataset\\nis stored in the S3 bucket speciﬁed in the  Input dataset location  ﬁeld.\\nOnce you have speciﬁed the percentage of data objects that you want to include in the sample, choose\\nCreate subset . The Amazon SageMaker console randomly picks the data objects for your labeling job.\\nOnce the objects are selected, choose Use this subset .\\nThe Amazon SageMaker console create a manifest ﬁle for the selected data objects. The Input dataset\\nlocation ﬁeld is modiﬁed to point to the new manifest ﬁle.\\nSpecifying a Subset\\nYou can specify a subset of your data objects using an Amazon S3 SELECT query on the object ﬁle\\nnames.\\n544Amazon SageMaker Developer Guide\\nOutput Data\\nThe SELECT statement of the SQL query is deﬁned for you. You provide the WHERE clause to specify\\nwhich data objects should be returned.\\nFor more information about the Amazon S3 SELECT  statement, see  Selecting Content from Objects\\nChoose Create subset  to start the selection, and then choose Use this subset  to use the selected data.\\nThe Amazon SageMaker console create a manifest ﬁle for the selected data objects. The Input dataset\\nlocation ﬁeld is modiﬁed to point to the new manifest ﬁle.\\nOutput Data\\nThe output from a labeling job is placed in the location that you speciﬁed in the console or in the call to\\nthe CreateLabelingJob (p. 643) operation.\\nEach line in the output data ﬁle is identical to the manifest ﬁle with the addition of an attribute and\\nvalue for the label assigned to the input object. The attribute name for the value is deﬁned in the\\nconsole or in the call to the CreateLabelingJob  operation. You can\\'t use -metadata  in the label\\nattribute name. If you are running a semantic segmentation job, the label attribute must end with -ref .\\nFor any other type of job, the attribute name can\\'t end with -ref .\\nThe output of the labeling job is the value of the key/value pair with the label. The label and the value\\noverwrites any existing JSON data in the input ﬁle with the new value.\\nFor example, the following is the output from an image classiﬁcation labeling job where the input data\\nﬁles were stored in an Amazon S3 bucket and the label attribute name was deﬁned as \"sport\". In this\\nexample the JSON object is formatted for readability, in the actual output ﬁle the JSON object is on a\\nsingle line. For more information about the data format, see JSON Lines.\\n{\\n    \"source-ref\": \" S3 bucket location \",\\n    \"sport\":0,\\n    \"sport-metadata\": \\n    {\\n        \"class-name\": \"football\",\\n        \"confidence\": 0.8,\\n        \"type\":\"groundtruth/image-classification\",\\n        \"job-name\": \"identify-sport\",\\n        \"human-annotated\": \"yes\",\\n        \"creation-date\": \"2018-10-18T22:18:13.527256\"\\n    }\\n}\\nThe value of the label can be any valid JSON. In this case the label\\'s value is the index of the class in the\\nclassiﬁcation list. Other job types, such as bounding box, have more complex values.\\nAny key-value pair in the input manifest ﬁle other than the label attribute is unchanged in the output\\nﬁle. You can use this to pass data to your application.\\nThe output from a labeling job can be used as the input to another labeling job. You can use this when\\nyou are chaining together labeling jobs. For example, you can send one labeling job to determine the\\nsport that is being played. Then you send another using the same data to determine if the sport is being\\nplayed indoors or outdoors. By using the output data from the ﬁrst job as the manifest for the second\\njob, you can consolidate the results of the two jobs into one output ﬁle for easier processing by your\\napplications.\\nThe output data ﬁle is written to the output location periodically while the job is in progress. These\\nintermediate ﬁles contain one line for each line in the manifest ﬁle. If an object is labeled, the label is\\n545Amazon SageMaker Developer Guide\\nOutput Data\\nincluded, if the object has not been labeled it is written to the intermediate output ﬁle identically to the\\nmanifest ﬁle.\\nOutput Directories\\nGround Truth creates several directories in your Amazon S3 output path. These directories contain the\\nresults of your labeling job and other artifacts of the job. The top-level directory for a labeling job is\\ngiven the same name as your labeling job, the output directories are placed beneath it. For example, if\\nyou named your labeling job find-people  you output would be in the following directories:\\ns3://bucket/find-people/activelearning\\ns3://bucket/find-people/annotations                \\ns3://bucket/find-people/inference\\ns3://bucket/find-people/manifests\\ns3://bucket/find-people/training\\n            \\nEach directories contain the following output:\\nactivelearning Directory\\nThe activelearning  directory is only present when you are using automated data labeling. It contains\\nthe input and output validation set for automated data labeling, and the input and output folder for\\nautomatically labeled data.\\nannotations Directory\\nThe annotations  directory contains all of the annotations made by the workforce. These are the\\nresponses from individual workers that have not been consolidated into a single label for the data object.\\nThere are three subdirectories in the annotations  directory. The ﬁrst, worker-response  contains the\\nresponses from individual workers. There may be more than one annotation for each data object in this\\ndirectory, depending on how many workers you want to annotate each object.\\nThe second, consolidated-annotation  contains information required to consolidate the annotations\\nin the current batch into labels for your data objects.\\nThe third, intermediate , contains the output manifest for the current batch with any completed labels.\\nThis ﬁle is updated as the label for each data object is completed.\\ninference Directory\\nThe inference  directory contains the input and output ﬁles for the Amazon SageMaker batch\\ntransform used while labeling data objects.\\nmanifest Directory\\nThe manifest  directory contains the output manifest from your labeling job. There are two\\nsubdirectories in the manifest directory, output  and intermediate . The output directory contains the\\noutput manifest ﬁle for your labeling job. The ﬁle is named output.manifest .\\nThe other directory, intermediate , contains the results of labeling each batch of data objects. The\\nintermediate data is in a directory numbered for each iteration. An iteration directory contains an\\noutput.manifest ﬁle that contains the results of that iteration and all previous iterations.\\nintermediate Directory\\nThe training  directory contains the input and output ﬁles used to train the automated data labeling\\nmodel.\\n546Amazon SageMaker Developer Guide\\nOutput Data\\nConﬁdence Score\\nGround Truth calculates a conﬁdence score for each label. A conﬁdence score  is a number between 0 and\\n1 that indicates how conﬁdent Ground Truth is in the label. You can use the conﬁdence score to compare\\nlabeled data objects to each other, and to identify the least or most conﬁdent labels.\\nYou should not interpret the value of the conﬁdence scores as an absolute value, or compare them across\\nlabeling jobs. For example, if all of the conﬁdence scores are between 0.98 and 0.998, you should only\\ncompare the data objects with each other and not rely on the high conﬁdence scores.\\nYou should not compare the conﬁdence scores of human-labeled data objects and auto-labeled data\\nobjects. The conﬁdence scores for humans are calculated using the annotation consolidation function for\\nthe task, the conﬁdence scores for automated labeling are calculated using a model that incorporates\\nobject features. The two models generally have diﬀerent scales and average conﬁdence.\\nFor a bounding box labeling job, Ground Truth calculates a conﬁdence score per box. You can compare\\nconﬁdence scores within one image or across images for the same labeling type (human or auto). You\\ncan\\'t compare conﬁdence scores across labeling jobs.\\nOutput Metadata\\nThe output from each job contains metadata about the label assigned to data objects. These elements\\nare the same for all jobs with minor variations. The following are the metadata elements:\\n    \"confidence\": 0.93, \\n    \"type\": \"groundtruth/image-classification\", \\n    \"job-name\": \"identify-animal-species\",\\n    \"human-annotated\": \"yes\", \\n    \"creation-date\": \"2018-10-18T22:18:13.527256\"\\nThe elements have the following meaning:\\n•confidence  — The conﬁdence that Ground Truth has that the label is correct. For more information,\\nsee Conﬁdence Score (p. 547).\\n•type — The type of classiﬁcation job. For job types, see the descriptions of the individual job types.\\n•job-name  — The name assigned to the job when it was created.\\n•human-annotated  — Indicates whether the data object was labeled by a human or by automated\\ndata labeling. For more information, see Using Automated Data Labeling  (p. 539).\\n•creation-date — The date and time that the label was created.\\nClassiﬁcation Job Output\\nThe following are sample output from an image classiﬁcation job and a text classiﬁcation job. It includes\\nthe label that Ground Truth assigned to the data object, the value for the label, and metadata that\\ndescribes the labeling task.\\nIn addition to the standard metadata elements, the metadata for a classiﬁcation job includes the text\\nvalue of the label\\'s class. For more information, see Image Classiﬁcation Algorithm  (p. 108).\\n{\\n    \"source-ref\":\" S3 bucket location \", \\n    \"species\":\"0\",    \\n    \"species-metadata\":  \\n    {\\n        \"class-name\": \"dog\", \\n        \"confidence\": 0.93, \\n        \"type\": \"groundtruth/image-classification\", \\n547Amazon SageMaker Developer Guide\\nOutput Data\\n        \"job-name\": \"identify-animal-species\",\\n        \"human-annotated\": \"yes\", \\n        \"creation-date\": \"2018-10-18T22:18:13.527256\"\\n    }\\n}\\n{\\n    \"source\":\"a bad day\", \\n    \"mood\":\"1\", \\n    \"mood-metadata\": \\n    {\\n        \"class-name\": \"sad\", \\n        \"confidence\": 0.8, \\n        \"type\": \"groundtruth/text-classification\", \\n        \"job-name\": \"label-mood\",\\n        \"human-annotated\": \"yes\", \\n        \"creation-date\": \"2018-10-18T22:18:13.527256\"\\n    }\\n}\\nBounding Box Job Output\\nThe following is sample output from a bounding box job. For this task, there are three bounding boxes\\nreturned. The value of the label contains information about the size of the image, and the location of the\\nbounding boxes.\\nThe class_id  element is the index of the box\\'s class in the list of available classes for the task. You can\\nsee the text of the class in the class-map  metadata element.\\nIn the metadata there is a separate conﬁdence score for each bounding box. The metadata also includes\\nthe class-map  element that maps the class_id  to the text value of the class. For more information,\\nsee Object Detection Algorithm (p. 199).\\n{\\n    \"source-ref\": \" S3 bucket location \",\\n    \"bounding-box\": \\n    {\\n        \"image_size\": [{ \"width\": 500, \"height\": 400, \"depth\":3}],\\n        \"annotations\": \\n        [\\n            {\"class_id\": 0, \"left\": 111, \"top\": 134,\\n                    \"width\": 61, \"height\": 128},\\n            {\"class_id\": 5, \"left\": 161, \"top\": 250,\\n                     \"width\": 30, \"height\": 30}, \\n            {\"class_id\": 5, \"left\": 20, \"top\": 20,\\n                     \"width\": 30, \"height\": 30}\\n        ]\\n    },\\n    \"bounding-box-metadata\":\\n    {\\n        \"objects\":  \\n        [\\n            {\"confidence\": 0.8},\\n            {\"confidence\": 0.9},\\n            {\"confidence\": 0.9}\\n        ], \\n        \"class-map\": \\n        {\\n            \"0\": \"dog\",\\n            \"5\": \"bone\"\\n        },\\n        \"type\": \"groundtruth/object_detection\",\\n548Amazon SageMaker Developer Guide\\nCreating Instruction Pages\\n        \"human-annotated\": \"yes\", \\n        \"creation-date\": \"2018-10-18T22:18:13.527256\",\\n        \"job-name\": \"identify-dogs-and-toys\"        \\n    }\\n }      \\nFor an example notebook, see object_detection_augmented_manifest_training.ipynb\\nSemantic Segmentation Job Output\\nThe following is the output from a semantic segmentation labeling job. The value of the label for this job\\nis a reference to a PNG ﬁle in an S3 bucket.\\nIn addition to the standard elements, the metadata for the label includes a color map that deﬁnes which\\ncolor was used to label the image, the class name associated with the color, and the conﬁdence score for\\neach color. For more information, see Semantic Segmentation Algorithm  (p. 234).\\n{\\n    \"source-ref\": \" S3 bucket location \", \\n    \"city-streets-ref\": \" S3 bucket location \", \\n    \"city-streets-metadata\": {\\n      \"internal-color-map\": {          \\n        \"5\": {                    \\n           \"class-name\": \"buildings\", \\n           \"confidence\": 0.9 \\n        },\\n        \"2\":  {                   \\n           \"class-name\": \"road\", \\n           \"confidence\": 0.9  \\n       }           \\n     },\\n     \"type\": \"groundtruth/semantic-segmentation\",\\n     \"human-annotated\": \"yes\",\\n     \"creation-date\": \"2018-10-18T22:18:13.527256\",\\n     \"job-name\": \"label-city-streets\",\\n     }\\n}\\nConﬁdence scores will be the same across all classes within an image. Conﬁdence is scored on a per-\\nimage basis.\\nAfter you create an augmented manifest ﬁle, you can use it in a training job. For more information, see\\nProvide Dataset Metadata to Training Jobs with an Augmented Manifest File (p. 308).\\nCreating Instruction Pages\\nCreate custom instructions for labeling jobs to improve your worker\\'s accuracy in completing their task.\\nYou can modify the default instructions that are provided in the console or you can create your own. The\\ninstructions are shown to the worker on the page where they complete their labeling task.\\nThere are two kinds of instructions:\\n•Short instructions—instructions that are shown on the same webpage where the worker completes\\ntheir task. These instructions should provide an easy reference to show the worker the correct way to\\nlabel an object.\\n•Full instructions—instructions that are shown on a dialog box that overlays the page where the worker\\ncompletes their task. We recommend that you provide detailed instructions for completing the task\\nwith multiple examples showing edge cases and other diﬃcult situations for labeling objects.\\n549Amazon SageMaker Developer Guide\\nShort Instructions\\nCreate instructions in the console when you are creating your labeling job. Start with the existing\\ninstructions for the task and use the editor to modify them to suit your labeling job.\\nShort Instructions\\nShort instructions appear on the same webpage that workers use to label your data object. For example,\\nthe following is the editing page for a bounding box task. The short instructions panel is on the left.\\nKeep in mind that a worker will only spend seconds looking at the short instructions. Workers must be\\nable to scan and understand your information quickly. In all cases it should take less time to understand\\nthe instructions than it takes to complete the task. Keep these points in mind:\\n•Your instructions should be clear and simple.\\n•Pictures are better than words. Create a simple illustration of your task that your workers can\\nimmediately understand.\\n•If you must use words, use short, concise examples.\\n•Your short instructions are more important than your full instructions.\\nThe Amazon SageMaker Ground Truth console provides an editor so that you can create your short\\ninstructions. Replace the placeholder text and images with instructions for your task. Preview the\\nworker\\'s task page by choosing Preview . The preview will open in a new window, be sure to turn oﬀ pop-\\nup blocking so that the window will show.\\n550Amazon SageMaker Developer Guide\\nFull Instructions\\nFull Instructions\\nYou can provide additional instructions for your workers in a dialog box that overlays the page where\\nworkers label your data objects. Use full instructions to explain more complex tasks and to show workers\\nthe proper way to label edge cases or other diﬃcult objects.\\nYou can create full instructions using an editor in the Ground Truth console. As with quick instructions,\\nkeep the following in mind:\\n•Workers will want detailed instruction the ﬁrst few times that the complete your task. Any information\\nthat they must  have should be in the quick instructions.\\n•Pictures are more important than words.\\n•Text should be concise.\\n•Full instructions should supplement the short instructions. Don\\'t repeat information that appears in\\nthe short instructions.\\nThe Ground Truth console provides an editor so that you can create your full instructions. Replace the\\nplaceholder text and images with instructions for your task. Preview the full instruction page by choosing\\nPreview . The preview will open in a new window, be sure to turn oﬀ pop-up blocking so that the window\\nwill show.\\nAdd example images to your instructions\\nImages provide useful examples for your workers. To add a publicly accessible image to your instructions:\\n•Place the cursor where the image should go in the instructions editor.\\n•Click the image icon in the editor toolbar.\\n•Enter the URL of your image.\\nIf your instruction image in Amazon S3 is not publicly accessible:\\n•As the image URL, enter: {{ \\'https://s3.amazonaws.com/ your-bucket-name /image-file-\\nname\\' | grant_read_access }} .\\n•This renders the image URL with a short-lived, one-time access code appended so the worker\\'s browser\\ncan display it. A broken image icon is displayed in the instructions editor, but previewing the tool\\ndisplays the image in the rendered preview.\\nManaging Your Workforce\\nA workforce  is the group of workers that you have selected to label your dataset. You can choose either\\nthe Amazon Mechanical Turk workforce, a vendor-managed workforce, or you can create your own\\nprivate workforce to label your dataset. Whichever you choose, Amazon SageMaker Ground Truth takes\\ncare of sending tasks to workers.\\nWhen you use a private workforce, you also create work teams , a group of workers from your workforce\\nthat are assigned to speciﬁc labeling jobs. You can have multiple work teams and can assign one or more\\nwork teams to each labeling job.\\nGround Truth uses Amazon Cognito to manage your workforce and work teams. For more information\\nabout the permissions required to manage this way, see Permissions Required to Use the Amazon\\nSageMaker Ground Truth Console (p. 484).\\nTopics\\n551Amazon SageMaker Developer Guide\\nUsing the Amazon Mechanical Turk Workforce\\n•Using the Amazon Mechanical Turk Workforce (p. 552)\\n•Managing Vendor Workforces (p. 553)\\n•Managing a Private Workforce (p. 553)\\n•Create and manage Amazon SNS topics for your work teams (p. 556)\\nUsing the Amazon Mechanical Turk Workforce\\nThe Amazon Mechanical Turk workforce provides the most workers for your labeling job.\\nYou can use the console to choose the Amazon Mechanical Turk workforce for your labeling job, or you\\ncan provide the Amazon Resource Name (ARN) for the Amazon Mechanical Turk workforce when you use\\nthe CreateLabelingJob (p. 643) operation.\\nAny Amazon Mechanical Turk workforce billing is handled as part of your Amazon SageMaker Ground\\nTruth billing. You do not need to create a separate Mechanical Turk account to use the Amazon\\nMechanical Turk workforce.\\nThe ARN for the Amazon Mechanical Turk workforce is:\\n•arn:aws:sagemaker: region:394669845002:workteam/public-crowd/default\\nThe Amazon Mechanical Turk workforce is a world-wide resource. Workers are available 24 hours a day,\\n7 days a week. You typically get the fastest turn-around for your labeling jobs when you use the Amazon\\nMechanical Turk workforce.\\nAdjust the number of workers that annotate each data object based on the complexity of the job\\nand the quality that you need. Ground Truth uses annotation consolidation to improve the quality\\nof the labels. More workers can make a diﬀerence in the quality of the labels for more complex\\nlabeling jobs, but might not make a diﬀerence for simpler jobs. For more information, see Annotation\\nConsolidation  (p. 537).\\nNote\\nOnly use the Amazon Mechanical Turk workforce to label data that is public or has been stripped\\nof any sensitive information. You should not use the Amazon Mechanical Turk workforce for a\\ndataset that contains personally identiﬁable information, such as names or email addresses.\\nTo choose the Amazon Mechanical Turk workforce when you are creating a labeling job using the\\nconsole, do the following during the Select workers and conﬁgure tool step:\\nTo use the Amazon Mechanical Turk workforce\\n1. Choose Public  from Worker types.\\n2. Choose The dataset does not contain adult content if your dataset doesn\\'t contain potentially\\noﬀensive content. This enables workers to opt out if they don\\'t want to work with it.\\n3. Acknowledge that your data will be viewed by the Amazon Mechanical Turk workforce and that all\\npersonally identiﬁable information (PII) has been removed.\\n4. Choose Additional conﬁguration to set optional parameters.\\n5. Optional. Enable automated data labeling to have Ground Truth automatically label some of your\\ndataset. For more information, see Using Automated Data Labeling  (p. 539).\\n6. Optional. Set the number of workers that should see each object in your dataset. Using more\\nworkers can increase the quality of your labels but also increases the cost.\\nYour labeling job will now be sent to the Amazon Mechanical Turk workforce. You can use the console to\\ncontinue conﬁguring your labeling job.\\n552Amazon SageMaker Developer Guide\\nManaging Vendor Workforces\\nManaging Vendor Workforces\\nYou can use a vendor-managed workforce to label your data using Amazon SageMaker Ground Truth.\\nVendors have extensive experience in providing data labeling services for the purpose of machine\\nlearning.\\nVendors make their services available via the AWS Marketplace. You can ﬁnd details of the vendor\\'s\\nservices on their detail page, such as the number of workers and the hours that they work. You can use\\nthese details to make estimates of how much the labeling job will cost and the amount of time that you\\ncan expect the job to take. Once you have chosen a vendor you subscribe to their services using the AWS\\nMarketplace.\\nA subscription is an agreement between you and the vendor. The agreement spells out the details of the\\nagreement, such as price, schedule, or refund policy. You work directly with the vendor if there are any\\nissues with your labeling job.\\nYou can subscribe to any number of vendors to meet your data annotation needs. When you create a\\nlabeling job you can specify that the job be routed to a speciﬁc vendor.\\nBefore you send sensitive data to a vendor, check the vendor\\'s security practices on their detail page and\\nreview the end user license agreement (EULA) that is part of your subscription agreement.\\nYou must use the console to subscribe to a vendor workforce. Once you have a subscription, you can use\\nthe ListSubscribedWorkteams (p. 801) operation to list your subscribed vendors.\\nTo subscribe to a vendor workforce\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Labeling workforces, choose Vendor, and then choose Find data labeling services.\\n3. The console opens the AWS Marketplace with the data labeling services category selected. You see a\\nlist of the data labeling services available.\\n4. Choose a vendor. The AWS Marketplace shows detailed information about the data labeling service.\\nUse this information to determine if the vendor meets your data labeling requirements.\\n5. If the vendor meets your requirements, choose Continue to subscribe .\\n6. Review the details of the subscription. If you agree to the terms, choose Subscribe  to complete your\\nsubscription to the service.\\nManaging a Private Workforce\\nA private workforce  is a group of workers that you choose. These can be employees of your company or\\na group of subject matter experts from your industry. For example, if the task is to label medical images,\\nyou could create a private workforce of people knowledgeable about the images in question.\\nYou create work teams  from your private workforce. If desired, you can assign each work team to a\\nseparate labeling job. A single worker can be in more than one work team.\\nAmazon SageMaker Ground Truth uses Amazon Cognito to deﬁne your private workforce and your\\nwork teams. Amazon Cognito is a service that you can use to create identities for your workers and\\nauthenticate these identities with identity providers. You can use providers such as the following:\\n•Amazon Cognito identity provider\\n•Social sign-in providers such as Facebook and Google\\n•OpenID Connect (OIDC) providers\\n•Security Assertion Markup Language (SAML) providers such as Active Directory\\n553Amazon SageMaker Developer Guide\\nManaging a Private Workforce\\nAfter your workers are set up, you use Amazon Cognito to manage them. For more information about\\nAmazon Cognito, see What Is Amazon Cognito?\\nYour workers are organized into two groups. The workforce  is the entire set of workers that are available\\nto work on your labeling jobs. The workforce corresponds to an Amazon Cognito user pool. A work team\\nis a group of workers within your workforce that you can assign jobs to. The work team corresponds to\\nan Amazon Cognito user group. A worker can be in more than one work team.\\nNote\\nYou can only use one Amazon Cognito user pool as your Ground Truth labeling workforce. If you\\nplan on using an existing Amazon Cognito user pool for your Ground Truth workforce, be sure to\\nimport the user pool and create a work team before you create your ﬁrst labeling job.\\nFor more information, see Amazon Cognito User Pools.\\nCreating a private workforce\\nThere are three ways that you can create a private workforce:\\n1.Import an existing Amazon Cognito user pool before you create your ﬁrst labeling job.\\n2.Use the Amazon SageMaker console to create a new Amazon Cognito user pool before you create your\\nﬁrst labeling job.\\n3.Create a new Amazon Cognito user pool while you are creating your ﬁrst labeling job.\\nIf you are using a pre-existing Amazon Cognito user pool for your private workforce, you must import the\\nuser pool into Ground Truth and create at least one work team, either by adding work team members in\\nthe Amazon SageMaker console or by importing an Amazon Cognito work group before you create your\\nﬁrst labeling job for your private workforce.\\nAfter you create or import your private workforce you will see the Private workforce summary screen.\\nOn this screen you can see information about the Amazon Cognito user pool for your workforce, a list of\\nwork teams for your workforce, and a list of all of the members of your private workforce.\\nIf you created your workforce using the Amazon SageMaker console, you can manage the members of\\nyour workforce in the Amazon SageMaker console or in the Amazon Cognito console. For example, you\\ncan use the Amazon SageMaker console to add, delete, and disable workers in the pool. If you imported\\nthe workforce from an existing Amazon Cognito user pool, you must use the Amazon Cognito console to\\nmanage the workforce.\\nCreating a workforce when creating a labeling job\\nIf you have not created a private workforce when you create your labeling job, you are prompted to\\ncreate one. Creating the workforce also creates a default work team containing all of the members of the\\nworkforce. If you have already created a private workforce, you instead enter the work team that should\\nhandle the labeling job.\\nYou provide the following information to create the workforce and work team.\\n•Up to 100 email addresses of the workforce members. Email addresses are case-sensitive. Your workers\\nmust log in using the same case as the address was initially entered. You can add additional workforce\\nmembers after the job is created.\\n•The name of your organization. This is used to customize the email sent to the workers.\\n•A contact email address for workers to report issues related to the task.\\nWhen you create the labeling job an email is sent to each worker inviting them to join the workforce.\\nOnce the workforce is created, you can add, delete, and disable workers using the Amazon SageMaker\\nconsole or the Amazon Cognito console.\\n554Amazon SageMaker Developer Guide\\nManaging a Private Workforce\\nCreating a private workforce using the console\\nTo create a private workforce using the console\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Labeling workforces from the left menu.\\n3. Select the Private  tab.\\n4. Click the Create private team  button. This process will create a private workforce and a work team.\\n5. Choose to Invite new workers by email or Import workers from existing Amazon Cognito user\\ngroups .\\n6. To invite new workers by email.\\n•Paste or type a list of email addresses, separated by commas, into the email addresses box. You\\nmay have up to 50 email addresses in this list.\\n•Enter an organization name and contact email.\\n•Optionally select an SNS topic to which to subscribe the team so workers are notiﬁed by email\\nwhen new labeling jobs become available.\\n•Click the Create private team  button.\\n7. To Import workers from existing Amazon Cognito user groups.\\n•Choose a user pool you have created. User pools require a domain and an existing user group. If\\nyou get an error that the domain is missing, set it in the Domain name  options within the App\\nintegration  section of the Amazon Cognito control console for your group.\\n•Select an app client. We recommend using a SageMaker generated client.\\n•Select a user group from your pool to import its members.\\n•Optionally select an SNS topic to which to subscribe the team so workers are notiﬁed by email\\nwhen new labeling jobs become available.\\n•Click the Create private team  button.\\nAfter you have created the workforce, Ground Truth automatically creates a work team called Everyone-\\nin-private-workforce. You can use this work team to assign a labeling job to your entire workforce.\\nCreating a Work Team\\nUse a work team to assign members of your private workforce to a labeling job. When you create your\\nworkforce using the Amazon SageMaker Ground Truth console, there is a work team called Everyone-\\nin-private-workforce that you can use if you want to assign your entire workforce to a labeling job.\\nBecause an imported Amazon Cognito user pool may contain members that you don\\'t want to include in\\nyour work teams, a similar work team is not created for Amazon Cognito user pools.\\nYou have two choices to create a new work team. You can create a user group by using the Amazon\\nCognito console and then create a work team by importing the user group. You can import more than\\none user group into each work team. You manage the members of the work team by updating the user\\ngroup in the Amazon Cognito console.\\nYou can also create a work team in the Ground Truth console and add members from your workforce to\\nthe team.\\nTo create a work team using the Ground Truth console\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Labeling workforces from the left menu.\\n3. Under Private teams , choose Create private team .\\n555Amazon SageMaker Developer Guide\\nCreate and manage Amazon\\nSNS topics for your work teams\\n4. Under Team details, give the team a name. The name must be unique in your account in an AWS\\nRegion.\\n5. Under Create a team using Amazon Cognito user groups, choose the method to use to create the\\ngroup.\\n6. If you chose Create a team by adding workers to a new Amazon Cognito user group, select the\\nworkers to add to the team.\\nIf you chose Create a team by importing existing Amazon Cognito user groups, choose the user\\ngroups that are part of the new team.\\n7. If you select an SNS topic , all workers added to the team are subscribed to the Amazon SNS topic\\nand notiﬁed when new work items are available to the team. Select from a list of your existing\\nGround Truth related Amazon SNS topics or select Create new topic  to open a topic-creation dialog.\\nWorkers in a workteam subscribed to a topic receive notiﬁcations when a new job for that team\\nbecomes available and when one is about to expire.\\nRead Create and manage Amazon SNS topics for your work teams (p. 556) for more information on\\ncreating and managing the Amazon SNS topic.\\nAfter you have created a work team, you can choose its name in the list of work teams to see more\\ninformation about the team and change or set the Amazon SNS topic to which its members are\\nsubscribed. Any members of the team who were added to the team prior to the team being subscribed\\nto a topic will need to be subscribed to that topic manually. Teams made from more than one imported\\nuser group must be edited in the Amazon Cognito console; otherwise you can add and remove workers\\nusing the team detail page.\\nCreate and manage Amazon SNS topics for your work\\nteams\\nCreate the Amazon SNS topic\\nThese instructions are needed when you:\\n•Create a topic to which you will subscribe an existing work team.\\n•Create a topic prior to creating a work team.\\n•Create or modify the work team with an API call and need to specify a topic ARN.\\nIf you create a work team using the console, that process provides an option to create a new topic for the\\nteam, and if used, handles these steps for you.\\nThe creation of Amazon SNS topics for work team notiﬁcation is similar to the steps in the Amazon SNS\\nGetting Started document, with one signiﬁcant addition: adding an access policy so the Sagemaker\\nservice can publish messages to the topic on your behalf.\\nAdd the policy while creating the topic\\n1. In the Access policy panel, select the advanced method.\\n2. In the JSON editor, ﬁnd the Resource  property, which displays what the ARN of the topic will be\\nwhen it is created. If the value ends in \"undeﬁned,\" change \"undeﬁned\" to the name of the topic.\\n3. Copy the Resource  value.\\n4. Before the ﬁnal closing bracket (]), add the following policy.\\n    {\\n556Amazon SageMaker Developer Guide\\nCreating Custom Labeling Workﬂows\\n      \"Sid\": \"AWSSagemaker_AccessPolicy\",\\n      \"Effect\": \"Allow\",\\n      \"Principal\": {\\n        \"Service\": \"sagemaker.amazonaws.com\"\\n      },\\n      \"Action\": \"sns:Publish\",\\n      \"Resource\": \" resource ARN you copied in the previous step \"\\n    }\\n5. Create the topic.\\nFor more details on creating topics, see the Amazon SNS \"Creating a Topic\" tutorial.\\nManage worker subscriptions\\nWorkers are auto-subscribed to your topic only when a Amazon Cognito user group is created or\\nimported during the creation of a work team that is subscribed to the topic at creation.\\nIf a work team is subscribed to a topic after creation, the individual members at the time of creation are\\nnot automatically subscribed. See \"Subscribing an Endpoint to an Amazon SNS Topic\" for information on\\nsubscribing the workers\\' email addresses to the topic.\\nCreating Custom Labeling Workﬂows\\nThis document guides you through the process of setting up a workﬂow with a custom labeling\\ntemplate. For more information about starting a labeling job, see Getting started (p. 533). In that\\nsection, when you choose the Task type, select Custom labeling task , and then follow this section\\'s\\ninstructions to conﬁgure it.\\nNext\\nStep 1: Setting up your workforce (p. 557)\\nStep 1: Setting up your workforce\\nIn this step you use the console to establish which worker type to use and make the necessary sub-\\nselections for the worker type. It assumes you have already completed the steps up to this point in the\\nGetting started (p. 533) section and have chosen the Custom labeling task  as the Task type.\\nTo conﬁgure your workforce.\\n1. First choose an option from the Worker types. There are three types currently available:\\n•Public  uses an on-demand workforce of independent contractors, powered by Amazon Mechanical\\nTurk. They are paid on a per-task basis.\\n•Private  uses your employees or contractors for handling data that needs to stay within your\\norganization.\\n•Vendor uses third party vendors that specialize in providing data labeling services, available via\\nthe AWS Marketplace.\\n2. If you choose the Public  option, you are asked to set the number of workers per dataset object.\\nHaving more than one worker perform the same task on the same object can help increase the\\naccuracy of your results. The default is three. You can raise or lower that depending on the accuracy\\nyou need.\\nYou are also asked to set a price per taskby using a drop-down menu. The menu recommends price\\npoints based on how long it will take to complete the task.\\n557Amazon SageMaker Developer Guide\\nStep 2: Creating your custom labeling task template\\nThe recommended method to determine this is to ﬁrst run a short test of your task with a private\\nworkforce. The test provides a realistic estimate of how long the task takes to complete. You can\\nthen select the range your estimate falls within on the Price per task menu. If your average time is\\nmore than 5 minutes, consider breaking your task into smaller units.\\nNext\\nStep 2: Creating your custom labeling task template (p. 558)\\nStep 2: Creating your custom labeling task template\\nTopics\\n•Starting with a base template (p. 558)\\n•Developing templates locally (p. 558)\\n•Using External Assets (p. 558)\\n•Track your variables (p. 559)\\n•A simple sample  (p. 559)\\n•Adding automation with Liquid (p. 560)\\n•End-to-end demos  (p. 563)\\n•Next (p. 563)\\nStarting with a base template\\nTo get you started, the Task type starts with a drop-down menu listing a number of our more common\\ntask types, plus a custom type. Choose one and the code editor area will be ﬁlled with a sample template\\nfor that task type. If you prefer not to start with a sample, choose Custom HTML  for a minimal template\\nskeleton.\\nIf you\\'ve already created a template, upload the ﬁle directly using the Upload ﬁle button in the upper\\nright of the task setup area or paste your template code into the editor area.\\nDeveloping templates locally\\nWhile you need to be in the console to test how your template will process incoming data, you can test\\nthe look and feel of your template\\'s HTML and custom elements in your browser by adding this code to\\nthe top of your HTML ﬁle.\\nExample\\n<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\n            \\nThis loads the necessary code to render the custom HTML elements. Use this if you want to develop your\\ntemplate\\'s look and feel in your preferred editor rather than in the console.\\nRemember, though, this will not parse your variables. You may want to replace them with sample\\ncontent while developing locally.\\nUsing External Assets\\nAmazon SageMaker Ground Truth custom templates allow external scripts and style sheets to be\\nembedded.\\n558Amazon SageMaker Developer Guide\\nStep 2: Creating your custom labeling task template\\nExample\\n<script src=\"https://www.example.com/my-enhancment-script.js\"></script>\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://www.example.com/my-enhancement-\\nstyles.css\">\\nIf you encounter errors, ensure that your originating server is sending the correct MIME type and\\nencoding headers with the assets.\\nFor example, the MIME and encoding types for remote scripts: application/\\njavascript;CHARSET=UTF-8 .\\nThe MIME and encoding type for remote stylesheets: text/css;CHARSET=UTF-8 .\\nTrack your variables\\nIn the process of building the sample below, there will be a step that adds variables to it to represent\\nthe pieces of data that may change from task to task, worker to worker. If you\\'re starting with one of the\\nsample templates, you will need to make sure you\\'re aware of the variables it already uses. When you\\ncreate your pre-annotation AWS Lambda script, its output will need to contain values for any of those\\nvariables you choose to keep.\\nThe values you use for the variables can come from your manifest ﬁle. All the key-value pairs in your\\ndata object are provided to your pre-annotation Lambda. If it\\'s a simple pass-through script, matching\\nkeys for values in your data object to variable names in your template is the easiest way to pass those\\nvalues through to the tasks forms your workers see.\\nA simple sample\\nAll tasks begin and end with the <crowd-form> </crowd-form>  elements. Like standard HTML\\n<form> elements, all of your form code should go between them.\\nFor a simple tweet-analysis task, use the <crowd-classifier>  element. It requires the following\\nattributes:\\n•name  - the variable name to use for the result in the form output.\\n•categories  - a JSON formatted array of the possible answers.\\n•header  - a title for the annotation tool\\nAs children of the <crowd-classifier>  element, you must have three regions.\\n•<classiﬁcation-target>  - the text the worker will classify based on the options speciﬁed in the\\ncategories  attribute above.\\n•<full-instructions>  - instructions that are available from the \"View full instructions\" link in the tool.\\nThis can be left blank, but it is recommended that you give good instructions to get better results.\\n•<short-instructions> - a more brief description of the task that appears in the tool\\'s sidebar. This can be\\nleft blank, but it is recommended that you give good instructions to get better results.\\nA simple version of this tool would look like this.\\nExample of using crowd-classifier\\n<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\n<crowd-form>\\n  <crowd-classifier \\n    name=\"tweetFeeling\"\\n559Amazon SageMaker Developer Guide\\nStep 2: Creating your custom labeling task template\\n    categories=\"[\\'positive\\',\\'negative\\',\\'neutral\\', \\'unclear\\']\"\\n    header=\"Which term best describes this tweet?\" \\n  >\\n     <classification-target>\\n      My favorite football team won today! \\n      Bring on the division finals!\\n    </classification-target>\\n    <full-instructions header=\"Sentiment Analysis Instructions\">\\n      Try to determine the sentiment the author \\n      of the tweet is trying to express. \\n      If none seem to match, choose \"cannot determine.\"\\n    </full-instructions>\\n    <short-instructions>\\n      Pick the term best describing the sentiment \\n      of the tweet. \\n    </short-instructions>\\n  </crowd-classifier>\\n</crowd-form>\\nYou can copy and paste the code into the editor in the Ground Truth labeling job creation workﬂow to\\npreview the tool, or try out a demo of this code on CodePen.\\nAdding automation with Liquid\\nOur custom template system uses Liquid  for automation. It is an open source inline markup language.\\nFor more information and documentation, visit the Liquid homepage .\\nThe most common use of Liquid will be to parse the data coming from your pre-annotation Lambda\\nand pull out the relevant variables to create the task. In Liquid, the text between single curly braces and\\npercent symbols is an instruction or \"tag\" that creates control ﬂow. Text between double curly braces is a\\nvariable or \"object\" which outputs its value.\\n560Amazon SageMaker Developer Guide\\nStep 2: Creating your custom labeling task template\\nThe taskInput  object returned by your Pre-annotation Lambda (p. 574) will be available as the\\ntask.input  object in your templates.\\nThe properties in your manifest\\'s data objects are passed into your Pre-annotation Lambda (p. 574)\\nas the event.dataObject . A simple pass-through script simply returns that object as the taskInput\\nobject. You would represent values from your manifest as variables as follows.\\nExample Manifest data object\\n{\\n  \"source\": \"This is a sample text for classification\",\\n  \"labels\": [ \"angry\" , \"sad\" , \"happy\" , \"inconclusive\" ],\\n  \"header\": \"What emotion is the speaker feeling?\"\\n}\\nExample Sample HTML using variables\\n<crowd-classifier \\n  name=\\'tweetFeeling\\'\\n  categories=\\'{{ task.input.labels | to_json }}\\'\\n  header=\\'{{ task.input.header }}\\' >\\n<classification-target>\\n  {{ task.input.source }}\\n</classification-target>\\nNote the addition of \"  | to_json \" to the labels property above. That\\'s a ﬁlter to turn the array into a\\nJSON representation of the array. Variable ﬁlters are explained next.\\nVariable ﬁlters\\nIn addition to the standard Liquid ﬁlters and actions, Ground Truth oﬀers a few additional ﬁlters. Filters\\nare applied by placing a pipe (|) character after the variable name, then specifying a ﬁlter name. Filters\\ncan be chained in the form of:\\nExample\\n{{ <content> | <filter> | <filter> }}\\nAutoescape and explicit escape\\nBy default, inputs will be HTML escaped to prevent confusion between your variable text and HTML.\\nYou can explicitly add the escape ﬁlter to make it more obvious to someone reading the source of your\\ntemplate that the escaping is being done.\\nescape_once\\nescape_once  ensures that if you\\'ve already escaped your code, it doesn\\'t get re-escaped on top of that.\\nFor example, so that &amp; doesn\\'t become &amp;amp;.\\nskip_autoescape\\nskip_autoescape  is useful when your content is meant to be used as HTML. For example, you might\\nhave a few paragraphs of text and some images in the full instructions for a bounding box.\\nUse skip_autoescape  sparingly\\nThe best practice in templates is to avoid passing in functional code or markup with\\nskip_autoescape  unless you are absolutely sure you have strict control over what\\'s being\\n561Amazon SageMaker Developer Guide\\nStep 2: Creating your custom labeling task template\\npassed. If you\\'re passing user input, you could be opening your workers up to a Cross Site\\nScripting attack.\\nto_json\\nto_json will encode what you feed it to JSON (JavaScript Object Notation). If you feed it an object, it\\nwill serialize it.\\ngrant_read_access\\ngrant_read_access  takes an S3 URI and encodes it into an HTTPS URL with a short-lived access token\\nfor that resource. This makes it possible to display to workers photo, audio, or video objects stored in S3\\nbuckets that are not otherwise publicly accessible.\\nExample of the ﬁlters\\nInput\\nauto-escape: {{ \"Have you read \\'James & the Giant Peach\\'?\" }}\\nexplicit escape: {{ \"Have you read \\'James & the Giant Peach\\'?\" | escape }}\\nexplicit escape_once: {{ \"Have you read \\'James &amp; the Giant Peach\\'?\" | escape_once }}\\nskip_autoescape: {{ \"Have you read \\'James & the Giant Peach\\'?\" | skip_autoescape }}\\nto_json: {{ jsObject | to_json }}                \\ngrant_read_access: {{ \"s3://mybucket/myphoto.png\" | grant_read_access }}\\nExample\\nOutput\\nauto-escape: Have you read &#39;James &amp; the Giant Peach&#39;?\\nexplicit escape: Have you read &#39;James &amp; the Giant Peach&#39;?\\nexplicit escape_once: Have you read &#39;James &amp; the Giant Peach&#39;?\\nskip_autoescape: Have you read \\'James & the Giant Peach\\'?\\nto_json: { \"point_number\": 8, \"coords\": [ 59, 76 ] }\\ngrant_read_access: https://s3.amazonaws.com/mybucket/myphoto.png? <access token and other\\n params>\\nExample of an automated classiﬁcation template.\\nTo automate the simple text classiﬁcation sample, replace the tweet text with a variable.\\nThe text classiﬁcation template is below with automation added. The changes/additions are highlighted\\nin bold.\\n<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\n<crowd-form>\\n  <crowd-classifier \\n    name=\"tweetFeeling\"\\n    categories=\"[\\'positive\\', \\'negative\\', \\'neutral\\', \\'cannot determine\\']\"\\n    header=\"Which term best describes this tweet?\" \\n  >\\n    <classification-target>\\n       {{ task.input.source }}\\n    </classification-target>\\n    <full-instructions header=\"Analyzing a sentiment\">\\n      Try to determine the feeling the author \\n      of the tweet is trying to express. \\n      If none seem to match, choose \"other.\"\\n    </full-instructions>\\n562Amazon SageMaker Developer Guide\\nDemo: Image Annotation with crowd-bounding-box\\n    <short-instructions>\\n      Pick the term best describing the sentiment \\n      of the tweet. \\n    </short-instructions>\\n  </crowd-classifier>\\n</crowd-form>\\nThe tweet text that was in the prior sample is now replaced with an object. The entry.taskInput\\nobject uses source (or another name you specify in your pre-annotation Lambda) as the property name\\nfor the text and it is inserted directly in the HTML by virtue of being between double curly braces.\\nEnd-to-end demos\\nYou can view the following end-to-end demos which include sample Lambdas:\\n•Demo Template: Annotation of Images with crowd-bounding-box  (p. 563)\\n•Demo Template: Labeling Intents with crowd-classifier  (p. 567)\\nNext\\nStep 3: Processing with AWS Lambda (p. 574)\\nDemo Template: Annotation of Images with crowd-\\nbounding-box\\nWhen you chose to use a custom template, you reach the Custom labeling task panel . There you can\\nchoose from multiple base templates. The templates represent some of the most common tasks and\\nprovide a sample to work from as you create your customized labeling task\\'s template.\\nThis demonstration works with the BoundingBox template. The demonstration also works with the AWS\\nLambda functions needed for processing your data before and after the task.\\nTopics\\n•Starter Bounding Box custom template (p. 563)\\n•Your own Bounding Box custom template (p. 564)\\n•Your manifest ﬁle (p. 565)\\n•Your pre-annotation Lambda function (p. 565)\\n•Your post-annotation Lambda function (p. 566)\\n•The output of your labeling job (p. 567)\\nStarter Bounding Box custom template\\nThis is the starter bounding box template that is provided.\\n<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\n<crowd-form>\\n  <crowd-bounding-box\\n    name=\"annotatedResult\"\\n    src=\"{{ task.input.taskObject | grant_read_access }}\"\\n    header=\"{{ task.input.header }}\"\\n    labels=\"{{ task.input.labels | to_json | escape }}\"\\n563Amazon SageMaker Developer Guide\\nDemo: Image Annotation with crowd-bounding-box\\n  >\\n    <!-- The <full-instructions> tag is where you will define the full instructions of your\\n task. -->\\n    <full-instructions header=\"Bounding Box Instructions\" >\\n      <p>Use the bounding box tool to draw boxes around the requested target of interest:</\\np>\\n      <ol>\\n        <li>Draw a rectangle using your mouse over each instance of the target.</li>\\n        <li>Make sure the box does not cut into the target, leave a 2 - 3 pixel margin</li>\\n        <li>\\n          When targets are overlapping, draw a box around each object,\\n          include all contiguous parts of the target in the box.\\n          Do not include parts that are completely overlapped by another object.\\n        </li>\\n        <li>\\n          Do not include parts of the target that cannot be seen,\\n          even though you think you can interpolate the whole shape of the target.\\n        </li>\\n        <li>Avoid shadows, they\\'re not considered as a part of the target.</li>\\n        <li>If the target goes off the screen, label up to the edge of the image.</li>\\n      </ol>\\n    </full-instructions>\\n    <!-- The <short-instructions> tag allows you to specify instructions that are displayed\\n in the left hand side of the task interface.\\n    It is a best practice to provide good and bad examples in this section for quick\\n reference. -->\\n    <short-instructions>\\n      Use the bounding box tool to draw boxes around the requested target of interest.\\n    </short-instructions>\\n  </crowd-bounding-box>\\n</crowd-form>\\nThe custom templates use the Liquid template language , and each of the items between double\\ncurly braces is a variable. The pre-annotation AWS Lambda function should provide an object named\\ntaskInput  and that object\\'s properties can be accessed as {{ task.input.<property name> }}  in\\nyour template.\\nYour own Bounding Box custom template\\nAs an example, assume you have a large collection of animal photos in which you know the kind of\\nanimal in an image from a prior image-classiﬁcation job. Now you want to have a bounding box drawn\\naround it.\\nIn the starter sample, there are three variables: taskObject , header , and labels .\\nEach of these would be represented in diﬀerent parts of the bounding box.\\n•taskObject  is an HTTP(S) URL or S3 URI for the photo to be annotated. The added |\\ngrant_read_access  is a ﬁlter that will convert an S3 URI to an HTTPS URL with short-lived access to\\nthat resource. If you\\'re using an HTTP(S) URL, it\\'s not needed.\\n•header is the text above the photo to be labeled, something like \"Draw a box around the bird in the\\nphoto.\"\\n•labels is an array, represented as [\\'item1\\', \\'item2\\', ...] . These are labels that can be\\nassigned by the worker to the diﬀerent boxes they draw. You can have one or many.\\nEach of the variable names come from the JSON object in the response from your pre-annotation\\nLambda, The names above are merely suggested, Use whatever variable names make sense to you and\\nwill promote code readability among your team.\\n564Amazon SageMaker Developer Guide\\nDemo: Image Annotation with crowd-bounding-box\\nOnly use variables when necessary\\nIf a ﬁeld will not change, you can remove that variable from the template and replace it with\\nthat text, otherwise you have to repeat that text as a value in each object in your manifest or\\ncode it into your pre-annotation Lambda function.\\nExample : Final Customized Bounding Box Template\\nTo keep things simple, this template will have one variable, one label, and very basic instructions.\\nAssuming your manifest has an \"animal\" property in each data object, that value can be re-used in two\\nparts of the template.\\n<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\n<crowd-form>\\n  <crowd-bounding-box\\n    name=\"annotatedResult\"\\n    labels=\"[ \\'{{ task.input.animal }}\\' ]\"\\n    src=\"{{ task.input.source-ref | grant_read_access }}\"\\n    header=\"Draw a box around the {{ task.input.animal }}.\"\\n  >\\n    <full-instructions header=\"Bounding Box Instructions\" >\\n      <p>Draw a bounding box around the {{ task.input.animal }} in the image. If \\n      there is more than one {{ task.input.animal }} per image, draw a bounding \\n      box around the largest one.</p>\\n      <p>The box should be tight around the {{ task.input.animal }} with \\n      no more than a couple of pixels of buffer around the \\n      edges.</p>\\n      <p>If the image does not contain a {{ task.input.animal }}, check the <strong>\\n      Nothing to label</strong> box.\\n    </full-instructions>\\n    <short-instructions>\\n      <p>Draw a bounding box around the {{ task.input.animal }} in each image. If \\n      there is more than one {{ task.input.animal }} per image, draw a bounding \\n      box around the largest one.</p>\\n    </short-instructions>\\n  </crowd-bounding-box>\\n</crowd-form>\\nNote the re-use of {{ task.input.animal }}  throughout the template. If your manifest had\\nall of the animal names beginning with a capital letter, you could use {{ task.input.animal |\\ndowncase }} , incorporating one of Liquid\\'s built-in ﬁlters in sentences where it needed to be presented\\nlowercase.\\nYour manifest ﬁle\\nYour manifest ﬁle should provide the variable values you\\'re using in your template. You can do some\\ntransformation of your manifest data in your pre-annotation Lambda, but if you don\\'t need to, you\\nmaintain a lower risk of errors and your Lambda will run faster. Here\\'s a sample manifest ﬁle for the\\ntemplate.\\n{\"source-ref\": \"<S3 image URI>\", \"animal\": \"horse\"}\\n{\"source-ref\": \"<S3 image URI>\", \"animal\" : \"bird\"}\\n{\"source-ref\": \"<S3 image URI>\", \"animal\" : \"dog\"}\\n{\"source-ref\": \"<S3 image URI>\", \"animal\" : \"cat\"}\\nYour pre-annotation Lambda function\\nAs part of the job set-up, provide the ARN of an AWS Lambda function that can be called to process your\\nmanifest entries and pass them to the template engine.\\n565Amazon SageMaker Developer Guide\\nDemo: Image Annotation with crowd-bounding-box\\nNaming your Lambda function\\nThe best practice in naming your function is to use one of the following four strings as part of\\nthe function name: SageMaker , Sagemaker , sagemaker , or LabelingFunction . This applies\\nto both your pre-annotation and post-annotation functions.\\nWhen you\\'re using the console, if you have AWS Lambda functions that are owned by your account, a\\ndrop-down list of functions meeting the naming requirements will be provided to choose one.\\nIn this very basic example, you\\'re just passing through the information from the manifest without doing\\nany additional processing on it. This sample pre-annotation function is written for Python 3.7.\\nimport json\\ndef lambda_handler(event, context):\\n    return {\\n        \"taskInput\": event[\\'dataObject\\']\\n    }\\nThe JSON object from your manifest will be provided as a child of the event object. The properties\\ninside the taskInput  object will be available as variables to your template, so simply setting the value\\nof taskInput  to event[\\'dataObject\\']  will pass all the values from your manifest object to your\\ntemplate without having to copy them individually. If you wish to send more values to the template, you\\ncan add them to the taskInput  object.\\nYour post-annotation Lambda function\\nAs part of the job set-up, provide the ARN of an AWS Lambda function that can be called to process the\\nform data when a worker completes a task. This can be as simple or complex as you want. If you want\\nto do answer consolidation and scoring as it comes in, you can apply the scoring and/or consolidation\\nalgorithms of your choice. If you want to store the raw data for oﬄine processing, that is an option.\\nProvide permissions to your post-annotation Lambda\\nThe annotation data will be in a ﬁle designated by the s3Uri  string in the payload object. To\\nprocess the annotations as they come in, even for a simple pass through function, you need to\\nassign S3ReadOnly  access to your Lambda so it can read the annotation ﬁles.\\nIn the Console page for creating your Lambda, scroll to the Execution role panel. Select Create\\na new role from one or more templates. Give the role a name. From the Policy templates\\ndrop-down, choose Amazon S3 object read-only permissions. Save the Lambda and the role\\nwill be saved and selected.\\nThe following sample is in Python 2.7.\\nimport json\\nimport boto3\\nfrom urlparse import urlparse\\ndef lambda_handler(event, context):\\n    consolidated_labels = []\\n    parsed_url = urlparse(event[\\'payload\\'][\\'s3Uri\\']);\\n    s3 = boto3.client(\\'s3\\')\\n    textFile = s3.get_object(Bucket = parsed_url.netloc, Key = parsed_url.path[1:])\\n    filecont = textFile[\\'Body\\'].read()\\n    annotations = json.loads(filecont);\\n    \\n    for dataset in annotations:\\n        for annotation in dataset[\\'annotations\\']:\\n            new_annotation = json.loads(annotation[\\'annotationData\\'][\\'content\\'])\\n            label = {\\n                \\'datasetObjectId\\': dataset[\\'datasetObjectId\\'],\\n566Amazon SageMaker Developer Guide\\nDemo: Text Intent with crowd-classifier\\n                \\'consolidatedAnnotation\\' : {\\n                \\'content\\': {\\n                    event[\\'labelAttributeName\\']: {\\n                        \\'workerId\\': annotation[\\'workerId\\'],\\n                        \\'boxesInfo\\': new_annotation,\\n                        \\'imageSource\\': dataset[\\'dataObject\\']\\n                        }\\n                    }\\n                }\\n            }\\n            consolidated_labels.append(label)\\n    \\n    return consolidated_labels\\nThe post-annotation Lambda will often receive batches of task results in the event object. That batch\\nwill be the payload object the Lambda should iterate through. What you send back will be an object\\nmeeting the API contract (p. 574).\\nThe output of your labeling job\\nYou\\'ll ﬁnd the output of the job in a folder named after your labeling job in the target S3 bucket you\\nspeciﬁed. It will be in a subfolder named manifests .\\nFor a bounding box task, the output you ﬁnd in the output manifest will look a bit like the demo below.\\nThe example has been cleaned up for printing. The actual output will be a single line per record.\\nExample : JSON in your output manifest\\n{\\n  \"source-ref\":\"<URL>\",\\n  \"<label attribute name >\":\\n    {\\n       \"workerId\":\"<URL>\",\\n       \"imageSource\":\"<image URL>\",\\n        \"boxesInfo\":\"{\\\\\"annotatedResult\\\\\":{\\\\\"boundingBoxes\\\\\":[{\\\\\"height\\\\\":878, \\\\\"label\\n\\\\\":\\\\\"bird\\\\\", \\\\\"left\\\\\":208, \\\\\"top\\\\\":6, \\\\\"width\\\\\":809}], \\\\\"inputImageProperties\\\\\":{\\\\\"height\\n\\\\\":924, \\\\\"width\\\\\":1280}}}\"},\\n  \"<label attribute name >-metadata\":\\n    {\\n      \"type\":\"groundTruth/custom\",\\n      \"job_name\":\"<Labeling job name>\",\\n      \"human-annotated\":\"yes\"\\n    },\\n  \"animal\" : \"bird\"\\n}\\nNote how the additional animal attribute from your original manifest is passed to the output manifest\\non the same level as the source-ref  and labeling data. Any properties from your input manifest,\\nwhether they were used in your template or not, will be passed to the output manifest.\\nThis should help you create your own custom template.\\nDemo Template: Labeling Intents with crowd-\\nclassifier\\nIf you choose a custom template, you\\'ll reach the Custom labeling task panel . There you can select from\\nmultiple starter templates that represent some of the more common tasks. The templates provide a\\nstarting point to work from in building your customized labeling task\\'s template.\\n567Amazon SageMaker Developer Guide\\nDemo: Text Intent with crowd-classifier\\nIn this demonstration, you work with the Intent Detection template, which uses the crowd-\\nclassifier  (p. 582) element, and the AWS Lambda functions needed for processing your data\\nbefore and after the task.\\nTopics\\n•Starter Intent Detection custom template (p. 568)\\n•Your Intent Detection custom template (p. 568)\\n•Your pre-annotation Lambda function (p. 572)\\n•Your post-annotation Lambda function (p. 572)\\n•Your labeling job output (p. 573)\\nStarter Intent Detection custom template\\nThis is the intent detection template that is provided as a starting point.\\n<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\n<crowd-form>\\n  <crowd-classifier\\n    name=\"intent\"\\n    categories=\"{{ task.input.labels | to_json | escape }}\"\\n    header=\"Pick the most relevant intention expressed by the below text\"\\n  >\\n    <classification-target>\\n      {{ task.input.utterance }}\\n    </classification-target>\\n    \\n    <full-instructions header=\"Intent Detection Instructions\">\\n        <p>Select the most relevant intention expressed by the text.</p>\\n        <div>\\n           <p><strong>Example: </strong>I would like to return a pair of shoes</p>\\n           <p><strong>Intent: </strong>Return</p>\\n        </div>\\n    </full-instructions>\\n    <short-instructions>\\n      Pick the most relevant intention expressed by the text\\n    </short-instructions>\\n  </crowd-classifier>\\n</crowd-form>\\nThe custom templates use the Liquid template language , and each of the items between double\\ncurly braces is a variable. The pre-annotation AWS Lambda function should provide an object named\\ntaskInput  and that object\\'s properties can be accessed as {{ task.input.<property name> }}  in\\nyour template.\\nYour Intent Detection custom template\\nIn the starter template, there are two variables: the task.input.labels  property in the crowd-\\nclassifier  element opening tag and the task.input.utterance  in the classification-target\\nregion\\'s content.\\nUnless you need to oﬀer diﬀerent sets of labels with diﬀerent utterances, avoiding a variable and\\njust using text will save processing time and creates less possibility of error. The template used in this\\ndemonstration will remove that variable, but variables and ﬁlters like to_json are explained in more\\ndetail in the crowd-bounding-box  demonstration  article.\\n568Amazon SageMaker Developer Guide\\nDemo: Text Intent with crowd-classifier\\nStyling Your Elements\\nTwo parts of these custom elements that sometimes get overlooked are the <full-instructions>\\nand <short-instructions>  regions. Good instructions generate good results.\\nIn the elements that include these regions, the <short-instructions>  appear automatically in the\\n\"Instructions\" pane on the left of the worker\\'s screen. The <full-instructions>  are linked from the\\n\"View full instructions\" link near the top of that pane. Clicking the link opens a modal pane with more\\ndetailed instructions.\\nYou can not only use HTML, CSS, and JavaScript in these sections, you are encouraged to if you believe\\nyou can provide a strong set of instructions and examples that will help workers complete your tasks\\nwith better speed and accuracy.\\nExample Try out a sample with JSFiddle\\nTry out an example <crowd-classifier>  task . The example is rendered by JSFiddle, therefore all the\\ntemplate variables are replaced with hard-coded values. Click the \"View full instructions\" link to see a set\\nof examples with extended CSS styling. You can fork the project to experiment with your own changes to\\nthe CSS, adding sample images, or adding extended JavaScript functionality.\\nExample : Final Customized Intent Detection Template\\nThis uses the example <crowd-classifier>  task , but with a variable for the <classification-\\ntarget>. If you are trying to keep a consistent CSS design among a series of diﬀerent labeling jobs, you\\ncan include an external stylesheet using a <link rel...>  element the same way you\\'d do in any other\\nHTML document.\\n<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\\n<crowd-form>\\n  <crowd-classifier\\n    name=\"intent\"\\n    categories=\"[\\'buy\\', \\'eat\\', \\'watch\\', \\'browse\\', \\'leave\\']\"\\n569Amazon SageMaker Developer Guide\\nDemo: Text Intent with crowd-classifier\\n    header=\"Pick the most relevant intent expressed by the text below\"\\n  >\\n    <classification-target>\\n      {{ task.input.source }}\\n    </classification-target>\\n    \\n    <full-instructions header=\"Emotion Classification Instructions\">\\n      <p>In the statements and questions provided in this exercise, what category of action\\n is the speaker interested in doing?</p>\\n          <table>\\n            <tr>\\n              <th>Example Utterance</th>\\n              <th>Good Choice</th>\\n            </tr>\\n            <tr>\\n              <td>When is the Seahawks game on?</td>\\n              <td>\\n                eat<br>\\n                <greenbg>watch</greenbg>\\n                <botchoice>browse</botchoice>\\n              </td>\\n            </tr>\\n            <tr>\\n              <th>Example Utterance</th>\\n              <th>Bad Choice</th>\\n            </tr>\\n            <tr>\\n              <td>When is the Seahawks game on?</td>\\n              <td>\\n                buy<br>\\n                <greenbg>eat</greenbg>\\n                <botchoice>watch</botchoice>\\n              </td>\\n            </tr>\\n          </table>\\n    </full-instructions>\\n    <short-instructions>\\n      What is the speaker expressing they would like to do next?\\n    </short-instructions>  \\n  </crowd-classifier>\\n</crowd-form>\\n<style>\\n  greenbg {\\n    background: #feee23;\\n    display: block;\\n  }\\n  table {\\n    *border-collapse: collapse; /* IE7 and lower */\\n    border-spacing: 0; \\n  }\\n  th, tfoot, .fakehead {\\n    background-color: #8888ee;\\n    color: #f3f3f3;\\n    font-weight: 700;\\n  }\\n  th, td, tfoot {\\n      border: 1px solid blue;\\n  }\\n  th:first-child {\\n    border-radius: 6px 0 0 0;\\n  }\\n570Amazon SageMaker Developer Guide\\nDemo: Text Intent with crowd-classifier\\n  th:last-child {\\n    border-radius: 0 6px 0 0;\\n  }\\n  th:only-child{\\n    border-radius: 6px 6px 0 0;\\n  }\\n  tfoot:first-child {\\n    border-radius: 0 0 6px 0;\\n  }\\n  tfoot:last-child {\\n    border-radius: 0 0 0 6px;\\n  }\\n  tfoot:only-child{\\n    border-radius: 6px 6px;\\n  }\\n  td {\\n    padding-left: 15px ;\\n    padding-right: 15px ;\\n  }\\n  botchoice {\\n    display: block;\\n    height: 17px;\\n    width: 490px;\\n    overflow: hidden;\\n    position: relative;\\n    background: #fff;\\n    padding-bottom: 20px;\\n  }\\n  botchoice:after {\\n    position: absolute;\\n    bottom: 0;\\n    left: 0;  \\n    height: 100%;\\n    width: 100%;\\n    content: \"\";\\n    background: linear-gradient(to top,\\n       rgba(255,255,255, 1) 55%, \\n       rgba(255,255,255, 0) 100%\\n    );\\n    pointer-events: none; /* so the text is still selectable */\\n  }\\n</style>\\nExample : Your manifest ﬁle\\nIf you are preparing your manifest ﬁle manually for a text-classiﬁcation task like this, have your data\\nformatted in the following manner.\\n{\"source\": \"Roses are red\"}\\n{\"source\": \"Violets are Blue\"}\\n{\"source\": \"Ground Truth is the best\"}\\n{\"source\": \"And so are you\"}\\nThis diﬀers from the manifest ﬁle used for the \"Demo Template: Annotation of Images with crowd-\\nbounding-box  (p. 563)\" demonstration in that source-ref  was used as the property name instead\\n571Amazon SageMaker Developer Guide\\nDemo: Text Intent with crowd-classifier\\nof source . The use of source-ref  designates S3 URIs for images or other ﬁles that must be converted\\nto HTTP. Otherwise, source should be used like it is with the text strings above.\\nYour pre-annotation Lambda function\\nAs part of the job set-up, provide the ARN of an AWS Lambda that can be called to process your manifest\\nentries and pass them to the template engine.\\nThis Lambda function is required to have one of the following four strings as part of the function name:\\nSageMaker , Sagemaker , sagemaker , or LabelingFunction .\\nThis applies to both your pre-annotation and post-annotation Lambdas.\\nWhen you\\'re using the console, if you have Lambdas that are owned by your account, a drop-down list of\\nfunctions meeting the naming requirements will be provided to choose one.\\nIn this very basic sample, where you have only one variable, it\\'s primarily a pass-through function. Here\\'s\\na sample pre-labeling Lambda using Python 3.7.\\nimport json\\ndef lambda_handler(event, context):\\n    return {\\n        \"taskInput\":  event[\\'dataObject\\']\\n    }\\nThe dataObject  property of the event contains the properties from a data object in your manifest.\\nIn this demonstration, which is a simple pass through, you just pass that straight through as\\nthe taskInput  value. If you add properties with those values to the event[\\'dataObject\\']\\nobject, they will be available to your HTML template as Liquid variables with the format\\n{{ task.input. <property name>  }}.\\nYour post-annotation Lambda function\\nAs part of the job set up, provide the ARN of an Lambda function that can be called to process the\\nform data when a worker completes a task. This can be as simple or complex as you want. If you want\\nto do answer-consolidation and scoring as data comes in, you can apply the scoring or consolidation\\nalgorithms of your choice. If you want to store the raw data for oﬄine processing, that is an option.\\nSet permissions for your post-annotation Lambda function\\nThe annotation data will be in a ﬁle designated by the s3Uri  string in the payload object. To\\nprocess the annotations as they come in, even for a simple pass through function, you need to\\nassign S3ReadOnly  access to your Lambda so it can read the annotation ﬁles.\\nIn the Console page for creating your Lambda, scroll to the Execution role panel. Select Create\\na new role from one or more templates. Give the role a name. From the Policy templates\\ndrop-down, choose Amazon S3 object read-only permissions. Save the Lambda and the role\\nwill be saved and selected.\\nThe following sample is for Python 3.7.\\nimport json\\nimport boto3\\nfrom urllib.parse import urlparse\\ndef lambda_handler(event, context):\\n    consolidated_labels = []\\n572Amazon SageMaker Developer Guide\\nDemo: Text Intent with crowd-classifier\\n    parsed_url = urlparse(event[\\'payload\\'][\\'s3Uri\\']);\\n    s3 = boto3.client(\\'s3\\')\\n    textFile = s3.get_object(Bucket = parsed_url.netloc, Key = parsed_url.path[1:])\\n    filecont = textFile[\\'Body\\'].read()\\n    annotations = json.loads(filecont);\\n    \\n    for dataset in annotations:\\n        for annotation in dataset[\\'annotations\\']:\\n            new_annotation = json.loads(annotation[\\'annotationData\\'][\\'content\\'])\\n            label = {\\n                \\'datasetObjectId\\': dataset[\\'datasetObjectId\\'],\\n                \\'consolidatedAnnotation\\' : {\\n                \\'content\\': {\\n                    event[\\'labelAttributeName\\']: {\\n                        \\'workerId\\': annotation[\\'workerId\\'],\\n                        \\'result\\': new_annotation,\\n                        \\'labeledContent\\': dataset[\\'dataObject\\']\\n                        }\\n                    }\\n                }\\n            }\\n            consolidated_labels.append(label)\\n    return consolidated_labels\\nYour labeling job output\\nThe post-annotation Lambda will often receive batches of task results in the event object. That batch will\\nbe the payload object the Lambda should iterate through.\\nYou\\'ll ﬁnd the output of the job in a folder named after your labeling job in the target S3 bucket you\\nspeciﬁed. It will be in a subfolder named manifests .\\nFor an intent detection task, the output in the output manifest will look a bit like the demo below. The\\nexample has been cleaned up and spaced out to be easier for humans to read. The actual output will be\\nmore compressed for machine reading.\\nExample : JSON in your output manifest\\n[\\n  {\\n    \"datasetObjectId\":\"<Number representing item\\'s place in the manifest>\",\\n     \"consolidatedAnnotation\":\\n     {\\n       \"content\":\\n       {\\n         \"<name of labeling job>\":\\n         {     \\n           \"workerId\":\"private.us-east-1. XXXXXXXXXXXXXXXXXXXXXX \",\\n           \"result\":\\n           {\\n             \"intent\":\\n             {\\n                 \"label\":\"<label chosen by worker>\"\\n             }\\n           },\\n           \"labeledContent\":\\n           {\\n             \"content\":\"<text content that was labeled>\"\\n           }\\n         }\\n       }\\n573Amazon SageMaker Developer Guide\\nStep 3: Processing with AWS Lambda\\n     }\\n   },\\n  \"datasetObjectId\":\"<Number representing item\\'s place in the manifest>\",\\n     \"consolidatedAnnotation\":\\n     {\\n       \"content\":\\n       {\\n         \"<name of labeling job>\":\\n         {     \\n           \"workerId\":\"private.us-east-1.6UDLPKQZHYWJQSCA4MBJBB7FWE\",\\n           \"result\":\\n           {\\n             \"intent\":\\n             {\\n                 \"label\": \"<label chosen by worker>\"\\n             }\\n           },\\n           \"labeledContent\":\\n           {\\n             \"content\": \"<text content that was labeled>\"\\n           }\\n         }\\n       }\\n     }\\n   },\\n     ...\\n     ...\\n     ...\\n]\\nThis should help you create and use your own custom template.\\nStep 3: Processing with AWS Lambda\\nIn this step, you set which AWS Lambda functions to trigger on each dataset object prior to sending\\nit to workers and which function will be used to process the results once the task is submitted. These\\nfunctions are required.\\nYou will ﬁrst need to visit the AWS Lambda console or use AWS Lambda\\'s APIs to create your functions.\\nThe AmazonSageMakerFullAccess policy is restricted to invoking AWS Lambda functions with one\\nof the following four strings as part of the function name: SageMaker , Sagemaker , sagemaker , or\\nLabelingFunction . This applies to both your pre-annotation and post-annotation Lambdas. If you\\nchoose to use names without those strings, you must explicitly provide lambda:InvokeFunction\\npermission to the IAM role used for creating the labeling job.\\nSelect your lambdas from the Lambda functions section that comes after the code editor for your\\ncustom HTML in the Ground Truth console.\\nIf you need an example, there is an end-to-end demo, including Python code for the Lambdas, in the\\n\"Demo Template: Annotation of Images with crowd-bounding-box  (p. 563)\" document.\\nPre-annotation Lambda\\nBefore a labeling task is sent to the worker, your AWS Lambda function will be sent a JSON formatted\\nrequest to provide details.\\nExample of a Pre-annotation request\\n{\\n    \"version\": \"2018-10-16\",\\n574Amazon SageMaker Developer Guide\\nStep 3: Processing with AWS Lambda\\n    \"labelingJobArn\": <labelingJobArn>\\n    \"dataObject\" : {\\n        \"source-ref\": \"s3://mybucket/myimage.png\"\\n    }\\n}\\nThe dataObject  will contain the JSON formatted properties from your manifest\\'s data object. For\\na very basic image annotation job, it might just be a source-ref  property specifying the image to\\nbe annotated. The JSON line objects in your manifest can be up to 100 kilobytes in size and contain a\\nvariety of data.\\nIn return, Ground Truth will require a response formatted like this:\\nExample of expected return data\\n{\\n    \"taskInput\": <json object> ,\\n    \"isHumanAnnotationRequired\": <boolean>  # Optional\\n}\\nThat <json object>  may be a bit deceiving. It needs to contain all the data your custom form will\\nneed. If you\\'re doing a bounding box task where the instructions stay the same all the time, it may just\\nbe the HTTP(S) or S3 resource for your image ﬁle. If it\\'s a sentiment analysis task and diﬀerent objects\\nmay have diﬀerent choices, it would be the object reference as a string and the choices as an array of\\nstrings.\\nImplications of isHumanAnnotationRequired\\nThis value is optional because it will default to true. The primary use case for explicitly setting\\nit is when you want to exclude this data object from being labeled by human workers.\\nIf you have a mix of objects in your manifest, with some requiring human annotation and some not\\nneeding it, you can include a isHumanAnnotationRequired  value in each data object. You can then\\nuse code in your pre-annotation Lambda to read the value from the data object and set the value in your\\nLambda output.\\nThe pre-annotation Lambda runs ﬁrst\\nBefore any tasks are available to workers, your entire manifest will be processed into an\\nintermediate form, using your Lambda. This means you won\\'t be able to change your Lambda\\npart of the way through a labeling job and see that have an impact on the remaining tasks.\\nPost-annotation Lambda\\nWhen the worker has completed the task, Ground Truth will send the results to your Post-annotation\\nLambda . This Lambda is generally used for Annotation Consolidation  (p. 537). The request object will\\ncome in like this:\\nExample of a post-labeling task request\\n{\\n    \"version\": \"2018-10-16\",\\n    \"labelingJobArn\": <labelingJobArn>,\\n    \"labelCategories\": [<string>],\\n    \"labelAttributeName\": <string>,\\n    \"roleArn\" : \"string\",\\n    \"payload\": {\\n        \"s3Uri\": <string>\\n    }\\n }\\n575Amazon SageMaker Developer Guide\\nStep 3: Processing with AWS Lambda\\nPost-labeling task Lambda permissions\\nThe actual annotation data will be in a ﬁle designated by the s3Uri  string in the payload object. To\\nprocess the annotations as they come in, even for a simple pass through function, you need to assign the\\nnecessary permissions to your Lambda to read ﬁles from your S3 bucket.\\nIn the Console page for creating your Lambda, scroll to the Execution role panel. Select Create a new\\nrole from one or more templates. Give the role a name. From the Policy templates drop-down, choose\\nAmazon S3 object read-only permissions. Save the Lambda and the role will be saved and selected.\\nExample of an annotation data ﬁle\\n[\\n    {\\n        \"datasetObjectId\": <string>,\\n        \"dataObject\": {\\n            \"s3Uri\": <string>,\\n            \"content\": <string>\\n        },\\n        \"annotations\": [{\\n            \"workerId\": <string>,\\n            \"annotationData\": {\\n                \"content\": <string>,\\n                \"s3Uri\": <string>\\n            }\\n       }]\\n    }\\n]\\nEssentially, all the ﬁelds from your form will be in the content object. At this point you can start\\nrunning data consolidation algorithms on the data, using an AWS database service to store results. Or\\nyou can pass some processed/optimized results back to Ground Truth for storage in your consolidated\\nannotation manifests in the S3 bucket you specify for output during the conﬁguration of the labeling\\njob.\\nIn return, Ground Truth will require a response formatted like this:\\nExample of expected return data\\n[\\n   {        \\n        \"datasetObjectId\": <string> ,\\n        \"consolidatedAnnotation\": {\\n            \"content\": {\\n                \" <labelattributename> \": {\\n                    # ... label content\\n                }\\n            }\\n        }\\n    },\\n   {        \\n        \"datasetObjectId\": <string> ,\\n        \"consolidatedAnnotation\": {\\n            \"content\": {\\n                \" <labelattributename> \": {\\n                    # ... label content\\n                }\\n            }\\n        }\\n    }\\n    .\\n576Amazon SageMaker Developer Guide\\nCustom Workﬂows via the API\\n    .\\n    .\\n]\\nAt this point, all the data you\\'re sending to your S3 bucket, other than the datasetObjectId  will be in\\nthe content object.\\nThat will result in an entry in your job\\'s consolidation manifest like this:\\nExample of label format in output manifest\\n{  \"source-ref\"/\"source\" : \" <s3uri or content> \", \\n   \"<labelAttributeName> \": {\\n        # ... label content from you\\n    },   \\n   \"<labelAttributeName> -metadata\": { # This will be added by Ground Truth\\n        \"job_name\": <labelingJobName> ,\\n        \"type\": \"groundTruth/custom\",\\n        \"human-annotated\": \"yes\", \\n        \"creation_date\": <date> # Timestamp of when received from Post-labeling Lambda\\n    }\\n}\\nBecause of the potentially complex nature of a custom template and the data it collects, Ground Truth\\ndoes not oﬀer further processing of the data or insights into it.\\nNext\\nCustom Workﬂows via the API (p. 577)\\nCustom Workﬂows via the API\\nWhen you have created your custom UI template (Step 2) and processing Lambda functions\\n(Step 3), you should place the template in an Amazon S3 bucket with a ﬁle name format of:\\n<FileName>.liquid.html .\\nUse the CreateLabelingJob (p. 643) action to conﬁgure your task. You\\'ll use the location of\\na custom template ( Step 2: Creating your custom labeling task template (p. 558)) stored in\\na <filename> .liquid.html  ﬁle on S3 as the value for the UiTemplateS3Uri  ﬁeld in the\\nUiConfig  (p. 1036) object within the HumanTaskConfig  (p. 907) object.\\nFor the AWS Lambda tasks described in Step 3: Processing with AWS Lambda (p. 574), the post-\\nannotation task\\'s ARN will be used as the value for the AnnotationConsolidationLambdaArn  ﬁeld,\\nand the pre-annotation task will be used as the value for the PreHumanTaskLambdaArn.\\nHTML Elements Reference\\nAmazon SageMaker Ground Truth provides customers with the ability to design their own custom task\\ntemplates in HTML. Documentation of how to implement custom templates is available in Creating\\nCustom Labeling Workﬂows (p. 557). Below is a list of enhanced HTML elements that make building a\\ncustom template easier and provide a familiar UI for workers.\\nTopics\\n•crowd-bounding-box (p. 578)\\n•crowd-image-classiﬁer (p. 581)\\n•crowd-classiﬁer (p. 582)\\n577Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n•crowd-instance-segmentation (p. 583)\\n•crowd-semantic-segmentation (p. 585)\\n•crowd-entity-annotation (p. 587)\\n•crowd-alert (p. 589)\\n•crowd-badge (p. 590)\\n•crowd-button (p. 591)\\n•crowd-card (p. 592)\\n•crowd-checkbox (p. 592)\\n•crowd-fab (p. 594)\\n•crowd-form (p. 595)\\n•crowd-icon-button (p. 595)\\n•crowd-input (p. 596)\\n•crowd-instructions (p. 598)\\n•crowd-keypoint (p. 599)\\n•crowd-modal (p. 601)\\n•crowd-polygon (p. 602)\\n•crowd-radio-button (p. 607)\\n•crowd-radio-group (p. 608)\\n•crowd-slider (p. 609)\\n•crowd-tab (p. 610)\\n•crowd-tabs (p. 610)\\n•crowd-text-area (p. 611)\\n•crowd-toast (p. 612)\\n•crowd-toggle-button (p. 613)\\ncrowd-bounding-box\\nA widget for drawing rectangles on an image and assigning a label to the portion of the image that is\\nenclosed in each rectangle.\\nAttributes\\nThe following attributes are supported by this element.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\nlabels\\nA JSON formatted array of strings, each of which is a label that a worker can assign to the image portion\\nenclosed by a rectangle. Limit:  10 labels.\\nname\\nThe name of this widget. It\\'s used as a key for the widget\\'s input in the form output.\\nsrc\\nThe URL of the image on which to draw bounding boxes.\\n578Amazon SageMaker Developer Guide\\nHTML Elements Reference\\ninitial-value\\nAn array of JSON objects, each of which sets a bounding box when the component is loaded. Each JSON\\nobject in the array contains the following properties.\\n•height  – The height of the box in pixels.\\n•label  – The text assigned to the box as part of the labeling task. This text must match one of the labels\\ndeﬁned in the labels  attribute of the <crowd-bounding-box> element.\\n•left – Distance of the top-left corner of the box from the left side of the image, measured in pixels.\\n•top – Distance of the top-left corner of the box from the top of the image, measured in pixels.\\n•width  – The width of the box in pixels.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: full-instructions (p. 579), short-instructions (p. 579)\\nRegions\\nThe following regions are required by this element.\\nfull-instructions\\nGeneral instructions about how to draw bounding boxes.\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe following output is supported by this element.\\nboundingBoxes\\nAn array of JSON objects, each of which speciﬁes a bounding box that has been created by the worker.\\nEach JSON object in the array contains the following properties.\\n•height  – The height of the box in pixels.\\n•label  – The text assigned to the box as part of the labeling task. This text must match one of the labels\\ndeﬁned in the labels  attribute of the <crowd-bounding-box> element.\\n•left – Distance of the top-left corner of the box from the left side of the image, measured in pixels.\\n•top – Distance of the top-left corner of the box from the top of the image, measured in pixels.\\n•width  – The width of the box in pixels.\\ninputImageProperties\\nA JSON object that speciﬁes the dimensions of the image that is being annotated by the worker. This\\nobject contains the following properties.\\n•height  – The height, in pixels, of the image.\\n•width  – The width, in pixels, of the image.\\n579Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nExample : Sample Element Outputs\\nThe following are samples of outputs from common use scenarios for this element.\\nSingle Label, Single Box / Multiple Label, Single Box\\n[\\n  {\\n    \"annotatedResult\": {\\n      \"boundingBoxes\": [\\n        {\\n          \"height\": 401,\\n          \"label\": \"Dog\",\\n          \"left\": 243,\\n          \"top\": 117,\\n          \"width\": 187\\n        }\\n      ],\\n      \"inputImageProperties\": {\\n        \"height\": 533,\\n        \"width\": 800\\n      }\\n    }\\n  }\\n]\\nSingle Label, Multiple Box\\n[\\n  {\\n    \"annotatedResult\": {\\n      \"boundingBoxes\": [\\n        {\\n          \"height\": 401,\\n          \"label\": \"Dog\",\\n          \"left\": 243,\\n          \"top\": 117,\\n          \"width\": 187\\n        },\\n        {\\n          \"height\": 283,\\n          \"label\": \"Dog\",\\n          \"left\": 684,\\n          \"top\": 120,\\n          \"width\": 116\\n        }\\n      ],\\n      \"inputImageProperties\": {\\n        \"height\": 533,\\n        \"width\": 800\\n      }\\n    }\\n  }\\n]\\nMultiple Label, Multiple Box\\n[\\n  {\\n    \"annotatedResult\": {\\n      \"boundingBoxes\": [\\n        {\\n580Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n          \"height\": 395,\\n          \"label\": \"Dog\",\\n          \"left\": 241,\\n          \"top\": 125,\\n          \"width\": 158\\n        },\\n        {\\n          \"height\": 298,\\n          \"label\": \"Cat\",\\n          \"left\": 699,\\n          \"top\": 116,\\n          \"width\": 101\\n        }\\n      ],\\n      \"inputImageProperties\": {\\n        \"height\": 533,\\n        \"width\": 800\\n      }\\n    }\\n  }\\n]\\nYou could have many labels available, but only the ones that are used appear in the output.\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-image-classiﬁer\\nA widget for classifying an image, which can be a JPG, PNG, or GIF, with no size limit.\\nAttributes\\nThe following attributes are required by this element.\\ncategories\\nA JSON formatted array of strings, each of which is a category that a worker can assign to the image. You\\nshould include \"other\" as a category, so that the worker can provide an answer. You can specify up to 10\\ncategories.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\nname\\nThe name of this widget. It is used as a key for the widget\\'s input in the form output.\\nsrc\\nThe URL of the image to be classiﬁed.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n581Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: full-instructions (p. 582), short-instructions (p. 582)\\nRegions\\nThe following regions are required by this element.\\nfull-instructions\\nGeneral instructions about how to do image classiﬁcation.\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe output of this element is a string that speciﬁes one of the values deﬁned in the categories  attribute\\nof the <crowd-image-classiﬁer> element.\\nExample : Sample Element Outputs\\nThe following is a sample of output from this element.\\n[\\n  {\\n    \"<name>\": {\\n      \"label\": \" <value>\"\\n    }\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-classiﬁer\\nA widget for classifying non-image content, such as audio, video, or text.\\nAttributes\\nThe following attributes are supported by this element.\\ncategories\\nA JSON formatted array of strings, each of which is a category that a worker can assign to the to the text.\\nYou should include \"other\" as a category, otherwise the worker my not be able to provide an answer.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\n582Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nname\\nThe name of this widget. It is used as a key for the widget\\'s input in the form output.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: classiﬁcation-target (p. 583), full-instructions (p. 583), short-instructions (p. 583)\\nRegions\\nThe following regions are supported by this element.\\nclassiﬁcation-target\\nThe content to be classiﬁed by the worker. This can be plain text or HTML. Examples of how the HTML\\ncan be used include but are not limited to  embedding a video or audio player, embedding a PDF, or\\nperforming a comparison of two or more images.\\nfull-instructions\\nGeneral instructions about how to do text classiﬁcation.\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe output of this element is an object using the speciﬁed name value as a property name, and a string\\nfrom the categories  as the property\\'s value.\\nExample : Sample Element Outputs\\nThe following is a sample of output from this element.\\n[\\n  {\\n    \"<name>\": {\\n      \"label\": \" <value>\"\\n    }\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-instance-segmentation\\nA widget for identifying individual instances of speciﬁc objects within an image and creating a colored\\noverlay for each labeled instance.\\n583Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nAttributes\\nThe following attributes are supported by this element.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\nlabels\\nA JSON formatted array of strings, each of which is a label that a worker can assign to an instance of an\\nobject in the image. Workers can generate diﬀerent overlay colors for each relevant instance by selecting\\n\"add instance\" under the label in the tool.\\nname\\nThe name of this widget. It is used as a key for the labeling data in the form output.\\nsrc\\nThe URL of the image that is to be labeled.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: full-instructions (p. 584), short-instructions (p. 584)\\nRegions\\nThe following regions are supported by this element.\\nfull-instructions\\nGeneral instructions about how to do image segmentation.\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe following output is supported by this element.\\nlabeledImage\\nA JSON Object containing a Base64 encoded PNG of the labels.\\ninstances\\nA JSON Array containing objects with the instance labels and colors.\\n•color – The hexadecimal value of the label\\'s RGB color in the labeledImage  PNG.\\n•label  – The label given to overlay(s) using that color. This value may repeat, because the diﬀerent\\ninstances of the label are identiﬁed by their unique color.\\n584Amazon SageMaker Developer Guide\\nHTML Elements Reference\\ninputImageProperties\\nA JSON object that speciﬁes the dimensions of the image that is being annotated by the worker. This\\nobject contains the following properties.\\n•height  – The height, in pixels, of the image.\\n•width  – The width, in pixels, of the image.\\nExample : Sample Element Outputs\\nThe following is a sample of output from this element.\\n[\\n  {\\n    \"annotatedResult\": {\\n      \"inputImageProperties\": {\\n        \"height\": 533,\\n        \"width\": 800\\n      },\\n      \"instances\": [\\n        {\\n          \"color\": \"#1f77b4\",\\n          \"label\": \" <Label 1>\": \\n        },\\n        {\\n          \"color\": \"#2ca02c\",\\n          \"label\": \" <Label 1>\": \\n        },\\n        {\\n          \"color\": \"#ff7f0e\",\\n          \"label\": \" <Label 3>\": \\n        },\\n      ],\\n      \"labeledImage\": {\\n        \"pngImageData\": \" <Base-64 Encoded Data >\"\\n      }\\n    }\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-semantic-segmentation\\nA widget for segmenting an image and assigning a label to each image segment.\\nAttributes\\nThe following attributes are supported by this element.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\n585Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nlabels\\nA JSON formatted array of strings, each of which is a label that a worker can assign to a segment of the\\nimage.\\nname\\nThe name of this widget. It is used as a key for the widget\\'s input in the form output.\\nsrc\\nThe URL of the image that is to be segmented.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: full-instructions (p. 586), short-instructions (p. 586)\\nRegions\\nThe following regions are supported by this element.\\nfull-instructions\\nGeneral instructions about how to do image segmentation.\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe following output is supported by this element.\\nlabeledImage\\nA JSON Object containing a Base64 encoded PNG of the labels.\\nlabelMappings\\nA JSON Object containing objects with named with the segmentation labels.\\n•color – The hexadecimal value of the label\\'s RGB color in the labeledImage  PNG.\\ninputImageProperties\\nA JSON object that speciﬁes the dimensions of the image that is being annotated by the worker. This\\nobject contains the following properties.\\n•height  – The height, in pixels, of the image.\\n•width  – The width, in pixels, of the image.\\nExample : Sample Element Outputs\\nThe following is a sample of output from this element.\\n586Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n[\\n  {\\n    \"annotatedResult\": {\\n      \"inputImageProperties\": {\\n        \"height\": 533,\\n        \"width\": 800\\n      },\\n      \"labelMappings\": {\\n        \" <Label 2>\": {\\n          \"color\": \"#ff7f0e\"\\n        },\\n        \" <label 3>\": {\\n          \"color\": \"#2ca02c\"\\n        },\\n        \" <label 1>\": {\\n          \"color\": \"#1f77b4\"\\n        }\\n      },\\n      \"labeledImage\": {\\n        \"pngImageData\": \" <Base-64 Encoded Data >\"\\n      }\\n    }\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-entity-annotation\\nA widget for labeling words, phrases, or character strings within a longer text.\\nImportant: Self-contained Widget\\nDo not use <crowd-entity-annotation>  element with the <crowd-form>  element. It\\ncontains its own form submission logic and Submit  button.\\nAttributes\\nThe following attributes are supported by this element.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\ninitial-value\\nA JSON formatted array of objects, each of which deﬁnes an annotation to apply to the text at\\ninitialization. Objects contain a label  value that matches one in the labels attribute, an integer\\nstartOffset  value for labeled span\\'s starting unicode oﬀset, and an integer endOffset  value for the\\nending unicode oﬀset.\\nExample\\n[\\n  {\\n587Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n    label: \\'person\\',\\n    startOffset: 0,\\n    endOffset: 16\\n  },\\n  ...\\n]\\nlabels\\nA JSON formatted array of objects, each of which contains:\\n•label (required): The name used to identify entities.\\n•fullDisplayName  (optional): Used for the label list in the task widget. Defaults to the label value if\\nnot speciﬁed.\\n•shortDisplayName  (optional): An abbreviation of 3-4 letters to display above selected entities.\\nDefaults to the label value if not speciﬁed.\\nshortDisplayName  is highly recommended\\nValues displayed above the selections can overlap and create diﬃculty managing labeled\\nentities in the workspace. Providing a 3-4 character shortDisplayName  for each label\\nis highly recommended to prevent overlap and keep the workspace manageable for your\\nworkers.\\nExample\\n[\\n  {\\n    label: \\'person\\',\\n    shortDisplayName: \\'per\\', \\n    fullDisplayName: \\'person\\'\\n  }\\n]\\nname\\nServes as the widget\\'s name in the DOM. It is also used as the label attribute name in form output and\\nthe output manifest.\\ntext\\nThe text to be annotated. The templating system escapes quotes and HTML strings by default. If your\\ncode is already escaped or partially escaped, see Variable ﬁlters (p. 561) for more ways to control\\nescaping.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Child elements: full-instructions (p. 588), short-instructions (p. 589)\\nRegions\\nThe following regions are supported by this element.\\nfull-instructions\\nGeneral instructions about how to work with the widget.\\n588Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe following output is supported by this element.\\nentities\\nA JSON object that speciﬁes the start, end, and label of an annotation. This object contains the following\\nproperties.\\n•label  – The assigned label.\\n•startOﬀset – The Unicode oﬀset of the beginning of the selected text.\\n•endOﬀset  – The Unicode oﬀset of the ﬁrst character after the selection.\\nExample : Sample Element Outputs\\nThe following is a sample of the output from this element.\\n{\\n  \"myAnnotatedResult\": {\\n    \"entities\": [\\n      {\\n        \"endOffset\": 54,\\n        \"label\": \"person\",\\n        \"startOffset\": 47\\n      },\\n      {\\n        \"endOffset\": 97,\\n        \"label\": \"event\",\\n        \"startOffset\": 93\\n      },\\n      {\\n        \"endOffset\": 219,\\n        \"label\": \"date\",\\n        \"startOffset\": 212\\n      },\\n      {\\n        \"endOffset\": 271,\\n        \"label\": \"location\",\\n        \"startOffset\": 260\\n      }\\n    ]\\n  }\\n}\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-alert\\nA message that alerts the worker to a current situation.\\n589Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nAttributes\\nThe following attributes are supported by this element.\\ndismissible\\nA Boolean switch that, if present, allows the message to be closed by the worker.\\ntype\\nA string that speciﬁes the type of message to be displayed. The possible values are \"info\" (the default),\\n\"success\", \"error\", and \"warning\".\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-badge\\nAn icon that ﬂoats over the top right corner of another element to which it is attached.\\nAttributes\\nThe following attributes are supported by this element.\\nfor\\nA string that speciﬁes the ID of the element to which the badge is attached.\\nicon\\nA string that speciﬁes the icon to be displayed in the badge. The string must be either the name of an\\nicon from the open-source iron-icons  set, which is pre-loaded, or the URL to a custom icon.\\nThis attribute overrides the label  attribute.\\nlabel\\nThe text to display in the badge. Three characters or less is recommended because text that is too large\\nwill overﬂow the badge area. An icon can be displayed instead of text by setting the icon attribute.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\n590Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-button\\nA styled button that represents some action.\\nAttributes\\nThe following attributes are supported by this element.\\ndisabled\\nA Boolean switch that, if present, displays the button as disabled and prevents clicks.\\nform-action\\nA switch that either submits its parent crowd-form (p. 595) element, if set to \"submit\", or resets its\\nparent <crowd-form> element, if set to \"reset\".\\nhref\\nThe URL to an online resource. Use this property if you need a link styled as a button.\\nicon\\nA string that speciﬁes the icon to be displayed next to the button\\'s text. The string must be either the\\nname of an icon from the open-source iron-icons  set, which is pre-loaded, or the URL to a custom icon.\\nThe icon is positioned to either the left or the right of the text, as speciﬁed by the icon-align  attribute.\\nicon-align\\nThe left or right position of the icon relative to the button\\'s text. The default is \"left\".\\nicon-url\\nA URL to a custom image for the icon. A custom image can be used in place of a standard icon that is\\nspeciﬁed by the icon attribute.\\nloading\\nA Boolean switch that, if present, displays the button as being in a loading state. This attribute has\\nprecedence over the disabled  attribute if both attributes are present.\\ntarget\\nWhen you use the href attribute to make the button act as a hyperlink to a speciﬁc URL, the target\\nattribute optionally targets a frame or window where the linked URL should load.\\nvariant\\nThe general style of the button. Use \"primary\" for primary buttons, \"normal\" for secondary buttons,\\n\"link\" for tertiary buttons, or \"icon\" to display only the icon without text.\\n591Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-card\\nA box with an elevated appearance for displaying information.\\nAttributes\\nThe following attributes are supported by this element.\\nheading\\nThe text displayed at the top of the box.\\nimage\\nA URL to an image to be displayed within the box.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-checkbox\\nA UI component that can be checked or unchecked allowing a user to select multiple options from a set.\\nAttributes\\nThe following attributes are supported by this element.\\nchecked\\nA Boolean switch that, if present, displays the check box as checked.\\n592Amazon SageMaker Developer Guide\\nHTML Elements Reference\\ndisabled\\nA Boolean switch that, if present, displays the check box as disabled and prevents it from being checked.\\nname\\nA string that is used to identify the answer submitted by the worker. This value will match a key in the\\nJSON object that speciﬁes the answer.\\nrequired\\nA Boolean switch that, if present, requires the worker to provide input.\\nvalue\\nA string used as the name for the check box state in the output. Defaults to \"on\" if not speciﬁed.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nOutput\\nProvides a JSON object. The name string is the object name and the valuestring is the property name\\nfor a Boolean value based on the check box state; true if checked, false if not checked.\\nExample : Sample Element Outputs\\nUsing the same name value for multiple boxes.\\n<!-- INPUT -->\\n<div><crowd-checkbox name=\"myformbit\" value=\"Red\"> Red </div>\\n<div><crowd-checkbox name=\"myformbit\" value=\"Yellow\"> Yellow </div>\\n<div><crowd-checkbox name=\"myformbit\" value=\"Green\"> Green </div>\\n    \\n//Output with \"Red\" checked\\n[\\n  {\\n    \"myformbit\": {\\n      \"Green\": false,\\n      \"Red\": true,\\n      \"Yellow\": false\\n    }\\n  }\\n]\\nNote that all three color values are properties of a single object.\\nUsing diﬀerent name values for each box.\\n<!-- INPUT -->\\n<div><crowd-checkbox name=\"Stop\" value=\"Red\"> Red </div>\\n<div><crowd-checkbox name=\"Slow\" value=\"Yellow\"> Yellow </div>\\n593Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n<div><crowd-checkbox name=\"Go\" value=\"Green\"> Green </div>\\n//Output with \"Red\" checked\\n[\\n  {\\n    \"Go\": {\\n      \"Green\": false\\n    },\\n    \"Slow\": {\\n      \"Yellow\": false\\n    },\\n    \"Stop\": {\\n      \"Red\": true\\n    }\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-fab\\nA ﬂoating button with an image in its center.\\nAttributes\\nThe following attributes are supported by this element.\\ndisabled\\nA Boolean switch that, if present, displays the ﬂoating button as disabled and prevents clicks.\\nicon\\nA string that speciﬁes the icon to be displayed in the center of the button. The string must be either the\\nname of an icon from the open-source iron-icons  set, which is pre-loaded, or the URL to a custom icon.\\nlabel\\nA string consisting of a single character that can be used instead of an icon. Emojis or multiple characters\\nmay result in the button displaying an ellipsis instead.\\ntitle\\nA string that will display as a tool tip when the mouse hovers over the button.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\n594Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-form\\nThe form wrapper for all custom tasks. Sets and implements important actions for the proper\\nsubmission of your form data.\\nIf a crowd-button (p. 591) of type \"submit\" is not included inside the <crowd-form> element, it will\\nautomatically be appended within the <crowd-form> element.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: none\\n•Child elements: Any of the UI Template (p. 577) elements\\nElement Events\\nThe crowd-form  element extends the standard HTML form  element  and inherits its events, such as\\nonclick  and onsubmit .\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-icon-button\\nA button with an image placed in the center. When the user touches the button, a ripple eﬀect emanates\\nfrom the center of the button.\\nAttributes\\nThe following attributes are supported by this element.\\ndisabled\\nA Boolean switch that, if present, displays the button as disabled and prevents clicks.\\nicon\\nA string that speciﬁes the icon to be displayed in the center of the button. The string must be either the\\nname of an icon from the open-source iron-icons  set, which is pre-loaded, or the URL to a custom icon.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n595Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-input\\nA box that accepts input data.\\nCannot be self-closing\\nUnlike the input element in the HTML standard, this element cannot be self-closed by putting\\na slash before the ending bracket, e.g. <crowd-input ... /> . It must be followed with a </\\ncrowd-input>  to close the element.\\nAttributes\\nThe following attributes are supported by this element.\\nallowed-pattern\\nA regular expression that is used with the auto-validate  attribute to ignore non-matching characters as\\nthe worker types.\\nauto-focus\\nWhen the value is set to true, the browser places focus inside the input area after loading. This way, the\\nworker can start typing without having to select it ﬁrst.\\nauto-validate\\nA Boolean switch that, if present, turns on input validation. The behavior of the validator can be\\nmodiﬁed by the error-message  and allowed-pattern  attributes.\\ndisabled\\nA Boolean switch that, if present, displays the input area as disabled.\\nerror-message\\nThe text to be displayed below the input ﬁeld, on the left side, if validation fails.\\nlabel\\nA string that is displayed inside a text ﬁeld.\\nThis text shrinks and rises up above a text ﬁeld when the worker starts typing in the ﬁeld or when the\\nvalue  attribute is set.\\nmax-length\\nA maximum number of characters the input will accept. Input beyond this limit is ignored.\\n596Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nmin-length\\nA minimum length for the input in the ﬁeld\\nname\\nSets the name of the input to be used in the DOM and the output of the form.\\nplaceholder\\nA string value that is used as placeholder text, displayed until the worker starts entering data into the\\ninput, It is not used as a default value.\\nrequired\\nA Boolean switch that, if present, requires the worker to provide input.\\ntype\\nTakes a string to set the HTML5 input-type  behavior for the input. Examples include file  and date .\\nvalue\\nA preset that becomes the default if the worker does not provide input. The preset appears in a text ﬁeld.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nOutput\\nProvides a name string as the property name, and the text that was entered in the ﬁeld as its value.\\nExample : Sample JSON Output\\nThe values for multiple elements are output in the same object, with their name attribute value as their\\nproperty name. Elements with no input do not appear in the output. For example, let\\'s use three inputs:\\n<crowd-input name=\"tag1\" label=\"Word/phrase 1\"></crowd-input>\\n<crowd-input name=\"tag2\" label=\"Word/phrase 2\"></crowd-input>\\n<crowd-input name=\"tag3\" label=\"Word/phrase 3\"></crowd-input>\\nThis is the output if only two have input:\\n[\\n  {\\n    \"tag1\": \"blue\",\\n    \"tag2\": \"red\"\\n  }\\n]\\nThis means any code built to parse these results should be able to handle the presence or absence of\\neach input in the answers.\\n597Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-instructions\\nAn element that displays instructions on three tabbed pages, Summary, Detailed Instructions, and\\nExamples, when the worker clicks on a link or button.\\nAttributes\\nThe following attributes are supported by this element.\\nlink-text\\nThe text to display for opening the instructions. The default is Click for instructions.\\nlink-type\\nA string that speciﬁes the type of trigger for the instructions. The possible values are \"link\" (default) and\\n\"button\".\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nRegions\\nThe following regions are supported by this element.\\ndetailed-instructions\\nContent that provides speciﬁc instructions for a task. This appears on the page of the \"Detailed\\nInstructions\" tab.\\nnegative-example\\nContent that provides examples of inadequate task completion. This appears on the page of the\\n\"Examples\" tab. More than one example may be provided within this element.\\npositive-example\\nContent that provides examples of proper task completion. This appears on the page of the \"Examples\"\\ntab.\\nshort-summary\\nA brief statement that summarizes the task to be completed. This appears on the page of the \"Summary\"\\ntab. More than one example may be provided within this element.\\n598Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-keypoint\\nGenerates a tool to select and annotate key points on an image.\\nAttributes\\nThe following attributes are supported by this element.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\ninitial-value\\nAn array, in JSON format, of keypoints to be applied to the image on start. For example:\\ninitial-value=\"[\\n  {\\n    \\'label\\': \\'Left Eye\\',\\n    \\'x\\': 1022,\\n    \\'y\\': 429\\n  },\\n  {\\n    \\'label\\': \\'Beak\\',\\n    \\'x\\': 941,\\n    \\'y\\': 403\\n  }\\n]\\nNote\\nPlease note that label values used in this attribute must have a matching value in the labels\\nattribute or the point will not be rendered.\\nlabels\\nAn array, in JSON format, of strings to be used as keypoint annotation labels.\\nname\\nA string used to identify the answer submitted by the worker. This value will match a key in the JSON\\nobject that speciﬁes the answer.\\nsrc\\nThe source URI of the image to be annotated.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n599Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n•Child elements: full-instructions (p. 600), short-instructions (p. 600)\\nRegions\\nThe following regions are required by this element.\\nfull-instructions\\nGeneral instructions about how to annotate the image.\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe following output is supported by this element.\\ninputImageProperties\\nA JSON object that speciﬁes the dimensions of the image that is being annotated by the worker. This\\nobject contains the following properties.\\n•height  – The height, in pixels, of the image.\\n•width  – The width, in pixels, of the image.\\nkeypoints\\nAn array of JSON objects containing the coordinates and label of a keypoint. Each object contains the\\nfollowing properties.\\n•label  – The assigned label for the keypoint.\\n•x – The X coordinate, in pixels, of the keypoint on the image.\\n•y – The Y coordinate, in pixels, of the keypoint on the image.\\nNote\\nX and Y coordinates are based on 0,0 being the top left corner of the image.\\nExample : Sample Element Outputs\\nThe following is a sample output from using this element.\\n[\\n  {\\n    \"crowdKeypoint\": {\\n      \"inputImageProperties\": {\\n        \"height\": 1314,\\n        \"width\": 962\\n      },\\n      \"keypoints\": [\\n        {\\n          \"label\": \"dog\",\\n          \"x\": 155,\\n          \"y\": 275\\n        },\\n        {\\n          \"label\": \"cat\",\\n600Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n          \"x\": 341,\\n          \"y\": 447\\n        },\\n        {\\n          \"label\": \"cat\",\\n          \"x\": 491,\\n          \"y\": 513\\n        },\\n        {\\n          \"label\": \"dog\",\\n          \"x\": 714,\\n          \"y\": 578\\n        },\\n        {\\n          \"label\": \"cat\",\\n          \"x\": 712,\\n          \"y\": 763\\n        },\\n        {\\n          \"label\": \"cat\",\\n          \"x\": 397,\\n          \"y\": 814\\n        }\\n      ]\\n    }\\n  }\\n]\\nYou may have many labels available, but only the ones that are used appear in the output.\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-modal\\nA small window that pops up on the display when it is opened.\\nAttributes\\nThe following attributes are supported by this element.\\nlink-text\\nThe text to display for opening the modal. The default is \"Click to open modal\".\\nlink-type\\nA string that speciﬁes the type of trigger for the modal. The possible values are \"link\" (default) and\\n\"button\".\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n601Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-polygon\\nA widget for drawing polygons on an image and assigning a label to the portion of the image that is\\nenclosed in each polygon.\\nAttributes\\nThe following attributes are supported by this element.\\nheader\\nThe text to display above the image. This is typically a question or simple instruction for the worker.\\nlabels\\nA JSON formatted array of strings, each of which is a label that a worker can assign to the image portion\\nenclosed by a polygon.\\nname\\nThe name of this widget. It\\'s used as a key for the widget\\'s input in the form output.\\nsrc\\nThe URL of the image on which to draw polygons.\\ninitial-value\\nAn array of JSON objects, each of which deﬁnes a polygon to be drawn when the component is loaded.\\nEach JSON object in the array contains the following properties.\\n•label  – The text assigned to the polygon as part of the labeling task. This text must match one of the\\nlabels deﬁned in the labels  attribute of the <crowd-polygon> element.\\n•vertices – An array of JSON objects. Each object contains an x and y coordinate value for a point in the\\npolygon.\\nExample\\nAn initial-value  attribute might look something like this.\\ninitial-value = \\n  \\'[\\n     {\\n     \"label\": \"dog\",\\n     \"vertices\": \\n       [\\n602Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n         {\\n            \"x\": 570,\\n            \"y\": 239\\n         },\\n        ... \\n         {\\n            \"x\": 759,\\n            \"y\": 281\\n         }\\n       ]\\n     }\\n  ]\\'\\nBecause this will be within an HTML element, the JSON array must be enclosed in single or double\\nquotes. The example above uses single quotes to encapsulate the JSON and double quotes within the\\nJSON itself. If you must mix single and double quotes inside your JSON, replace them with their HTML\\nentity codes (&quot;  for double quote, &#39;  for single) to safely escape them.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: full-instructions (p. 603), short-instructions (p. 603)\\nRegions\\nThe following regions are required.\\nfull-instructions\\nGeneral instructions about how to draw polygons.\\nshort-instructions\\nImportant task-speciﬁc instructions that are displayed in a prominent place.\\nOutput\\nThe following output is supported by this element.\\npolygons\\nAn array of JSON objects, each of which describes a polygon that has been created by the worker. Each\\nJSON object in the array contains the following properties.\\n•label  – The text assigned to the polygon as part of the labeling task.\\n•vertices – An array of JSON objects. Each object contains an x and y coordinate value for a point in the\\npolygon. The top left corner of the image is 0,0.\\ninputImageProperties\\nA JSON object that speciﬁes the dimensions of the image that is being annotated by the worker. This\\nobject contains the following properties.\\n•height  – The height, in pixels, of the image.\\n•width  – The width, in pixels, of the image.\\n603Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nExample : Sample Element Outputs\\nThe following are samples of outputs from common use scenarios for this element.\\nSingle Label, Single Polygon\\n{\\n    \"annotatedResult\": \\n    {\\n      \"inputImageProperties\": {\\n        \"height\": 853,\\n        \"width\": 1280\\n      },\\n      \"polygons\": \\n      [\\n        {\\n          \"label\": \"dog\",\\n          \"vertices\": \\n          [\\n            {\\n              \"x\": 570,\\n              \"y\": 239\\n            },\\n            {\\n              \"x\": 603,\\n              \"y\": 513\\n            },\\n            {\\n              \"x\": 823,\\n              \"y\": 645\\n            },\\n            {\\n              \"x\": 901,\\n              \"y\": 417\\n            },\\n            {\\n              \"x\": 759,\\n              \"y\": 281\\n            }\\n          ]\\n        }\\n      ]\\n    }\\n  }\\n]\\nSingle Label, Multiple Polygons\\n[\\n  {\\n    \"annotatedResult\": {\\n      \"inputImageProperties\": {\\n        \"height\": 853,\\n        \"width\": 1280\\n      },\\n      \"polygons\": [\\n        {\\n          \"label\": \"dog\",\\n          \"vertices\": [\\n            {\\n              \"x\": 570,\\n              \"y\": 239\\n            },\\n            {\\n604Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n              \"x\": 603,\\n              \"y\": 513\\n            },\\n            {\\n              \"x\": 823,\\n              \"y\": 645\\n            },\\n            {\\n              \"x\": 901,\\n              \"y\": 417\\n            },\\n            {\\n              \"x\": 759,\\n              \"y\": 281\\n            }\\n          ]\\n        },\\n        {\\n          \"label\": \"dog\",\\n          \"vertices\": [\\n            {\\n              \"x\": 870,\\n              \"y\": 278\\n            },\\n            {\\n              \"x\": 908,\\n              \"y\": 446\\n            },\\n            {\\n              \"x\": 1009,\\n              \"y\": 602\\n            },\\n            {\\n              \"x\": 1116,\\n              \"y\": 519\\n            },\\n            {\\n              \"x\": 1174,\\n              \"y\": 498\\n            },\\n            {\\n              \"x\": 1227,\\n              \"y\": 479\\n            },\\n            {\\n              \"x\": 1179,\\n              \"y\": 405\\n            },\\n            {\\n              \"x\": 1179,\\n              \"y\": 337\\n            }\\n          ]\\n        }\\n      ]\\n    }\\n  }\\n]\\nMultiple Labels, Multiple Polygons\\n[\\n  {\\n    \"annotatedResult\": {\\n      \"inputImageProperties\": {\\n605Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n        \"height\": 853,\\n        \"width\": 1280\\n      },\\n      \"polygons\": [\\n        {\\n          \"label\": \"dog\",\\n          \"vertices\": [\\n            {\\n              \"x\": 570,\\n              \"y\": 239\\n            },\\n            {\\n              \"x\": 603,\\n              \"y\": 513\\n            },\\n            {\\n              \"x\": 823,\\n              \"y\": 645\\n            },\\n            {\\n              \"x\": 901,\\n              \"y\": 417\\n            },\\n            {\\n              \"x\": 759,\\n              \"y\": 281\\n            }\\n          ]\\n        },\\n        {\\n          \"label\": \"cat\",\\n          \"vertices\": [\\n            {\\n              \"x\": 870,\\n              \"y\": 278\\n            },\\n            {\\n              \"x\": 908,\\n              \"y\": 446\\n            },\\n            {\\n              \"x\": 1009,\\n              \"y\": 602\\n            },\\n            {\\n              \"x\": 1116,\\n              \"y\": 519\\n            },\\n            {\\n              \"x\": 1174,\\n              \"y\": 498\\n            },\\n            {\\n              \"x\": 1227,\\n              \"y\": 479\\n            },\\n            {\\n              \"x\": 1179,\\n              \"y\": 405\\n            },\\n            {\\n              \"x\": 1179,\\n              \"y\": 337\\n            }\\n          ]\\n        }\\n606Amazon SageMaker Developer Guide\\nHTML Elements Reference\\n      ]\\n    }\\n  }\\n]\\nYou could have many labels available, but only the ones that are used appear in the output.\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-radio-button\\nA button that can be either checked or unchecked. When radio buttons are inside a radio group, exactly\\none radio button in the group can be checked at any time.\\nAttributes\\nThe following attributes are supported by this element.\\nchecked\\nA Boolean switch that, if present, displays the radio button as checked.\\ndisabled\\nA Boolean switch that, if present, displays the button as disabled and prevents it from being checked.\\nname\\nA string that is used to identify the answer submitted by the worker. This value will match a key in the\\nJSON object that speciﬁes the answer.\\nNote\\nIf you use the buttons outside of a crowd-radio-group (p. 608) element, but with the same\\nname string and diﬀerent value  strings, the name object in the output will contain a Boolean\\nvalue for each value string. To ensure that only one button in a group is selected, make them\\nchildren of a crowd-radio-group (p. 608) element and use diﬀerent name values.\\nvalue\\nA property name for the element\\'s boolean value. If not speciﬁed, it uses \"on\" as the default, e.g.\\n{ \"<name>\": { \"<value>\": <true or false> } } .\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-radio-group (p. 608)\\n•Child elements: none\\nOutput\\nOutputs an object with the following pattern: { \"<name>\": { \"<value>\": <true or false> } } .\\nIf you use the buttons outside of a crowd-radio-group (p. 608) element, but with the same name\\n607Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nstring and diﬀerent value strings, the name object will contain a Boolean value for each value\\nstring. To ensure that only one in a group of buttons is selected, make them children of a crowd-radio-\\ngroup (p. 608) element and use diﬀerent name values.\\nExample Sample output of this element\\n[\\n  {\\n    \"btn1\": {\\n      \"yes\": true\\n    },\\n    \"btn2\": {\\n      \"no\": false\\n    }\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-radio-group\\nA group of radio buttons. Only one radio button within the group can be selected. Choosing one radio\\nbutton clears any previously chosen radio button within the same group.\\nAttributes\\nNo special attributes are supported by this element.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: crowd-radio-button (p. 607)\\nOutput\\nOutputs an array of objects representing the crowd-radio-button (p. 607) elements within it.\\nExample Sample of Element Output\\n[\\n  {\\n    \"btn1\": {\\n      \"yes\": true\\n    },\\n    \"btn2\": {\\n      \"no\": false\\n    }\\n  }\\n]\\n608Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-slider\\nA bar with a sliding knob that allows a worker to select a value from a range of values by moving\\nthe knob. The slider makes it a great choice for settings that reﬂect intensity levels, such as volume,\\nbrightness, or color saturation.\\nAttributes\\nThe following attributes are supported by this element.\\ndisabled\\nA Boolean switch that, if present, displays the slider as disabled.\\neditable\\nA Boolean switch that, if present, displays an up/down button that can be chosen to select the value.\\nSelecting the value via the up/down button is an alternative to selecting the value by moving the knob\\non the slider. The knob on the slider will move synchronously with the up/down button choices.\\nmax\\nA number that speciﬁes the maximum value on the slider.\\nmin\\nA number that speciﬁes the minimum value on the slider.\\nname\\nA string that is used to identify the answer submitted by the worker. This value will match a key in the\\nJSON object that speciﬁes the answer.\\npin\\nA Boolean switch that, if present, displays the current value above the knob as the knob is moved.\\nrequired\\nA Boolean switch that, if present, requires the worker to provide input.\\nsecondary-progress\\nWhen used with a crowd-slider-secondary-color  CSS attribute, the progress bar is colored\\nto the point represented by the secondary-progress . For example, if this was representing the\\nprogress on a streaming video, the value would represent where the viewer was in the video timeline.\\nThe secondary-progress  value would represent the point on the timeline to which the video had\\nbuﬀered.\\nstep\\nA number that speciﬁes the diﬀerence between selectable values on the slider.\\n609Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nvalue\\nA preset that becomes the default if the worker does not provide input.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-tab\\nA component styled to look like a tab with information below.\\nAttributes\\nThe following attributes are supported by this element.\\nheader\\nThe text appearing on the tab. This is usually some short descriptive name indicative of the information\\ncontained below the tab.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-tabs (p. 610)\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-tabs\\nA container for tabbed information.\\nAttributes\\nThis element has no attributes.\\n610Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: crowd-tab (p. 610)\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-text-area\\nA ﬁeld for text input.\\nAttributes\\nThe following attributes are supported by this element.\\nauto-focus\\nA Boolean switch that, if present, puts the cursor in this element on-load so that users can immediately\\nbegin typing without having to click inside the element.\\nauto-validate\\nA Boolean switch that, if present, turns on input validation. The behavior of the validator can be\\nmodiﬁed by the error-message  and allowed-pattern  attributes.\\nchar-counter\\nA Boolean switch that, if present, puts a small text ﬁeld beneath the lower-right corner of the element,\\ndisplaying the number of characters inside the element.\\ndisabled\\nA Boolean switch that, if present, displays the input area as disabled.\\nerror-message\\nThe text to be displayed below the input ﬁeld, on the left side, if validation fails.\\nlabel\\nA string that is displayed inside a text ﬁeld.\\nThis text shrinks and rises up above a text ﬁeld when the worker starts typing in the ﬁeld or when the\\nvalue  attribute is set.\\nmax-length\\nAn integer that speciﬁes the maximum number of characters allowed by the element. Characters typed\\nor pasted beyond the maximum are ignored.\\n611Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nmax-rows\\nAn integer that speciﬁes the maximum number of rows of text that are allowed within a crowd-text-\\narea. Normally the element expands to accommodate new rows. If this is set, after the number of rows\\nexceeds it, content scrolls upward out of view and a scrollbar control appears.\\nname\\nA string used to represent the element\\'s data in the output.\\nplaceholder\\nA string presented to the user as placeholder text. It disappears after the user puts something in the\\ninput area.\\nrows\\nAn integer that speciﬁes the height of the element in rows of text.\\nvalue\\nA preset that becomes the default if the worker does not provide input. The preset appears in a text ﬁeld.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nOutput\\nThis element outputs the name as a property name and the element\\'s text contents as the value. Carriage\\nreturns in the text are represented as \\\\n.\\nExample Sample output for this element\\n[\\n  {\\n    \"textInput1\": \"This is the text; the text that\\\\nmakes the crowd go wild.\"\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-toast\\nA subtle notiﬁcation that temporarily appears on the display. Only one crowd-toast is visible.\\nAttributes\\nThe following attributes are supported by this element.\\n612Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nduration\\nA number that speciﬁes the duration, in seconds, that the notiﬁcation appears on the screen.\\ntext\\nThe text to display in the notiﬁcation.\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\ncrowd-toggle-button\\nA button that acts as an ON/OFF switch, toggling a state.\\nAttributes\\nThe following attributes are supported by this element.\\nchecked\\nA Boolean switch that, if present, displays the button switched to the ON position.\\ndisabled\\nA Boolean switch that, if present, displays the button as disabled and prevents toggling.\\ninvalid\\nWhen in an oﬀ position, a button using this attribute, will display in an alert color. The standard is red,\\nbut may be changed in CSS. When toggled on, the button will display in the same color as other buttons\\nin the on position.\\nname\\nA string that is used to identify the answer submitted by the worker. This value matches a key in the\\nJSON object that speciﬁes the answer.\\nrequired\\nA Boolean switch that, if present, requires the worker to provide input.\\nvalue\\nA value used in the output as the property name for the element\\'s Boolean state. Defaults to \"on\" if not\\nprovided.\\n613Amazon SageMaker Developer Guide\\nHTML Elements Reference\\nElement Hierarchy\\nThis element has the following parent and child elements.\\n•Parent elements: crowd-form (p. 595)\\n•Child elements: none\\nOutput\\nThis element outputs the name as the name of an object, containing the value as a property name\\nand the element\\'s state as Boolean value for the property. If no value for the element is speciﬁed, the\\nproperty name defaults to \"on.\"\\nExample Sample output for this element\\n[\\n  {\\n    \"theToggler\": {\\n      \"on\": true\\n    }\\n  }\\n]\\nSee Also\\nFor more information, see the following.\\n•Amazon SageMaker Ground Truth (p. 532)\\n•HTML Elements Reference (p. 577)\\n614Amazon SageMaker Developer Guide\\nLimits and Supported Regions\\nFor Amazon SageMaker service limits, see Amazon SageMaker Limits.\\nFor information about requesting limit increases for AWS resources, see AWS Service Limits.\\nFor a list of the AWS Regions supporting Amazon SageMaker, see Amazon SageMaker Regions.\\n615Amazon SageMaker Developer Guide\\nActions\\nAPI Reference\\nThis section contains the API Reference documentation.\\nTopics\\n•Actions (p. 616)\\n•Data Types (p. 856)\\nActions\\nThe following actions are supported by Amazon SageMaker Service:\\n•AddTags (p. 620)\\n•CreateAlgorithm (p. 622)\\n•CreateCodeRepository (p. 627)\\n•CreateCompilationJob (p. 629)\\n•CreateEndpoint (p. 632)\\n•CreateEndpointConﬁg (p. 635)\\n•CreateHyperParameterTuningJob (p. 638)\\n•CreateLabelingJob (p. 643)\\n•CreateModel (p. 648)\\n•CreateModelPackage (p. 652)\\n•CreateNotebookInstance (p. 656)\\n•CreateNotebookInstanceLifecycleConﬁg (p. 662)\\n•CreatePresignedNotebookInstanceUrl (p. 665)\\n•CreateTrainingJob (p. 667)\\n•CreateTransformJob (p. 673)\\n•CreateWorkteam (p. 678)\\n•DeleteAlgorithm  (p. 681)\\n•DeleteCodeRepository (p. 682)\\n•DeleteEndpoint  (p. 683)\\n•DeleteEndpointConﬁg  (p. 685)\\n•DeleteModel  (p. 686)\\n•DeleteModelPackage (p. 688)\\n•DeleteNotebookInstance (p. 690)\\n•DeleteNotebookInstanceLifecycleConﬁg (p. 692)\\n•DeleteTags (p. 693)\\n•DeleteWorkteam (p. 695)\\n•DescribeAlgorithm  (p. 697)\\n•DescribeCodeRepository (p. 703)\\n•DescribeCompilationJob  (p. 705)\\n•DescribeEndpoint  (p. 709)\\n616Amazon SageMaker Developer Guide\\nActions\\n•DescribeEndpointConﬁg  (p. 712)\\n•DescribeHyperParameterTuningJob (p. 715)\\n•DescribeLabelingJob  (p. 721)\\n•DescribeModel  (p. 727)\\n•DescribeModelPackage (p. 730)\\n•DescribeNotebookInstance (p. 734)\\n•DescribeNotebookInstanceLifecycleConﬁg (p. 739)\\n•DescribeSubscribedWorkteam (p. 742)\\n•DescribeTrainingJob (p. 744)\\n•DescribeTransformJob (p. 752)\\n•DescribeWorkteam (p. 757)\\n•GetSearchSuggestions (p. 759)\\n•ListAlgorithms  (p. 761)\\n•ListCodeRepositories (p. 764)\\n•ListCompilationJobs  (p. 767)\\n•ListEndpointConﬁgs  (p. 771)\\n•ListEndpoints  (p. 774)\\n•ListHyperParameterTuningJobs (p. 777)\\n•ListLabelingJobs  (p. 781)\\n•ListLabelingJobsForWorkteam (p. 785)\\n•ListModelPackages (p. 788)\\n•ListModels  (p. 791)\\n•ListNotebookInstanceLifecycleConﬁgs (p. 794)\\n•ListNotebookInstances (p. 797)\\n•ListSubscribedWorkteams (p. 801)\\n•ListTags (p. 803)\\n•ListTrainingJobs (p. 805)\\n•ListTrainingJobsForHyperParameterTuningJob (p. 808)\\n•ListTransformJobs (p. 811)\\n•ListWorkteams (p. 814)\\n•RenderUiTemplate (p. 817)\\n•Search (p. 819)\\n•StartNotebookInstance (p. 824)\\n•StopCompilationJob  (p. 826)\\n•StopHyperParameterTuningJob (p. 828)\\n•StopLabelingJob  (p. 830)\\n•StopNotebookInstance (p. 832)\\n•StopTrainingJob (p. 834)\\n•StopTransformJob (p. 836)\\n•UpdateCodeRepository (p. 838)\\n•UpdateEndpoint  (p. 840)\\n•UpdateEndpointWeightsAndCapacities (p. 842)\\n•UpdateNotebookInstance (p. 844)\\n•UpdateNotebookInstanceLifecycleConﬁg (p. 848)\\n•UpdateWorkteam (p. 850)\\n617Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nThe following actions are supported by Amazon SageMaker Runtime:\\n•InvokeEndpoint (p. 853)\\nAmazon SageMaker Service\\nThe following actions are supported by Amazon SageMaker Service:\\n•AddTags (p. 620)\\n•CreateAlgorithm (p. 622)\\n•CreateCodeRepository (p. 627)\\n•CreateCompilationJob (p. 629)\\n•CreateEndpoint (p. 632)\\n•CreateEndpointConﬁg (p. 635)\\n•CreateHyperParameterTuningJob (p. 638)\\n•CreateLabelingJob (p. 643)\\n•CreateModel (p. 648)\\n•CreateModelPackage (p. 652)\\n•CreateNotebookInstance (p. 656)\\n•CreateNotebookInstanceLifecycleConﬁg (p. 662)\\n•CreatePresignedNotebookInstanceUrl (p. 665)\\n•CreateTrainingJob (p. 667)\\n•CreateTransformJob (p. 673)\\n•CreateWorkteam (p. 678)\\n•DeleteAlgorithm  (p. 681)\\n•DeleteCodeRepository (p. 682)\\n•DeleteEndpoint  (p. 683)\\n•DeleteEndpointConﬁg  (p. 685)\\n•DeleteModel  (p. 686)\\n•DeleteModelPackage (p. 688)\\n•DeleteNotebookInstance (p. 690)\\n•DeleteNotebookInstanceLifecycleConﬁg (p. 692)\\n•DeleteTags (p. 693)\\n•DeleteWorkteam (p. 695)\\n•DescribeAlgorithm  (p. 697)\\n•DescribeCodeRepository (p. 703)\\n•DescribeCompilationJob  (p. 705)\\n•DescribeEndpoint  (p. 709)\\n•DescribeEndpointConﬁg  (p. 712)\\n•DescribeHyperParameterTuningJob (p. 715)\\n•DescribeLabelingJob  (p. 721)\\n•DescribeModel  (p. 727)\\n•DescribeModelPackage (p. 730)\\n•DescribeNotebookInstance (p. 734)\\n•DescribeNotebookInstanceLifecycleConﬁg (p. 739)\\n•DescribeSubscribedWorkteam (p. 742)\\n618Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•DescribeTrainingJob (p. 744)\\n•DescribeTransformJob (p. 752)\\n•DescribeWorkteam (p. 757)\\n•GetSearchSuggestions (p. 759)\\n•ListAlgorithms  (p. 761)\\n•ListCodeRepositories (p. 764)\\n•ListCompilationJobs  (p. 767)\\n•ListEndpointConﬁgs  (p. 771)\\n•ListEndpoints  (p. 774)\\n•ListHyperParameterTuningJobs (p. 777)\\n•ListLabelingJobs  (p. 781)\\n•ListLabelingJobsForWorkteam (p. 785)\\n•ListModelPackages (p. 788)\\n•ListModels  (p. 791)\\n•ListNotebookInstanceLifecycleConﬁgs (p. 794)\\n•ListNotebookInstances (p. 797)\\n•ListSubscribedWorkteams (p. 801)\\n•ListTags (p. 803)\\n•ListTrainingJobs (p. 805)\\n•ListTrainingJobsForHyperParameterTuningJob (p. 808)\\n•ListTransformJobs (p. 811)\\n•ListWorkteams (p. 814)\\n•RenderUiTemplate (p. 817)\\n•Search (p. 819)\\n•StartNotebookInstance (p. 824)\\n•StopCompilationJob  (p. 826)\\n•StopHyperParameterTuningJob (p. 828)\\n•StopLabelingJob  (p. 830)\\n•StopNotebookInstance (p. 832)\\n•StopTrainingJob (p. 834)\\n•StopTransformJob (p. 836)\\n•UpdateCodeRepository (p. 838)\\n•UpdateEndpoint  (p. 840)\\n•UpdateEndpointWeightsAndCapacities (p. 842)\\n•UpdateNotebookInstance (p. 844)\\n•UpdateNotebookInstanceLifecycleConﬁg (p. 848)\\n•UpdateWorkteam (p. 850)\\n619Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAddTags\\nService: Amazon SageMaker Service\\nAdds or overwrites one or more tags for the speciﬁed Amazon SageMaker resource. You can add tags to\\nnotebook instances, training jobs, hyperparameter tuning jobs, batch transform jobs, models, labeling\\njobs, work teams, endpoint conﬁgurations, and endpoints.\\nEach tag consists of a key and an optional value. Tag keys must be unique per resource. For more\\ninformation about tags, see For more information, see AWS Tagging Strategies.\\nNote\\nTags that you add to a hyperparameter tuning job by calling this API are also added to any\\ntraining jobs that the hyperparameter tuning job launches after you call this API, but not to\\ntraining jobs that the hyperparameter tuning job launched before you called this API. To make\\nsure that the tags associated with a hyperparameter tuning job are also added to all training\\njobs that the hyperparameter tuning job launches, add the tags when you ﬁrst create the tuning\\njob by specifying them in the Tags  parameter of CreateHyperParameterTuningJob (p. 638)\\nRequest Syntax\\n{\\n   \"ResourceArn \": \"string\",\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ]\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nResourceArn (p. 620)\\nThe Amazon Resource Name (ARN) of the resource that you want to tag.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:.*\\nRequired: Yes\\nTags (p. 620)\\nAn array of Tag objects. Each tag is a key-value pair. Only the key parameter is required. If you don\\'t\\nspecify a value, Amazon SageMaker sets the value to an empty string.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: Yes\\n620Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResponse Syntax\\n{\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nTags (p. 621)\\nA list of tags associated with the Amazon SageMaker resource.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n621Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateAlgorithm\\nService: Amazon SageMaker Service\\nCreate a machine learning algorithm that you can use in Amazon SageMaker and list in the AWS\\nMarketplace.\\nRequest Syntax\\n{\\n   \"AlgorithmDescription \": \"string\",\\n   \"AlgorithmName \": \"string\",\\n   \"CertifyForMarketplace \": boolean,\\n   \"InferenceSpecification \": { \\n      \"Containers \": [ \\n         { \\n            \" ContainerHostname \": \"string\",\\n            \" Image\": \"string\",\\n            \" ImageDigest \": \"string\",\\n            \" ModelDataUrl \": \"string\",\\n            \" ProductId \": \"string\"\\n         }\\n      ],\\n      \"SupportedContentTypes \": [ \"string\" ],\\n      \"SupportedRealtimeInferenceInstanceTypes \": [ \"string\" ],\\n      \"SupportedResponseMIMETypes \": [ \"string\" ],\\n      \"SupportedTransformInstanceTypes \": [ \"string\" ]\\n   },\\n   \"TrainingSpecification \": { \\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"SupportedHyperParameters \": [ \\n         { \\n            \" DefaultValue \": \"string\",\\n            \" Description \": \"string\",\\n            \" IsRequired \": boolean,\\n            \" IsTunable \": boolean,\\n            \" Name\": \"string\",\\n            \" Range\": { \\n               \" CategoricalParameterRangeSpecification \": { \\n                  \" Values\": [ \"string\" ]\\n               },\\n               \" ContinuousParameterRangeSpecification \": { \\n                  \" MaxValue \": \"string\",\\n                  \" MinValue \": \"string\"\\n               },\\n               \" IntegerParameterRangeSpecification \": { \\n                  \" MaxValue \": \"string\",\\n                  \" MinValue \": \"string\"\\n               }\\n            },\\n            \" Type\": \"string\"\\n         }\\n      ],\\n      \"SupportedTrainingInstanceTypes \": [ \"string\" ],\\n      \"SupportedTuningJobObjectiveMetrics \": [ \\n         { \\n            \" MetricName \": \"string\",\\n            \" Type\": \"string\"\\n         }\\n      ],\\n622Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      \"SupportsDistributedTraining \": boolean,\\n      \"TrainingChannels \": [ \\n         { \\n            \" Description \": \"string\",\\n            \" IsRequired \": boolean,\\n            \" Name\": \"string\",\\n            \" SupportedCompressionTypes \": [ \"string\" ],\\n            \" SupportedContentTypes \": [ \"string\" ],\\n            \" SupportedInputModes \": [ \"string\" ]\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingImageDigest \": \"string\"\\n   },\\n   \"ValidationSpecification \": { \\n      \"ValidationProfiles \": [ \\n         { \\n            \" ProfileName \": \"string\",\\n            \" TrainingJobDefinition \": { \\n               \" HyperParameters \": { \\n                  \" string\" : \"string\" \\n               },\\n               \" InputDataConfig \": [ \\n                  { \\n                     \" ChannelName \": \"string\",\\n                     \" CompressionType \": \"string\",\\n                     \" ContentType \": \"string\",\\n                     \" DataSource \": { \\n                        \" FileSystemDataSource \": { \\n                           \" DirectoryPath \": \"string\",\\n                           \" FileSystemAccessMode \": \"string\",\\n                           \" FileSystemId \": \"string\",\\n                           \" FileSystemType \": \"string\"\\n                        },\\n                        \" S3DataSource \": { \\n                           \" AttributeNames \": [ \"string\" ],\\n                           \" S3DataDistributionType \": \"string\",\\n                           \" S3DataType \": \"string\",\\n                           \" S3Uri\": \"string\"\\n                        }\\n                     },\\n                     \" InputMode \": \"string\",\\n                     \" RecordWrapperType \": \"string\",\\n                     \" ShuffleConfig \": { \\n                        \" Seed\": number\\n                     }\\n                  }\\n               ],\\n               \" OutputDataConfig \": { \\n                  \" KmsKeyId \": \"string\",\\n                  \" S3OutputPath \": \"string\"\\n               },\\n               \" ResourceConfig \": { \\n                  \" InstanceCount \": number,\\n                  \" InstanceType \": \"string\",\\n                  \" VolumeKmsKeyId \": \"string\",\\n                  \" VolumeSizeInGB \": number\\n               },\\n               \" StoppingCondition \": { \\n                  \" MaxRuntimeInSeconds \": number,\\n                  \" MaxWaitTimeInSeconds \": number\\n               },\\n               \" TrainingInputMode \": \"string\"\\n            },\\n            \" TransformJobDefinition \": { \\n               \" BatchStrategy \": \"string\",\\n623Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n               \" Environment \": { \\n                  \" string\" : \"string\" \\n               },\\n               \" MaxConcurrentTransforms \": number,\\n               \" MaxPayloadInMB \": number,\\n               \" TransformInput \": { \\n                  \" CompressionType \": \"string\",\\n                  \" ContentType \": \"string\",\\n                  \" DataSource \": { \\n                     \" S3DataSource \": { \\n                        \" S3DataType \": \"string\",\\n                        \" S3Uri\": \"string\"\\n                     }\\n                  },\\n                  \" SplitType \": \"string\"\\n               },\\n               \" TransformOutput \": { \\n                  \" Accept\": \"string\",\\n                  \" AssembleWith \": \"string\",\\n                  \" KmsKeyId \": \"string\",\\n                  \" S3OutputPath \": \"string\"\\n               },\\n               \" TransformResources \": { \\n                  \" InstanceCount \": number,\\n                  \" InstanceType \": \"string\",\\n                  \" VolumeKmsKeyId \": \"string\"\\n               }\\n            }\\n         }\\n      ],\\n      \"ValidationRole \": \"string\"\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAlgorithmDescription (p. 622)\\nA description of the algorithm.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nRequired: No\\nAlgorithmName (p. 622)\\nThe name of the algorithm.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\n624Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCertifyForMarketplace (p. 622)\\nWhether to certify the algorithm so that it can be listed in AWS Marketplace.\\nType: Boolean\\nRequired: No\\nInferenceSpeciﬁcation (p. 622)\\nSpeciﬁes details about inference jobs that the algorithm runs, including the following:\\n•The Amazon ECR paths of containers that contain the inference code and model artifacts.\\n•The instance types that the algorithm supports for transform jobs and real-time endpoints used\\nfor inference.\\n•The input and output content formats that the algorithm supports for inference.\\nType: InferenceSpeciﬁcation (p. 929) object\\nRequired: No\\nTrainingSpeciﬁcation (p. 622)\\nSpeciﬁes details about training jobs run by this algorithm, including the following:\\n•The Amazon ECR path of the container and the version digest of the algorithm.\\n•The hyperparameters that the algorithm supports.\\n•The instance types that the algorithm supports for training.\\n•Whether the algorithm supports distributed training.\\n•The metrics that the algorithm emits to Amazon CloudWatch.\\n•Which metrics that the algorithm emits can be used as the objective metric for hyperparameter\\ntuning jobs.\\n•The input channels that the algorithm supports for training data. For example, an algorithm might\\nsupport train , validation , and test  channels.\\nType: TrainingSpeciﬁcation (p. 1021 ) object\\nRequired: Yes\\nValidationSpeciﬁcation (p. 622)\\nSpeciﬁes conﬁgurations for one or more training jobs and that Amazon SageMaker runs to test the\\nalgorithm\\'s training code and, optionally, one or more batch transform jobs that Amazon SageMaker\\nruns to test the algorithm\\'s inference code.\\nType: AlgorithmValidationSpeciﬁcation (p. 870) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"AlgorithmArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\n625Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmArn (p. 625)\\nThe Amazon Resource Name (ARN) of the new algorithm.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:algorithm/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n626Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateCodeRepository\\nService: Amazon SageMaker Service\\nCreates a Git repository as a resource in your Amazon SageMaker account. You can associate the\\nrepository with notebook instances so that you can use Git source control for the notebooks you create.\\nThe Git repository is a resource in your Amazon SageMaker account, so it can be associated with more\\nthan one notebook instance, and it persists independently from the lifecycle of any notebook instances it\\nis associated with.\\nThe repository can be hosted either in AWS CodeCommit or in any other Git repository.\\nRequest Syntax\\n{\\n   \"CodeRepositoryName \": \"string\",\\n   \"GitConfig \": { \\n      \"Branch\": \"string\",\\n      \"RepositoryUrl \": \"string\",\\n      \"SecretArn \": \"string\"\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCodeRepositoryName (p. 627)\\nThe name of the Git repository. The name must have 1 to 63 characters. Valid characters are a-z, A-\\nZ, 0-9, and - (hyphen).\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nGitConﬁg  (p. 627)\\nSpeciﬁes details about the repository, including the URL where the repository is located, the default\\nbranch, and credentials to use to access the repository.\\nType: GitConﬁg  (p. 905) object\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CodeRepositoryArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\n627Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nThe following data is returned in JSON format by the service.\\nCodeRepositoryArn (p. 627)\\nThe Amazon Resource Name (ARN) of the new repository.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:code-repository/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n628Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateCompilationJob\\nService: Amazon SageMaker Service\\nStarts a model compilation job. After the model has been compiled, Amazon SageMaker saves the\\nresulting model artifacts to an Amazon Simple Storage Service (Amazon S3) bucket that you specify.\\nIf you choose to host your model using Amazon SageMaker hosting services, you can use the resulting\\nmodel artifacts as part of the model. You can also use the artifacts with AWS IoT Greengrass. In that\\ncase, deploy them as an ML resource.\\nIn the request body, you provide the following:\\n•A name for the compilation job\\n•Information about the input model artifacts\\n•The output location for the compiled model and the device (target) that the model runs on\\n•The Amazon Resource Name (ARN) of the IAM role that Amazon SageMaker assumes\\nto perform the model compilation job\\nYou can also provide a Tag to track the model compilation job\\'s resource use and costs. The response\\nbody contains the CompilationJobArn  for the compiled job.\\nTo stop a model compilation job, use StopCompilationJob  (p. 826). To get information about a\\nparticular model compilation job, use DescribeCompilationJob  (p. 705). To get information about\\nmultiple model compilation jobs, use ListCompilationJobs  (p. 767).\\nRequest Syntax\\n{\\n   \"CompilationJobName \": \"string\",\\n   \"InputConfig \": { \\n      \"DataInputConfig \": \"string\",\\n      \"Framework \": \"string\",\\n      \"S3Uri\": \"string\"\\n   },\\n   \"OutputConfig \": { \\n      \"S3OutputLocation \": \"string\",\\n      \"TargetDevice \": \"string\"\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,\\n      \"MaxWaitTimeInSeconds \": number\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCompilationJobName  (p. 629)\\nA name for the model compilation job. The name must be unique within the AWS Region and within\\nyour AWS account.\\nType: String\\n629Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nInputConﬁg  (p. 629)\\nProvides information about the location of input model artifacts, the name and shape of the\\nexpected data inputs, and the framework in which the model was trained.\\nType: InputConﬁg  (p. 931) object\\nRequired: Yes\\nOutputConﬁg  (p. 629)\\nProvides information about the output location for the compiled model and the target device the\\nmodel runs on.\\nType: OutputConﬁg  (p. 975) object\\nRequired: Yes\\nRoleArn (p. 629)\\nThe Amazon Resource Name (ARN) of an IAM role that enables Amazon SageMaker to perform tasks\\non your behalf.\\nDuring model compilation, Amazon SageMaker needs your permission to:\\n•Read input data from an S3 bucket\\n•Write model artifacts to an S3 bucket\\n•Write logs to Amazon CloudWatch Logs\\n•Publish metrics to Amazon CloudWatch\\nYou grant permissions for all of these tasks to an IAM role. To pass this role to Amazon SageMaker,\\nthe caller of this API must have the iam:PassRole  permission. For more information, see Amazon\\nSageMaker Roles.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStoppingCondition  (p. 629)\\nSpeciﬁes a limit to how long a model compilation job can run. When the job reaches the time limit,\\nAmazon SageMaker ends the compilation job. Use this API to cap model training costs.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CompilationJobArn \": \"string\"\\n}\\n630Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCompilationJobArn  (p. 630)\\nIf the action is successful, the service sends back an HTTP 200 response. Amazon SageMaker returns\\nthe following data in JSON format:\\n•CompilationJobArn : The Amazon Resource Name (ARN) of the compiled job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:compilation-job/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n631Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateEndpoint\\nService: Amazon SageMaker Service\\nCreates an endpoint using the endpoint conﬁguration speciﬁed in the request. Amazon SageMaker uses\\nthe endpoint to provision resources and deploy models. You create the endpoint conﬁguration with the\\nCreateEndpointConﬁg API.\\nNote\\nUse this API only for hosting models using Amazon SageMaker hosting services.\\nYou must not delete an EndpointConfig  in use by an endpoint that is live or while the\\nUpdateEndpoint  or CreateEndpoint  operations are being performed on the endpoint. To\\nupdate an endpoint, you must create a new EndpointConfig .\\nThe endpoint name must be unique within an AWS Region in your AWS account.\\nWhen it receives the request, Amazon SageMaker creates the endpoint, launches the resources (ML\\ncompute instances), and deploys the model(s) on them.\\nWhen Amazon SageMaker receives the request, it sets the endpoint status to Creating . After it creates\\nthe endpoint, it sets the status to InService . Amazon SageMaker can then process incoming requests\\nfor inferences. To check the status of an endpoint, use the DescribeEndpoint  API.\\nFor an example, see Exercise 1: Using the K-Means Algorithm Provided by Amazon SageMaker.\\nIf any of the models hosted at this endpoint get model data from an Amazon S3 location, Amazon\\nSageMaker uses AWS Security Token Service to download model artifacts from the S3 path you provided.\\nAWS STS is activated in your IAM user account by default. If you previously deactivated AWS STS for\\na region, you need to reactivate AWS STS for that region. For more information, see Activating and\\nDeactivating AWS STS i an AWS Region in the AWS Identity and Access Management User Guide.\\nRequest Syntax\\n{\\n   \"EndpointConfigName \": \"string\",\\n   \"EndpointName \": \"string\",\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ]\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nEndpointConﬁgName  (p. 632)\\nThe name of an endpoint conﬁguration. For more information, see CreateEndpointConﬁg.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\n632Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nEndpointName  (p. 632)\\nThe name of the endpoint. The name must be unique within an AWS Region in your AWS account.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nTags (p. 632)\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tagsin the AWS Billing\\nand Cost Management User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nResponse Syntax\\n{\\n   \"EndpointArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nEndpointArn  (p. 633)\\nThe Amazon Resource Name (ARN) of the endpoint.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n633Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n634Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateEndpointConﬁg\\nService: Amazon SageMaker Service\\nCreates an endpoint conﬁguration that Amazon SageMaker hosting services uses to deploy models. In\\nthe conﬁguration, you identify one or more models, created using the CreateModel  API, to deploy and\\nthe resources that you want Amazon SageMaker to provision. Then you call the CreateEndpoint API.\\nNote\\nUse this API only if you want to use Amazon SageMaker hosting services to deploy models into\\nproduction.\\nIn the request, you deﬁne one or more ProductionVariant s, each of which identiﬁes a model. Each\\nProductionVariant  parameter also describes the resources that you want Amazon SageMaker to\\nprovision. This includes the number and type of ML compute instances to deploy.\\nIf you are hosting multiple models, you also assign a VariantWeight  to specify how much traﬃc you\\nwant to allocate to each model. For example, suppose that you want to host two models, A and B, and\\nyou assign traﬃc weight 2 for model A and 1 for model B. Amazon SageMaker distributes two-thirds of\\nthe traﬃc to Model A, and one-third to model B.\\nRequest Syntax\\n{\\n   \"EndpointConfigName \": \"string\",\\n   \"KmsKeyId \": \"string\",\\n   \"ProductionVariants \": [ \\n      { \\n         \" AcceleratorType \": \"string\",\\n         \" InitialInstanceCount \": number,\\n         \" InitialVariantWeight \": number,\\n         \" InstanceType \": \"string\",\\n         \" ModelName \": \"string\",\\n         \" VariantName \": \"string\"\\n      }\\n   ],\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ]\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nEndpointConﬁgName  (p. 635)\\nThe name of the endpoint conﬁguration. You specify this name in a CreateEndpoint request.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\n635Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nKmsKeyId (p. 635)\\nThe Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker\\nuses to encrypt data on the storage volume attached to the ML compute instance that hosts the\\nendpoint.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nProductionVariants (p. 635)\\nAn list of ProductionVariant  objects, one for each model that you want to host at this endpoint.\\nType: Array of ProductionVariant (p. 981) objects\\nArray Members: Minimum number of 1 item. Maximum number of 10 items.\\nRequired: Yes\\nTags (p. 635)\\nA list of key-value pairs. For more information, see Using Cost Allocation Tags in the  AWS Billing and\\nCost Management User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nResponse Syntax\\n{\\n   \"EndpointConfigArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nEndpointConﬁgArn  (p. 636)\\nThe Amazon Resource Name (ARN) of the endpoint conﬁguration.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint-config/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\n636Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n637Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateHyperParameterTuningJob\\nService: Amazon SageMaker Service\\nStarts a hyperparameter tuning job. A hyperparameter tuning job ﬁnds the best version of a model\\nby running many training jobs on your dataset using the algorithm you choose and values for\\nhyperparameters within ranges that you specify. It then chooses the hyperparameter values that result in\\na model that performs the best, as measured by an objective metric that you choose.\\nRequest Syntax\\n{\\n   \"HyperParameterTuningJobConfig \": { \\n      \"HyperParameterTuningJobObjective \": { \\n         \" MetricName \": \"string\",\\n         \" Type\": \"string\"\\n      },\\n      \"ParameterRanges \": { \\n         \" CategoricalParameterRanges \": [ \\n            { \\n               \" Name\": \"string\",\\n               \" Values\": [ \"string\" ]\\n            }\\n         ],\\n         \" ContinuousParameterRanges \": [ \\n            { \\n               \" MaxValue \": \"string\",\\n               \" MinValue \": \"string\",\\n               \" Name\": \"string\",\\n               \" ScalingType \": \"string\"\\n            }\\n         ],\\n         \" IntegerParameterRanges \": [ \\n            { \\n               \" MaxValue \": \"string\",\\n               \" MinValue \": \"string\",\\n               \" Name\": \"string\",\\n               \" ScalingType \": \"string\"\\n            }\\n         ]\\n      },\\n      \"ResourceLimits \": { \\n         \" MaxNumberOfTrainingJobs \": number,\\n         \" MaxParallelTrainingJobs \": number\\n      },\\n      \"Strategy \": \"string\",\\n      \"TrainingJobEarlyStoppingType \": \"string\"\\n   },\\n   \"HyperParameterTuningJobName \": \"string\",\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"TrainingJobDefinition \": { \\n      \"AlgorithmSpecification \": { \\n         \" AlgorithmName \": \"string\",\\n         \" MetricDefinitions \": [ \\n            { \\n               \" Name\": \"string\",\\n               \" Regex\": \"string\"\\n            }\\n         ],\\n638Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n         \" TrainingImage \": \"string\",\\n         \" TrainingInputMode \": \"string\"\\n      },\\n      \"CheckpointConfig \": { \\n         \" LocalPath \": \"string\",\\n         \" S3Uri\": \"string\"\\n      },\\n      \"EnableInterContainerTrafficEncryption \": boolean,\\n      \"EnableManagedSpotTraining \": boolean,\\n      \"EnableNetworkIsolation \": boolean,\\n      \"InputDataConfig \": [ \\n         { \\n            \" ChannelName \": \"string\",\\n            \" CompressionType \": \"string\",\\n            \" ContentType \": \"string\",\\n            \" DataSource \": { \\n               \" FileSystemDataSource \": { \\n                  \" DirectoryPath \": \"string\",\\n                  \" FileSystemAccessMode \": \"string\",\\n                  \" FileSystemId \": \"string\",\\n                  \" FileSystemType \": \"string\"\\n               },\\n               \" S3DataSource \": { \\n                  \" AttributeNames \": [ \"string\" ],\\n                  \" S3DataDistributionType \": \"string\",\\n                  \" S3DataType \": \"string\",\\n                  \" S3Uri\": \"string\"\\n               }\\n            },\\n            \" InputMode \": \"string\",\\n            \" RecordWrapperType \": \"string\",\\n            \" ShuffleConfig \": { \\n               \" Seed\": number\\n            }\\n         }\\n      ],\\n      \"OutputDataConfig \": { \\n         \" KmsKeyId \": \"string\",\\n         \" S3OutputPath \": \"string\"\\n      },\\n      \"ResourceConfig \": { \\n         \" InstanceCount \": number,\\n         \" InstanceType \": \"string\",\\n         \" VolumeKmsKeyId \": \"string\",\\n         \" VolumeSizeInGB \": number\\n      },\\n      \"RoleArn\": \"string\",\\n      \"StaticHyperParameters \": { \\n         \" string\" : \"string\" \\n      },\\n      \"StoppingCondition \": { \\n         \" MaxRuntimeInSeconds \": number,\\n         \" MaxWaitTimeInSeconds \": number\\n      },\\n      \"VpcConfig \": { \\n         \" SecurityGroupIds \": [ \"string\" ],\\n         \" Subnets\": [ \"string\" ]\\n      }\\n   },\\n   \"WarmStartConfig \": { \\n      \"ParentHyperParameterTuningJobs \": [ \\n         { \\n            \" HyperParameterTuningJobName \": \"string\"\\n         }\\n      ],\\n      \"WarmStartType \": \"string\"\\n639Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nHyperParameterTuningJobConﬁg (p. 638)\\nThe HyperParameterTuningJobConﬁg (p. 922) object that describes the tuning job, including the\\nsearch strategy, the objective metric used to evaluate training jobs, ranges of parameters to search,\\nand resource limits for the tuning job. For more information, see Automatic Model Tuning (p. 288)\\nType: HyperParameterTuningJobConﬁg (p. 922) object\\nRequired: Yes\\nHyperParameterTuningJobName (p. 638)\\nThe name of the tuning job. This name is the preﬁx for the names of all training jobs that this tuning\\njob launches. The name must be unique within the same AWS account and AWS Region. The name\\nmust have { } to { } characters. Valid characters are a-z, A-Z, 0-9, and : + = @ _ % - (hyphen). The\\nname is not case sensitive.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nTags (p. 638)\\nAn array of key-value pairs. You can use tags to categorize your AWS resources in diﬀerent ways, for\\nexample, by purpose, owner, or environment. For more information, see AWS Tagging Strategies.\\nTags that you specify for the tuning job are also added to all training jobs that the tuning job\\nlaunches.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTrainingJobDeﬁnition (p. 638)\\nThe HyperParameterTrainingJobDeﬁnition (p. 916) object that describes the training jobs that\\nthis tuning job launches, including static hyperparameters, input data conﬁguration, output data\\nconﬁguration, resource conﬁguration, and stopping condition.\\nType: HyperParameterTrainingJobDeﬁnition (p. 916) object\\nRequired: No\\nWarmStartConﬁg (p. 638)\\nSpeciﬁes the conﬁguration for starting the hyperparameter tuning job using one or more previous\\ntuning jobs as a starting point. The results of previous tuning jobs are used to inform which\\ncombinations of hyperparameters to search over in the new tuning job.\\n640Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAll training jobs launched by the new hyperparameter tuning job are evaluated by using the\\nobjective metric. If you specify IDENTICAL_DATA_AND_ALGORITHM  as the WarmStartType  value\\nfor the warm start conﬁguration, the training job that performs the best in the new tuning job is\\ncompared to the best training jobs from the parent tuning jobs. From these, the training job that\\nperforms the best as measured by the objective metric is returned as the overall best training job.\\nNote\\nAll training jobs launched by parent hyperparameter tuning jobs and the new\\nhyperparameter tuning jobs count against the limit of training jobs for the tuning job.\\nType: HyperParameterTuningJobWarmStartConﬁg (p. 927) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"HyperParameterTuningJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nHyperParameterTuningJobArn (p. 641)\\nThe Amazon Resource Name (ARN) of the tuning job. Amazon SageMaker assigns an ARN to a\\nhyperparameter tuning job when you create it.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:hyper-parameter-\\ntuning-job/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n641Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n642Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateLabelingJob\\nService: Amazon SageMaker Service\\nCreates a job that uses workers to label the data objects in your input dataset. You can use the labeled\\ndata to train machine learning models.\\nYou can select your workforce from one of three providers:\\n•A private workforce that you create. It can include employees, contractors, and outside experts. Use a\\nprivate workforce when want the data to stay within your organization or when a speciﬁc set of skills is\\nrequired.\\n•One or more vendors that you select from the AWS Marketplace. Vendors provide expertise in speciﬁc\\nareas.\\n•The Amazon Mechanical Turk workforce. This is the largest workforce, but it should only be used for\\npublic data or data that has been stripped of any personally identiﬁable information.\\nYou can also use automated data labeling  to reduce the number of data objects that need to be labeled\\nby a human. Automated data labeling uses active learning  to determine if a data object can be labeled by\\nmachine or if it needs to be sent to a human worker. For more information, see Using Automated Data\\nLabeling .\\nThe data objects to be labeled are contained in an Amazon S3 bucket. You create a manifest ﬁle  that\\ndescribes the location of each object. For more information, see Using Input and Output Data .\\nThe output can be used as the manifest ﬁle for another labeling job or as training data for your machine\\nlearning models.\\nRequest Syntax\\n{\\n   \"HumanTaskConfig \": { \\n      \"AnnotationConsolidationConfig \": { \\n         \" AnnotationConsolidationLambdaArn \": \"string\"\\n      },\\n      \"MaxConcurrentTaskCount \": number,\\n      \"NumberOfHumanWorkersPerDataObject \": number,\\n      \"PreHumanTaskLambdaArn \": \"string\",\\n      \"PublicWorkforceTaskPrice \": { \\n         \" AmountInUsd \": { \\n            \" Cents\": number,\\n            \" Dollars\": number,\\n            \" TenthFractionsOfACent \": number\\n         }\\n      },\\n      \"TaskAvailabilityLifetimeInSeconds \": number,\\n      \"TaskDescription \": \"string\",\\n      \"TaskKeywords \": [ \"string\" ],\\n      \"TaskTimeLimitInSeconds \": number,\\n      \"TaskTitle \": \"string\",\\n      \"UiConfig \": { \\n         \" UiTemplateS3Uri \": \"string\"\\n      },\\n      \"WorkteamArn \": \"string\"\\n   },\\n   \"InputConfig \": { \\n      \"DataAttributes \": { \\n         \" ContentClassifiers \": [ \"string\" ]\\n      },\\n      \"DataSource \": { \\n         \" S3DataSource \": { \\n643Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n            \" ManifestS3Uri \": \"string\"\\n         }\\n      }\\n   },\\n   \"LabelAttributeName \": \"string\",\\n   \"LabelCategoryConfigS3Uri \": \"string\",\\n   \"LabelingJobAlgorithmsConfig \": { \\n      \"InitialActiveLearningModelArn \": \"string\",\\n      \"LabelingJobAlgorithmSpecificationArn \": \"string\",\\n      \"LabelingJobResourceConfig \": { \\n         \" VolumeKmsKeyId \": \"string\"\\n      }\\n   },\\n   \"LabelingJobName \": \"string\",\\n   \"OutputConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingConditions \": { \\n      \"MaxHumanLabeledObjectCount \": number,\\n      \"MaxPercentageOfInputDatasetLabeled \": number\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ]\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nHumanTaskConﬁg (p. 643)\\nConﬁgures the information required for human workers to complete a labeling task.\\nType: HumanTaskConﬁg (p. 907) object\\nRequired: Yes\\nInputConﬁg  (p. 643)\\nInput data for the labeling job, such as the Amazon S3 location of the data objects and the location\\nof the manifest ﬁle that describes the data objects.\\nType: LabelingJobInputConﬁg  (p. 945) object\\nRequired: Yes\\nLabelAttributeName (p. 643)\\nThe attribute name to use for the label in the output manifest ﬁle. This is the key for the key/value\\npair formed with the label that a worker assigns to the object. The name can\\'t end with \"-metadata\".\\nIf you are running a semantic segmentation labeling job, the attribute name must end with \"-ref\". If\\nyou are running any other kind of labeling job, the attribute name must not end with \"-ref\".\\nType: String\\n644Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLength Constraints: Minimum length of 1. Maximum length of 127.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nLabelCategoryConﬁgS3Uri (p. 643)\\nThe S3 URL of the ﬁle that deﬁnes the categories used to label the data objects.\\nThe ﬁle is a JSON structure in the following format:\\n{\\n\"document-version\": \"2018-11-28\"\\n\"labels\": [\\n{\\n\"label\": \" label 1\"\\n},\\n{\\n\"label\": \" label 2\"\\n},\\n...\\n{\\n\"label\": \" label n\"\\n}\\n]\\n}\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: No\\nLabelingJobAlgorithmsConﬁg (p. 643)\\nConﬁgures the information required to perform automated data labeling.\\nType: LabelingJobAlgorithmsConﬁg  (p. 939) object\\nRequired: No\\nLabelingJobName  (p. 643)\\nThe name of the labeling job. This name is used to identify the job in a list of labeling jobs.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\n645Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nOutputConﬁg  (p. 643)\\nThe location of the output data and the AWS Key Management Service key ID for the key used to\\nencrypt the output data, if any.\\nType: LabelingJobOutputConﬁg  (p. 947) object\\nRequired: Yes\\nRoleArn (p. 643)\\nThe Amazon Resource Number (ARN) that Amazon SageMaker assumes to perform tasks on your\\nbehalf during data labeling. You must grant this role the necessary permissions so that Amazon\\nSageMaker can successfully complete data labeling.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStoppingConditions  (p. 643)\\nA set of conditions for stopping the labeling job. If any of the conditions are met, the job is\\nautomatically stopped. You can use these conditions to control the cost of data labeling.\\nType: LabelingJobStoppingConditions  (p. 950) object\\nRequired: No\\nTags (p. 643)\\nAn array of key/value pairs. For more information, see Using Cost Allocation Tags in the AWS Billing\\nand Cost Management User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nResponse Syntax\\n{\\n   \"LabelingJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nLabelingJobArn  (p. 646)\\nThe Amazon Resource Name (ARN) of the labeling job. You use this ARN to identify the labeling job.\\n646Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:labeling-job/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n647Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateModel\\nService: Amazon SageMaker Service\\nCreates a model in Amazon SageMaker. In the request, you name the model and describe a primary\\ncontainer. For the primary container, you specify the docker image containing inference code, artifacts\\n(from prior training), and custom environment map that the inference code uses when you deploy the\\nmodel for predictions.\\nUse this API to create a model if you want to use Amazon SageMaker hosting services or run a batch\\ntransform job.\\nTo host your model, you create an endpoint conﬁguration with the CreateEndpointConfig  API, and\\nthen create an endpoint with the CreateEndpoint  API. Amazon SageMaker then deploys all of the\\ncontainers that you deﬁned for the model in the hosting environment.\\nTo run a batch transform using your model, you start a job with the CreateTransformJob  API. Amazon\\nSageMaker uses your model and your dataset to get inferences which are then saved to a speciﬁed S3\\nlocation.\\nIn the CreateModel  request, you must deﬁne a container with the PrimaryContainer  parameter.\\nIn the request, you also provide an IAM role that Amazon SageMaker can assume to access model\\nartifacts and docker image for deployment on ML compute hosting instances or for batch transform jobs.\\nIn addition, you also use the IAM role to manage permissions the inference code needs. For example, if\\nthe inference code access any other AWS resources, you grant necessary permissions via this role.\\nRequest Syntax\\n{\\n   \"Containers \": [ \\n      { \\n         \" ContainerHostname \": \"string\",\\n         \" Environment \": { \\n            \" string\" : \"string\" \\n         },\\n         \" Image\": \"string\",\\n         \" ModelDataUrl \": \"string\",\\n         \" ModelPackageName \": \"string\"\\n      }\\n   ],\\n   \"EnableNetworkIsolation \": boolean,\\n   \"ExecutionRoleArn \": \"string\",\\n   \"ModelName \": \"string\",\\n   \"PrimaryContainer \": { \\n      \"ContainerHostname \": \"string\",\\n      \"Environment \": { \\n         \" string\" : \"string\" \\n      },\\n      \"Image\": \"string\",\\n      \"ModelDataUrl \": \"string\",\\n      \"ModelPackageName \": \"string\"\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n      \"Subnets\": [ \"string\" ]\\n   }\\n648Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nContainers  (p. 648)\\nSpeciﬁes the containers in the inference pipeline.\\nType: Array of ContainerDeﬁnition  (p. 886) objects\\nArray Members: Maximum number of 5 items.\\nRequired: No\\nEnableNetworkIsolation (p. 648)\\nIsolates the model container. No inbound or outbound network calls can be made to or from the\\nmodel container.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network isolation.\\nType: Boolean\\nRequired: No\\nExecutionRoleArn (p. 648)\\nThe Amazon Resource Name (ARN) of the IAM role that Amazon SageMaker can assume to access\\nmodel artifacts and docker image for deployment on ML compute instances or for batch transform\\njobs. Deploying on ML compute instances is part of model hosting. For more information, see\\nAmazon SageMaker Roles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must have the\\niam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nModelName  (p. 648)\\nThe name of the new model.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nPrimaryContainer (p. 648)\\nThe location of the primary docker image containing inference code, associated artifacts, and\\ncustom environment map that the inference code uses when the model is deployed for predictions.\\n649Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: ContainerDeﬁnition  (p. 886) object\\nRequired: No\\nTags (p. 648)\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tags in the AWS Billing\\nand Cost Management User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nVpcConﬁg (p. 648)\\nA VpcConﬁg object that speciﬁes the VPC that you want your model to connect to. Control access to\\nand from your model container by conﬁguring the VPC. VpcConfig  is used in hosting services and\\nin batch transform. For more information, see Protect Endpoints by Using an Amazon Virtual Private\\nCloud  and Protect Data in Batch Transform Jobs by Using an Amazon Virtual Private Cloud.\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"ModelArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nModelArn  (p. 650)\\nThe ARN of the model created in Amazon SageMaker.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\n650Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n651Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateModelPackage\\nService: Amazon SageMaker Service\\nCreates a model package that you can use to create Amazon SageMaker models or list on AWS\\nMarketplace. Buyers can subscribe to model packages listed on AWS Marketplace to create models in\\nAmazon SageMaker.\\nTo create a model package by specifying a Docker container that contains your inference code and the\\nAmazon S3 location of your model artifacts, provide values for InferenceSpecification . To create a\\nmodel from an algorithm resource that you created or subscribed to in AWS Marketplace, provide a value\\nfor SourceAlgorithmSpecification .\\nRequest Syntax\\n{\\n   \"CertifyForMarketplace \": boolean,\\n   \"InferenceSpecification \": { \\n      \"Containers \": [ \\n         { \\n            \" ContainerHostname \": \"string\",\\n            \" Image\": \"string\",\\n            \" ImageDigest \": \"string\",\\n            \" ModelDataUrl \": \"string\",\\n            \" ProductId \": \"string\"\\n         }\\n      ],\\n      \"SupportedContentTypes \": [ \"string\" ],\\n      \"SupportedRealtimeInferenceInstanceTypes \": [ \"string\" ],\\n      \"SupportedResponseMIMETypes \": [ \"string\" ],\\n      \"SupportedTransformInstanceTypes \": [ \"string\" ]\\n   },\\n   \"ModelPackageDescription \": \"string\",\\n   \"ModelPackageName \": \"string\",\\n   \"SourceAlgorithmSpecification \": { \\n      \"SourceAlgorithms \": [ \\n         { \\n            \" AlgorithmName \": \"string\",\\n            \" ModelDataUrl \": \"string\"\\n         }\\n      ]\\n   },\\n   \"ValidationSpecification \": { \\n      \"ValidationProfiles \": [ \\n         { \\n            \" ProfileName \": \"string\",\\n            \" TransformJobDefinition \": { \\n               \" BatchStrategy \": \"string\",\\n               \" Environment \": { \\n                  \" string\" : \"string\" \\n               },\\n               \" MaxConcurrentTransforms \": number,\\n               \" MaxPayloadInMB \": number,\\n               \" TransformInput \": { \\n                  \" CompressionType \": \"string\",\\n                  \" ContentType \": \"string\",\\n                  \" DataSource \": { \\n                     \" S3DataSource \": { \\n                        \" S3DataType \": \"string\",\\n                        \" S3Uri\": \"string\"\\n                     }\\n                  },\\n                  \" SplitType \": \"string\"\\n               },\\n652Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n               \" TransformOutput \": { \\n                  \" Accept\": \"string\",\\n                  \" AssembleWith \": \"string\",\\n                  \" KmsKeyId \": \"string\",\\n                  \" S3OutputPath \": \"string\"\\n               },\\n               \" TransformResources \": { \\n                  \" InstanceCount \": number,\\n                  \" InstanceType \": \"string\",\\n                  \" VolumeKmsKeyId \": \"string\"\\n               }\\n            }\\n         }\\n      ],\\n      \"ValidationRole \": \"string\"\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCertifyForMarketplace (p. 652)\\nWhether to certify the model package for listing on AWS Marketplace.\\nType: Boolean\\nRequired: No\\nInferenceSpeciﬁcation (p. 652)\\nSpeciﬁes details about inference jobs that can be run with models based on this model package,\\nincluding the following:\\n•The Amazon ECR paths of containers that contain the inference code and model artifacts.\\n•The instance types that the model package supports for transform jobs and real-time endpoints\\nused for inference.\\n•The input and output content formats that the model package supports for inference.\\nType: InferenceSpeciﬁcation (p. 929) object\\nRequired: No\\nModelPackageDescription (p. 652)\\nA description of the model package.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nRequired: No\\nModelPackageName (p. 652)\\nThe name of the model package. The name must have 1 to 63 characters. Valid characters are a-z, A-\\nZ, 0-9, and - (hyphen).\\n653Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nSourceAlgorithmSpeciﬁcation (p. 652)\\nDetails about the algorithm that was used to create the model package.\\nType: SourceAlgorithmSpeciﬁcation (p. 1003 ) object\\nRequired: No\\nValidationSpeciﬁcation (p. 652)\\nSpeciﬁes conﬁgurations for one or more transform jobs that Amazon SageMaker runs to test the\\nmodel package.\\nType: ModelPackageValidationSpeciﬁcation (p. 965) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"ModelPackageArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nModelPackageArn (p. 654)\\nThe Amazon Resource Name (ARN) of the new model package.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model-package/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n654Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n655Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateNotebookInstance\\nService: Amazon SageMaker Service\\nCreates an Amazon SageMaker notebook instance. A notebook instance is a machine learning (ML)\\ncompute instance running on a Jupyter notebook.\\nIn a CreateNotebookInstance  request, specify the type of ML compute instance that you want to run.\\nAmazon SageMaker launches the instance, installs common libraries that you can use to explore datasets\\nfor model training, and attaches an ML storage volume to the notebook instance.\\nAmazon SageMaker also provides a set of example notebooks. Each notebook demonstrates how to use\\nAmazon SageMaker with a speciﬁc algorithm or with a machine learning framework.\\nAfter receiving the request, Amazon SageMaker does the following:\\n1.Creates a network interface in the Amazon SageMaker VPC.\\n2.(Option) If you speciﬁed SubnetId , Amazon SageMaker creates a network interface in your own\\nVPC, which is inferred from the subnet ID that you provide in the input. When creating this network\\ninterface, Amazon SageMaker attaches the security group that you speciﬁed in the request to the\\nnetwork interface that it creates in your VPC.\\n3.Launches an EC2 instance of the type speciﬁed in the request in the Amazon SageMaker VPC. If\\nyou speciﬁed SubnetId  of your VPC, Amazon SageMaker speciﬁes both network interfaces when\\nlaunching this instance. This enables inbound traﬃc from your own VPC to the notebook instance,\\nassuming that the security groups allow it.\\nAfter creating the notebook instance, Amazon SageMaker returns its Amazon Resource Name (ARN). You\\ncan\\'t change the name of a notebook instance after you create it.\\nAfter Amazon SageMaker creates the notebook instance, you can connect to the Jupyter server and work\\nin Jupyter notebooks. For example, you can write code to explore a dataset that you can use for model\\ntraining, train a model, host models by creating Amazon SageMaker endpoints, and validate hosted\\nmodels.\\nFor more information, see How It Works.\\nRequest Syntax\\n{\\n   \"AcceleratorTypes \": [ \"string\" ],\\n   \"AdditionalCodeRepositories \": [ \"string\" ],\\n   \"DefaultCodeRepository \": \"string\",\\n   \"DirectInternetAccess \": \"string\",\\n   \"InstanceType \": \"string\",\\n   \"KmsKeyId \": \"string\",\\n   \"LifecycleConfigName \": \"string\",\\n   \"NotebookInstanceName \": \"string\",\\n   \"RoleArn\": \"string\",\\n   \"RootAccess \": \"string\",\\n   \"SecurityGroupIds \": [ \"string\" ],\\n   \"SubnetId \": \"string\",\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"VolumeSizeInGB \": number\\n}\\n656Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAcceleratorTypes (p. 656)\\nA list of Elastic Inference (EI) instance types to associate with this notebook instance. Currently, only\\none instance type can be associated with a notebook instance. For more information, see Using\\nElastic Inference in Amazon SageMaker.\\nType: Array of strings\\nValid Values: ml.eia1.medium | ml.eia1.large | ml.eia1.xlarge\\nRequired: No\\nAdditionalCodeRepositories (p. 656)\\nAn array of up to three Git repositories to associate with the notebook instance. These can be either\\nthe names of Git repositories stored as resources in your account, or the URL of Git repositories in\\nAWS CodeCommit or in any other Git repository. These repositories are cloned at the same level\\nas the default repository of your notebook instance. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: Array of strings\\nArray Members: Maximum number of 3 items.\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nDefaultCodeRepository (p. 656)\\nA Git repository to associate with the notebook instance as its default code repository. This can\\nbe either the name of a Git repository stored as a resource in your account, or the URL of a Git\\nrepository in AWS CodeCommit or in any other Git repository. When you open a notebook instance,\\nit opens in the directory that contains this repository. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nDirectInternetAccess (p. 656)\\nSets whether Amazon SageMaker provides internet access to the notebook instance. If you set this\\nto Disabled  this notebook instance will be able to access resources only in your VPC, and will not\\nbe able to connect to Amazon SageMaker training and endpoint services unless your conﬁgure a NAT\\nGateway in your VPC.\\nFor more information, see Notebook Instances Are Internet-Enabled by Default. You can set the\\nvalue of this parameter to Disabled  only if you set a value for the SubnetId  parameter.\\n657Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nValid Values: Enabled | Disabled\\nRequired: No\\nInstanceType (p. 656)\\nThe type of ML compute instance to launch for the notebook instance.\\nType: String\\nValid Values: ml.t2.medium | ml.t2.large | ml.t2.xlarge | ml.t2.2xlarge |\\nml.t3.medium | ml.t3.large | ml.t3.xlarge | ml.t3.2xlarge | ml.m4.xlarge\\n| ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge | ml.m4.16xlarge\\n| ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge | ml.m5.12xlarge\\n| ml.m5.24xlarge | ml.c4.xlarge | ml.c4.2xlarge | ml.c4.4xlarge |\\nml.c4.8xlarge | ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge\\n| ml.c5.18xlarge | ml.c5d.xlarge | ml.c5d.2xlarge | ml.c5d.4xlarge\\n| ml.c5d.9xlarge | ml.c5d.18xlarge | ml.p2.xlarge | ml.p2.8xlarge |\\nml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge\\nRequired: Yes\\nKmsKeyId (p. 656)\\nThe Amazon Resource Name (ARN) of a AWS Key Management Service key that Amazon SageMaker\\nuses to encrypt data on the storage volume attached to your notebook instance. The KMS key\\nyou provide must be enabled. For information, see Enabling and Disabling Keys in the AWS Key\\nManagement Service Developer Guide.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nLifecycleConﬁgName (p. 656)\\nThe name of a lifecycle conﬁguration to associate with the notebook instance. For information about\\nlifestyle conﬁgurations, see Step 2.1: (Optional) Customize a Notebook Instance.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nNotebookInstanceName (p. 656)\\nThe name of the new notebook instance.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\n658Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRoleArn (p. 656)\\nWhen you send any requests to AWS resources from the notebook instance, Amazon SageMaker\\nassumes this role to perform tasks on your behalf. You must grant this role necessary permissions so\\nAmazon SageMaker can perform these tasks. The policy must allow the Amazon SageMaker service\\nprincipal (sagemaker.amazonaws.com) permissionsto to assume this role. For more information, see\\nAmazon SageMaker Roles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must have the\\niam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nRootAccess (p. 656)\\nWhether root access is enabled or disabled for users of the notebook instance. The default value is\\nEnabled .\\nNote\\nLifecycle conﬁgurations need root access to be able to set up a notebook instance. Because\\nof this, lifecycle conﬁgurations associated with a notebook instance always run with root\\naccess even if you disable root access for users.\\nType: String\\nValid Values: Enabled | Disabled\\nRequired: No\\nSecurityGroupIds (p. 656)\\nThe VPC security group IDs, in the form sg-xxxxxxxx. The security groups must be for the same VPC\\nas speciﬁed in the subnet.\\nType: Array of strings\\nArray Members: Maximum number of 5 items.\\nLength Constraints: Maximum length of 32.\\nPattern: [-0-9a-zA-Z]+\\nRequired: No\\nSubnetId  (p. 656)\\nThe ID of the subnet in a VPC to which you would like to have a connectivity from your ML compute\\ninstance.\\nType: String\\nLength Constraints: Maximum length of 32.\\nPattern: [-0-9a-zA-Z]+\\nRequired: No\\n659Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTags (p. 656)\\nA list of tags to associate with the notebook instance. You can add tags later by using the\\nCreateTags  API.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nVolumeSizeInGB (p. 656)\\nThe size, in GB, of the ML storage volume to attach to the notebook instance. The default value is 5\\nGB.\\nType: Integer\\nValid Range: Minimum value of 5. Maximum value of 16384.\\nRequired: No\\nResponse Syntax\\n{\\n   \"NotebookInstanceArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNotebookInstanceArn (p. 660)\\nThe Amazon Resource Name (ARN) of the notebook instance.\\nType: String\\nLength Constraints: Maximum length of 256.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n660Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n661Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateNotebookInstanceLifecycleConﬁg\\nService: Amazon SageMaker Service\\nCreates a lifecycle conﬁguration that you can associate with a notebook instance. A lifecycle conﬁguration\\nis a collection of shell scripts that run when you create or start a notebook instance.\\nEach lifecycle conﬁguration script has a limit of 16384 characters.\\nThe value of the $PATH environment variable that is available to both scripts is /sbin:bin:/usr/\\nsbin:/usr/bin .\\nView CloudWatch Logs for notebook instance lifecycle conﬁgurations in log group /aws/sagemaker/\\nNotebookInstances  in log stream [notebook-instance-name]/[LifecycleConfigHook] .\\nLifecycle conﬁguration scripts cannot run for longer than 5 minutes. If a script runs for longer than 5\\nminutes, it fails and the notebook instance is not created or started.\\nFor information about notebook instance lifestyle conﬁgurations, see Step 2.1: (Optional) Customize a\\nNotebook Instance.\\nRequest Syntax\\n{\\n   \"NotebookInstanceLifecycleConfigName \": \"string\",\\n   \"OnCreate \": [ \\n      { \\n         \" Content\": \"string\"\\n      }\\n   ],\\n   \"OnStart\": [ \\n      { \\n         \" Content\": \"string\"\\n      }\\n   ]\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceLifecycleConﬁgName (p. 662)\\nThe name of the lifecycle conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nOnCreate  (p. 662)\\nA shell script that runs only once, when you create a notebook instance. The shell script must be a\\nbase64-encoded string.\\nType: Array of NotebookInstanceLifecycleHook (p. 969) objects\\n662Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nArray Members: Maximum number of 1 item.\\nRequired: No\\nOnStart (p. 662)\\nA shell script that runs every time you start a notebook instance, including when you create the\\nnotebook instance. The shell script must be a base64-encoded string.\\nType: Array of NotebookInstanceLifecycleHook (p. 969) objects\\nArray Members: Maximum number of 1 item.\\nRequired: No\\nResponse Syntax\\n{\\n   \"NotebookInstanceLifecycleConfigArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNotebookInstanceLifecycleConﬁgArn (p. 663)\\nThe Amazon Resource Name (ARN) of the lifecycle conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 256.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n663Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n664Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreatePresignedNotebookInstanceUrl\\nService: Amazon SageMaker Service\\nReturns a URL that you can use to connect to the Jupyter server from a notebook instance. In the\\nAmazon SageMaker console, when you choose Open next to a notebook instance, Amazon SageMaker\\nopens a new tab showing the Jupyter server home page from the notebook instance. The console uses\\nthis API to get the URL and show the page.\\nIAM authorization policies for this API are also enforced for every HTTP request and WebSocket frame\\nthat attempts to connect to the notebook instance.For example, you can restrict access to this API and\\nto the URL that it returns to a list of IP addresses that you specify. Use the NotIpAddress  condition\\noperator and the aws:SourceIP  condition context key to specify the list of IP addresses that you want\\nto have access to the notebook instance. For more information, see Limit Access to a Notebook Instance\\nby IP Address.\\nNote\\nThe URL that you get from a call to CreatePresignedNotebookInstanceUrl (p. 665) is valid only\\nfor 5 minutes. If you try to use the URL after the 5-minute limit expires, you are directed to the\\nAWS console sign-in page.\\nRequest Syntax\\n{\\n   \"NotebookInstanceName \": \"string\",\\n   \"SessionExpirationDurationInSeconds \": number\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceName (p. 665)\\nThe name of the notebook instance.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSessionExpirationDurationInSeconds (p. 665)\\nThe duration of the session, in seconds. The default is 12 hours.\\nType: Integer\\nValid Range: Minimum value of 1800. Maximum value of 43200.\\nRequired: No\\nResponse Syntax\\n{\\n665Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"AuthorizedUrl \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nAuthorizedUrl (p. 665)\\nA JSON object that contains the URL string.\\nType: String\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n666Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateTrainingJob\\nService: Amazon SageMaker Service\\nStarts a model training job. After training completes, Amazon SageMaker saves the resulting model\\nartifacts to an Amazon S3 location that you specify.\\nIf you choose to host your model using Amazon SageMaker hosting services, you can use the resulting\\nmodel artifacts as part of the model. You can also use the artifacts in a machine learning service other\\nthan Amazon SageMaker, provided that you know how to use them for inferences.\\nIn the request body, you provide the following:\\n•AlgorithmSpecification  - Identiﬁes the training algorithm to use.\\n•HyperParameters  - Specify these algorithm-speciﬁc parameters to enable the estimation of model\\nparameters during training. Hyperparameters can be tuned to optimize this learning process. For a list\\nof hyperparameters for each training algorithm provided by Amazon SageMaker, see Algorithms .\\n•InputDataConfig  - Describes the training dataset and the Amazon S3, EFS, or FSx location where it\\nis stored.\\n•OutputDataConfig  - Identiﬁes the Amazon S3 bucket where you want Amazon SageMaker to save\\nthe results of model training.\\n•ResourceConfig  - Identiﬁes the resources, ML compute instances, and ML storage volumes to deploy\\nfor model training. In distributed training, you specify more than one instance.\\n•EnableManagedSpotTraining  - Optimize the cost of training machine learning models by up to\\n80% by using Amazon EC2 Spot instances. For more information, see Managed Spot Training.\\n•RoleARN - The Amazon Resource Number (ARN) that Amazon SageMaker assumes to perform tasks on\\nyour behalf during model training. You must grant this role the necessary permissions so that Amazon\\nSageMaker can successfully complete model training.\\n•StoppingCondition  - To help cap training costs, use MaxRuntimeInSeconds  to set a time limit for\\ntraining. Use MaxWaitTimeInSeconds  to specify how long you are willing to to wait for a managed\\nspot training job to complete.\\nFor more information about Amazon SageMaker, see How It Works.\\nRequest Syntax\\n{\\n   \"AlgorithmSpecification \": { \\n      \"AlgorithmName \": \"string\",\\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingInputMode \": \"string\"\\n   },\\n   \"CheckpointConfig \": { \\n      \"LocalPath \": \"string\",\\n      \"S3Uri\": \"string\"\\n   },\\n   \"EnableInterContainerTrafficEncryption \": boolean,\\n   \"EnableManagedSpotTraining \": boolean,\\n   \"EnableNetworkIsolation \": boolean,\\n   \"HyperParameters \": { \\n667Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      \"string\" : \"string\" \\n   },\\n   \"InputDataConfig \": [ \\n      { \\n         \" ChannelName \": \"string\",\\n         \" CompressionType \": \"string\",\\n         \" ContentType \": \"string\",\\n         \" DataSource \": { \\n            \" FileSystemDataSource \": { \\n               \" DirectoryPath \": \"string\",\\n               \" FileSystemAccessMode \": \"string\",\\n               \" FileSystemId \": \"string\",\\n               \" FileSystemType \": \"string\"\\n            },\\n            \" S3DataSource \": { \\n               \" AttributeNames \": [ \"string\" ],\\n               \" S3DataDistributionType \": \"string\",\\n               \" S3DataType \": \"string\",\\n               \" S3Uri\": \"string\"\\n            }\\n         },\\n         \" InputMode \": \"string\",\\n         \" RecordWrapperType \": \"string\",\\n         \" ShuffleConfig \": { \\n            \" Seed\": number\\n         }\\n      }\\n   ],\\n   \"OutputDataConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"ResourceConfig \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\",\\n      \"VolumeSizeInGB \": number\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,\\n      \"MaxWaitTimeInSeconds \": number\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"TrainingJobName \": \"string\",\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n      \"Subnets\": [ \"string\" ]\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\n668Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmSpeciﬁcation (p. 667)\\nThe registry path of the Docker image that contains the training algorithm and algorithm-speciﬁc\\nmetadata, including the input mode. For more information about algorithms provided by Amazon\\nSageMaker, see Algorithms . For information about providing your own algorithms, see Using Your\\nOwn Algorithms with Amazon SageMaker.\\nType: AlgorithmSpeciﬁcation  (p. 863) object\\nRequired: Yes\\nCheckpointConﬁg  (p. 667)\\nContains information about the output location for managed spot training checkpoint data.\\nType: CheckpointConﬁg  (p. 880) object\\nRequired: No\\nEnableInterContainerTraﬃcEncryption (p. 667)\\nTo encrypt all communications between ML compute instances in distributed training, choose True .\\nEncryption provides greater security for distributed training, but training might take longer. How\\nlong it takes depends on the amount of communication between compute instances, especially\\nif you use a deep learning algorithm in distributed training. For more information, see Protect\\nCommunications Between ML Compute Instances in a Distributed Training Job.\\nType: Boolean\\nRequired: No\\nEnableManagedSpotTraining (p. 667)\\nTo train models using managed spot training, choose True. Managed spot training provides a fully\\nmanaged and scalable infrastructure for training machine learning models. this option is useful\\nwhen training jobs can be interrupted and when there is ﬂexibility when the training job is run.\\nThe complete and intermediate results of jobs are stored in an Amazon S3 bucket, and can be used\\nas a starting point to train models incrementally. Amazon SageMaker provides metrics and logs in\\nCloudWatch. They can be used to see when managed spot training jobs are running, interrupted,\\nresumed, or completed.\\nType: Boolean\\nRequired: No\\nEnableNetworkIsolation (p. 667)\\nIsolates the training container. No inbound or outbound network calls can be made, except for calls\\nbetween peers within a training cluster for distributed training. If you enable network isolation\\nfor training jobs that are conﬁgured to use a VPC, Amazon SageMaker downloads and uploads\\ncustomer data and model artifacts through the speciﬁed VPC, but the training container does not\\nhave network access.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network isolation.\\nType: Boolean\\nRequired: No\\nHyperParameters (p. 667)\\nAlgorithm-speciﬁc parameters that inﬂuence the quality of the model. You set hyperparameters\\nbefore you start the learning process. For a list of hyperparameters for each training algorithm\\nprovided by Amazon SageMaker, see Algorithms .\\n669Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nYou can specify a maximum of 100 hyperparameters. Each hyperparameter is a key-value pair. Each\\nkey and value is limited to 256 characters, as speciﬁed by the Length Constraint .\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nInputDataConﬁg  (p. 667)\\nAn array of Channel objects. Each channel is a named input source. InputDataConfig  describes\\nthe input data and its location.\\nAlgorithms can accept input data from one or more channels. For example, an algorithm might\\nhave two channels of input data, training_data  and validation_data . The conﬁguration for\\neach channel provides the S3, EFS, or FSx location where the input data is stored. It also provides\\ninformation about the stored data: the MIME type, compression method, and whether the data is\\nwrapped in RecordIO format.\\nDepending on the input mode that the algorithm supports, Amazon SageMaker either copies input\\ndata ﬁles from an S3 bucket to a local directory in the Docker container, or makes it available as\\ninput streams. For example, if you specify an EFS location, input data ﬁles will be made available as\\ninput streams. They do not need to be downloaded.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No\\nOutputDataConﬁg  (p. 667)\\nSpeciﬁes the path to the S3 location where you want to store model artifacts. Amazon SageMaker\\ncreates subfolders for the artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: Yes\\nResourceConﬁg (p. 667)\\nThe resources, including the ML compute instances and ML storage volumes, to use for model\\ntraining.\\nML storage volumes store model artifacts and incremental states. Training algorithms might also use\\nML storage volumes for scratch space. If you want Amazon SageMaker to use the ML storage volume\\nto store the training data, choose File  as the TrainingInputMode  in the algorithm speciﬁcation.\\nFor distributed training algorithms, specify an instance count greater than 1.\\nType: ResourceConﬁg (p. 991) object\\nRequired: Yes\\nRoleArn (p. 667)\\nThe Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker can assume to perform\\ntasks on your behalf.\\n670Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDuring model training, Amazon SageMaker needs your permission to read input data from an S3\\nbucket, download a Docker image that contains training code, write model artifacts to an S3 bucket,\\nwrite logs to Amazon CloudWatch Logs, and publish metrics to Amazon CloudWatch. You grant\\npermissions for all of these tasks to an IAM role. For more information, see Amazon SageMaker\\nRoles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must have the\\niam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStoppingCondition  (p. 667)\\nSpeciﬁes a limit to how long a model training job can run. When the job reaches the time limit,\\nAmazon SageMaker ends the training job. Use this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job\\ntermination for 120 seconds. Algorithms can use this 120-second window to save the model\\nartifacts, so the results of training are not lost.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\nTags (p. 667)\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tags in the AWS Billing\\nand Cost Management User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTrainingJobName (p. 667)\\nThe name of the training job. The name must be unique within an AWS Region in an AWS account.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nVpcConﬁg (p. 667)\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that you want your training job to connect to.\\nControl access to and from your training container by conﬁguring the VPC. For more information,\\nsee Protect Training Jobs by Using an Amazon Virtual Private Cloud.\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\n671Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResponse Syntax\\n{\\n   \"TrainingJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nTrainingJobArn (p. 672)\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-job/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n672Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateTransformJob\\nService: Amazon SageMaker Service\\nStarts a transform job. A transform job uses a trained model to get inferences on a dataset and saves\\nthese results to an Amazon S3 location that you specify.\\nTo perform batch transformations, you create a transform job and use the data that you have readily\\navailable.\\nIn the request body, you provide the following:\\n•TransformJobName  - Identiﬁes the transform job. The name must be unique within an AWS Region in\\nan AWS account.\\n•ModelName  - Identiﬁes the model to use. ModelName  must be the name of an existing Amazon\\nSageMaker model in the same AWS Region and AWS account. For information on creating a model, see\\nCreateModel (p. 648).\\n•TransformInput  - Describes the dataset to be transformed and the Amazon S3 location where it is\\nstored.\\n•TransformOutput  - Identiﬁes the Amazon S3 location where you want Amazon SageMaker to save\\nthe results from the transform job.\\n•TransformResources  - Identiﬁes the ML compute instances for the transform job.\\nFor more information about how batch transformation works Amazon SageMaker, see How It Works.\\nRequest Syntax\\n{\\n   \"BatchStrategy \": \"string\",\\n   \"DataProcessing \": { \\n      \"InputFilter \": \"string\",\\n      \"JoinSource \": \"string\",\\n      \"OutputFilter \": \"string\"\\n   },\\n   \"Environment \": { \\n      \"string\" : \"string\" \\n   },\\n   \"MaxConcurrentTransforms \": number,\\n   \"MaxPayloadInMB \": number,\\n   \"ModelName \": \"string\",\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"TransformInput \": { \\n      \"CompressionType \": \"string\",\\n      \"ContentType \": \"string\",\\n      \"DataSource \": { \\n         \" S3DataSource \": { \\n            \" S3DataType \": \"string\",\\n            \" S3Uri\": \"string\"\\n         }\\n      },\\n      \"SplitType \": \"string\"\\n   },\\n   \"TransformJobName \": \"string\",\\n   \"TransformOutput \": { \\n      \"Accept\": \"string\",\\n      \"AssembleWith \": \"string\",\\n673Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"TransformResources \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\"\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nBatchStrategy  (p. 673)\\nSpeciﬁes the number of records to include in a mini-batch for an HTTP inference request. A record   is\\na single unit of input data that inference can be made on. For example, a single line in a CSV ﬁle is a\\nrecord.\\nTo enable the batch strategy, you must set SplitType  to Line , RecordIO , or TFRecord .\\nTo use only one record when making an HTTP invocation request to a container, set\\nBatchStrategy  to SingleRecord  and SplitType  to Line .\\nTo ﬁt as many records in a mini-batch as can ﬁt within the MaxPayloadInMB  limit, set\\nBatchStrategy  to MultiRecord  and SplitType  to Line .\\nType: String\\nValid Values: MultiRecord | SingleRecord\\nRequired: No\\nDataProcessing (p. 673)\\nThe data structure used to specify the data to be used for inference in a batch transform job and to\\nassociate the data that is relevant to the prediction results in the output. The input ﬁlter provided\\nallows you to exclude input data that is not needed for inference in a batch transform job. The\\noutput ﬁlter provided allows you to include input data relevant to interpreting the predictions\\nin the output from the job. For more information, see Associate Prediction Results with their\\nCorresponding Input Records.\\nType: DataProcessing (p. 891) object\\nRequired: No\\nEnvironment (p. 673)\\nThe environment variables to set in the Docker container. We support up to 16 key and values\\nentries in the map.\\nType: String to string map\\nKey Length Constraints: Maximum length of 1024.\\nKey Pattern: [a-zA-Z_][a-zA-Z0-9_]*\\nValue Length Constraints: Maximum length of 10240.\\n674Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValue Pattern: [\\\\S\\\\s]*\\nRequired: No\\nMaxConcurrentTransforms (p. 673)\\nThe maximum number of parallel requests that can be sent to each instance in a transform job.\\nIf MaxConcurrentTransforms  is set to 0 or left unset, Amazon SageMaker checks the optional\\nexecution-parameters to determine the optimal settings for your chosen algorithm. If the execution-\\nparameters endpoint is not enabled, the default value is 1. For more information on execution-\\nparameters, see How Containers Serve Requests. For built-in algorithms, you don\\'t need to set a\\nvalue for MaxConcurrentTransforms .\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nMaxPayloadInMB (p. 673)\\nThe maximum allowed size of the payload, in MB. A payload  is the data portion of a record (without\\nmetadata). The value in MaxPayloadInMB  must be greater than, or equal to, the size of a single\\nrecord. To estimate the size of a record in MB, divide the size of your dataset by the number of\\nrecords. To ensure that the records ﬁt within the maximum payload size, we recommend using a\\nslightly larger value. The default value is 6 MB.\\nFor cases where the payload might be arbitrarily large and is transmitted using HTTP chunked\\nencoding, set the value to 0. This feature works only in supported algorithms. Currently, Amazon\\nSageMaker built-in algorithms do not support HTTP chunked encoding.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nModelName  (p. 673)\\nThe name of the model that you want to use for the transform job. ModelName  must be the name of\\nan existing Amazon SageMaker model within an AWS Region in an AWS account.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nTags (p. 673)\\n(Optional) An array of key-value pairs. For more information, see Using Cost Allocation Tags in the\\nAWS Billing and Cost Management User Guide.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTransformInput (p. 673)\\nDescribes the input source and the way the transform job consumes it.\\n675Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: TransformInput (p. 1024 ) object\\nRequired: Yes\\nTransformJobName (p. 673)\\nThe name of the transform job. The name must be unique within an AWS Region in an AWS account.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nTransformOutput (p. 673)\\nDescribes the results of the transform job.\\nType: TransformOutput (p. 1030 ) object\\nRequired: Yes\\nTransformResources (p. 673)\\nDescribes the resources, including ML instance types and ML instance count, to use for the transform\\njob.\\nType: TransformResources (p. 1032 ) object\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"TransformJobArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nTransformJobArn (p. 676)\\nThe Amazon Resource Name (ARN) of the transform job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:transform-job/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceInUse\\nResource being accessed is in use.\\n676Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n677Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreateWorkteam\\nService: Amazon SageMaker Service\\nCreates a new work team for labeling your data. A work team is deﬁned by one or more Amazon Cognito\\nuser pools. You must ﬁrst create the user pools before you can create a work team.\\nYou cannot create more than 25 work teams in an account and region.\\nRequest Syntax\\n{\\n   \"Description \": \"string\",\\n   \"MemberDefinitions \": [ \\n      { \\n         \" CognitoMemberDefinition \": { \\n            \" ClientId \": \"string\",\\n            \" UserGroup \": \"string\",\\n            \" UserPool \": \"string\"\\n         }\\n      }\\n   ],\\n   \"NotificationConfiguration \": { \\n      \"NotificationTopicArn \": \"string\"\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ],\\n   \"WorkteamName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nDescription  (p. 678)\\nA description of the work team.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 200.\\nPattern: .+\\nRequired: Yes\\nMemberDeﬁnitions  (p. 678)\\nA list of MemberDefinition  objects that contains objects that identify the Amazon Cognito user\\npool that makes up the work team. For more information, see Amazon Cognito User Pools.\\nAll of the CognitoMemberDefinition  objects that make up the member deﬁnition must have the\\nsame ClientId  and UserPool  values.\\nType: Array of MemberDeﬁnition  (p. 954) objects\\nArray Members: Minimum number of 1 item. Maximum number of 10 items.\\n678Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: Yes\\nNotiﬁcationConﬁguration  (p. 678)\\nConﬁgures notiﬁcation of workers regarding available or expiring work items.\\nType: NotiﬁcationConﬁguration  (p. 973) object\\nRequired: No\\nTags (p. 678)\\nAn array of key-value pairs.\\nFor more information, see Resource Tag and Using Cost Allocation Tags in the  AWS Billing and Cost\\nManagement User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nWorkteamName (p. 678)\\nThe name of the work team. Use this name to identify the work team.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"WorkteamArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nWorkteamArn (p. 679)\\nThe Amazon Resource Name (ARN) of the work team. You can use this ARN to identify the work\\nteam.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:workteam/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\n679Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResourceInUse\\nResource being accessed is in use.\\nHTTP Status Code: 400\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n680Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteAlgorithm\\nService: Amazon SageMaker Service\\nRemoves the speciﬁed algorithm from your account.\\nRequest Syntax\\n{\\n   \"AlgorithmName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAlgorithmName (p. 681)\\nThe name of the algorithm to delete.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n681Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteCodeRepository\\nService: Amazon SageMaker Service\\nDeletes the speciﬁed Git repository from your account.\\nRequest Syntax\\n{\\n   \"CodeRepositoryName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCodeRepositoryName (p. 682)\\nThe name of the Git repository to delete.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n682Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteEndpoint\\nService: Amazon SageMaker Service\\nDeletes an endpoint. Amazon SageMaker frees up all of the resources that were deployed when the\\nendpoint was created.\\nAmazon SageMaker retires any custom KMS key grants associated with the endpoint, meaning you don\\'t\\nneed to use the RevokeGrant API call.\\nRequest Syntax\\n{\\n   \"EndpointName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nEndpointName  (p. 683)\\nThe name of the endpoint that you want to delete.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n683Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Ruby V2\\n684Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteEndpointConﬁg\\nService: Amazon SageMaker Service\\nDeletes an endpoint conﬁguration. The DeleteEndpointConfig  API deletes only the speciﬁed\\nconﬁguration. It does not delete endpoints created using the conﬁguration.\\nRequest Syntax\\n{\\n   \"EndpointConfigName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nEndpointConﬁgName  (p. 685)\\nThe name of the endpoint conﬁguration that you want to delete.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n685Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteModel\\nService: Amazon SageMaker Service\\nDeletes a model. The DeleteModel  API deletes only the model entry that was created in Amazon\\nSageMaker when you called the CreateModel API. It does not delete model artifacts, inference code, or\\nthe IAM role that you speciﬁed when creating the model.\\nRequest Syntax\\n{\\n   \"ModelName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nModelName  (p. 686)\\nThe name of the model to delete.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n686Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n687Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteModelPackage\\nService: Amazon SageMaker Service\\nDeletes a model package.\\nA model package is used to create Amazon SageMaker models or list on AWS Marketplace. Buyers can\\nsubscribe to model packages listed on AWS Marketplace to create models in Amazon SageMaker.\\nRequest Syntax\\n{\\n   \"ModelPackageName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nModelPackageName (p. 688)\\nThe name of the model package. The name must have 1 to 63 characters. Valid characters are a-z, A-\\nZ, 0-9, and - (hyphen).\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n688Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Ruby V2\\n689Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteNotebookInstance\\nService: Amazon SageMaker Service\\nDeletes an Amazon SageMaker notebook instance. Before you can delete a notebook instance, you must\\ncall the StopNotebookInstance  API.\\nImportant\\nWhen you delete a notebook instance, you lose all of your data. Amazon SageMaker removes\\nthe ML compute instance, and deletes the ML storage volume and the network interface\\nassociated with the notebook instance.\\nRequest Syntax\\n{\\n   \"NotebookInstanceName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceName (p. 690)\\nThe name of the Amazon SageMaker notebook instance to delete.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n690Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n691Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteNotebookInstanceLifecycleConﬁg\\nService: Amazon SageMaker Service\\nDeletes a notebook instance lifecycle conﬁguration.\\nRequest Syntax\\n{\\n   \"NotebookInstanceLifecycleConfigName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceLifecycleConﬁgName (p. 692)\\nThe name of the lifecycle conﬁguration to delete.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n692Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteTags\\nService: Amazon SageMaker Service\\nDeletes the speciﬁed tags from an Amazon SageMaker resource.\\nTo list a resource\\'s tags, use the ListTags  API.\\nNote\\nWhen you call this API to delete tags from a hyperparameter tuning job, the deleted tags are\\nnot removed from training jobs that the hyperparameter tuning job launched before you called\\nthis API.\\nRequest Syntax\\n{\\n   \"ResourceArn \": \"string\",\\n   \"TagKeys\": [ \"string\" ]\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nResourceArn (p. 693)\\nThe Amazon Resource Name (ARN) of the resource whose tags you want to delete.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:.*\\nRequired: Yes\\nTagKeys (p. 693)\\nAn array or one or more tag keys to delete.\\nType: Array of strings\\nArray Members: Minimum number of 1 item. Maximum number of 50 items.\\nLength Constraints: Minimum length of 1. Maximum length of 128.\\nPattern: ^([\\\\p{L}\\\\p{Z}\\\\p{N}_.:/=+\\\\-@]*)$\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\n693Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n694Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeleteWorkteam\\nService: Amazon SageMaker Service\\nDeletes an existing work team. This operation can\\'t be undone.\\nRequest Syntax\\n{\\n   \"WorkteamName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nWorkteamName (p. 695)\\nThe name of the work team to delete.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"Success\": boolean\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nSuccess (p. 695)\\nReturns true if the work team was successfully deleted; otherwise, returns false .\\nType: Boolean\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\n695Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n696Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeAlgorithm\\nService: Amazon SageMaker Service\\nReturns a description of the speciﬁed algorithm that is in your account.\\nRequest Syntax\\n{\\n   \"AlgorithmName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAlgorithmName (p. 697)\\nThe name of the algorithm to describe.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 170.\\nPattern: (arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:[a-z\\\\-]*\\\\/)?([a-zA-\\nZ0-9]([a-zA-Z0-9-]){0,62})(?<!-)$\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"AlgorithmArn \": \"string\",\\n   \"AlgorithmDescription \": \"string\",\\n   \"AlgorithmName \": \"string\",\\n   \"AlgorithmStatus \": \"string\",\\n   \"AlgorithmStatusDetails \": { \\n      \"ImageScanStatuses \": [ \\n         { \\n            \" FailureReason \": \"string\",\\n            \" Name\": \"string\",\\n            \" Status\": \"string\"\\n         }\\n      ],\\n      \"ValidationStatuses \": [ \\n         { \\n            \" FailureReason \": \"string\",\\n            \" Name\": \"string\",\\n            \" Status\": \"string\"\\n         }\\n      ]\\n   },\\n   \"CertifyForMarketplace \": boolean,\\n   \"CreationTime \": number,\\n   \"InferenceSpecification \": { \\n      \"Containers \": [ \\n         { \\n            \" ContainerHostname \": \"string\",\\n697Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n            \" Image\": \"string\",\\n            \" ImageDigest \": \"string\",\\n            \" ModelDataUrl \": \"string\",\\n            \" ProductId \": \"string\"\\n         }\\n      ],\\n      \"SupportedContentTypes \": [ \"string\" ],\\n      \"SupportedRealtimeInferenceInstanceTypes \": [ \"string\" ],\\n      \"SupportedResponseMIMETypes \": [ \"string\" ],\\n      \"SupportedTransformInstanceTypes \": [ \"string\" ]\\n   },\\n   \"ProductId \": \"string\",\\n   \"TrainingSpecification \": { \\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"SupportedHyperParameters \": [ \\n         { \\n            \" DefaultValue \": \"string\",\\n            \" Description \": \"string\",\\n            \" IsRequired \": boolean,\\n            \" IsTunable \": boolean,\\n            \" Name\": \"string\",\\n            \" Range\": { \\n               \" CategoricalParameterRangeSpecification \": { \\n                  \" Values\": [ \"string\" ]\\n               },\\n               \" ContinuousParameterRangeSpecification \": { \\n                  \" MaxValue \": \"string\",\\n                  \" MinValue \": \"string\"\\n               },\\n               \" IntegerParameterRangeSpecification \": { \\n                  \" MaxValue \": \"string\",\\n                  \" MinValue \": \"string\"\\n               }\\n            },\\n            \" Type\": \"string\"\\n         }\\n      ],\\n      \"SupportedTrainingInstanceTypes \": [ \"string\" ],\\n      \"SupportedTuningJobObjectiveMetrics \": [ \\n         { \\n            \" MetricName \": \"string\",\\n            \" Type\": \"string\"\\n         }\\n      ],\\n      \"SupportsDistributedTraining \": boolean,\\n      \"TrainingChannels \": [ \\n         { \\n            \" Description \": \"string\",\\n            \" IsRequired \": boolean,\\n            \" Name\": \"string\",\\n            \" SupportedCompressionTypes \": [ \"string\" ],\\n            \" SupportedContentTypes \": [ \"string\" ],\\n            \" SupportedInputModes \": [ \"string\" ]\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingImageDigest \": \"string\"\\n   },\\n   \"ValidationSpecification \": { \\n      \"ValidationProfiles \": [ \\n         { \\n698Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n            \" ProfileName \": \"string\",\\n            \" TrainingJobDefinition \": { \\n               \" HyperParameters \": { \\n                  \" string\" : \"string\" \\n               },\\n               \" InputDataConfig \": [ \\n                  { \\n                     \" ChannelName \": \"string\",\\n                     \" CompressionType \": \"string\",\\n                     \" ContentType \": \"string\",\\n                     \" DataSource \": { \\n                        \" FileSystemDataSource \": { \\n                           \" DirectoryPath \": \"string\",\\n                           \" FileSystemAccessMode \": \"string\",\\n                           \" FileSystemId \": \"string\",\\n                           \" FileSystemType \": \"string\"\\n                        },\\n                        \" S3DataSource \": { \\n                           \" AttributeNames \": [ \"string\" ],\\n                           \" S3DataDistributionType \": \"string\",\\n                           \" S3DataType \": \"string\",\\n                           \" S3Uri\": \"string\"\\n                        }\\n                     },\\n                     \" InputMode \": \"string\",\\n                     \" RecordWrapperType \": \"string\",\\n                     \" ShuffleConfig \": { \\n                        \" Seed\": number\\n                     }\\n                  }\\n               ],\\n               \" OutputDataConfig \": { \\n                  \" KmsKeyId \": \"string\",\\n                  \" S3OutputPath \": \"string\"\\n               },\\n               \" ResourceConfig \": { \\n                  \" InstanceCount \": number,\\n                  \" InstanceType \": \"string\",\\n                  \" VolumeKmsKeyId \": \"string\",\\n                  \" VolumeSizeInGB \": number\\n               },\\n               \" StoppingCondition \": { \\n                  \" MaxRuntimeInSeconds \": number,\\n                  \" MaxWaitTimeInSeconds \": number\\n               },\\n               \" TrainingInputMode \": \"string\"\\n            },\\n            \" TransformJobDefinition \": { \\n               \" BatchStrategy \": \"string\",\\n               \" Environment \": { \\n                  \" string\" : \"string\" \\n               },\\n               \" MaxConcurrentTransforms \": number,\\n               \" MaxPayloadInMB \": number,\\n               \" TransformInput \": { \\n                  \" CompressionType \": \"string\",\\n                  \" ContentType \": \"string\",\\n                  \" DataSource \": { \\n                     \" S3DataSource \": { \\n                        \" S3DataType \": \"string\",\\n                        \" S3Uri\": \"string\"\\n                     }\\n                  },\\n                  \" SplitType \": \"string\"\\n               },\\n               \" TransformOutput \": { \\n699Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n                  \" Accept\": \"string\",\\n                  \" AssembleWith \": \"string\",\\n                  \" KmsKeyId \": \"string\",\\n                  \" S3OutputPath \": \"string\"\\n               },\\n               \" TransformResources \": { \\n                  \" InstanceCount \": number,\\n                  \" InstanceType \": \"string\",\\n                  \" VolumeKmsKeyId \": \"string\"\\n               }\\n            }\\n         }\\n      ],\\n      \"ValidationRole \": \"string\"\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nAlgorithmArn (p. 697)\\nThe Amazon Resource Name (ARN) of the algorithm.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:algorithm/.*\\nAlgorithmDescription (p. 697)\\nA brief summary about the algorithm.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nAlgorithmName (p. 697)\\nThe name of the algorithm being described.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nAlgorithmStatus (p. 697)\\nThe current status of the algorithm.\\nType: String\\nValid Values: Pending | InProgress | Completed | Failed | Deleting\\nAlgorithmStatusDetails (p. 697)\\nDetails about the current status of the algorithm.\\n700Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: AlgorithmStatusDetails  (p. 865) object\\nCertifyForMarketplace (p. 697)\\nWhether the algorithm is certiﬁed to be listed in AWS Marketplace.\\nType: Boolean\\nCreationTime  (p. 697)\\nA timestamp specifying when the algorithm was created.\\nType: Timestamp\\nInferenceSpeciﬁcation (p. 697)\\nDetails about inference jobs that the algorithm runs.\\nType: InferenceSpeciﬁcation (p. 929) object\\nProductId (p. 697)\\nThe product identiﬁer of the algorithm.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nTrainingSpeciﬁcation (p. 697)\\nDetails about training jobs run by this algorithm.\\nType: TrainingSpeciﬁcation (p. 1021 ) object\\nValidationSpeciﬁcation (p. 697)\\nDetails about conﬁgurations for one or more training jobs that Amazon SageMaker runs to test the\\nalgorithm.\\nType: AlgorithmValidationSpeciﬁcation (p. 870) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n701Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n702Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeCodeRepository\\nService: Amazon SageMaker Service\\nGets details about the speciﬁed Git repository.\\nRequest Syntax\\n{\\n   \"CodeRepositoryName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCodeRepositoryName (p. 703)\\nThe name of the Git repository to describe.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CodeRepositoryArn \": \"string\",\\n   \"CodeRepositoryName \": \"string\",\\n   \"CreationTime \": number,\\n   \"GitConfig \": { \\n      \"Branch\": \"string\",\\n      \"RepositoryUrl \": \"string\",\\n      \"SecretArn \": \"string\"\\n   },\\n   \"LastModifiedTime \": number\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCodeRepositoryArn (p. 703)\\nThe Amazon Resource Name (ARN) of the Git repository.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:code-repository/.*\\n703Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCodeRepositoryName (p. 703)\\nThe name of the Git repository.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nCreationTime  (p. 703)\\nThe date and time that the repository was created.\\nType: Timestamp\\nGitConﬁg  (p. 703)\\nConﬁguration details about the repository, including the URL where the repository is located, the\\ndefault branch, and the Amazon Resource Name (ARN) of the AWS Secrets Manager secret that\\ncontains the credentials used to access the repository.\\nType: GitConﬁg  (p. 905) object\\nLastModiﬁedTime  (p. 703)\\nThe date and time that the repository was last changed.\\nType: Timestamp\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n704Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeCompilationJob\\nService: Amazon SageMaker Service\\nReturns information about a model compilation job.\\nTo create a model compilation job, use CreateCompilationJob (p. 629). To get information about multiple\\nmodel compilation jobs, use ListCompilationJobs  (p. 767).\\nRequest Syntax\\n{\\n   \"CompilationJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCompilationJobName  (p. 705)\\nThe name of the model compilation job that you want information about.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CompilationEndTime \": number,\\n   \"CompilationJobArn \": \"string\",\\n   \"CompilationJobName \": \"string\",\\n   \"CompilationJobStatus \": \"string\",\\n   \"CompilationStartTime \": number,\\n   \"CreationTime \": number,\\n   \"FailureReason \": \"string\",\\n   \"InputConfig \": { \\n      \"DataInputConfig \": \"string\",\\n      \"Framework \": \"string\",\\n      \"S3Uri\": \"string\"\\n   },\\n   \"LastModifiedTime \": number,\\n   \"ModelArtifacts \": { \\n      \"S3ModelArtifacts \": \"string\"\\n   },\\n   \"OutputConfig \": { \\n      \"S3OutputLocation \": \"string\",\\n      \"TargetDevice \": \"string\"\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,\\n      \"MaxWaitTimeInSeconds \": number\\n705Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCompilationEndTime  (p. 705)\\nThe time when the model compilation job on a compilation job instance ended. For a successful or\\nstopped job, this is when the job\\'s model artifacts have ﬁnished uploading. For a failed job, this is\\nwhen Amazon SageMaker detected that the job failed.\\nType: Timestamp\\nCompilationJobArn  (p. 705)\\nThe Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker assumes to perform the\\nmodel compilation job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:compilation-job/.*\\nCompilationJobName  (p. 705)\\nThe name of the model compilation job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nCompilationJobStatus  (p. 705)\\nThe status of the model compilation job.\\nType: String\\nValid Values: INPROGRESS | COMPLETED | FAILED | STARTING | STOPPING | STOPPED\\nCompilationStartTime (p. 705)\\nThe time when the model compilation job started the CompilationJob  instances.\\nYou are billed for the time between this timestamp and the timestamp in the\\nDescribeCompilationJob:CompilationEndTime  (p. 706) ﬁeld. In Amazon CloudWatch Logs, the start\\ntime might be later than this time. That\\'s because it takes time to download the compilation job,\\nwhich depends on the size of the compilation job container.\\nType: Timestamp\\nCreationTime  (p. 705)\\nThe time that the model compilation job was created.\\nType: Timestamp\\nFailureReason (p. 705)\\nIf a model compilation job failed, the reason it failed.\\n706Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 1024.\\nInputConﬁg  (p. 705)\\nInformation about the location in Amazon S3 of the input model artifacts, the name and shape of\\nthe expected data inputs, and the framework in which the model was trained.\\nType: InputConﬁg  (p. 931) object\\nLastModiﬁedTime  (p. 705)\\nThe time that the status of the model compilation job was last modiﬁed.\\nType: Timestamp\\nModelArtifacts (p. 705)\\nInformation about the location in Amazon S3 that has been conﬁgured for storing the model\\nartifacts used in the compilation job.\\nType: ModelArtifacts (p. 957) object\\nOutputConﬁg  (p. 705)\\nInformation about the output location for the compiled model and the target device that the model\\nruns on.\\nType: OutputConﬁg  (p. 975) object\\nRoleArn (p. 705)\\nThe Amazon Resource Name (ARN) of the model compilation job.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nStoppingCondition  (p. 705)\\nSpeciﬁes a limit to how long a model compilation job can run. When the job reaches the time limit,\\nAmazon SageMaker ends the compilation job. Use this API to cap model training costs.\\nType: StoppingCondition  (p. 1004 ) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n707Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n708Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeEndpoint\\nService: Amazon SageMaker Service\\nReturns the description of an endpoint.\\nRequest Syntax\\n{\\n   \"EndpointName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nEndpointName  (p. 709)\\nThe name of the endpoint.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CreationTime \": number,\\n   \"EndpointArn \": \"string\",\\n   \"EndpointConfigName \": \"string\",\\n   \"EndpointName \": \"string\",\\n   \"EndpointStatus \": \"string\",\\n   \"FailureReason \": \"string\",\\n   \"LastModifiedTime \": number,\\n   \"ProductionVariants \": [ \\n      { \\n         \" CurrentInstanceCount \": number,\\n         \" CurrentWeight \": number,\\n         \" DeployedImages \": [ \\n            { \\n               \" ResolutionTime \": number,\\n               \" ResolvedImage \": \"string\",\\n               \" SpecifiedImage \": \"string\"\\n            }\\n         ],\\n         \" DesiredInstanceCount \": number,\\n         \" DesiredWeight \": number,\\n         \" VariantName \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\n709Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nThe following data is returned in JSON format by the service.\\nCreationTime  (p. 709)\\nA timestamp that shows when the endpoint was created.\\nType: Timestamp\\nEndpointArn  (p. 709)\\nThe Amazon Resource Name (ARN) of the endpoint.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint/.*\\nEndpointConﬁgName  (p. 709)\\nThe name of the endpoint conﬁguration associated with this endpoint.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nEndpointName  (p. 709)\\nName of the endpoint.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nEndpointStatus  (p. 709)\\nThe status of the endpoint.\\n•OutOfService : Endpoint is not available to take incoming requests.\\n•Creating : CreateEndpoint (p. 632) is executing.\\n•Updating : UpdateEndpoint  (p. 840) or UpdateEndpointWeightsAndCapacities (p. 842) is\\nexecuting.\\n•SystemUpdating : Endpoint is undergoing maintenance and cannot be updated or deleted or re-\\nscaled until it has completed. This maintenance operation does not change any customer-speciﬁed\\nvalues such as VPC conﬁg, KMS encryption, model, instance type, or instance count.\\n•RollingBack : Endpoint fails to scale up or down or change its variant weight and is in\\nthe process of rolling back to its previous conﬁguration. Once the rollback completes,\\nendpoint returns to an InService  status. This transitional status only applies to an\\nendpoint that has autoscaling enabled and is undergoing variant weight or capacity\\nchanges as part of an UpdateEndpointWeightsAndCapacities (p. 842) call or when the\\nUpdateEndpointWeightsAndCapacities (p. 842) operation is called explicitly.\\n•InService : Endpoint is available to process incoming requests.\\n•Deleting : DeleteEndpoint  (p. 683) is executing.\\n•Failed: Endpoint could not be created, updated, or re-scaled. Use\\nDescribeEndpoint:FailureReason (p. 711) for information about the failure.\\nDeleteEndpoint  (p. 683) is the only operation that can be performed on a failed endpoint.\\nType: String\\n710Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Values: OutOfService | Creating | Updating | SystemUpdating | RollingBack\\n| InService | Deleting | Failed\\nFailureReason (p. 709)\\nIf the status of the endpoint is Failed, the reason why it failed.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nLastModiﬁedTime  (p. 709)\\nA timestamp that shows when the endpoint was last modiﬁed.\\nType: Timestamp\\nProductionVariants (p. 709)\\nAn array of ProductionVariantSummary (p. 983) objects, one for each model hosted behind this\\nendpoint.\\nType: Array of ProductionVariantSummary (p. 983) objects\\nArray Members: Minimum number of 1 item.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n711Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeEndpointConﬁg\\nService: Amazon SageMaker Service\\nReturns the description of an endpoint conﬁguration created using the CreateEndpointConfig  API.\\nRequest Syntax\\n{\\n   \"EndpointConfigName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nEndpointConﬁgName  (p. 712)\\nThe name of the endpoint conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CreationTime \": number,\\n   \"EndpointConfigArn \": \"string\",\\n   \"EndpointConfigName \": \"string\",\\n   \"KmsKeyId \": \"string\",\\n   \"ProductionVariants \": [ \\n      { \\n         \" AcceleratorType \": \"string\",\\n         \" InitialInstanceCount \": number,\\n         \" InitialVariantWeight \": number,\\n         \" InstanceType \": \"string\",\\n         \" ModelName \": \"string\",\\n         \" VariantName \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCreationTime  (p. 712)\\nA timestamp that shows when the endpoint conﬁguration was created.\\n712Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: Timestamp\\nEndpointConﬁgArn  (p. 712)\\nThe Amazon Resource Name (ARN) of the endpoint conﬁguration.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint-config/.*\\nEndpointConﬁgName  (p. 712)\\nName of the Amazon SageMaker endpoint conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nKmsKeyId (p. 712)\\nAWS KMS key ID Amazon SageMaker uses to encrypt data when storing it on the ML storage volume\\nattached to the instance.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nProductionVariants (p. 712)\\nAn array of ProductionVariant  objects, one for each model that you want to host at this\\nendpoint.\\nType: Array of ProductionVariant (p. 981) objects\\nArray Members: Minimum number of 1 item. Maximum number of 10 items.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n713Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n714Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeHyperParameterTuningJob\\nService: Amazon SageMaker Service\\nGets a description of a hyperparameter tuning job.\\nRequest Syntax\\n{\\n   \"HyperParameterTuningJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nHyperParameterTuningJobName (p. 715)\\nThe name of the tuning job to describe.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"BestTrainingJob \": { \\n      \"CreationTime \": number,\\n      \"FailureReason \": \"string\",\\n      \"FinalHyperParameterTuningJobObjectiveMetric \": { \\n         \" MetricName \": \"string\",\\n         \" Type\": \"string\",\\n         \" Value\": number\\n      },\\n      \"ObjectiveStatus \": \"string\",\\n      \"TrainingEndTime \": number,\\n      \"TrainingJobArn \": \"string\",\\n      \"TrainingJobName \": \"string\",\\n      \"TrainingJobStatus \": \"string\",\\n      \"TrainingStartTime \": number,\\n      \"TunedHyperParameters \": { \\n         \" string\" : \"string\" \\n      },\\n      \"TuningJobName \": \"string\"\\n   },\\n   \"CreationTime \": number,\\n   \"FailureReason \": \"string\",\\n   \"HyperParameterTuningEndTime \": number,\\n   \"HyperParameterTuningJobArn \": \"string\",\\n   \"HyperParameterTuningJobConfig \": { \\n      \"HyperParameterTuningJobObjective \": { \\n         \" MetricName \": \"string\",\\n         \" Type\": \"string\"\\n715Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      },\\n      \"ParameterRanges \": { \\n         \" CategoricalParameterRanges \": [ \\n            { \\n               \" Name\": \"string\",\\n               \" Values\": [ \"string\" ]\\n            }\\n         ],\\n         \" ContinuousParameterRanges \": [ \\n            { \\n               \" MaxValue \": \"string\",\\n               \" MinValue \": \"string\",\\n               \" Name\": \"string\",\\n               \" ScalingType \": \"string\"\\n            }\\n         ],\\n         \" IntegerParameterRanges \": [ \\n            { \\n               \" MaxValue \": \"string\",\\n               \" MinValue \": \"string\",\\n               \" Name\": \"string\",\\n               \" ScalingType \": \"string\"\\n            }\\n         ]\\n      },\\n      \"ResourceLimits \": { \\n         \" MaxNumberOfTrainingJobs \": number,\\n         \" MaxParallelTrainingJobs \": number\\n      },\\n      \"Strategy \": \"string\",\\n      \"TrainingJobEarlyStoppingType \": \"string\"\\n   },\\n   \"HyperParameterTuningJobName \": \"string\",\\n   \"HyperParameterTuningJobStatus \": \"string\",\\n   \"LastModifiedTime \": number,\\n   \"ObjectiveStatusCounters \": { \\n      \"Failed\": number,\\n      \"Pending\": number,\\n      \"Succeeded \": number\\n   },\\n   \"OverallBestTrainingJob \": { \\n      \"CreationTime \": number,\\n      \"FailureReason \": \"string\",\\n      \"FinalHyperParameterTuningJobObjectiveMetric \": { \\n         \" MetricName \": \"string\",\\n         \" Type\": \"string\",\\n         \" Value\": number\\n      },\\n      \"ObjectiveStatus \": \"string\",\\n      \"TrainingEndTime \": number,\\n      \"TrainingJobArn \": \"string\",\\n      \"TrainingJobName \": \"string\",\\n      \"TrainingJobStatus \": \"string\",\\n      \"TrainingStartTime \": number,\\n      \"TunedHyperParameters \": { \\n         \" string\" : \"string\" \\n      },\\n      \"TuningJobName \": \"string\"\\n   },\\n   \"TrainingJobDefinition \": { \\n      \"AlgorithmSpecification \": { \\n         \" AlgorithmName \": \"string\",\\n         \" MetricDefinitions \": [ \\n            { \\n               \" Name\": \"string\",\\n               \" Regex\": \"string\"\\n716Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n            }\\n         ],\\n         \" TrainingImage \": \"string\",\\n         \" TrainingInputMode \": \"string\"\\n      },\\n      \"CheckpointConfig \": { \\n         \" LocalPath \": \"string\",\\n         \" S3Uri\": \"string\"\\n      },\\n      \"EnableInterContainerTrafficEncryption \": boolean,\\n      \"EnableManagedSpotTraining \": boolean,\\n      \"EnableNetworkIsolation \": boolean,\\n      \"InputDataConfig \": [ \\n         { \\n            \" ChannelName \": \"string\",\\n            \" CompressionType \": \"string\",\\n            \" ContentType \": \"string\",\\n            \" DataSource \": { \\n               \" FileSystemDataSource \": { \\n                  \" DirectoryPath \": \"string\",\\n                  \" FileSystemAccessMode \": \"string\",\\n                  \" FileSystemId \": \"string\",\\n                  \" FileSystemType \": \"string\"\\n               },\\n               \" S3DataSource \": { \\n                  \" AttributeNames \": [ \"string\" ],\\n                  \" S3DataDistributionType \": \"string\",\\n                  \" S3DataType \": \"string\",\\n                  \" S3Uri\": \"string\"\\n               }\\n            },\\n            \" InputMode \": \"string\",\\n            \" RecordWrapperType \": \"string\",\\n            \" ShuffleConfig \": { \\n               \" Seed\": number\\n            }\\n         }\\n      ],\\n      \"OutputDataConfig \": { \\n         \" KmsKeyId \": \"string\",\\n         \" S3OutputPath \": \"string\"\\n      },\\n      \"ResourceConfig \": { \\n         \" InstanceCount \": number,\\n         \" InstanceType \": \"string\",\\n         \" VolumeKmsKeyId \": \"string\",\\n         \" VolumeSizeInGB \": number\\n      },\\n      \"RoleArn\": \"string\",\\n      \"StaticHyperParameters \": { \\n         \" string\" : \"string\" \\n      },\\n      \"StoppingCondition \": { \\n         \" MaxRuntimeInSeconds \": number,\\n         \" MaxWaitTimeInSeconds \": number\\n      },\\n      \"VpcConfig \": { \\n         \" SecurityGroupIds \": [ \"string\" ],\\n         \" Subnets\": [ \"string\" ]\\n      }\\n   },\\n   \"TrainingJobStatusCounters \": { \\n      \"Completed \": number,\\n      \"InProgress \": number,\\n      \"NonRetryableError \": number,\\n      \"RetryableError \": number,\\n717Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      \"Stopped\": number\\n   },\\n   \"WarmStartConfig \": { \\n      \"ParentHyperParameterTuningJobs \": [ \\n         { \\n            \" HyperParameterTuningJobName \": \"string\"\\n         }\\n      ],\\n      \"WarmStartType \": \"string\"\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nBestTrainingJob (p. 715)\\nA TrainingJobSummary (p. 1019 ) object that describes the training job that completed with the best\\ncurrent HyperParameterTuningJobObjective (p. 924).\\nType: HyperParameterTrainingJobSummary (p. 919) object\\nCreationTime  (p. 715)\\nThe date and time that the tuning job started.\\nType: Timestamp\\nFailureReason (p. 715)\\nIf the tuning job failed, the reason it failed.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nHyperParameterTuningEndTime (p. 715)\\nThe date and time that the tuning job ended.\\nType: Timestamp\\nHyperParameterTuningJobArn (p. 715)\\nThe Amazon Resource Name (ARN) of the tuning job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:hyper-parameter-\\ntuning-job/.*\\nHyperParameterTuningJobConﬁg (p. 715)\\nThe HyperParameterTuningJobConﬁg (p. 922) object that speciﬁes the conﬁguration of the tuning\\njob.\\nType: HyperParameterTuningJobConﬁg (p. 922) object\\nHyperParameterTuningJobName (p. 715)\\nThe name of the tuning job.\\n718Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nHyperParameterTuningJobStatus (p. 715)\\nThe status of the tuning job: InProgress, Completed, Failed, Stopping, or Stopped.\\nType: String\\nValid Values: Completed | InProgress | Failed | Stopped | Stopping\\nLastModiﬁedTime  (p. 715)\\nThe date and time that the status of the tuning job was modiﬁed.\\nType: Timestamp\\nObjectiveStatusCounters (p. 715)\\nThe ObjectiveStatusCounters (p. 974) object that speciﬁes the number of training jobs, categorized\\nby the status of their ﬁnal objective metric, that this tuning job launched.\\nType: ObjectiveStatusCounters (p. 974) object\\nOverallBestTrainingJob (p. 715)\\nIf the hyperparameter tuning job is an warm start tuning job with a WarmStartType  of\\nIDENTICAL_DATA_AND_ALGORITHM , this is the TrainingJobSummary (p. 1019 ) for the training job\\nwith the best objective metric value of all training jobs launched by this tuning job and all parent\\njobs speciﬁed for the warm start tuning job.\\nType: HyperParameterTrainingJobSummary (p. 919) object\\nTrainingJobDeﬁnition (p. 715)\\nThe HyperParameterTrainingJobDeﬁnition (p. 916) object that speciﬁes the deﬁnition of the\\ntraining jobs that this tuning job launches.\\nType: HyperParameterTrainingJobDeﬁnition (p. 916) object\\nTrainingJobStatusCounters (p. 715)\\nThe TrainingJobStatusCounters (p. 1017 ) object that speciﬁes the number of training jobs,\\ncategorized by status, that this tuning job launched.\\nType: TrainingJobStatusCounters (p. 1017 ) object\\nWarmStartConﬁg (p. 715)\\nThe conﬁguration for starting the hyperparameter parameter tuning job using one or more previous\\ntuning jobs as a starting point. The results of previous tuning jobs are used to inform which\\ncombinations of hyperparameters to search over in the new tuning job.\\nType: HyperParameterTuningJobWarmStartConﬁg (p. 927) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\n719Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n720Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeLabelingJob\\nService: Amazon SageMaker Service\\nGets information about a labeling job.\\nRequest Syntax\\n{\\n   \"LabelingJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nLabelingJobName  (p. 721)\\nThe name of the labeling job to return information for.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CreationTime \": number,\\n   \"FailureReason \": \"string\",\\n   \"HumanTaskConfig \": { \\n      \"AnnotationConsolidationConfig \": { \\n         \" AnnotationConsolidationLambdaArn \": \"string\"\\n      },\\n      \"MaxConcurrentTaskCount \": number,\\n      \"NumberOfHumanWorkersPerDataObject \": number,\\n      \"PreHumanTaskLambdaArn \": \"string\",\\n      \"PublicWorkforceTaskPrice \": { \\n         \" AmountInUsd \": { \\n            \" Cents\": number,\\n            \" Dollars\": number,\\n            \" TenthFractionsOfACent \": number\\n         }\\n      },\\n      \"TaskAvailabilityLifetimeInSeconds \": number,\\n      \"TaskDescription \": \"string\",\\n      \"TaskKeywords \": [ \"string\" ],\\n      \"TaskTimeLimitInSeconds \": number,\\n      \"TaskTitle \": \"string\",\\n      \"UiConfig \": { \\n         \" UiTemplateS3Uri \": \"string\"\\n      },\\n      \"WorkteamArn \": \"string\"\\n   },\\n   \"InputConfig \": { \\n      \"DataAttributes \": { \\n721Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n         \" ContentClassifiers \": [ \"string\" ]\\n      },\\n      \"DataSource \": { \\n         \" S3DataSource \": { \\n            \" ManifestS3Uri \": \"string\"\\n         }\\n      }\\n   },\\n   \"JobReferenceCode \": \"string\",\\n   \"LabelAttributeName \": \"string\",\\n   \"LabelCategoryConfigS3Uri \": \"string\",\\n   \"LabelCounters \": { \\n      \"FailedNonRetryableError \": number,\\n      \"HumanLabeled \": number,\\n      \"MachineLabeled \": number,\\n      \"TotalLabeled \": number,\\n      \"Unlabeled \": number\\n   },\\n   \"LabelingJobAlgorithmsConfig \": { \\n      \"InitialActiveLearningModelArn \": \"string\",\\n      \"LabelingJobAlgorithmSpecificationArn \": \"string\",\\n      \"LabelingJobResourceConfig \": { \\n         \" VolumeKmsKeyId \": \"string\"\\n      }\\n   },\\n   \"LabelingJobArn \": \"string\",\\n   \"LabelingJobName \": \"string\",\\n   \"LabelingJobOutput \": { \\n      \"FinalActiveLearningModelArn \": \"string\",\\n      \"OutputDatasetS3Uri \": \"string\"\\n   },\\n   \"LabelingJobStatus \": \"string\",\\n   \"LastModifiedTime \": number,\\n   \"OutputConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"RoleArn\": \"string\",\\n   \"StoppingConditions \": { \\n      \"MaxHumanLabeledObjectCount \": number,\\n      \"MaxPercentageOfInputDatasetLabeled \": number\\n   },\\n   \"Tags\": [ \\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCreationTime  (p. 721)\\nThe date and time that the labeling job was created.\\nType: Timestamp\\nFailureReason (p. 721)\\nIf the job failed, the reason that it failed.\\n722Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 1024.\\nHumanTaskConﬁg (p. 721)\\nConﬁguration information required for human workers to complete a labeling task.\\nType: HumanTaskConﬁg (p. 907) object\\nInputConﬁg  (p. 721)\\nInput conﬁguration information for the labeling job, such as the Amazon S3 location of the data\\nobjects and the location of the manifest ﬁle that describes the data objects.\\nType: LabelingJobInputConﬁg  (p. 945) object\\nJobReferenceCode (p. 721)\\nA unique identiﬁer for work done as part of a labeling job.\\nType: String\\nLength Constraints: Minimum length of 1.\\nPattern: .+\\nLabelAttributeName (p. 721)\\nThe attribute used as the label in the output manifest ﬁle.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 127.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nLabelCategoryConﬁgS3Uri (p. 721)\\nThe S3 location of the JSON ﬁle that deﬁnes the categories used to label data objects.\\nThe ﬁle is a JSON structure in the following format:\\n{\\n\"document-version\": \"2018-11-28\"\\n\"labels\": [\\n{\\n\"label\": \" label 1\"\\n},\\n{\\n\"label\": \" label 2\"\\n},\\n...\\n{\\n723Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n\"label\": \" label n\"\\n}\\n]\\n}\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nLabelCounters  (p. 721)\\nProvides a breakdown of the number of data objects labeled by humans, the number of objects\\nlabeled by machine, the number of objects than couldn\\'t be labeled, and the total number of objects\\nlabeled.\\nType: LabelCounters  (p. 936) object\\nLabelingJobAlgorithmsConﬁg (p. 721)\\nConﬁguration information for automated data labeling.\\nType: LabelingJobAlgorithmsConﬁg  (p. 939) object\\nLabelingJobArn  (p. 721)\\nThe Amazon Resource Name (ARN) of the labeling job.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:labeling-job/.*\\nLabelingJobName  (p. 721)\\nThe name assigned to the labeling job when it was created.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nLabelingJobOutput  (p. 721)\\nThe location of the output produced by the labeling job.\\nType: LabelingJobOutput  (p. 946) object\\nLabelingJobStatus  (p. 721)\\nThe processing status of the labeling job.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nLastModiﬁedTime  (p. 721)\\nThe date and time that the labeling job was last updated.\\nType: Timestamp\\n724Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nOutputConﬁg  (p. 721)\\nThe location of the job\\'s output data and the AWS Key Management Service key ID for the key used\\nto encrypt the output data, if any.\\nType: LabelingJobOutputConﬁg  (p. 947) object\\nRoleArn (p. 721)\\nThe Amazon Resource Name (ARN) that Amazon SageMaker assumes to perform tasks on your\\nbehalf during data labeling.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nStoppingConditions  (p. 721)\\nA set of conditions for stopping a labeling job. If any of the conditions are met, the job is\\nautomatically stopped.\\nType: LabelingJobStoppingConditions  (p. 950) object\\nTags (p. 721)\\nAn array of key/value pairs. For more information, see Using Cost Allocation Tags in the AWS Billing\\nand Cost Management User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n725Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n726Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeModel\\nService: Amazon SageMaker Service\\nDescribes a model that you created using the CreateModel  API.\\nRequest Syntax\\n{\\n   \"ModelName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nModelName  (p. 727)\\nThe name of the model.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"Containers \": [ \\n      { \\n         \" ContainerHostname \": \"string\",\\n         \" Environment \": { \\n            \" string\" : \"string\" \\n         },\\n         \" Image\": \"string\",\\n         \" ModelDataUrl \": \"string\",\\n         \" ModelPackageName \": \"string\"\\n      }\\n   ],\\n   \"CreationTime \": number,\\n   \"EnableNetworkIsolation \": boolean,\\n   \"ExecutionRoleArn \": \"string\",\\n   \"ModelArn \": \"string\",\\n   \"ModelName \": \"string\",\\n   \"PrimaryContainer \": { \\n      \"ContainerHostname \": \"string\",\\n      \"Environment \": { \\n         \" string\" : \"string\" \\n      },\\n      \"Image\": \"string\",\\n      \"ModelDataUrl \": \"string\",\\n      \"ModelPackageName \": \"string\"\\n   },\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n727Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      \"Subnets\": [ \"string\" ]\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nContainers  (p. 727)\\nThe containers in the inference pipeline.\\nType: Array of ContainerDeﬁnition  (p. 886) objects\\nArray Members: Maximum number of 5 items.\\nCreationTime  (p. 727)\\nA timestamp that shows when the model was created.\\nType: Timestamp\\nEnableNetworkIsolation (p. 727)\\nIf True, no inbound or outbound network calls can be made to or from the model container.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network isolation.\\nType: Boolean\\nExecutionRoleArn (p. 727)\\nThe Amazon Resource Name (ARN) of the IAM role that you speciﬁed for the model.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nModelArn  (p. 727)\\nThe Amazon Resource Name (ARN) of the model.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model/.*\\nModelName  (p. 727)\\nName of the Amazon SageMaker model.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nPrimaryContainer (p. 727)\\nThe location of the primary inference code, associated artifacts, and custom environment map that\\nthe inference code uses when it is deployed in production.\\n728Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: ContainerDeﬁnition  (p. 886) object\\nVpcConﬁg (p. 727)\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that this model has access to. For more\\ninformation, see Protect Endpoints by Using an Amazon Virtual Private Cloud\\nType: VpcConﬁg (p. 1039 ) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n729Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeModelPackage\\nService: Amazon SageMaker Service\\nReturns a description of the speciﬁed model package, which is used to create Amazon SageMaker models\\nor list them on AWS Marketplace.\\nTo create models in Amazon SageMaker, buyers can subscribe to model packages listed on AWS\\nMarketplace.\\nRequest Syntax\\n{\\n   \"ModelPackageName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nModelPackageName (p. 730)\\nThe name of the model package to describe.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 170.\\nPattern: (arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:[a-z\\\\-]*\\\\/)?([a-zA-\\nZ0-9]([a-zA-Z0-9-]){0,62})(?<!-)$\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CertifyForMarketplace \": boolean,\\n   \"CreationTime \": number,\\n   \"InferenceSpecification \": { \\n      \"Containers \": [ \\n         { \\n            \" ContainerHostname \": \"string\",\\n            \" Image\": \"string\",\\n            \" ImageDigest \": \"string\",\\n            \" ModelDataUrl \": \"string\",\\n            \" ProductId \": \"string\"\\n         }\\n      ],\\n      \"SupportedContentTypes \": [ \"string\" ],\\n      \"SupportedRealtimeInferenceInstanceTypes \": [ \"string\" ],\\n      \"SupportedResponseMIMETypes \": [ \"string\" ],\\n      \"SupportedTransformInstanceTypes \": [ \"string\" ]\\n   },\\n   \"ModelPackageArn \": \"string\",\\n   \"ModelPackageDescription \": \"string\",\\n   \"ModelPackageName \": \"string\",\\n   \"ModelPackageStatus \": \"string\",\\n   \"ModelPackageStatusDetails \": { \\n      \"ImageScanStatuses \": [ \\n730Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n         { \\n            \" FailureReason \": \"string\",\\n            \" Name\": \"string\",\\n            \" Status\": \"string\"\\n         }\\n      ],\\n      \"ValidationStatuses \": [ \\n         { \\n            \" FailureReason \": \"string\",\\n            \" Name\": \"string\",\\n            \" Status\": \"string\"\\n         }\\n      ]\\n   },\\n   \"SourceAlgorithmSpecification \": { \\n      \"SourceAlgorithms \": [ \\n         { \\n            \" AlgorithmName \": \"string\",\\n            \" ModelDataUrl \": \"string\"\\n         }\\n      ]\\n   },\\n   \"ValidationSpecification \": { \\n      \"ValidationProfiles \": [ \\n         { \\n            \" ProfileName \": \"string\",\\n            \" TransformJobDefinition \": { \\n               \" BatchStrategy \": \"string\",\\n               \" Environment \": { \\n                  \" string\" : \"string\" \\n               },\\n               \" MaxConcurrentTransforms \": number,\\n               \" MaxPayloadInMB \": number,\\n               \" TransformInput \": { \\n                  \" CompressionType \": \"string\",\\n                  \" ContentType \": \"string\",\\n                  \" DataSource \": { \\n                     \" S3DataSource \": { \\n                        \" S3DataType \": \"string\",\\n                        \" S3Uri\": \"string\"\\n                     }\\n                  },\\n                  \" SplitType \": \"string\"\\n               },\\n               \" TransformOutput \": { \\n                  \" Accept\": \"string\",\\n                  \" AssembleWith \": \"string\",\\n                  \" KmsKeyId \": \"string\",\\n                  \" S3OutputPath \": \"string\"\\n               },\\n               \" TransformResources \": { \\n                  \" InstanceCount \": number,\\n                  \" InstanceType \": \"string\",\\n                  \" VolumeKmsKeyId \": \"string\"\\n               }\\n            }\\n         }\\n      ],\\n      \"ValidationRole \": \"string\"\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\n731Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nThe following data is returned in JSON format by the service.\\nCertifyForMarketplace (p. 730)\\nWhether the model package is certiﬁed for listing on AWS Marketplace.\\nType: Boolean\\nCreationTime  (p. 730)\\nA timestamp specifying when the model package was created.\\nType: Timestamp\\nInferenceSpeciﬁcation (p. 730)\\nDetails about inference jobs that can be run with models based on this model package.\\nType: InferenceSpeciﬁcation (p. 929) object\\nModelPackageArn (p. 730)\\nThe Amazon Resource Name (ARN) of the model package.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model-package/.*\\nModelPackageDescription (p. 730)\\nA brief summary of the model package.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nModelPackageName (p. 730)\\nThe name of the model package being described.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nModelPackageStatus (p. 730)\\nThe current status of the model package.\\nType: String\\nValid Values: Pending | InProgress | Completed | Failed | Deleting\\nModelPackageStatusDetails (p. 730)\\nDetails about the current status of the model package.\\nType: ModelPackageStatusDetails (p. 960) object\\nSourceAlgorithmSpeciﬁcation (p. 730)\\nDetails about the algorithm that was used to create the model package.\\n732Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: SourceAlgorithmSpeciﬁcation (p. 1003 ) object\\nValidationSpeciﬁcation (p. 730)\\nConﬁgurations for one or more transform jobs that Amazon SageMaker runs to test the model\\npackage.\\nType: ModelPackageValidationSpeciﬁcation (p. 965) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n733Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeNotebookInstance\\nService: Amazon SageMaker Service\\nReturns information about a notebook instance.\\nRequest Syntax\\n{\\n   \"NotebookInstanceName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceName (p. 734)\\nThe name of the notebook instance that you want information about.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"AcceleratorTypes \": [ \"string\" ],\\n   \"AdditionalCodeRepositories \": [ \"string\" ],\\n   \"CreationTime \": number,\\n   \"DefaultCodeRepository \": \"string\",\\n   \"DirectInternetAccess \": \"string\",\\n   \"FailureReason \": \"string\",\\n   \"InstanceType \": \"string\",\\n   \"KmsKeyId \": \"string\",\\n   \"LastModifiedTime \": number,\\n   \"NetworkInterfaceId \": \"string\",\\n   \"NotebookInstanceArn \": \"string\",\\n   \"NotebookInstanceLifecycleConfigName \": \"string\",\\n   \"NotebookInstanceName \": \"string\",\\n   \"NotebookInstanceStatus \": \"string\",\\n   \"RoleArn\": \"string\",\\n   \"RootAccess \": \"string\",\\n   \"SecurityGroups \": [ \"string\" ],\\n   \"SubnetId \": \"string\",\\n   \"Url\": \"string\",\\n   \"VolumeSizeInGB \": number\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\n734Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nThe following data is returned in JSON format by the service.\\nAcceleratorTypes (p. 734)\\nA list of the Elastic Inference (EI) instance types associated with this notebook instance. Currently\\nonly one EI instance type can be associated with a notebook instance. For more information, see\\nUsing Elastic Inference in Amazon SageMaker.\\nType: Array of strings\\nValid Values: ml.eia1.medium | ml.eia1.large | ml.eia1.xlarge\\nAdditionalCodeRepositories (p. 734)\\nAn array of up to three Git repositories associated with the notebook instance. These can be either\\nthe names of Git repositories stored as resources in your account, or the URL of Git repositories in\\nAWS CodeCommit or in any other Git repository. These repositories are cloned at the same level\\nas the default repository of your notebook instance. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: Array of strings\\nArray Members: Maximum number of 3 items.\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nCreationTime  (p. 734)\\nA timestamp. Use this parameter to return the time when the notebook instance was created\\nType: Timestamp\\nDefaultCodeRepository (p. 734)\\nThe Git repository associated with the notebook instance as its default code repository. This can\\nbe either the name of a Git repository stored as a resource in your account, or the URL of a Git\\nrepository in AWS CodeCommit or in any other Git repository. When you open a notebook instance,\\nit opens in the directory that contains this repository. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nDirectInternetAccess (p. 734)\\nDescribes whether Amazon SageMaker provides internet access to the notebook instance. If this\\nvalue is set to Disabled , the notebook instance does not have internet access, and cannot connect to\\nAmazon SageMaker training and endpoint services.\\nFor more information, see Notebook Instances Are Internet-Enabled by Default.\\nType: String\\nValid Values: Enabled | Disabled\\nFailureReason (p. 734)\\nIf status is Failed, the reason it failed.\\nType: String\\n735Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLength Constraints: Maximum length of 1024.\\nInstanceType (p. 734)\\nThe type of ML compute instance running on the notebook instance.\\nType: String\\nValid Values: ml.t2.medium | ml.t2.large | ml.t2.xlarge | ml.t2.2xlarge |\\nml.t3.medium | ml.t3.large | ml.t3.xlarge | ml.t3.2xlarge | ml.m4.xlarge\\n| ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge | ml.m4.16xlarge\\n| ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge | ml.m5.12xlarge\\n| ml.m5.24xlarge | ml.c4.xlarge | ml.c4.2xlarge | ml.c4.4xlarge |\\nml.c4.8xlarge | ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge\\n| ml.c5.18xlarge | ml.c5d.xlarge | ml.c5d.2xlarge | ml.c5d.4xlarge\\n| ml.c5d.9xlarge | ml.c5d.18xlarge | ml.p2.xlarge | ml.p2.8xlarge |\\nml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge\\nKmsKeyId (p. 734)\\nThe AWS KMS key ID Amazon SageMaker uses to encrypt data when storing it on the ML storage\\nvolume attached to the instance.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nLastModiﬁedTime  (p. 734)\\nA timestamp. Use this parameter to retrieve the time when the notebook instance was last modiﬁed.\\nType: Timestamp\\nNetworkInterfaceId (p. 734)\\nThe network interface IDs that Amazon SageMaker created at the time of creating the instance.\\nType: String\\nNotebookInstanceArn (p. 734)\\nThe Amazon Resource Name (ARN) of the notebook instance.\\nType: String\\nLength Constraints: Maximum length of 256.\\nNotebookInstanceLifecycleConﬁgName (p. 734)\\nReturns the name of a notebook instance lifecycle conﬁguration.\\nFor information about notebook instance lifestyle conﬁgurations, see Step 2.1: (Optional) Customize\\na Notebook Instance\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nNotebookInstanceName (p. 734)\\nThe name of the Amazon SageMaker notebook instance.\\nType: String\\n736Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nNotebookInstanceStatus (p. 734)\\nThe status of the notebook instance.\\nType: String\\nValid Values: Pending | InService | Stopping | Stopped | Failed | Deleting |\\nUpdating\\nRoleArn (p. 734)\\nThe Amazon Resource Name (ARN) of the IAM role associated with the instance.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRootAccess (p. 734)\\nWhether root access is enabled or disabled for users of the notebook instance.\\nNote\\nLifecycle conﬁgurations need root access to be able to set up a notebook instance. Because\\nof this, lifecycle conﬁgurations associated with a notebook instance always run with root\\naccess even if you disable root access for users.\\nType: String\\nValid Values: Enabled | Disabled\\nSecurityGroups (p. 734)\\nThe IDs of the VPC security groups.\\nType: Array of strings\\nArray Members: Maximum number of 5 items.\\nLength Constraints: Maximum length of 32.\\nPattern: [-0-9a-zA-Z]+\\nSubnetId  (p. 734)\\nThe ID of the VPC subnet.\\nType: String\\nLength Constraints: Maximum length of 32.\\nPattern: [-0-9a-zA-Z]+\\nUrl (p. 734)\\nThe URL that you use to connect to the Jupyter notebook that is running in your notebook instance.\\nType: String\\nVolumeSizeInGB (p. 734)\\nThe size, in GB, of the ML storage volume attached to the notebook instance.\\n737Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: Integer\\nValid Range: Minimum value of 5. Maximum value of 16384.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n738Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeNotebookInstanceLifecycleConﬁg\\nService: Amazon SageMaker Service\\nReturns a description of a notebook instance lifecycle conﬁguration.\\nFor information about notebook instance lifestyle conﬁgurations, see Step 2.1: (Optional) Customize a\\nNotebook Instance.\\nRequest Syntax\\n{\\n   \"NotebookInstanceLifecycleConfigName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceLifecycleConﬁgName (p. 739)\\nThe name of the lifecycle conﬁguration to describe.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"CreationTime \": number,\\n   \"LastModifiedTime \": number,\\n   \"NotebookInstanceLifecycleConfigArn \": \"string\",\\n   \"NotebookInstanceLifecycleConfigName \": \"string\",\\n   \"OnCreate \": [ \\n      { \\n         \" Content\": \"string\"\\n      }\\n   ],\\n   \"OnStart\": [ \\n      { \\n         \" Content\": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\n739Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCreationTime  (p. 739)\\nA timestamp that tells when the lifecycle conﬁguration was created.\\nType: Timestamp\\nLastModiﬁedTime  (p. 739)\\nA timestamp that tells when the lifecycle conﬁguration was last modiﬁed.\\nType: Timestamp\\nNotebookInstanceLifecycleConﬁgArn (p. 739)\\nThe Amazon Resource Name (ARN) of the lifecycle conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 256.\\nNotebookInstanceLifecycleConﬁgName (p. 739)\\nThe name of the lifecycle conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nOnCreate  (p. 739)\\nThe shell script that runs only once, when you create a notebook instance.\\nType: Array of NotebookInstanceLifecycleHook (p. 969) objects\\nArray Members: Maximum number of 1 item.\\nOnStart (p. 739)\\nThe shell script that runs every time you start a notebook instance, including when you create the\\nnotebook instance.\\nType: Array of NotebookInstanceLifecycleHook (p. 969) objects\\nArray Members: Maximum number of 1 item.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n740Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n741Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeSubscribedWorkteam\\nService: Amazon SageMaker Service\\nGets information about a work team provided by a vendor. It returns details about the subscription with\\na vendor in the AWS Marketplace.\\nRequest Syntax\\n{\\n   \"WorkteamArn \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nWorkteamArn (p. 742)\\nThe Amazon Resource Name (ARN) of the subscribed work team to describe.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:workteam/.*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"SubscribedWorkteam \": { \\n      \"ListingId \": \"string\",\\n      \"MarketplaceDescription \": \"string\",\\n      \"MarketplaceTitle \": \"string\",\\n      \"SellerName \": \"string\",\\n      \"WorkteamArn \": \"string\"\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nSubscribedWorkteam (p. 742)\\nA Workteam  instance that contains information about the work team.\\nType: SubscribedWorkteam (p. 1005 ) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\n742Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n743Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeTrainingJob\\nService: Amazon SageMaker Service\\nReturns information about a training job.\\nRequest Syntax\\n{\\n   \"TrainingJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nTrainingJobName (p. 744)\\nThe name of the training job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"AlgorithmSpecification \": { \\n      \"AlgorithmName \": \"string\",\\n      \"MetricDefinitions \": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Regex\": \"string\"\\n         }\\n      ],\\n      \"TrainingImage \": \"string\",\\n      \"TrainingInputMode \": \"string\"\\n   },\\n   \"BillableTimeInSeconds \": number,\\n   \"CheckpointConfig \": { \\n      \"LocalPath \": \"string\",\\n      \"S3Uri\": \"string\"\\n   },\\n   \"CreationTime \": number,\\n   \"EnableInterContainerTrafficEncryption \": boolean,\\n   \"EnableManagedSpotTraining \": boolean,\\n   \"EnableNetworkIsolation \": boolean,\\n   \"FailureReason \": \"string\",\\n   \"FinalMetricDataList \": [ \\n      { \\n         \" MetricName \": \"string\",\\n         \" Timestamp \": number,\\n         \" Value\": number\\n      }\\n744Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   ],\\n   \"HyperParameters \": { \\n      \"string\" : \"string\" \\n   },\\n   \"InputDataConfig \": [ \\n      { \\n         \" ChannelName \": \"string\",\\n         \" CompressionType \": \"string\",\\n         \" ContentType \": \"string\",\\n         \" DataSource \": { \\n            \" FileSystemDataSource \": { \\n               \" DirectoryPath \": \"string\",\\n               \" FileSystemAccessMode \": \"string\",\\n               \" FileSystemId \": \"string\",\\n               \" FileSystemType \": \"string\"\\n            },\\n            \" S3DataSource \": { \\n               \" AttributeNames \": [ \"string\" ],\\n               \" S3DataDistributionType \": \"string\",\\n               \" S3DataType \": \"string\",\\n               \" S3Uri\": \"string\"\\n            }\\n         },\\n         \" InputMode \": \"string\",\\n         \" RecordWrapperType \": \"string\",\\n         \" ShuffleConfig \": { \\n            \" Seed\": number\\n         }\\n      }\\n   ],\\n   \"LabelingJobArn \": \"string\",\\n   \"LastModifiedTime \": number,\\n   \"ModelArtifacts \": { \\n      \"S3ModelArtifacts \": \"string\"\\n   },\\n   \"OutputDataConfig \": { \\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"ResourceConfig \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\",\\n      \"VolumeSizeInGB \": number\\n   },\\n   \"RoleArn\": \"string\",\\n   \"SecondaryStatus \": \"string\",\\n   \"SecondaryStatusTransitions \": [ \\n      { \\n         \" EndTime\": number,\\n         \" StartTime \": number,\\n         \" Status\": \"string\",\\n         \" StatusMessage \": \"string\"\\n      }\\n   ],\\n   \"StoppingCondition \": { \\n      \"MaxRuntimeInSeconds \": number,\\n      \"MaxWaitTimeInSeconds \": number\\n   },\\n   \"TrainingEndTime \": number,\\n   \"TrainingJobArn \": \"string\",\\n   \"TrainingJobName \": \"string\",\\n   \"TrainingJobStatus \": \"string\",\\n   \"TrainingStartTime \": number,\\n   \"TrainingTimeInSeconds \": number,\\n   \"TuningJobArn \": \"string\",\\n745Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"VpcConfig \": { \\n      \"SecurityGroupIds \": [ \"string\" ],\\n      \"Subnets\": [ \"string\" ]\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nAlgorithmSpeciﬁcation (p. 744)\\nInformation about the algorithm used for training, and algorithm metadata.\\nType: AlgorithmSpeciﬁcation  (p. 863) object\\nBillableTimeInSeconds (p. 744)\\nThe billable time in seconds.\\nYou can calculate the savings from using managed spot training using the formula (1\\n- BillableTimeInSeconds / TrainingTimeInSeconds) * 100 . For example, if\\nBillableTimeInSeconds  is 100 and TrainingTimeInSeconds  is 500, the savings is 80%.\\nType: Integer\\nValid Range: Minimum value of 1.\\nCheckpointConﬁg  (p. 744)\\nContains information about the output location for managed spot training checkpoint data.\\nType: CheckpointConﬁg  (p. 880) object\\nCreationTime  (p. 744)\\nA timestamp that indicates when the training job was created.\\nType: Timestamp\\nEnableInterContainerTraﬃcEncryption (p. 744)\\nTo encrypt all communications between ML compute instances in distributed training, choose True .\\nEncryption provides greater security for distributed training, but training might take longer. How\\nlong it takes depends on the amount of communication between compute instances, especially if\\nyou use a deep learning algorithms in distributed training.\\nType: Boolean\\nEnableManagedSpotTraining (p. 744)\\nA Boolean indicating whether managed spot training is enabled ( True ) or not (False ).\\nType: Boolean\\nEnableNetworkIsolation (p. 744)\\nIf you want to allow inbound or outbound network calls, except for calls between peers within a\\ntraining cluster for distributed training, choose True. If you enable network isolation for training\\njobs that are conﬁgured to use a VPC, Amazon SageMaker downloads and uploads customer data\\nand model artifacts through the speciﬁed VPC, but the training container does not have network\\naccess.\\n746Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network isolation.\\nType: Boolean\\nFailureReason (p. 744)\\nIf the training job failed, the reason it failed.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nFinalMetricDataList  (p. 744)\\nA collection of MetricData  objects that specify the names, values, and dates and times that the\\ntraining algorithm emitted to Amazon CloudWatch.\\nType: Array of MetricData  (p. 955) objects\\nArray Members: Minimum number of 0 items. Maximum number of 40 items.\\nHyperParameters (p. 744)\\nAlgorithm-speciﬁc parameters.\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nInputDataConﬁg  (p. 744)\\nAn array of Channel objects that describes each data input channel.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nLabelingJobArn  (p. 744)\\nThe Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created\\nthe transform or training job.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:labeling-job/.*\\nLastModiﬁedTime  (p. 744)\\nA timestamp that indicates when the status of the training job was last modiﬁed.\\nType: Timestamp\\nModelArtifacts (p. 744)\\nInformation about the Amazon S3 location that is conﬁgured for storing model artifacts.\\nType: ModelArtifacts (p. 957) object\\n747Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nOutputDataConﬁg  (p. 744)\\nThe S3 path where model artifacts that you conﬁgured when creating the job are stored. Amazon\\nSageMaker creates subfolders for model artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nResourceConﬁg (p. 744)\\nResources, including ML compute instances and ML storage volumes, that are conﬁgured for model\\ntraining.\\nType: ResourceConﬁg (p. 991) object\\nRoleArn (p. 744)\\nThe AWS Identity and Access Management (IAM) role conﬁgured for the training job.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nSecondaryStatus (p. 744)\\nProvides detailed information about the state of the training job. For detailed\\ninformation on the secondary status of the training job, see StatusMessage  under\\nSecondaryStatusTransition (p. 999).\\nAmazon SageMaker provides primary statuses and secondary statuses that apply to each of them:\\nInProgress\\n•Starting  - Starting the training job.\\n•Downloading  - An optional stage for algorithms that support File  training input mode. It\\nindicates that data is being downloaded to the ML storage volumes.\\n•Training  - Training is in progress.\\n•Uploading  - Training is complete and the model artifacts are being uploaded to the S3\\nlocation.\\nCompleted\\n•Completed  - The training job has completed.\\nFailed\\n•Failed - The training job has failed. The reason for the failure is returned in the\\nFailureReason  ﬁeld of DescribeTrainingJobResponse .\\nStopped\\n•MaxRuntimeExceeded  - The job stopped because it exceeded the maximum allowed\\nruntime.\\n•MaxWaitTmeExceeded  - The job stopped because it exceeded the maximum allowed wait\\ntime.\\n•Interrupted  - The job stopped because the managed spot training instances were\\ninterrupted.\\n•Stopped  - The training job has stopped.\\nStopping\\n•Stopping  - Stopping the training job.\\nImportant\\nValid values for SecondaryStatus  are subject to change.\\nWe no longer support the following secondary statuses:\\n748Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•LaunchingMLInstances\\n•PreparingTrainingStack\\n•DownloadingTrainingImage\\nType: String\\nValid Values: Starting | LaunchingMLInstances | PreparingTrainingStack |\\nDownloading | DownloadingTrainingImage | Training | Uploading | Stopping\\n| Stopped | MaxRuntimeExceeded | Completed | Failed | Interrupted |\\nMaxWaitTimeExceeded\\nSecondaryStatusTransitions (p. 744)\\nA history of all of the secondary statuses that the training job has transitioned through.\\nType: Array of SecondaryStatusTransition (p. 999) objects\\nStoppingCondition  (p. 744)\\nSpeciﬁes a limit to how long a model training job can run. It also speciﬁes the maximum time to wait\\nfor a spot instance. When the job reaches the time limit, Amazon SageMaker ends the training job.\\nUse this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job\\ntermination for 120 seconds. Algorithms can use this 120-second window to save the model\\nartifacts, so the results of training are not lost.\\nType: StoppingCondition  (p. 1004 ) object\\nTrainingEndTime (p. 744)\\nIndicates the time when the training job ends on training instances. You are billed for the time\\ninterval between the value of TrainingStartTime  and this time. For successful jobs and stopped\\njobs, this is the time after model artifacts are uploaded. For failed jobs, this is the time when\\nAmazon SageMaker detects a job failure.\\nType: Timestamp\\nTrainingJobArn (p. 744)\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-job/.*\\nTrainingJobName (p. 744)\\nName of the model training job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nTrainingJobStatus (p. 744)\\nThe status of the training job.\\nAmazon SageMaker provides the following training job statuses:\\n•InProgress  - The training is in progress.\\n749Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•Completed  - The training job has completed.\\n•Failed - The training job has failed. To see the reason for the failure, see the FailureReason\\nﬁeld in the response to a DescribeTrainingJobResponse  call.\\n•Stopping  - The training job is stopping.\\n•Stopped  - The training job has stopped.\\nFor more detailed information, see SecondaryStatus .\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nTrainingStartTime (p. 744)\\nIndicates the time when the training job starts on training instances. You are billed for the time\\ninterval between this time and the value of TrainingEndTime . The start time in CloudWatch Logs\\nmight be later than this time. The diﬀerence is due to the time it takes to download the training data\\nand to the size of the training container.\\nType: Timestamp\\nTrainingTimeInSeconds (p. 744)\\nThe training time in seconds.\\nType: Integer\\nValid Range: Minimum value of 1.\\nTuningJobArn (p. 744)\\nThe Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the training job\\nwas launched by a hyperparameter tuning job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:hyper-parameter-\\ntuning-job/.*\\nVpcConﬁg (p. 744)\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that this training job has access to. For more\\ninformation, see Protect Training Jobs by Using an Amazon Virtual Private Cloud.\\nType: VpcConﬁg (p. 1039 ) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n750Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n751Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeTransformJob\\nService: Amazon SageMaker Service\\nReturns information about a transform job.\\nRequest Syntax\\n{\\n   \"TransformJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nTransformJobName (p. 752)\\nThe name of the transform job that you want to view details of.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"BatchStrategy \": \"string\",\\n   \"CreationTime \": number,\\n   \"DataProcessing \": { \\n      \"InputFilter \": \"string\",\\n      \"JoinSource \": \"string\",\\n      \"OutputFilter \": \"string\"\\n   },\\n   \"Environment \": { \\n      \"string\" : \"string\" \\n   },\\n   \"FailureReason \": \"string\",\\n   \"LabelingJobArn \": \"string\",\\n   \"MaxConcurrentTransforms \": number,\\n   \"MaxPayloadInMB \": number,\\n   \"ModelName \": \"string\",\\n   \"TransformEndTime \": number,\\n   \"TransformInput \": { \\n      \"CompressionType \": \"string\",\\n      \"ContentType \": \"string\",\\n      \"DataSource \": { \\n         \" S3DataSource \": { \\n            \" S3DataType \": \"string\",\\n            \" S3Uri\": \"string\"\\n         }\\n      },\\n      \"SplitType \": \"string\"\\n   },\\n752Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"TransformJobArn \": \"string\",\\n   \"TransformJobName \": \"string\",\\n   \"TransformJobStatus \": \"string\",\\n   \"TransformOutput \": { \\n      \"Accept\": \"string\",\\n      \"AssembleWith \": \"string\",\\n      \"KmsKeyId \": \"string\",\\n      \"S3OutputPath \": \"string\"\\n   },\\n   \"TransformResources \": { \\n      \"InstanceCount \": number,\\n      \"InstanceType \": \"string\",\\n      \"VolumeKmsKeyId \": \"string\"\\n   },\\n   \"TransformStartTime \": number\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nBatchStrategy  (p. 752)\\nSpeciﬁes the number of records to include in a mini-batch for an HTTP inference request. A record   is\\na single unit of input data that inference can be made on. For example, a single line in a CSV ﬁle is a\\nrecord.\\nTo enable the batch strategy, you must set SplitType  to Line , RecordIO , or TFRecord .\\nType: String\\nValid Values: MultiRecord | SingleRecord\\nCreationTime  (p. 752)\\nA timestamp that shows when the transform Job was created.\\nType: Timestamp\\nDataProcessing (p. 752)\\nThe data structure used to specify the data to be used for inference in a batch transform job and to\\nassociate the data that is relevant to the prediction results in the output. The input ﬁlter provided\\nallows you to exclude input data that is not needed for inference in a batch transform job. The\\noutput ﬁlter provided allows you to include input data relevant to interpreting the predictions\\nin the output from the job. For more information, see Associate Prediction Results with their\\nCorresponding Input Records.\\nType: DataProcessing (p. 891) object\\nEnvironment (p. 752)\\nThe environment variables to set in the Docker container. We support up to 16 key and values\\nentries in the map.\\nType: String to string map\\nKey Length Constraints: Maximum length of 1024.\\nKey Pattern: [a-zA-Z_][a-zA-Z0-9_]*\\nValue Length Constraints: Maximum length of 10240.\\n753Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValue Pattern: [\\\\S\\\\s]*\\nFailureReason (p. 752)\\nIf the transform job failed, FailureReason  describes why it failed. A transform job creates a log\\nﬁle, which includes error messages, and stores it as an Amazon S3 object. For more information, see\\nLog Amazon SageMaker Events with Amazon CloudWatch.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nLabelingJobArn  (p. 752)\\nThe Amazon Resource Name (ARN) of the Amazon SageMaker Ground Truth labeling job that created\\nthe transform or training job.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:labeling-job/.*\\nMaxConcurrentTransforms (p. 752)\\nThe maximum number of parallel requests on each instance node that can be launched in a\\ntransform job. The default value is 1.\\nType: Integer\\nValid Range: Minimum value of 0.\\nMaxPayloadInMB (p. 752)\\nThe maximum payload size, in MB, used in the transform job.\\nType: Integer\\nValid Range: Minimum value of 0.\\nModelName  (p. 752)\\nThe name of the model used in the transform job.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nTransformEndTime (p. 752)\\nIndicates when the transform job has been completed, or has stopped or failed. You are billed for\\nthe time interval between this time and the value of TransformStartTime .\\nType: Timestamp\\nTransformInput (p. 752)\\nDescribes the dataset to be transformed and the Amazon S3 location where it is stored.\\nType: TransformInput (p. 1024 ) object\\nTransformJobArn (p. 752)\\nThe Amazon Resource Name (ARN) of the transform job.\\nType: String\\n754Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:transform-job/.*\\nTransformJobName (p. 752)\\nThe name of the transform job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nTransformJobStatus (p. 752)\\nThe status of the transform job. If the transform job failed, the reason is returned in the\\nFailureReason  ﬁeld.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nTransformOutput (p. 752)\\nIdentiﬁes the Amazon S3 location where you want Amazon SageMaker to save the results from the\\ntransform job.\\nType: TransformOutput (p. 1030 ) object\\nTransformResources (p. 752)\\nDescribes the resources, including ML instance types and ML instance count, to use for the transform\\njob.\\nType: TransformResources (p. 1032 ) object\\nTransformStartTime (p. 752)\\nIndicates when the transform job starts on ML instances. You are billed for the time interval between\\nthis time and the value of TransformEndTime .\\nType: Timestamp\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n755Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n756Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDescribeWorkteam\\nService: Amazon SageMaker Service\\nGets information about a speciﬁc work team. You can see information such as the create date, the last\\nupdated date, membership information, and the work team\\'s Amazon Resource Name (ARN).\\nRequest Syntax\\n{\\n   \"WorkteamName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nWorkteamName (p. 757)\\nThe name of the work team to return a description of.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"Workteam \": { \\n      \"CreateDate \": number,\\n      \"Description \": \"string\",\\n      \"LastUpdatedDate \": number,\\n      \"MemberDefinitions \": [ \\n         { \\n            \" CognitoMemberDefinition \": { \\n               \" ClientId \": \"string\",\\n               \" UserGroup \": \"string\",\\n               \" UserPool \": \"string\"\\n            }\\n         }\\n      ],\\n      \"NotificationConfiguration \": { \\n         \" NotificationTopicArn \": \"string\"\\n      },\\n      \"ProductListingIds \": [ \"string\" ],\\n      \"SubDomain \": \"string\",\\n      \"WorkteamArn \": \"string\",\\n      \"WorkteamName \": \"string\"\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\n757Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nThe following data is returned in JSON format by the service.\\nWorkteam (p. 757)\\nA Workteam  instance that contains information about the work team.\\nType: Workteam (p. 1040 ) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n758Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nGetSearchSuggestions\\nService: Amazon SageMaker Service\\nAn auto-complete API for the search functionality in the Amazon SageMaker console. It returns\\nsuggestions of possible matches for the property name to use in Search queries. Provides suggestions\\nfor HyperParameters , Tags , and Metrics .\\nRequest Syntax\\n{\\n   \"Resource \": \"string\",\\n   \"SuggestionQuery \": { \\n      \"PropertyNameQuery \": { \\n         \" PropertyNameHint \": \"string\"\\n      }\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nResource (p. 759)\\nThe name of the Amazon SageMaker resource to Search for. The only valid Resource  value is\\nTrainingJob .\\nType: String\\nValid Values: TrainingJob\\nRequired: Yes\\nSuggestionQuery (p. 759)\\nLimits the property names that are included in the response.\\nType: SuggestionQuery (p. 1007 ) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"PropertyNameSuggestions \": [ \\n      { \\n         \" PropertyName \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\n759Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nPropertyNameSuggestions (p. 759)\\nA list of property names for a Resource  that match a SuggestionQuery .\\nType: Array of PropertyNameSuggestion (p. 986) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n760Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListAlgorithms\\nService: Amazon SageMaker Service\\nLists the machine learning algorithms that have been created.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 761)\\nA ﬁlter that returns only algorithms created after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 761)\\nA ﬁlter that returns only algorithms created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 761)\\nThe maximum number of algorithms to return in the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 761)\\nA string in the algorithm name. This ﬁlter returns only algorithms whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9\\\\-]+\\nRequired: No\\n761Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNextToken (p. 761)\\nIf the response to a previous ListAlgorithms  request was truncated, the response includes a\\nNextToken . To retrieve the next set of algorithms, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 761)\\nThe parameter by which to sort the results. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime\\nRequired: No\\nSortOrder (p. 761)\\nThe sort order for the results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"AlgorithmSummaryList \": [ \\n      { \\n         \" AlgorithmArn \": \"string\",\\n         \" AlgorithmDescription \": \"string\",\\n         \" AlgorithmName \": \"string\",\\n         \" AlgorithmStatus \": \"string\",\\n         \" CreationTime \": number\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nAlgorithmSummaryList (p. 762)\\n>An array of AlgorithmSummary  objects, each of which lists an algorithm.\\nType: Array of AlgorithmSummary (p. 867) objects\\nNextToken (p. 762)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\nalgorithms, use it in the subsequent request.\\n762Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n763Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListCodeRepositories\\nService: Amazon SageMaker Service\\nGets a list of the Git repositories in your account.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 764)\\nA ﬁlter that returns only Git repositories that were created after the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 764)\\nA ﬁlter that returns only Git repositories that were created before the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 764)\\nA ﬁlter that returns only Git repositories that were last modiﬁed after the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 764)\\nA ﬁlter that returns only Git repositories that were last modiﬁed before the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 764)\\nThe maximum number of Git repositories to return in the response.\\nType: Integer\\n764Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 764)\\nA string in the Git repositories name. This ﬁlter returns only repositories whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9-]+\\nRequired: No\\nNextToken (p. 764)\\nIf the result of a ListCodeRepositoriesOutput  request was truncated, the response includes a\\nNextToken . To get the next set of Git repositories, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 764)\\nThe ﬁeld to sort results by. The default is Name .\\nType: String\\nValid Values: Name | CreationTime | LastModifiedTime\\nRequired: No\\nSortOrder (p. 764)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"CodeRepositorySummaryList \": [ \\n      { \\n         \" CodeRepositoryArn \": \"string\",\\n         \" CodeRepositoryName \": \"string\",\\n         \" CreationTime \": number,\\n         \" GitConfig \": { \\n            \" Branch\": \"string\",\\n            \" RepositoryUrl \": \"string\",\\n            \" SecretArn \": \"string\"\\n         },\\n         \" LastModifiedTime \": number\\n765Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCodeRepositorySummaryList (p. 765)\\nGets a list of summaries of the Git repositories. Each summary speciﬁes the following values for the\\nrepository:\\n•Name\\n•Amazon Resource Name (ARN)\\n•Creation time\\n•Last modiﬁed time\\n•Conﬁguration information, including the URL location of the repository and the ARN of the AWS\\nSecrets Manager secret that contains the credentials used to access the repository.\\nType: Array of CodeRepositorySummary (p. 881) objects\\nNextToken (p. 765)\\nIf the result of a ListCodeRepositoriesOutput  request was truncated, the response includes a\\nNextToken . To get the next set of Git repositories, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n766Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListCompilationJobs\\nService: Amazon SageMaker Service\\nLists model compilation jobs that satisfy various ﬁlters.\\nTo create a model compilation job, use CreateCompilationJob (p. 629). To get information about a\\nparticular model compilation job you have created, use DescribeCompilationJob  (p. 705).\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 767)\\nA ﬁlter that returns the model compilation jobs that were created after a speciﬁed time.\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 767)\\nA ﬁlter that returns the model compilation jobs that were created before a speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 767)\\nA ﬁlter that returns the model compilation jobs that were modiﬁed after a speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 767)\\nA ﬁlter that returns the model compilation jobs that were modiﬁed before a speciﬁed time.\\nType: Timestamp\\nRequired: No\\n767Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nMaxResults (p. 767)\\nThe maximum number of model compilation jobs to return in the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 767)\\nA ﬁlter that returns the model compilation jobs whose name contains a speciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9\\\\-]+\\nRequired: No\\nNextToken (p. 767)\\nIf the result of the previous ListCompilationJobs  request was truncated, the response includes a\\nNextToken . To retrieve the next set of model compilation jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 767)\\nThe ﬁeld by which to sort results. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime | Status\\nRequired: No\\nSortOrder (p. 767)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 767)\\nA ﬁlter that retrieves model compilation jobs with a speciﬁc\\nDescribeCompilationJob:CompilationJobStatus  (p. 706) status.\\nType: String\\nValid Values: INPROGRESS | COMPLETED | FAILED | STARTING | STOPPING | STOPPED\\nRequired: No\\n768Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResponse Syntax\\n{\\n   \"CompilationJobSummaries \": [ \\n      { \\n         \" CompilationEndTime \": number,\\n         \" CompilationJobArn \": \"string\",\\n         \" CompilationJobName \": \"string\",\\n         \" CompilationJobStatus \": \"string\",\\n         \" CompilationStartTime \": number,\\n         \" CompilationTargetDevice \": \"string\",\\n         \" CreationTime \": number,\\n         \" LastModifiedTime \": number\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCompilationJobSummaries  (p. 769)\\nAn array of CompilationJobSummary (p. 884) objects, each describing a model compilation job.\\nType: Array of CompilationJobSummary (p. 884) objects\\nNextToken (p. 769)\\nIf the response is truncated, Amazon SageMaker returns this NextToken . To retrieve the next set of\\nmodel compilation jobs, use this token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n769Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Ruby V2\\n770Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListEndpointConﬁgs\\nService: Amazon SageMaker Service\\nLists endpoint conﬁgurations.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 771)\\nA ﬁlter that returns only endpoint conﬁgurations with a creation time greater than or equal to the\\nspeciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 771)\\nA ﬁlter that returns only endpoint conﬁgurations created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 771)\\nThe maximum number of training jobs to return in the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 771)\\nA string in the endpoint conﬁguration name. This ﬁlter returns only endpoint conﬁgurations whose\\nname contains the speciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9-]+\\nRequired: No\\n771Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNextToken (p. 771)\\nIf the result of the previous ListEndpointConfig  request was truncated, the response includes a\\nNextToken . To retrieve the next set of endpoint conﬁgurations, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 771)\\nThe ﬁeld to sort results by. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime\\nRequired: No\\nSortOrder (p. 771)\\nThe sort order for results. The default is Descending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"EndpointConfigs \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" EndpointConfigArn \": \"string\",\\n         \" EndpointConfigName \": \"string\"\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nEndpointConﬁgs  (p. 772)\\nAn array of endpoint conﬁgurations.\\nType: Array of EndpointConﬁgSummary (p. 896) objects\\nNextToken (p. 772)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\nendpoint conﬁgurations, use it in the subsequent request\\n772Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n773Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListEndpoints\\nService: Amazon SageMaker Service\\nLists endpoints.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 774)\\nA ﬁlter that returns only endpoints with a creation time greater than or equal to the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 774)\\nA ﬁlter that returns only endpoints that were created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 774)\\nA ﬁlter that returns only endpoints that were modiﬁed after the speciﬁed timestamp.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 774)\\nA ﬁlter that returns only endpoints that were modiﬁed before the speciﬁed timestamp.\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 774)\\nThe maximum number of endpoints to return in the response.\\n774Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 774)\\nA string in endpoint names. This ﬁlter returns only endpoints whose name contains the speciﬁed\\nstring.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9-]+\\nRequired: No\\nNextToken (p. 774)\\nIf the result of a ListEndpoints  request was truncated, the response includes a NextToken . To\\nretrieve the next set of endpoints, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 774)\\nSorts the list of results. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime | Status\\nRequired: No\\nSortOrder (p. 774)\\nThe sort order for results. The default is Descending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 774)\\nA ﬁlter that returns only endpoints with the speciﬁed status.\\nType: String\\nValid Values: OutOfService | Creating | Updating | SystemUpdating | RollingBack\\n| InService | Deleting | Failed\\nRequired: No\\nResponse Syntax\\n{\\n775Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"Endpoints \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" EndpointArn \": \"string\",\\n         \" EndpointName \": \"string\",\\n         \" EndpointStatus \": \"string\",\\n         \" LastModifiedTime \": number\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nEndpoints  (p. 775)\\nAn array or endpoint objects.\\nType: Array of EndpointSummary (p. 897) objects\\nNextToken (p. 775)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\ntraining jobs, use it in the subsequent request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n776Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListHyperParameterTuningJobs\\nService: Amazon SageMaker Service\\nGets a list of HyperParameterTuningJobSummary (p. 925) objects that describe the hyperparameter\\ntuning jobs launched in your account.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 777)\\nA ﬁlter that returns only tuning jobs that were created after the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 777)\\nA ﬁlter that returns only tuning jobs that were created before the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 777)\\nA ﬁlter that returns only tuning jobs that were modiﬁed after the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 777)\\nA ﬁlter that returns only tuning jobs that were modiﬁed before the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 777)\\nThe maximum number of tuning jobs to return. The default value is 10.\\n777Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 777)\\nA string in the tuning job name. This ﬁlter returns only tuning jobs whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9\\\\-]+\\nRequired: No\\nNextToken (p. 777)\\nIf the result of the previous ListHyperParameterTuningJobs  request was truncated, the\\nresponse includes a NextToken . To retrieve the next set of tuning jobs, use the token in the next\\nrequest.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 777)\\nThe ﬁeld to sort results by. The default is Name .\\nType: String\\nValid Values: Name | Status | CreationTime\\nRequired: No\\nSortOrder (p. 777)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 777)\\nA ﬁlter that returns only tuning jobs with the speciﬁed status.\\nType: String\\nValid Values: Completed | InProgress | Failed | Stopped | Stopping\\nRequired: No\\nResponse Syntax\\n{\\n778Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"HyperParameterTuningJobSummaries \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" HyperParameterTuningEndTime \": number,\\n         \" HyperParameterTuningJobArn \": \"string\",\\n         \" HyperParameterTuningJobName \": \"string\",\\n         \" HyperParameterTuningJobStatus \": \"string\",\\n         \" LastModifiedTime \": number,\\n         \" ObjectiveStatusCounters \": { \\n            \" Failed\": number,\\n            \" Pending\": number,\\n            \" Succeeded \": number\\n         },\\n         \" ResourceLimits \": { \\n            \" MaxNumberOfTrainingJobs \": number,\\n            \" MaxParallelTrainingJobs \": number\\n         },\\n         \" Strategy \": \"string\",\\n         \" TrainingJobStatusCounters \": { \\n            \" Completed \": number,\\n            \" InProgress \": number,\\n            \" NonRetryableError \": number,\\n            \" RetryableError \": number,\\n            \" Stopped\": number\\n         }\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nHyperParameterTuningJobSummaries (p. 778)\\nA list of HyperParameterTuningJobSummary (p. 925) objects that describe the tuning jobs that the\\nListHyperParameterTuningJobs  request returned.\\nType: Array of HyperParameterTuningJobSummary (p. 925) objects\\nNextToken (p. 778)\\nIf the result of this ListHyperParameterTuningJobs  request was truncated, the response\\nincludes a NextToken . To retrieve the next set of tuning jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n779Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n780Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListLabelingJobs\\nService: Amazon SageMaker Service\\nGets a list of labeling jobs.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 781)\\nA ﬁlter that returns only labeling jobs created after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 781)\\nA ﬁlter that returns only labeling jobs created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 781)\\nA ﬁlter that returns only labeling jobs modiﬁed after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 781)\\nA ﬁlter that returns only labeling jobs modiﬁed before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 781)\\nThe maximum number of labeling jobs to return in each page of the response.\\nType: Integer\\n781Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 781)\\nA string in the labeling job name. This ﬁlter returns only labeling jobs whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9\\\\-]+\\nRequired: No\\nNextToken (p. 781)\\nIf the result of the previous ListLabelingJobs  request was truncated, the response includes a\\nNextToken . To retrieve the next set of labeling jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 781)\\nThe ﬁeld to sort results by. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime | Status\\nRequired: No\\nSortOrder (p. 781)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 781)\\nA ﬁlter that retrieves only labeling jobs with a speciﬁc status.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: No\\nResponse Syntax\\n{\\n782Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"LabelingJobSummaryList \": [ \\n      { \\n         \" AnnotationConsolidationLambdaArn \": \"string\",\\n         \" CreationTime \": number,\\n         \" FailureReason \": \"string\",\\n         \" InputConfig \": { \\n            \" DataAttributes \": { \\n               \" ContentClassifiers \": [ \"string\" ]\\n            },\\n            \" DataSource \": { \\n               \" S3DataSource \": { \\n                  \" ManifestS3Uri \": \"string\"\\n               }\\n            }\\n         },\\n         \" LabelCounters \": { \\n            \" FailedNonRetryableError \": number,\\n            \" HumanLabeled \": number,\\n            \" MachineLabeled \": number,\\n            \" TotalLabeled \": number,\\n            \" Unlabeled \": number\\n         },\\n         \" LabelingJobArn \": \"string\",\\n         \" LabelingJobName \": \"string\",\\n         \" LabelingJobOutput \": { \\n            \" FinalActiveLearningModelArn \": \"string\",\\n            \" OutputDatasetS3Uri \": \"string\"\\n         },\\n         \" LabelingJobStatus \": \"string\",\\n         \" LastModifiedTime \": number,\\n         \" PreHumanTaskLambdaArn \": \"string\",\\n         \" WorkteamArn \": \"string\"\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nLabelingJobSummaryList (p. 782)\\nAn array of LabelingJobSummary  objects, each describing a labeling job.\\nType: Array of LabelingJobSummary (p. 951) objects\\nNextToken (p. 782)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\nlabeling jobs, use it in the subsequent request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\n783Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n784Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListLabelingJobsForWorkteam\\nService: Amazon SageMaker Service\\nGets a list of labeling jobs assigned to a speciﬁed work team.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"JobReferenceCodeContains \": \"string\",\\n   \"MaxResults \": number,\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"WorkteamArn \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 785)\\nA ﬁlter that returns only labeling jobs created after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 785)\\nA ﬁlter that returns only labeling jobs created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nJobReferenceCodeContains (p. 785)\\nA ﬁlter the limits jobs to only the ones whose job reference code contains the speciﬁed string.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: No\\nMaxResults (p. 785)\\nThe maximum number of labeling jobs to return in each page of the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\n785Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNextToken (p. 785)\\nIf the result of the previous ListLabelingJobsForWorkteam  request was truncated, the response\\nincludes a NextToken . To retrieve the next set of labeling jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 785)\\nThe ﬁeld to sort results by. The default is CreationTime .\\nType: String\\nValid Values: CreationTime\\nRequired: No\\nSortOrder (p. 785)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nWorkteamArn (p. 785)\\nThe Amazon Resource Name (ARN) of the work team for which you want to see labeling jobs for.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:workteam/.*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"LabelingJobSummaryList \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" JobReferenceCode \": \"string\",\\n         \" LabelCounters \": { \\n            \" HumanLabeled \": number,\\n            \" PendingHuman \": number,\\n            \" Total\": number\\n         },\\n         \" LabelingJobName \": \"string\",\\n         \" NumberOfHumanWorkersPerDataObject \": number,\\n         \" WorkRequesterAccountId \": \"string\"\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n786Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nLabelingJobSummaryList (p. 786)\\nAn array of LabelingJobSummary  objects, each describing a labeling job.\\nType: Array of LabelingJobForWorkteamSummary (p. 943) objects\\nNextToken (p. 786)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\nlabeling jobs, use it in the subsequent request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n787Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListModelPackages\\nService: Amazon SageMaker Service\\nLists the model packages that have been created.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 788)\\nA ﬁlter that returns only model packages created after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 788)\\nA ﬁlter that returns only model packages created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 788)\\nThe maximum number of model packages to return in the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 788)\\nA string in the model package name. This ﬁlter returns only model packages whose name contains\\nthe speciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9\\\\-]+\\nRequired: No\\n788Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNextToken (p. 788)\\nIf the response to a previous ListModelPackages  request was truncated, the response includes a\\nNextToken . To retrieve the next set of model packages, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 788)\\nThe parameter by which to sort the results. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime\\nRequired: No\\nSortOrder (p. 788)\\nThe sort order for the results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"ModelPackageSummaryList \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" ModelPackageArn \": \"string\",\\n         \" ModelPackageDescription \": \"string\",\\n         \" ModelPackageName \": \"string\",\\n         \" ModelPackageStatus \": \"string\"\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nModelPackageSummaryList (p. 789)\\nAn array of ModelPackageSummary  objects, each of which lists a model package.\\nType: Array of ModelPackageSummary (p. 962) objects\\nNextToken (p. 789)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of model\\npackages, use it in the subsequent request.\\n789Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n790Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListModels\\nService: Amazon SageMaker Service\\nLists models created with the CreateModel API.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 791)\\nA ﬁlter that returns only models with a creation time greater than or equal to the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 791)\\nA ﬁlter that returns only models created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 791)\\nThe maximum number of models to return in the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 791)\\nA string in the training job name. This ﬁlter returns only models in the training job whose name\\ncontains the speciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9-]+\\nRequired: No\\n791Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNextToken (p. 791)\\nIf the response to a previous ListModels  request was truncated, the response includes a\\nNextToken . To retrieve the next set of models, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 791)\\nSorts the list of results. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime\\nRequired: No\\nSortOrder (p. 791)\\nThe sort order for results. The default is Descending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"Models\": [ \\n      { \\n         \" CreationTime \": number,\\n         \" ModelArn \": \"string\",\\n         \" ModelName \": \"string\"\\n      }\\n   ],\\n   \"NextToken \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nModels  (p. 792)\\nAn array of ModelSummary  objects, each of which lists a model.\\nType: Array of ModelSummary (p. 966) objects\\nNextToken (p. 792)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\nmodels, use it in the subsequent request.\\n792Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n793Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListNotebookInstanceLifecycleConﬁgs\\nService: Amazon SageMaker Service\\nLists notebook instance lifestyle conﬁgurations created with the\\nCreateNotebookInstanceLifecycleConﬁg (p. 662) API.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 794)\\nA ﬁlter that returns only lifecycle conﬁgurations that were created after the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 794)\\nA ﬁlter that returns only lifecycle conﬁgurations that were created before the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 794)\\nA ﬁlter that returns only lifecycle conﬁgurations that were modiﬁed after the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 794)\\nA ﬁlter that returns only lifecycle conﬁgurations that were modiﬁed before the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\n794Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nMaxResults (p. 794)\\nThe maximum number of lifecycle conﬁgurations to return in the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 794)\\nA string in the lifecycle conﬁguration name. This ﬁlter returns only lifecycle conﬁgurations whose\\nname contains the speciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9-]+\\nRequired: No\\nNextToken (p. 794)\\nIf the result of a ListNotebookInstanceLifecycleConfigs  request was truncated, the\\nresponse includes a NextToken . To get the next set of lifecycle conﬁgurations, use the token in the\\nnext request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 794)\\nSorts the list of results. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime | LastModifiedTime\\nRequired: No\\nSortOrder (p. 794)\\nThe sort order for results.\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n   \"NotebookInstanceLifecycleConfigs \": [ \\n      { \\n795Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n         \" CreationTime \": number,\\n         \" LastModifiedTime \": number,\\n         \" NotebookInstanceLifecycleConfigArn \": \"string\",\\n         \" NotebookInstanceLifecycleConfigName \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 795)\\nIf the response is truncated, Amazon SageMaker returns this token. To get the next set of lifecycle\\nconﬁgurations, use it in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nNotebookInstanceLifecycleConﬁgs (p. 795)\\nAn array of NotebookInstanceLifecycleConfiguration  objects, each listing a lifecycle\\nconﬁguration.\\nType: Array of NotebookInstanceLifecycleConﬁgSummary (p. 968) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n796Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListNotebookInstances\\nService: Amazon SageMaker Service\\nReturns a list of the Amazon SageMaker notebook instances in the requester\\'s account in an AWS Region.\\nRequest Syntax\\n{\\n   \"AdditionalCodeRepositoryEquals \": \"string\",\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"DefaultCodeRepositoryContains \": \"string\",\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"NotebookInstanceLifecycleConfigNameContains \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAdditionalCodeRepositoryEquals (p. 797)\\nA ﬁlter that returns only notebook instances with associated with the speciﬁed git repository.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nCreationTimeAfter (p. 797)\\nA ﬁlter that returns only notebook instances that were created after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 797)\\nA ﬁlter that returns only notebook instances that were created before the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nDefaultCodeRepositoryContains (p. 797)\\nA string in the name or URL of a Git repository associated with this notebook instance. This ﬁlter\\nreturns only notebook instances associated with a git repository with a name that contains the\\nspeciﬁed string.\\n797Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [a-zA-Z0-9-]+\\nRequired: No\\nLastModiﬁedTimeAfter (p. 797)\\nA ﬁlter that returns only notebook instances that were modiﬁed after the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 797)\\nA ﬁlter that returns only notebook instances that were modiﬁed before the speciﬁed time\\n(timestamp).\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 797)\\nThe maximum number of notebook instances to return.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 797)\\nA string in the notebook instances\\' name. This ﬁlter returns only notebook instances whose name\\ncontains the speciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9-]+\\nRequired: No\\nNextToken (p. 797)\\nIf the previous call to the ListNotebookInstances  is truncated, the response includes a\\nNextToken . You can use this token in your subsequent ListNotebookInstances  request to fetch\\nthe next set of notebook instances.\\nNote\\nYou might specify a ﬁlter or a sort order in your request. When response is truncated, you\\nmust use the same values for the ﬁler and sort order in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\n798Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNotebookInstanceLifecycleConﬁgNameContains (p. 797)\\nA string in the name of a notebook instances lifecycle conﬁguration associated with this notebook\\ninstance. This ﬁlter returns only notebook instances associated with a lifecycle conﬁguration with a\\nname that contains the speciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nSortBy (p. 797)\\nThe ﬁeld to sort results by. The default is Name .\\nType: String\\nValid Values: Name | CreationTime | Status\\nRequired: No\\nSortOrder (p. 797)\\nThe sort order for results.\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 797)\\nA ﬁlter that returns only notebook instances with the speciﬁed status.\\nType: String\\nValid Values: Pending | InService | Stopping | Stopped | Failed | Deleting |\\nUpdating\\nRequired: No\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n   \"NotebookInstances \": [ \\n      { \\n         \" AdditionalCodeRepositories \": [ \"string\" ],\\n         \" CreationTime \": number,\\n         \" DefaultCodeRepository \": \"string\",\\n         \" InstanceType \": \"string\",\\n         \" LastModifiedTime \": number,\\n         \" NotebookInstanceArn \": \"string\",\\n         \" NotebookInstanceLifecycleConfigName \": \"string\",\\n         \" NotebookInstanceName \": \"string\",\\n         \" NotebookInstanceStatus \": \"string\",\\n         \" Url\": \"string\"\\n      }\\n   ]\\n799Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 799)\\nIf the response to the previous ListNotebookInstances  request was truncated, Amazon\\nSageMaker returns this token. To retrieve the next set of notebook instances, use the token in the\\nnext request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nNotebookInstances (p. 799)\\nAn array of NotebookInstanceSummary  objects, one for each notebook instance.\\nType: Array of NotebookInstanceSummary (p. 970) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n800Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListSubscribedWorkteams\\nService: Amazon SageMaker Service\\nGets a list of the work teams that you are subscribed to in the AWS Marketplace. The list may be empty if\\nno work team satisﬁes the ﬁlter speciﬁed in the NameContains  parameter.\\nRequest Syntax\\n{\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nMaxResults (p. 801)\\nThe maximum number of work teams to return in each page of the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 801)\\nA string in the work team name. This ﬁlter returns only work teams whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nNextToken (p. 801)\\nIf the result of the previous ListSubscribedWorkteams  request was truncated, the response\\nincludes a NextToken . To retrieve the next set of labeling jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nResponse Syntax\\n{\\n801Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"NextToken \": \"string\",\\n   \"SubscribedWorkteams \": [ \\n      { \\n         \" ListingId \": \"string\",\\n         \" MarketplaceDescription \": \"string\",\\n         \" MarketplaceTitle \": \"string\",\\n         \" SellerName \": \"string\",\\n         \" WorkteamArn \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 801)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of work\\nteams, use it in the subsequent request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nSubscribedWorkteams (p. 801)\\nAn array of Workteam  objects, each describing a work team.\\nType: Array of SubscribedWorkteam (p. 1005 ) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n802Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListTags\\nService: Amazon SageMaker Service\\nReturns the tags for the speciﬁed Amazon SageMaker resource.\\nRequest Syntax\\n{\\n   \"MaxResults \": number,\\n   \"NextToken \": \"string\",\\n   \"ResourceArn \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nMaxResults (p. 803)\\nMaximum number of tags to return.\\nType: Integer\\nValid Range: Minimum value of 50.\\nRequired: No\\nNextToken (p. 803)\\nIf the response to the previous ListTags  request is truncated, Amazon SageMaker returns this\\ntoken. To retrieve the next set of tags, use it in the subsequent request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nResourceArn (p. 803)\\nThe Amazon Resource Name (ARN) of the resource whose tags you want to retrieve.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:.*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n   \"Tags\": [ \\n803Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n      { \\n         \" Key\": \"string\",\\n         \" Value\": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 803)\\nIf response is truncated, Amazon SageMaker includes a token in the response. You can use this token\\nin your subsequent request to fetch next set of tokens.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nTags (p. 803)\\nAn array of Tag objects, each with a tag key and a value.\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n804Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListTrainingJobs\\nService: Amazon SageMaker Service\\nLists training jobs.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 805)\\nA ﬁlter that returns only training jobs created after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 805)\\nA ﬁlter that returns only training jobs created before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 805)\\nA ﬁlter that returns only training jobs modiﬁed after the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 805)\\nA ﬁlter that returns only training jobs modiﬁed before the speciﬁed time (timestamp).\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 805)\\nThe maximum number of training jobs to return in the response.\\nType: Integer\\n805Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 805)\\nA string in the training job name. This ﬁlter returns only training jobs whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9\\\\-]+\\nRequired: No\\nNextToken (p. 805)\\nIf the result of the previous ListTrainingJobs  request was truncated, the response includes a\\nNextToken . To retrieve the next set of training jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 805)\\nThe ﬁeld to sort results by. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime | Status\\nRequired: No\\nSortOrder (p. 805)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 805)\\nA ﬁlter that retrieves only training jobs with a speciﬁc status.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: No\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n806Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"TrainingJobSummaries \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" LastModifiedTime \": number,\\n         \" TrainingEndTime \": number,\\n         \" TrainingJobArn \": \"string\",\\n         \" TrainingJobName \": \"string\",\\n         \" TrainingJobStatus \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 806)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\ntraining jobs, use it in the subsequent request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nTrainingJobSummaries (p. 806)\\nAn array of TrainingJobSummary  objects, each listing a training job.\\nType: Array of TrainingJobSummary (p. 1019 ) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n807Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListTrainingJobsForHyperParameterTuningJob\\nService: Amazon SageMaker Service\\nGets a list of TrainingJobSummary (p. 1019 ) objects that describe the training jobs that a\\nhyperparameter tuning job launched.\\nRequest Syntax\\n{\\n   \"HyperParameterTuningJobName \": \"string\",\\n   \"MaxResults \": number,\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nHyperParameterTuningJobName (p. 808)\\nThe name of the tuning job whose training jobs you want to list.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nMaxResults (p. 808)\\nThe maximum number of training jobs to return. The default value is 10.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNextToken (p. 808)\\nIf the result of the previous ListTrainingJobsForHyperParameterTuningJob  request was\\ntruncated, the response includes a NextToken . To retrieve the next set of training jobs, use the\\ntoken in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 808)\\nThe ﬁeld to sort results by. The default is Name .\\n808Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nIf the value of this ﬁeld is FinalObjectiveMetricValue , any training jobs that did not return an\\nobjective metric are not listed.\\nType: String\\nValid Values: Name | CreationTime | Status | FinalObjectiveMetricValue\\nRequired: No\\nSortOrder (p. 808)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 808)\\nA ﬁlter that returns only training jobs with the speciﬁed status.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: No\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n   \"TrainingJobSummaries \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" FailureReason \": \"string\",\\n         \" FinalHyperParameterTuningJobObjectiveMetric \": { \\n            \" MetricName \": \"string\",\\n            \" Type\": \"string\",\\n            \" Value\": number\\n         },\\n         \" ObjectiveStatus \": \"string\",\\n         \" TrainingEndTime \": number,\\n         \" TrainingJobArn \": \"string\",\\n         \" TrainingJobName \": \"string\",\\n         \" TrainingJobStatus \": \"string\",\\n         \" TrainingStartTime \": number,\\n         \" TunedHyperParameters \": { \\n            \" string\" : \"string\" \\n         },\\n         \" TuningJobName \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\n809Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNextToken (p. 809)\\nIf the result of this ListTrainingJobsForHyperParameterTuningJob  request was truncated,\\nthe response includes a NextToken . To retrieve the next set of training jobs, use the token in the\\nnext request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nTrainingJobSummaries (p. 809)\\nA list of TrainingJobSummary (p. 1019 ) objects that describe the training jobs that the\\nListTrainingJobsForHyperParameterTuningJob  request returned.\\nType: Array of HyperParameterTrainingJobSummary (p. 919) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n810Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListTransformJobs\\nService: Amazon SageMaker Service\\nLists transform jobs.\\nRequest Syntax\\n{\\n   \"CreationTimeAfter \": number,\\n   \"CreationTimeBefore \": number,\\n   \"LastModifiedTimeAfter \": number,\\n   \"LastModifiedTimeBefore \": number,\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\",\\n   \"StatusEquals \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCreationTimeAfter (p. 811)\\nA ﬁlter that returns only transform jobs created after the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nCreationTimeBefore  (p. 811)\\nA ﬁlter that returns only transform jobs created before the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeAfter (p. 811)\\nA ﬁlter that returns only transform jobs modiﬁed after the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTimeBefore  (p. 811)\\nA ﬁlter that returns only transform jobs modiﬁed before the speciﬁed time.\\nType: Timestamp\\nRequired: No\\nMaxResults (p. 811)\\nThe maximum number of transform jobs to return in the response. The default value is 10.\\nType: Integer\\n811Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 811)\\nA string in the transform job name. This ﬁlter returns only transform jobs whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: [a-zA-Z0-9\\\\-]+\\nRequired: No\\nNextToken (p. 811)\\nIf the result of the previous ListTransformJobs  request was truncated, the response includes a\\nNextToken . To retrieve the next set of transform jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 811)\\nThe ﬁeld to sort results by. The default is CreationTime .\\nType: String\\nValid Values: Name | CreationTime | Status\\nRequired: No\\nSortOrder (p. 811)\\nThe sort order for results. The default is Descending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nStatusEquals (p. 811)\\nA ﬁlter that retrieves only transform jobs with a speciﬁc status.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: No\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n812Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"TransformJobSummaries \": [ \\n      { \\n         \" CreationTime \": number,\\n         \" FailureReason \": \"string\",\\n         \" LastModifiedTime \": number,\\n         \" TransformEndTime \": number,\\n         \" TransformJobArn \": \"string\",\\n         \" TransformJobName \": \"string\",\\n         \" TransformJobStatus \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 812)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of\\ntransform jobs, use it in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nTransformJobSummaries (p. 812)\\nAn array of TransformJobSummary  objects.\\nType: Array of TransformJobSummary (p. 1028 ) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n813Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nListWorkteams\\nService: Amazon SageMaker Service\\nGets a list of work teams that you have deﬁned in a region. The list may be empty if no work team\\nsatisﬁes the ﬁlter speciﬁed in the NameContains  parameter.\\nRequest Syntax\\n{\\n   \"MaxResults \": number,\\n   \"NameContains \": \"string\",\\n   \"NextToken \": \"string\",\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nMaxResults (p. 814)\\nThe maximum number of work teams to return in each page of the response.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nNameContains  (p. 814)\\nA string in the work team\\'s name. This ﬁlter returns only work teams whose name contains the\\nspeciﬁed string.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nNextToken (p. 814)\\nIf the result of the previous ListWorkteams  request was truncated, the response includes a\\nNextToken . To retrieve the next set of labeling jobs, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nSortBy (p. 814)\\nThe ﬁeld to sort results by. The default is CreationTime .\\n814Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nValid Values: Name | CreateDate\\nRequired: No\\nSortOrder (p. 814)\\nThe sort order for results. The default is Ascending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n   \"Workteams \": [ \\n      { \\n         \" CreateDate \": number,\\n         \" Description \": \"string\",\\n         \" LastUpdatedDate \": number,\\n         \" MemberDefinitions \": [ \\n            { \\n               \" CognitoMemberDefinition \": { \\n                  \" ClientId \": \"string\",\\n                  \" UserGroup \": \"string\",\\n                  \" UserPool \": \"string\"\\n               }\\n            }\\n         ],\\n         \" NotificationConfiguration \": { \\n            \" NotificationTopicArn \": \"string\"\\n         },\\n         \" ProductListingIds \": [ \"string\" ],\\n         \" SubDomain \": \"string\",\\n         \" WorkteamArn \": \"string\",\\n         \" WorkteamName \": \"string\"\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 815)\\nIf the response is truncated, Amazon SageMaker returns this token. To retrieve the next set of work\\nteams, use it in the subsequent request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\n815Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nWorkteams (p. 815)\\nAn array of Workteam  objects, each describing a work team.\\nType: Array of Workteam (p. 1040 ) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n816Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRenderUiTemplate\\nService: Amazon SageMaker Service\\nRenders the UI template so that you can preview the worker\\'s experience.\\nRequest Syntax\\n{\\n   \"RoleArn\": \"string\",\\n   \"Task\": { \\n      \"Input\": \"string\"\\n   },\\n   \"UiTemplate \": { \\n      \"Content\": \"string\"\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nRoleArn (p. 817)\\nThe Amazon Resource Name (ARN) that has access to the S3 objects that are used by the template.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nTask (p. 817)\\nA RenderableTask  object containing a representative task to render.\\nType: RenderableTask (p. 989) object\\nRequired: Yes\\nUiTemplate (p. 817)\\nA Template  object containing the worker UI template to render.\\nType: UiTemplate (p. 1037 ) object\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"Errors\": [ \\n      { \\n         \" Code\": \"string\",\\n         \" Message\": \"string\"\\n      }\\n817Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   ],\\n   \"RenderedContent \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nErrors  (p. 817)\\nA list of one or more RenderingError  objects if any were encountered while rendering the\\ntemplate. If there were no errors, the list is empty.\\nType: Array of RenderingError (p. 990) objects\\nRenderedContent (p. 817)\\nA Liquid template that renders the HTML for the worker UI.\\nType: String\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n818Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSearch\\nService: Amazon SageMaker Service\\nFinds Amazon SageMaker resources that match a search query. Matching resource objects are returned as\\na list of SearchResult  objects in the response. You can sort the search results by any resource property\\nin a ascending or descending order.\\nYou can query against the following value types: numerical, text, Booleans, and timestamps.\\nRequest Syntax\\n{\\n   \"MaxResults \": number,\\n   \"NextToken \": \"string\",\\n   \"Resource \": \"string\",\\n   \"SearchExpression \": { \\n      \"Filters\": [ \\n         { \\n            \" Name\": \"string\",\\n            \" Operator \": \"string\",\\n            \" Value\": \"string\"\\n         }\\n      ],\\n      \"NestedFilters \": [ \\n         { \\n            \" Filters\": [ \\n               { \\n                  \" Name\": \"string\",\\n                  \" Operator \": \"string\",\\n                  \" Value\": \"string\"\\n               }\\n            ],\\n            \" NestedPropertyName \": \"string\"\\n         }\\n      ],\\n      \"Operator \": \"string\",\\n      \"SubExpressions \": [ \\n         \" SearchExpression \"\\n      ]\\n   },\\n   \"SortBy\": \"string\",\\n   \"SortOrder \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nMaxResults (p. 819)\\nThe maximum number of results to return in a SearchResponse .\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\n819Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNextToken (p. 819)\\nIf more than MaxResults  resource objects match the speciﬁed SearchExpression ,\\nthe SearchResponse  includes a NextToken . The NextToken  can be passed to the next\\nSearchRequest  to continue retrieving results for the speciﬁed SearchExpression  and Sort\\nparameters.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nRequired: No\\nResource (p. 819)\\nThe name of the Amazon SageMaker resource to search for. Currently, the only valid Resource\\nvalue is TrainingJob .\\nType: String\\nValid Values: TrainingJob\\nRequired: Yes\\nSearchExpression  (p. 819)\\nA Boolean conditional statement. Resource objects must satisfy this condition to be included in\\nsearch results. You must provide at least one subexpression, ﬁlter, or nested ﬁlter. The maximum\\nnumber of recursive SubExpressions , NestedFilters , and Filters  that can be included in a\\nSearchExpression  object is 50.\\nType: SearchExpression (p. 996) object\\nRequired: No\\nSortBy (p. 819)\\nThe name of the resource property used to sort the SearchResults . The default is\\nLastModifiedTime .\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: No\\nSortOrder (p. 819)\\nHow SearchResults  are ordered. Valid values are Ascending  or Descending . The default is\\nDescending .\\nType: String\\nValid Values: Ascending | Descending\\nRequired: No\\nResponse Syntax\\n{\\n   \"NextToken \": \"string\",\\n820Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n   \"Results\": [ \\n      { \\n         \" TrainingJob \": { \\n            \" AlgorithmSpecification \": { \\n               \" AlgorithmName \": \"string\",\\n               \" MetricDefinitions \": [ \\n                  { \\n                     \" Name\": \"string\",\\n                     \" Regex\": \"string\"\\n                  }\\n               ],\\n               \" TrainingImage \": \"string\",\\n               \" TrainingInputMode \": \"string\"\\n            },\\n            \" CreationTime \": number,\\n            \" EnableInterContainerTrafficEncryption \": boolean,\\n            \" EnableNetworkIsolation \": boolean,\\n            \" FailureReason \": \"string\",\\n            \" FinalMetricDataList \": [ \\n               { \\n                  \" MetricName \": \"string\",\\n                  \" Timestamp \": number,\\n                  \" Value\": number\\n               }\\n            ],\\n            \" HyperParameters \": { \\n               \" string\" : \"string\" \\n            },\\n            \" InputDataConfig \": [ \\n               { \\n                  \" ChannelName \": \"string\",\\n                  \" CompressionType \": \"string\",\\n                  \" ContentType \": \"string\",\\n                  \" DataSource \": { \\n                     \" FileSystemDataSource \": { \\n                        \" DirectoryPath \": \"string\",\\n                        \" FileSystemAccessMode \": \"string\",\\n                        \" FileSystemId \": \"string\",\\n                        \" FileSystemType \": \"string\"\\n                     },\\n                     \" S3DataSource \": { \\n                        \" AttributeNames \": [ \"string\" ],\\n                        \" S3DataDistributionType \": \"string\",\\n                        \" S3DataType \": \"string\",\\n                        \" S3Uri\": \"string\"\\n                     }\\n                  },\\n                  \" InputMode \": \"string\",\\n                  \" RecordWrapperType \": \"string\",\\n                  \" ShuffleConfig \": { \\n                     \" Seed\": number\\n                  }\\n               }\\n            ],\\n            \" LabelingJobArn \": \"string\",\\n            \" LastModifiedTime \": number,\\n            \" ModelArtifacts \": { \\n               \" S3ModelArtifacts \": \"string\"\\n            },\\n            \" OutputDataConfig \": { \\n               \" KmsKeyId \": \"string\",\\n               \" S3OutputPath \": \"string\"\\n            },\\n            \" ResourceConfig \": { \\n               \" InstanceCount \": number,\\n               \" InstanceType \": \"string\",\\n821Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n               \" VolumeKmsKeyId \": \"string\",\\n               \" VolumeSizeInGB \": number\\n            },\\n            \" RoleArn\": \"string\",\\n            \" SecondaryStatus \": \"string\",\\n            \" SecondaryStatusTransitions \": [ \\n               { \\n                  \" EndTime\": number,\\n                  \" StartTime \": number,\\n                  \" Status\": \"string\",\\n                  \" StatusMessage \": \"string\"\\n               }\\n            ],\\n            \" StoppingCondition \": { \\n               \" MaxRuntimeInSeconds \": number,\\n               \" MaxWaitTimeInSeconds \": number\\n            },\\n            \" Tags\": [ \\n               { \\n                  \" Key\": \"string\",\\n                  \" Value\": \"string\"\\n               }\\n            ],\\n            \" TrainingEndTime \": number,\\n            \" TrainingJobArn \": \"string\",\\n            \" TrainingJobName \": \"string\",\\n            \" TrainingJobStatus \": \"string\",\\n            \" TrainingStartTime \": number,\\n            \" TuningJobArn \": \"string\",\\n            \" VpcConfig \": { \\n               \" SecurityGroupIds \": [ \"string\" ],\\n               \" Subnets\": [ \"string\" ]\\n            }\\n         }\\n      }\\n   ]\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nNextToken (p. 820)\\nIf the result of the previous Search request was truncated, the response includes a NextToken. To\\nretrieve the next set of results, use the token in the next request.\\nType: String\\nLength Constraints: Maximum length of 8192.\\nPattern: .*\\nResults (p. 820)\\nA list of SearchResult  objects.\\nType: Array of SearchRecord (p. 998) objects\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\n822Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n823Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStartNotebookInstance\\nService: Amazon SageMaker Service\\nLaunches an ML compute instance with the latest version of the libraries and attaches your ML storage\\nvolume. After conﬁguring the notebook instance, Amazon SageMaker sets the notebook instance status\\nto InService . A notebook instance\\'s status must be InService  before you can connect to your Jupyter\\nnotebook.\\nRequest Syntax\\n{\\n   \"NotebookInstanceName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceName (p. 824)\\nThe name of the notebook instance to start.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n824Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n825Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStopCompilationJob\\nService: Amazon SageMaker Service\\nStops a model compilation job.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal. This gracefully shuts the job\\ndown. If the job hasn\\'t stopped, it sends the SIGKILL signal.\\nWhen it receives a StopCompilationJob  request, Amazon SageMaker changes the\\nCompilationJobSummary:CompilationJobStatus (p. 884) of the job to Stopping . After Amazon\\nSageMaker stops the job, it sets the CompilationJobSummary:CompilationJobStatus (p. 884) to\\nStopped .\\nRequest Syntax\\n{\\n   \"CompilationJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCompilationJobName  (p. 826)\\nThe name of the model compilation job to stop.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n826Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n827Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStopHyperParameterTuningJob\\nService: Amazon SageMaker Service\\nStops a running hyperparameter tuning job and all running training jobs that the tuning job launched.\\nAll model artifacts output from the training jobs are stored in Amazon Simple Storage Service (Amazon\\nS3). All data that the training jobs write to Amazon CloudWatch Logs are still available in CloudWatch.\\nAfter the tuning job moves to the Stopped state, it releases all reserved resources for the tuning job.\\nRequest Syntax\\n{\\n   \"HyperParameterTuningJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nHyperParameterTuningJobName (p. 828)\\nThe name of the tuning job to stop.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n828Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n829Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStopLabelingJob\\nService: Amazon SageMaker Service\\nStops a running labeling job. A job that is stopped cannot be restarted. Any results obtained before the\\njob is stopped are placed in the Amazon S3 output bucket.\\nRequest Syntax\\n{\\n   \"LabelingJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nLabelingJobName  (p. 830)\\nThe name of the labeling job to stop.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n830Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n831Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStopNotebookInstance\\nService: Amazon SageMaker Service\\nTerminates the ML compute instance. Before terminating the instance, Amazon SageMaker disconnects\\nthe ML storage volume from it. Amazon SageMaker preserves the ML storage volume. Amazon\\nSageMaker stops charging you for the ML compute instance when you call StopNotebookInstance .\\nTo access data on the ML storage volume for a notebook instance that has been terminated, call the\\nStartNotebookInstance  API. StartNotebookInstance  launches another ML compute instance,\\nconﬁgures it, and attaches the preserved ML storage volume so you can continue your work.\\nRequest Syntax\\n{\\n   \"NotebookInstanceName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceName (p. 832)\\nThe name of the notebook instance to terminate.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n832Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n833Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStopTrainingJob\\nService: Amazon SageMaker Service\\nStops a training job. To stop a job, Amazon SageMaker sends the algorithm the SIGTERM  signal, which\\ndelays job termination for 120 seconds. Algorithms might use this 120-second window to save the model\\nartifacts, so the results of the training is not lost.\\nWhen it receives a StopTrainingJob  request, Amazon SageMaker changes the status of the job to\\nStopping . After Amazon SageMaker stops the job, it sets the status to Stopped .\\nRequest Syntax\\n{\\n   \"TrainingJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nTrainingJobName (p. 834)\\nThe name of the training job to stop.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n834Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n835Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStopTransformJob\\nService: Amazon SageMaker Service\\nStops a transform job.\\nWhen Amazon SageMaker receives a StopTransformJob  request, the status of the job changes to\\nStopping . After Amazon SageMaker stops the job, the status is set to Stopped. When you stop a\\ntransform job before it is completed, Amazon SageMaker doesn\\'t store the job\\'s output in Amazon S3.\\nRequest Syntax\\n{\\n   \"TransformJobName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nTransformJobName (p. 836)\\nThe name of the transform job to stop.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceNotFound\\nResource being access is not found.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n836Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n837Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUpdateCodeRepository\\nService: Amazon SageMaker Service\\nUpdates the speciﬁed Git repository with the speciﬁed values.\\nRequest Syntax\\n{\\n   \"CodeRepositoryName \": \"string\",\\n   \"GitConfig \": { \\n      \"SecretArn \": \"string\"\\n   }\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nCodeRepositoryName (p. 838)\\nThe name of the Git repository to update.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nGitConﬁg  (p. 838)\\nThe conﬁguration of the git repository, including the URL and the Amazon Resource Name (ARN)\\nof the AWS Secrets Manager secret that contains the credentials used to access the repository. The\\nsecret must have a staging label of AWSCURRENT  and must be in the following format:\\n{\"username\": UserName , \"password\": Password }\\nType: GitConﬁgForUpdate (p. 906) object\\nRequired: No\\nResponse Syntax\\n{\\n   \"CodeRepositoryArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nCodeRepositoryArn (p. 838)\\nThe ARN of the Git repository.\\n838Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:code-repository/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n839Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUpdateEndpoint\\nService: Amazon SageMaker Service\\nDeploys the new EndpointConfig  speciﬁed in the request, switches to using newly created endpoint,\\nand then deletes resources provisioned for the endpoint using the previous EndpointConfig  (there is\\nno availability loss).\\nWhen Amazon SageMaker receives the request, it sets the endpoint status to Updating . After\\nupdating the endpoint, it sets the status to InService . To check the status of an endpoint, use the\\nDescribeEndpoint  API.\\nNote\\nYou must not delete an EndpointConfig  in use by an endpoint that is live or while the\\nUpdateEndpoint  or CreateEndpoint  operations are being performed on the endpoint. To\\nupdate an endpoint, you must create a new EndpointConfig .\\nRequest Syntax\\n{\\n   \"EndpointConfigName \": \"string\",\\n   \"EndpointName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nEndpointConﬁgName  (p. 840)\\nThe name of the new endpoint conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nEndpointName  (p. 840)\\nThe name of the endpoint whose conﬁguration you want to update.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"EndpointArn \": \"string\"\\n}\\n840Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nEndpointArn  (p. 840)\\nThe Amazon Resource Name (ARN) of the endpoint.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n841Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUpdateEndpointWeightsAndCapacities\\nService: Amazon SageMaker Service\\nUpdates variant weight of one or more variants associated with an existing endpoint, or capacity of one\\nvariant associated with an existing endpoint. When it receives the request, Amazon SageMaker sets the\\nendpoint status to Updating . After updating the endpoint, it sets the status to InService . To check\\nthe status of an endpoint, use the DescribeEndpoint  API.\\nRequest Syntax\\n{\\n   \"DesiredWeightsAndCapacities \": [ \\n      { \\n         \" DesiredInstanceCount \": number,\\n         \" DesiredWeight \": number,\\n         \" VariantName \": \"string\"\\n      }\\n   ],\\n   \"EndpointName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nDesiredWeightsAndCapacities (p. 842)\\nAn object that provides new capacity and weight values for a variant.\\nType: Array of DesiredWeightAndCapacity (p. 895) objects\\nArray Members: Minimum number of 1 item.\\nRequired: Yes\\nEndpointName  (p. 842)\\nThe name of an existing Amazon SageMaker endpoint.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"EndpointArn \": \"string\"\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\n842Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nThe following data is returned in JSON format by the service.\\nEndpointArn  (p. 842)\\nThe Amazon Resource Name (ARN) of the updated endpoint.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint/.*\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n843Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUpdateNotebookInstance\\nService: Amazon SageMaker Service\\nUpdates a notebook instance. NotebookInstance updates include upgrading or downgrading the\\nML compute instance used for your notebook instance to accommodate changes in your workload\\nrequirements.\\nRequest Syntax\\n{\\n   \"AcceleratorTypes \": [ \"string\" ],\\n   \"AdditionalCodeRepositories \": [ \"string\" ],\\n   \"DefaultCodeRepository \": \"string\",\\n   \"DisassociateAcceleratorTypes \": boolean,\\n   \"DisassociateAdditionalCodeRepositories \": boolean,\\n   \"DisassociateDefaultCodeRepository \": boolean,\\n   \"DisassociateLifecycleConfig \": boolean,\\n   \"InstanceType \": \"string\",\\n   \"LifecycleConfigName \": \"string\",\\n   \"NotebookInstanceName \": \"string\",\\n   \"RoleArn\": \"string\",\\n   \"RootAccess \": \"string\",\\n   \"VolumeSizeInGB \": number\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nAcceleratorTypes (p. 844)\\nA list of the Elastic Inference (EI) instance types to associate with this notebook instance. Currently\\nonly one EI instance type can be associated with a notebook instance. For more information, see\\nUsing Elastic Inference in Amazon SageMaker.\\nType: Array of strings\\nValid Values: ml.eia1.medium | ml.eia1.large | ml.eia1.xlarge\\nRequired: No\\nAdditionalCodeRepositories (p. 844)\\nAn array of up to three Git repositories to associate with the notebook instance. These can be either\\nthe names of Git repositories stored as resources in your account, or the URL of Git repositories in\\nAWS CodeCommit or in any other Git repository. These repositories are cloned at the same level\\nas the default repository of your notebook instance. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: Array of strings\\nArray Members: Maximum number of 3 items.\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\n844Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDefaultCodeRepository (p. 844)\\nThe Git repository to associate with the notebook instance as its default code repository. This can\\nbe either the name of a Git repository stored as a resource in your account, or the URL of a Git\\nrepository in AWS CodeCommit or in any other Git repository. When you open a notebook instance,\\nit opens in the directory that contains this repository. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nDisassociateAcceleratorTypes (p. 844)\\nA list of the Elastic Inference (EI) instance types to remove from this notebook instance. This\\noperation is idempotent. If you specify an accelerator type that is not associated with the notebook\\ninstance when you call this method, it does not throw an error.\\nType: Boolean\\nRequired: No\\nDisassociateAdditionalCodeRepositories (p. 844)\\nA list of names or URLs of the default Git repositories to remove from this notebook instance. This\\noperation is idempotent. If you specify a Git repository that is not associated with the notebook\\ninstance when you call this method, it does not throw an error.\\nType: Boolean\\nRequired: No\\nDisassociateDefaultCodeRepository (p. 844)\\nThe name or URL of the default Git repository to remove from this notebook instance. This\\noperation is idempotent. If you specify a Git repository that is not associated with the notebook\\ninstance when you call this method, it does not throw an error.\\nType: Boolean\\nRequired: No\\nDisassociateLifecycleConﬁg (p. 844)\\nSet to true to remove the notebook instance lifecycle conﬁguration currently associated with the\\nnotebook instance. This operation is idempotent. If you specify a lifecycle conﬁguration that is not\\nassociated with the notebook instance when you call this method, it does not throw an error.\\nType: Boolean\\nRequired: No\\nInstanceType (p. 844)\\nThe Amazon ML compute instance type.\\nType: String\\nValid Values: ml.t2.medium | ml.t2.large | ml.t2.xlarge | ml.t2.2xlarge |\\nml.t3.medium | ml.t3.large | ml.t3.xlarge | ml.t3.2xlarge | ml.m4.xlarge\\n845Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n| ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge | ml.m4.16xlarge\\n| ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge | ml.m5.12xlarge\\n| ml.m5.24xlarge | ml.c4.xlarge | ml.c4.2xlarge | ml.c4.4xlarge |\\nml.c4.8xlarge | ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge\\n| ml.c5.18xlarge | ml.c5d.xlarge | ml.c5d.2xlarge | ml.c5d.4xlarge\\n| ml.c5d.9xlarge | ml.c5d.18xlarge | ml.p2.xlarge | ml.p2.8xlarge |\\nml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge\\nRequired: No\\nLifecycleConﬁgName (p. 844)\\nThe name of a lifecycle conﬁguration to associate with the notebook instance. For information about\\nlifestyle conﬁgurations, see Step 2.1: (Optional) Customize a Notebook Instance.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nNotebookInstanceName (p. 844)\\nThe name of the notebook instance to update.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nRoleArn (p. 844)\\nThe Amazon Resource Name (ARN) of the IAM role that Amazon SageMaker can assume to access the\\nnotebook instance. For more information, see Amazon SageMaker Roles.\\nNote\\nTo be able to pass this role to Amazon SageMaker, the caller of this API must have the\\niam:PassRole  permission.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: No\\nRootAccess (p. 844)\\nWhether root access is enabled or disabled for users of the notebook instance. The default value is\\nEnabled .\\nNote\\nIf you set this to Disabled , users don\\'t have root access on the notebook instance, but\\nlifecycle conﬁguration scripts still run with root permissions.\\nType: String\\nValid Values: Enabled | Disabled\\n846Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: No\\nVolumeSizeInGB (p. 844)\\nThe size, in GB, of the ML storage volume to attach to the notebook instance. The default value is\\n5 GB. ML storage volumes are encrypted, so Amazon SageMaker can\\'t determine the amount of\\navailable free space on the volume. Because of this, you can increase the volume size when you\\nupdate a notebook instance, but you can\\'t decrease the volume size. If you want to decrease the size\\nof the ML storage volume in use, create a new notebook instance with the desired size.\\nType: Integer\\nValid Range: Minimum value of 5. Maximum value of 16384.\\nRequired: No\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n847Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUpdateNotebookInstanceLifecycleConﬁg\\nService: Amazon SageMaker Service\\nUpdates a notebook instance lifecycle conﬁguration created with the\\nCreateNotebookInstanceLifecycleConﬁg (p. 662) API.\\nRequest Syntax\\n{\\n   \"NotebookInstanceLifecycleConfigName \": \"string\",\\n   \"OnCreate \": [ \\n      { \\n         \" Content\": \"string\"\\n      }\\n   ],\\n   \"OnStart\": [ \\n      { \\n         \" Content\": \"string\"\\n      }\\n   ]\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nNotebookInstanceLifecycleConﬁgName (p. 848)\\nThe name of the lifecycle conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nOnCreate  (p. 848)\\nThe shell script that runs only once, when you create a notebook instance. The shell script must be a\\nbase64-encoded string.\\nType: Array of NotebookInstanceLifecycleHook (p. 969) objects\\nArray Members: Maximum number of 1 item.\\nRequired: No\\nOnStart (p. 848)\\nThe shell script that runs every time you start a notebook instance, including when you create the\\nnotebook instance. The shell script must be a base64-encoded string.\\nType: Array of NotebookInstanceLifecycleHook (p. 969) objects\\nArray Members: Maximum number of 1 item.\\nRequired: No\\n848Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\n849Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUpdateWorkteam\\nService: Amazon SageMaker Service\\nUpdates an existing work team with new member deﬁnitions or description.\\nRequest Syntax\\n{\\n   \"Description \": \"string\",\\n   \"MemberDefinitions \": [ \\n      { \\n         \" CognitoMemberDefinition \": { \\n            \" ClientId \": \"string\",\\n            \" UserGroup \": \"string\",\\n            \" UserPool \": \"string\"\\n         }\\n      }\\n   ],\\n   \"NotificationConfiguration \": { \\n      \"NotificationTopicArn \": \"string\"\\n   },\\n   \"WorkteamName \": \"string\"\\n}\\nRequest Parameters\\nFor information about the parameters that are common to all actions, see Common\\nParameters (p. 1043 ).\\nThe request accepts the following data in JSON format.\\nDescription  (p. 850)\\nAn updated description for the work team.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 200.\\nPattern: .+\\nRequired: No\\nMemberDeﬁnitions  (p. 850)\\nA list of MemberDefinition  objects that contain the updated work team members.\\nType: Array of MemberDeﬁnition  (p. 954) objects\\nArray Members: Minimum number of 1 item. Maximum number of 10 items.\\nRequired: No\\nNotiﬁcationConﬁguration  (p. 850)\\nConﬁgures SNS topic notiﬁcations for available or expiring work items\\nType: NotiﬁcationConﬁguration  (p. 973) object\\nRequired: No\\n850Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nWorkteamName (p. 850)\\nThe name of the work team to update.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nResponse Syntax\\n{\\n   \"Workteam \": { \\n      \"CreateDate \": number,\\n      \"Description \": \"string\",\\n      \"LastUpdatedDate \": number,\\n      \"MemberDefinitions \": [ \\n         { \\n            \" CognitoMemberDefinition \": { \\n               \" ClientId \": \"string\",\\n               \" UserGroup \": \"string\",\\n               \" UserPool \": \"string\"\\n            }\\n         }\\n      ],\\n      \"NotificationConfiguration \": { \\n         \" NotificationTopicArn \": \"string\"\\n      },\\n      \"ProductListingIds \": [ \"string\" ],\\n      \"SubDomain \": \"string\",\\n      \"WorkteamArn \": \"string\",\\n      \"WorkteamName \": \"string\"\\n   }\\n}\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe following data is returned in JSON format by the service.\\nWorkteam (p. 851)\\nA Workteam  object that describes the updated work team.\\nType: Workteam (p. 1040 ) object\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nResourceLimitExceeded\\nYou have exceeded an Amazon SageMaker resource limit. For example, you might have too many\\ntraining jobs created.\\nHTTP Status Code: 400\\n851Amazon SageMaker Developer Guide\\nAmazon SageMaker Runtime\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\nAmazon SageMaker Runtime\\nThe following actions are supported by Amazon SageMaker Runtime:\\n•InvokeEndpoint (p. 853)\\n852Amazon SageMaker Developer Guide\\nAmazon SageMaker Runtime\\nInvokeEndpoint\\nService: Amazon SageMaker Runtime\\nAfter you deploy a model into production using Amazon SageMaker hosting services, your client\\napplications use this API to get inferences from the model hosted at the speciﬁed endpoint.\\nFor an overview of Amazon SageMaker, see How It Works.\\nAmazon SageMaker strips all POST headers except those supported by the API. Amazon SageMaker\\nmight add additional headers. You should not rely on the behavior of headers outside those enumerated\\nin the request syntax.\\nCalls to InvokeEndpoint  are authenticated by using AWS Signature Version 4. For information, see\\nAuthenticating Requests (AWS Signature Version 4) in the Amazon S3 API Reference.\\nA customer\\'s model containers must respond to requests within 60 seconds. The model itself can have a\\nmaximum processing time of 60 seconds before responding to the /invocations. If your model is going to\\ntake 50-60 seconds of processing time, the SDK socket timeout should be set to be 70 seconds.\\nNote\\nEndpoints are scoped to an individual account, and are not public. The URL does not contain the\\naccount ID, but Amazon SageMaker determines the account ID from the authentication token\\nthat is supplied by the caller.\\nRequest Syntax\\nPOST /endpoints/ EndpointName /invocations HTTP/1.1\\nContent-Type: ContentType\\nAccept: Accept\\nX-Amzn-SageMaker-Custom-Attributes: CustomAttributes\\nBody\\nURI Request Parameters\\nThe request requires the following URI parameters.\\nAccept (p. 853)\\nThe desired MIME type of the inference in the response.\\nLength Constraints: Maximum length of 1024.\\nPattern: \\\\p{ASCII}*\\nContentType (p. 853)\\nThe MIME type of the input data in the request body.\\nLength Constraints: Maximum length of 1024.\\nPattern: \\\\p{ASCII}*\\nCustomAttributes (p. 853)\\nProvides additional information about a request for an inference submitted to a model hosted at an\\nAmazon SageMaker endpoint. The information is an opaque value that is forwarded verbatim. You\\ncould use this value, for example, to provide an ID that you can use to track a request or to provide\\nother metadata that a service endpoint was programmed to process. The value must consist of no\\nmore than 1024 visible US-ASCII characters as speciﬁed in Section 3.3.6. Field Value Components of\\n853Amazon SageMaker Developer Guide\\nAmazon SageMaker Runtime\\nthe Hypertext Transfer Protocol (HTTP/1.1). This feature is currently supported in the AWS SDKs but\\nnot in the Amazon SageMaker Python SDK.\\nLength Constraints: Maximum length of 1024.\\nPattern: \\\\p{ASCII}*\\nEndpointName  (p. 853)\\nThe name of the endpoint that you speciﬁed when you created the endpoint using the\\nCreateEndpoint API.\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequest Body\\nThe request accepts the following binary data.\\nBody  (p. 853)\\nProvides input data, in the format speciﬁed in the ContentType  request header. Amazon\\nSageMaker passes all of the data in the body to the model.\\nFor information about the format of the request body, see Common Data Formats—Inference.\\nLength Constraints: Maximum length of 5242880.\\nResponse Syntax\\nHTTP/1.1 200\\nContent-Type: ContentType\\nx-Amzn-Invoked-Production-Variant: InvokedProductionVariant\\nX-Amzn-SageMaker-Custom-Attributes: CustomAttributes\\nBody\\nResponse Elements\\nIf the action is successful, the service sends back an HTTP 200 response.\\nThe response returns the following HTTP headers.\\nContentType (p. 854)\\nThe MIME type of the inference returned in the response body.\\nLength Constraints: Maximum length of 1024.\\nPattern: \\\\p{ASCII}*\\nCustomAttributes (p. 854)\\nProvides additional information in the response about the inference returned by a model hosted at\\nan Amazon SageMaker endpoint. The information is an opaque value that is forwarded verbatim.\\nYou could use this value, for example, to return an ID received in the CustomAttributes  header\\nof a request or other metadata that a service endpoint was programmed to produce. The value\\nmust consist of no more than 1024 visible US-ASCII characters as speciﬁed in Section 3.3.6. Field\\n854Amazon SageMaker Developer Guide\\nAmazon SageMaker Runtime\\nValue Components of the Hypertext Transfer Protocol (HTTP/1.1). If the customer wants the custom\\nattribute returned, the model must set the custom attribute to be included on the way back.\\nThis feature is currently supported in the AWS SDKs but not in the Amazon SageMaker Python SDK.\\nLength Constraints: Maximum length of 1024.\\nPattern: \\\\p{ASCII}*\\nInvokedProductionVariant (p. 854)\\nIdentiﬁes the production variant that was invoked.\\nLength Constraints: Maximum length of 1024.\\nPattern: \\\\p{ASCII}*\\nThe response returns the following as the HTTP body.\\nBody  (p. 854)\\nIncludes the inference provided by the model.\\nFor information about the format of the response body, see Common Data Formats—Inference.\\nLength Constraints: Maximum length of 5242880.\\nErrors\\nFor information about the errors that are common to all actions, see Common Errors (p. 1041 ).\\nInternalFailure\\nAn internal failure occurred.\\nHTTP Status Code: 500\\nModelError\\nModel (owned by the customer in the container) returned 4xx or 5xx error code.\\nHTTP Status Code: 424\\nServiceUnavailable\\nThe service is unavailable. Try your call again.\\nHTTP Status Code: 503\\nValidationError\\nInspect your request and try again.\\nHTTP Status Code: 400\\nExample\\nPass a trace ID in the CustomAttribute of a request and return it in the CustomAttribute of the\\nresponse.\\nIn this example a trace ID is passed to the service endpoint in the CustomAttributes  header of the\\nrequest and then retrieved and returned in the CustomAttributes  header of the response.\\n855Amazon SageMaker Developer Guide\\nData Types\\nSample Request\\nimport boto3\\nclient = boto3.client(\\'sagemaker-runtime\\')\\ncustom_attributes = \"c000b4f9-df62-4c85-a0bf-7c525f9104a4\"  # An example of a trace ID.\\nendpoint_name = \"...\"                                       # Your endpoint name.\\ncontent_type = \"...\"                                        # The MIME type of the input\\n data in the request body.\\naccept = \"...\"                                              # The desired MIME type of the\\n inference in the response.\\npayload = \"...\"                                             # Payload for inference.\\n \\nSample Response\\nresponse = client.invoke_endpoint(\\n    EndpointName=endpoint_name, \\n    CustomAttributes=custom_attributes, \\n    ContentType=content_type,\\n    Accept=accept,\\n    Body=payload\\n    )\\nprint(response[\\'CustomAttributes\\'])                         # If model receives and updates\\n the custom_attributes header \\n                                                            # by adding \"Trace id: \" in\\n front of custom_attributes in the request,\\n                                                            # custom_attributes in response\\n becomes\\n                                                            # \"Trace ID: c000b4f9-\\ndf62-4c85-a0bf-7c525f9104a4\"\\n \\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS Command Line Interface\\n•AWS SDK for .NET\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for JavaScript\\n•AWS SDK for PHP V3\\n•AWS SDK for Python\\n•AWS SDK for Ruby V2\\nData Types\\nThe following data types are supported by Amazon SageMaker Service:\\n•AlgorithmSpeciﬁcation  (p. 863)\\n856Amazon SageMaker Developer Guide\\nData Types\\n•AlgorithmStatusDetails  (p. 865)\\n•AlgorithmStatusItem  (p. 866)\\n•AlgorithmSummary (p. 867)\\n•AlgorithmValidationProﬁle (p. 869)\\n•AlgorithmValidationSpeciﬁcation (p. 870)\\n•AnnotationConsolidationConﬁg  (p. 871)\\n•CategoricalParameterRange (p. 874)\\n•CategoricalParameterRangeSpeciﬁcation (p. 875)\\n•Channel  (p. 876)\\n•ChannelSpeciﬁcation  (p. 878)\\n•CheckpointConﬁg  (p. 880)\\n•CodeRepositorySummary (p. 881)\\n•CognitoMemberDeﬁnition  (p. 883)\\n•CompilationJobSummary (p. 884)\\n•ContainerDeﬁnition  (p. 886)\\n•ContinuousParameterRange (p. 888)\\n•ContinuousParameterRangeSpeciﬁcation (p. 890)\\n•DataProcessing (p. 891)\\n•DataSource (p. 893)\\n•DeployedImage (p. 894)\\n•DesiredWeightAndCapacity (p. 895)\\n•EndpointConﬁgSummary (p. 896)\\n•EndpointSummary (p. 897)\\n•FileSystemDataSource (p. 899)\\n•Filter  (p. 901)\\n•FinalHyperParameterTuningJobObjectiveMetric (p. 904)\\n•GitConﬁg  (p. 905)\\n•GitConﬁgForUpdate (p. 906)\\n•HumanTaskConﬁg (p. 907)\\n•HyperParameterAlgorithmSpeciﬁcation (p. 912)\\n•HyperParameterSpeciﬁcation (p. 914)\\n•HyperParameterTrainingJobDeﬁnition (p. 916)\\n•HyperParameterTrainingJobSummary (p. 919)\\n•HyperParameterTuningJobConﬁg (p. 922)\\n•HyperParameterTuningJobObjective (p. 924)\\n•HyperParameterTuningJobSummary (p. 925)\\n•HyperParameterTuningJobWarmStartConﬁg (p. 927)\\n•InferenceSpeciﬁcation (p. 929)\\n•InputConﬁg  (p. 931)\\n•IntegerParameterRange (p. 933)\\n•IntegerParameterRangeSpeciﬁcation (p. 935)\\n•LabelCounters  (p. 936)\\n•LabelCountersForWorkteam (p. 938)\\n•LabelingJobAlgorithmsConﬁg  (p. 939)\\n•LabelingJobDataAttributes (p. 941)\\n•LabelingJobDataSource (p. 942)\\n857Amazon SageMaker Developer Guide\\nData Types\\n•LabelingJobForWorkteamSummary (p. 943)\\n•LabelingJobInputConﬁg  (p. 945)\\n•LabelingJobOutput  (p. 946)\\n•LabelingJobOutputConﬁg  (p. 947)\\n•LabelingJobResourceConﬁg (p. 948)\\n•LabelingJobS3DataSource (p. 949)\\n•LabelingJobStoppingConditions  (p. 950)\\n•LabelingJobSummary (p. 951)\\n•MemberDeﬁnition  (p. 954)\\n•MetricData  (p. 955)\\n•MetricDeﬁnition  (p. 956)\\n•ModelArtifacts (p. 957)\\n•ModelPackageContainerDeﬁnition (p. 958)\\n•ModelPackageStatusDetails (p. 960)\\n•ModelPackageStatusItem (p. 961)\\n•ModelPackageSummary (p. 962)\\n•ModelPackageValidationProﬁle (p. 964)\\n•ModelPackageValidationSpeciﬁcation (p. 965)\\n•ModelSummary (p. 966)\\n•NestedFilters  (p. 967)\\n•NotebookInstanceLifecycleConﬁgSummary (p. 968)\\n•NotebookInstanceLifecycleHook (p. 969)\\n•NotebookInstanceSummary (p. 970)\\n•NotiﬁcationConﬁguration  (p. 973)\\n•ObjectiveStatusCounters (p. 974)\\n•OutputConﬁg  (p. 975)\\n•OutputDataConﬁg  (p. 976)\\n•ParameterRange (p. 978)\\n•ParameterRanges (p. 979)\\n•ParentHyperParameterTuningJob (p. 980)\\n•ProductionVariant (p. 981)\\n•ProductionVariantSummary (p. 983)\\n•PropertyNameQuery (p. 985)\\n•PropertyNameSuggestion (p. 986)\\n•PublicWorkforceTaskPrice (p. 987)\\n•RenderableTask (p. 989)\\n•RenderingError (p. 990)\\n•ResourceConﬁg (p. 991)\\n•ResourceLimits (p. 993)\\n•S3DataSource (p. 994)\\n•SearchExpression (p. 996)\\n•SearchRecord (p. 998)\\n•SecondaryStatusTransition (p. 999)\\n•ShuﬄeConﬁg  (p. 1001 )\\n•SourceAlgorithm (p. 1002 )\\n•SourceAlgorithmSpeciﬁcation (p. 1003 )\\n858Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•StoppingCondition  (p. 1004 )\\n•SubscribedWorkteam (p. 1005 )\\n•SuggestionQuery (p. 1007 )\\n•Tag (p. 1008 )\\n•TrainingJob (p. 1009 )\\n•TrainingJobDeﬁnition (p. 1015 )\\n•TrainingJobStatusCounters (p. 1017 )\\n•TrainingJobSummary (p. 1019 )\\n•TrainingSpeciﬁcation (p. 1021 )\\n•TransformDataSource (p. 1023 )\\n•TransformInput (p. 1024 )\\n•TransformJobDeﬁnition (p. 1026 )\\n•TransformJobSummary (p. 1028 )\\n•TransformOutput (p. 1030 )\\n•TransformResources (p. 1032 )\\n•TransformS3DataSource (p. 1034 )\\n•UiConﬁg  (p. 1036 )\\n•UiTemplate (p. 1037 )\\n•USD  (p. 1038 )\\n•VpcConﬁg (p. 1039 )\\n•Workteam (p. 1040 )\\nThe following data types are supported by Amazon SageMaker Runtime:\\nAmazon SageMaker Service\\nThe following data types are supported by Amazon SageMaker Service:\\n•AlgorithmSpeciﬁcation  (p. 863)\\n•AlgorithmStatusDetails  (p. 865)\\n•AlgorithmStatusItem  (p. 866)\\n•AlgorithmSummary (p. 867)\\n•AlgorithmValidationProﬁle (p. 869)\\n•AlgorithmValidationSpeciﬁcation (p. 870)\\n•AnnotationConsolidationConﬁg  (p. 871)\\n•CategoricalParameterRange (p. 874)\\n•CategoricalParameterRangeSpeciﬁcation (p. 875)\\n•Channel  (p. 876)\\n•ChannelSpeciﬁcation  (p. 878)\\n•CheckpointConﬁg  (p. 880)\\n•CodeRepositorySummary (p. 881)\\n•CognitoMemberDeﬁnition  (p. 883)\\n•CompilationJobSummary (p. 884)\\n•ContainerDeﬁnition  (p. 886)\\n•ContinuousParameterRange (p. 888)\\n•ContinuousParameterRangeSpeciﬁcation (p. 890)\\n859Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•DataProcessing (p. 891)\\n•DataSource (p. 893)\\n•DeployedImage (p. 894)\\n•DesiredWeightAndCapacity (p. 895)\\n•EndpointConﬁgSummary (p. 896)\\n•EndpointSummary (p. 897)\\n•FileSystemDataSource (p. 899)\\n•Filter  (p. 901)\\n•FinalHyperParameterTuningJobObjectiveMetric (p. 904)\\n•GitConﬁg  (p. 905)\\n•GitConﬁgForUpdate (p. 906)\\n•HumanTaskConﬁg (p. 907)\\n•HyperParameterAlgorithmSpeciﬁcation (p. 912)\\n•HyperParameterSpeciﬁcation (p. 914)\\n•HyperParameterTrainingJobDeﬁnition (p. 916)\\n•HyperParameterTrainingJobSummary (p. 919)\\n•HyperParameterTuningJobConﬁg (p. 922)\\n•HyperParameterTuningJobObjective (p. 924)\\n•HyperParameterTuningJobSummary (p. 925)\\n•HyperParameterTuningJobWarmStartConﬁg (p. 927)\\n•InferenceSpeciﬁcation (p. 929)\\n•InputConﬁg  (p. 931)\\n•IntegerParameterRange (p. 933)\\n•IntegerParameterRangeSpeciﬁcation (p. 935)\\n•LabelCounters  (p. 936)\\n•LabelCountersForWorkteam (p. 938)\\n•LabelingJobAlgorithmsConﬁg  (p. 939)\\n•LabelingJobDataAttributes (p. 941)\\n•LabelingJobDataSource (p. 942)\\n•LabelingJobForWorkteamSummary (p. 943)\\n•LabelingJobInputConﬁg  (p. 945)\\n•LabelingJobOutput  (p. 946)\\n•LabelingJobOutputConﬁg  (p. 947)\\n•LabelingJobResourceConﬁg (p. 948)\\n•LabelingJobS3DataSource (p. 949)\\n•LabelingJobStoppingConditions  (p. 950)\\n•LabelingJobSummary (p. 951)\\n•MemberDeﬁnition  (p. 954)\\n•MetricData  (p. 955)\\n•MetricDeﬁnition  (p. 956)\\n•ModelArtifacts (p. 957)\\n•ModelPackageContainerDeﬁnition (p. 958)\\n•ModelPackageStatusDetails (p. 960)\\n•ModelPackageStatusItem (p. 961)\\n•ModelPackageSummary (p. 962)\\n•ModelPackageValidationProﬁle (p. 964)\\n860Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•ModelPackageValidationSpeciﬁcation (p. 965)\\n•ModelSummary (p. 966)\\n•NestedFilters  (p. 967)\\n•NotebookInstanceLifecycleConﬁgSummary (p. 968)\\n•NotebookInstanceLifecycleHook (p. 969)\\n•NotebookInstanceSummary (p. 970)\\n•NotiﬁcationConﬁguration  (p. 973)\\n•ObjectiveStatusCounters (p. 974)\\n•OutputConﬁg  (p. 975)\\n•OutputDataConﬁg  (p. 976)\\n•ParameterRange (p. 978)\\n•ParameterRanges (p. 979)\\n•ParentHyperParameterTuningJob (p. 980)\\n•ProductionVariant (p. 981)\\n•ProductionVariantSummary (p. 983)\\n•PropertyNameQuery (p. 985)\\n•PropertyNameSuggestion (p. 986)\\n•PublicWorkforceTaskPrice (p. 987)\\n•RenderableTask (p. 989)\\n•RenderingError (p. 990)\\n•ResourceConﬁg (p. 991)\\n•ResourceLimits (p. 993)\\n•S3DataSource (p. 994)\\n•SearchExpression (p. 996)\\n•SearchRecord (p. 998)\\n•SecondaryStatusTransition (p. 999)\\n•ShuﬄeConﬁg  (p. 1001 )\\n•SourceAlgorithm (p. 1002 )\\n•SourceAlgorithmSpeciﬁcation (p. 1003 )\\n•StoppingCondition  (p. 1004 )\\n•SubscribedWorkteam (p. 1005 )\\n•SuggestionQuery (p. 1007 )\\n•Tag (p. 1008 )\\n•TrainingJob (p. 1009 )\\n•TrainingJobDeﬁnition (p. 1015 )\\n•TrainingJobStatusCounters (p. 1017 )\\n•TrainingJobSummary (p. 1019 )\\n•TrainingSpeciﬁcation (p. 1021 )\\n•TransformDataSource (p. 1023 )\\n•TransformInput (p. 1024 )\\n•TransformJobDeﬁnition (p. 1026 )\\n•TransformJobSummary (p. 1028 )\\n•TransformOutput (p. 1030 )\\n•TransformResources (p. 1032 )\\n•TransformS3DataSource (p. 1034 )\\n•UiConﬁg  (p. 1036 )\\n861Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•UiTemplate (p. 1037 )\\n•USD  (p. 1038 )\\n•VpcConﬁg (p. 1039 )\\n•Workteam (p. 1040 )\\n862Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmSpeciﬁcation\\nService: Amazon SageMaker Service\\nSpeciﬁes the training algorithm to use in a CreateTrainingJob request.\\nFor more information about algorithms provided by Amazon SageMaker, see Algorithms . For information\\nabout using your own algorithms, see Using Your Own Algorithms with Amazon SageMaker.\\nContents\\nAlgorithmName\\nThe name of the algorithm resource to use for the training job. This must be an algorithm resource\\nthat you created or subscribe to on AWS Marketplace. If you specify a value for this parameter, you\\ncan\\'t specify a value for TrainingImage .\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 170.\\nPattern: (arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:[a-z\\\\-]*\\\\/)?([a-zA-\\nZ0-9]([a-zA-Z0-9-]){0,62})(?<!-)$\\nRequired: No\\nMetricDeﬁnitions\\nA list of metric deﬁnition objects. Each object speciﬁes the metric name and regular expressions\\nused to parse algorithm logs. Amazon SageMaker publishes each metric to Amazon CloudWatch.\\nType: Array of MetricDeﬁnition  (p. 956) objects\\nArray Members: Minimum number of 0 items. Maximum number of 40 items.\\nRequired: No\\nTrainingImage\\nThe registry path of the Docker image that contains the training algorithm. For information about\\ndocker registry paths for built-in algorithms, see Algorithms Provided by Amazon SageMaker:\\nCommon Parameters. Amazon SageMaker supports both registry/repository[:tag]  and\\nregistry/repository[@digest]  image path formats. For more information, see Using Your\\nOwn Algorithms with Amazon SageMaker.\\nType: String\\nLength Constraints: Maximum length of 255.\\nPattern: .*\\nRequired: No\\nTrainingInputMode\\nThe input mode that the algorithm supports. For the input modes that Amazon SageMaker\\nalgorithms support, see Algorithms . If an algorithm supports the File input mode, Amazon\\nSageMaker downloads the training data from S3 to the provisioned ML storage Volume, and mounts\\nthe directory to docker volume for training container. If an algorithm supports the Pipe  input mode,\\nAmazon SageMaker streams data directly from S3 to the container.\\nIn File mode, make sure you provision ML storage volume with suﬃcient capacity to accommodate\\nthe data download from S3. In addition to the training data, the ML storage volume also stores\\n863Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nthe output model. The algorithm container use ML storage volume to also store intermediate\\ninformation, if any.\\nFor distributed algorithms using File mode, training data is distributed uniformly, and your training\\nduration is predictable if the input data objects size is approximately same. Amazon SageMaker does\\nnot split the ﬁles any further for model training. If the object sizes are skewed, training won\\'t be\\noptimal as the data distribution is also skewed where one host in a training cluster is overloaded,\\nthus becoming bottleneck in training.\\nType: String\\nValid Values: Pipe | File\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n864Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmStatusDetails\\nService: Amazon SageMaker Service\\nSpeciﬁes the validation and image scan statuses of the algorithm.\\nContents\\nImageScanStatuses\\nThe status of the scan of the algorithm\\'s Docker image container.\\nType: Array of AlgorithmStatusItem  (p. 866) objects\\nRequired: No\\nValidationStatuses\\nThe status of algorithm validation.\\nType: Array of AlgorithmStatusItem  (p. 866) objects\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n865Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmStatusItem\\nService: Amazon SageMaker Service\\nRepresents the overall status of an algorithm.\\nContents\\nFailureReason\\nif the overall status is Failed, the reason for the failure.\\nType: String\\nRequired: No\\nName\\nThe name of the algorithm for which the overall status is being reported.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nStatus\\nThe current status.\\nType: String\\nValid Values: NotStarted | InProgress | Completed | Failed\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n866Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmSummary\\nService: Amazon SageMaker Service\\nProvides summary information about an algorithm.\\nContents\\nAlgorithmArn\\nThe Amazon Resource Name (ARN) of the algorithm.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:algorithm/.*\\nRequired: Yes\\nAlgorithmDescription\\nA brief description of the algorithm.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nRequired: No\\nAlgorithmName\\nThe name of the algorithm that is described by the summary.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nAlgorithmStatus\\nThe overall status of the algorithm.\\nType: String\\nValid Values: Pending | InProgress | Completed | Failed | Deleting\\nRequired: Yes\\nCreationTime\\nA timestamp that shows when the algorithm was created.\\nType: Timestamp\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n867Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n868Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmValidationProﬁle\\nService: Amazon SageMaker Service\\nDeﬁnes a training job and a batch transform job that Amazon SageMaker runs to validate your\\nalgorithm.\\nThe data provided in the validation proﬁle is made available to your buyers on AWS Marketplace.\\nContents\\nProﬁleName\\nThe name of the proﬁle for the algorithm. The name must have 1 to 63 characters. Valid characters\\nare a-z, A-Z, 0-9, and - (hyphen).\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nTrainingJobDeﬁnition\\nThe TrainingJobDefinition  object that describes the training job that Amazon SageMaker runs\\nto validate your algorithm.\\nType: TrainingJobDeﬁnition (p. 1015 ) object\\nRequired: Yes\\nTransformJobDeﬁnition\\nThe TransformJobDefinition  object that describes the transform job that Amazon SageMaker\\nruns to validate your algorithm.\\nType: TransformJobDeﬁnition (p. 1026 ) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n869Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAlgorithmValidationSpeciﬁcation\\nService: Amazon SageMaker Service\\nSpeciﬁes conﬁgurations for one or more training jobs that Amazon SageMaker runs to test the\\nalgorithm.\\nContents\\nValidationProﬁles\\nAn array of AlgorithmValidationProfile  objects, each of which speciﬁes a training job and\\nbatch transform job that Amazon SageMaker runs to validate your algorithm.\\nType: Array of AlgorithmValidationProﬁle (p. 869) objects\\nArray Members: Fixed number of 1 item.\\nRequired: Yes\\nValidationRole\\nThe IAM roles that Amazon SageMaker uses to run the training jobs.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n870Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nAnnotationConsolidationConﬁg\\nService: Amazon SageMaker Service\\nConﬁgures how labels are consolidated across human workers.\\nContents\\nAnnotationConsolidationLambdaArn\\nThe Amazon Resource Name (ARN) of a Lambda function implements the logic for annotation\\nconsolidation.\\nFor the built-in bounding box, image classiﬁcation, semantic segmentation, and text classiﬁcation\\ntask types, Amazon SageMaker Ground Truth provides the following Lambda functions:\\n•Bounding box - Finds the most similar boxes from diﬀerent workers based on the Jaccard index of\\nthe boxes.\\narn:aws:lambda:us-east-1:432418664414:function:ACS-BoundingBox\\narn:aws:lambda:us-east-2:266458841044:function:ACS-BoundingBox\\narn:aws:lambda:us-west-2:081040173940:function:ACS-BoundingBox\\narn:aws:lambda:eu-west-1:568282634449:function:ACS-BoundingBox\\narn:aws:lambda:ap-northeast-1:477331159723:function:ACS-BoundingBox\\narn:aws:lambda:ap-southeast-2:454466003867:function:ACS-BoundingBox\\narn:aws:lambda:ap-south-1:565803892007:function:ACS-BoundingBox\\narn:aws:lambda:eu-central-1:203001061592:function:ACS-BoundingBox\\narn:aws:lambda:ap-northeast-2:845288260483:function:ACS-BoundingBox\\narn:aws:lambda:eu-west-2:487402164563:function:ACS-BoundingBox\\narn:aws:lambda:ap-southeast-1:377565633583:function:ACS-BoundingBox\\narn:aws:lambda:ca-central-1:918755190332:function:ACS-BoundingBox\\n•Image classiﬁcation  - Uses a variant of the Expectation Maximization approach to estimate the\\ntrue class of an image based on annotations from individual workers.\\narn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClass\\narn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClass\\narn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClass\\narn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClass\\narn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClass\\narn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClass\\narn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClass\\narn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClass\\narn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClass\\n871Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\narn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClass\\narn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClass\\narn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClass\\n•Semantic segmentation  - Treats each pixel in an image as a multi-class classiﬁcation and treats\\npixel annotations from workers as \"votes\" for the correct label.\\narn:aws:lambda:us-east-1:432418664414:function:ACS-SemanticSegmentation\\narn:aws:lambda:us-east-2:266458841044:function:ACS-SemanticSegmentation\\narn:aws:lambda:us-west-2:081040173940:function:ACS-SemanticSegmentation\\narn:aws:lambda:eu-west-1:568282634449:function:ACS-SemanticSegmentation\\narn:aws:lambda:ap-northeast-1:477331159723:function:ACS-\\nSemanticSegmentation\\narn:aws:lambda:ap-southeast-2:454466003867:function:ACS-\\nSemanticSegmentation\\narn:aws:lambda:ap-south-1:565803892007:function:ACS-SemanticSegmentation\\narn:aws:lambda:eu-central-1:203001061592:function:ACS-SemanticSegmentation\\narn:aws:lambda:ap-northeast-2:845288260483:function:ACS-\\nSemanticSegmentation\\narn:aws:lambda:eu-west-2:487402164563:function:ACS-SemanticSegmentation\\narn:aws:lambda:ap-southeast-1:377565633583:function:ACS-\\nSemanticSegmentation\\narn:aws:lambda:ca-central-1:918755190332:function:ACS-SemanticSegmentation\\n•Text classiﬁcation - Uses a variant of the Expectation Maximization approach to estimate the true\\nclass of text based on annotations from individual workers.\\narn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClass\\narn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClass\\narn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClass\\narn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClass\\narn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClass\\narn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClass\\narn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClass\\narn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClass\\narn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClass\\narn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClass\\narn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClass\\n872Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\narn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClass\\n•Named entity eecognition  - Groups similar selections and calculates aggregate boundaries,\\nresolving to most-assigned label.\\narn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition\\narn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition\\narn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition\\narn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition\\narn:aws:lambda:ap-northeast-1:477331159723:function:ACS-\\nNamedEntityRecognition\\narn:aws:lambda:ap-southeast-2:454466003867:function:ACS-\\nNamedEntityRecognition\\narn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition\\narn:aws:lambda:eu-central-1:203001061592:function:ACS-\\nNamedEntityRecognition\\narn:aws:lambda:ap-northeast-2:845288260483:function:ACS-\\nNamedEntityRecognition\\narn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition\\narn:aws:lambda:ap-southeast-1:377565633583:function:ACS-\\nNamedEntityRecognition\\narn:aws:lambda:ca-central-1:918755190332:function:ACS-\\nNamedEntityRecognition\\nFor more information, see Annotation Consolidation .\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:lambda:[a-z]{2}-[a-z]+-\\\\d{1}:\\\\d{12}:function:[a-zA-\\nZ0-9-_\\\\.]+(:(\\\\$LATEST|[a-zA-Z0-9-_]+))?\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n873Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCategoricalParameterRange\\nService: Amazon SageMaker Service\\nA list of categorical hyperparameters to tune.\\nContents\\nName\\nThe name of the categorical hyperparameter to tune.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nValues\\nA list of the categories for the hyperparameter.\\nType: Array of strings\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n874Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCategoricalParameterRangeSpeciﬁcation\\nService: Amazon SageMaker Service\\nDeﬁnes the possible values for a categorical hyperparameter.\\nContents\\nValues\\nThe allowed categories for the hyperparameter.\\nType: Array of strings\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n875Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nChannel\\nService: Amazon SageMaker Service\\nA channel is a named input source that training algorithms can consume.\\nContents\\nChannelName\\nThe name of the channel.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 64.\\nPattern: [A-Za-z0-9\\\\.\\\\-_]+\\nRequired: Yes\\nCompressionType\\nIf training data is compressed, the compression type. The default value is None . CompressionType\\nis used only in Pipe input mode. In File mode, leave this ﬁeld unset or set it to None.\\nType: String\\nValid Values: None | Gzip\\nRequired: No\\nContentType\\nThe MIME type of the data.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: No\\nDataSource\\nThe location of the channel data.\\nType: DataSource (p. 893) object\\nRequired: Yes\\nInputMode\\n(Optional) The input mode to use for the data channel in a training job. If you don\\'t set a value for\\nInputMode , Amazon SageMaker uses the value set for TrainingInputMode . Use this parameter\\nto override the TrainingInputMode  setting in a AlgorithmSpeciﬁcation  (p. 863) request when\\nyou have a channel that needs a diﬀerent input mode from the training job\\'s general setting. To\\ndownload the data from Amazon Simple Storage Service (Amazon S3) to the provisioned ML storage\\nvolume, and mount the directory to a Docker volume, use File input mode. To stream data directly\\nfrom Amazon S3 to the container, choose Pipe  input mode.\\nTo use a model for incremental training, choose File  input model.\\nType: String\\n876Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Values: Pipe | File\\nRequired: No\\nRecordWrapperType\\nSpecify RecordIO as the value when input data is in raw format but the training algorithm requires\\nthe RecordIO format. In this case, Amazon SageMaker wraps each individual S3 object in a RecordIO\\nrecord. If the input data is already in RecordIO format, you don\\'t need to set this attribute. For more\\ninformation, see Create a Dataset Using RecordIO.\\nIn File mode, leave this ﬁeld unset or set it to None.\\nType: String\\nValid Values: None | RecordIO\\nRequired: No\\nShuﬄeConﬁg\\nA conﬁguration for a shuﬄe option for input data in a channel. If you use S3Prefix  for\\nS3DataType , this shuﬄes the results of the S3 key preﬁx matches. If you use ManifestFile ,\\nthe order of the S3 object references in the ManifestFile  is shuﬄed. If you use\\nAugmentedManifestFile , the order of the JSON lines in the AugmentedManifestFile  is\\nshuﬄed. The shuﬄing order is determined using the Seed  value.\\nFor Pipe input mode, shuﬄing is done at the start of every epoch. With large datasets this\\nensures that the order of the training data is diﬀerent for each epoch, it helps reduce bias\\nand possible overﬁtting. In a multi-node training job when ShuﬄeConﬁg is combined with\\nS3DataDistributionType  of ShardedByS3Key , the data is shuﬄed across nodes so that the\\ncontent sent to a particular node on the ﬁrst epoch might be sent to a diﬀerent node on the second\\nepoch.\\nType: ShuﬄeConﬁg  (p. 1001 ) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n877Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nChannelSpeciﬁcation\\nService: Amazon SageMaker Service\\nDeﬁnes a named input source, called a channel, to be used by an algorithm.\\nContents\\nDescription\\nA brief description of the channel.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nRequired: No\\nIsRequired\\nIndicates whether the channel is required by the algorithm.\\nType: Boolean\\nRequired: No\\nName\\nThe name of the channel.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 64.\\nPattern: [A-Za-z0-9\\\\.\\\\-_]+\\nRequired: Yes\\nSupportedCompressionTypes\\nThe allowed compression types, if data compression is used.\\nType: Array of strings\\nValid Values: None | Gzip\\nRequired: No\\nSupportedContentTypes\\nThe supported MIME types for the data.\\nType: Array of strings\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nSupportedInputModes\\nThe allowed input mode, either FILE or PIPE.\\n878Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nIn FILE mode, Amazon SageMaker copies the data from the input source onto the local Amazon\\nElastic Block Store (Amazon EBS) volumes before starting your training algorithm. This is the most\\ncommonly used input mode.\\nIn PIPE mode, Amazon SageMaker streams input data from the source directly to your algorithm\\nwithout using the EBS volume.\\nType: Array of strings\\nArray Members: Minimum number of 1 item.\\nValid Values: Pipe | File\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n879Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCheckpointConﬁg\\nService: Amazon SageMaker Service\\nContains information about the output location for managed spot training checkpoint data.\\nContents\\nLocalPath\\n(Optional) The local directory where checkpoints are written. The default directory is /opt/ml/\\ncheckpoints/ .\\nType: String\\nLength Constraints: Maximum length of 4096.\\nPattern: .*\\nRequired: No\\nS3Uri\\nIdentiﬁes the S3 path where you want Amazon SageMaker to store checkpoints. For example, s3://\\nbucket-name/key-name-prefix .\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n880Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCodeRepositorySummary\\nService: Amazon SageMaker Service\\nSpeciﬁes summary information about a Git repository.\\nContents\\nCodeRepositoryArn\\nThe Amazon Resource Name (ARN) of the Git repository.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:code-repository/.*\\nRequired: Yes\\nCodeRepositoryName\\nThe name of the Git repository.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nCreationTime\\nThe date and time that the Git repository was created.\\nType: Timestamp\\nRequired: Yes\\nGitConﬁg\\nConﬁguration details for the Git repository, including the URL where it is located and the ARN of the\\nAWS Secrets Manager secret that contains the credentials used to access the repository.\\nType: GitConﬁg  (p. 905) object\\nRequired: No\\nLastModiﬁedTime\\nThe date and time that the Git repository was last modiﬁed.\\nType: Timestamp\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n881Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n882Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCognitoMemberDeﬁnition\\nService: Amazon SageMaker Service\\nIdentiﬁes a Amazon Cognito user group. A user group can be used in on or more work teams.\\nContents\\nClientId\\nAn identiﬁer for an application client. You must create the app client ID using Amazon Cognito.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 128.\\nPattern: [\\\\w+]+\\nRequired: Yes\\nUserGroup\\nAn identiﬁer for a user group.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 128.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{S}\\\\p{N}\\\\p{P}]+\\nRequired: Yes\\nUserPool\\nAn identiﬁer for a user pool. The user pool must be in the same region as the service that you are\\ncalling.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 55.\\nPattern: [\\\\w-]+_[0-9a-zA-Z]+\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n883Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nCompilationJobSummary\\nService: Amazon SageMaker Service\\nA summary of a model compilation job.\\nContents\\nCompilationEndTime\\nThe time when the model compilation job completed.\\nType: Timestamp\\nRequired: No\\nCompilationJobArn\\nThe Amazon Resource Name (ARN) of the model compilation job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:compilation-job/.*\\nRequired: Yes\\nCompilationJobName\\nThe name of the model compilation job that you want a summary for.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nCompilationJobStatus\\nThe status of the model compilation job.\\nType: String\\nValid Values: INPROGRESS | COMPLETED | FAILED | STARTING | STOPPING | STOPPED\\nRequired: Yes\\nCompilationStartTime\\nThe time when the model compilation job started.\\nType: Timestamp\\nRequired: No\\nCompilationTargetDevice\\nThe type of device that the model will run on after compilation has completed.\\nType: String\\nValid Values: lambda | ml_m4 | ml_m5 | ml_c4 | ml_c5 | ml_p2 | ml_p3 |\\njetson_tx1 | jetson_tx2 | jetson_nano | rasp3b | deeplens | rk3399 | rk3288\\n| aisage | sbe_c | qcs605 | qcs603\\n884Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: Yes\\nCreationTime\\nThe time when the model compilation job was created.\\nType: Timestamp\\nRequired: Yes\\nLastModiﬁedTime\\nThe time when the model compilation job was last modiﬁed.\\nType: Timestamp\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n885Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nContainerDeﬁnition\\nService: Amazon SageMaker Service\\nDescribes the container, as part of model deﬁnition.\\nContents\\nContainerHostname\\nThis parameter is ignored for models that contain only a PrimaryContainer .\\nWhen a ContainerDefinition  is part of an inference pipeline, the value of ths parameter\\nuniquely identiﬁes the container for the purposes of logging and metrics. For information, see Use\\nLogs and Metrics to Monitor an Inference Pipeline. If you don\\'t specify a value for this parameter\\nfor a ContainerDefinition  that is part of an inference pipeline, a unique name is automatically\\nassigned based on the position of the ContainerDefinition  in the pipeline. If you specify a value\\nfor the ContainerHostName  for any ContainerDefinition  that is part of an inference pipeline,\\nyou must specify a value for the ContainerHostName  parameter of every ContainerDefinition\\nin that pipeline.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nEnvironment\\nThe environment variables to set in the Docker container. Each key and value in the Environment\\nstring to string map can have length of up to 1024. We support up to 16 entries in the map.\\nType: String to string map\\nKey Length Constraints: Maximum length of 1024.\\nKey Pattern: [a-zA-Z_][a-zA-Z0-9_]*\\nValue Length Constraints: Maximum length of 1024.\\nValue Pattern: [\\\\S\\\\s]*\\nRequired: No\\nImage\\nThe Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored. If you are\\nusing your own custom algorithm instead of an algorithm provided by Amazon SageMaker, the\\ninference code must meet Amazon SageMaker requirements. Amazon SageMaker supports both\\nregistry/repository[:tag]  and registry/repository[@digest]  image path formats. For\\nmore information, see Using Your Own Algorithms with Amazon SageMaker\\nType: String\\nLength Constraints: Maximum length of 255.\\nPattern: [\\\\S]+\\nRequired: No\\n886Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelDataUrl\\nThe S3 path where the model artifacts, which result from model training, are stored. This path must\\npoint to a single gzip compressed tar archive (.tar.gz suﬃx). The S3 path is required for Amazon\\nSageMaker built-in algorithms, but not if you use your own algorithms. For more information on\\nbuilt-in algorithms, see Common Parameters.\\nIf you provide a value for this parameter, Amazon SageMaker uses AWS Security Token Service to\\ndownload model artifacts from the S3 path you provide. AWS STS is activated in your IAM user\\naccount by default. If you previously deactivated AWS STS for a region, you need to reactivate AWS\\nSTS for that region. For more information, see Activating and Deactivating AWS STS in an AWS\\nRegion in the AWS Identity and Access Management User Guide.\\nImportant\\nIf you use a built-in algorithm to create a model, Amazon SageMaker requires that you\\nprovide a S3 path to the model artifacts in ModelDataUrl .\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: No\\nModelPackageName\\nThe name or Amazon Resource Name (ARN) of the model package to use to create the model.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 170.\\nPattern: (arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:[a-z\\\\-]*\\\\/)?([a-zA-\\nZ0-9]([a-zA-Z0-9-]){0,62})(?<!-)$\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n887Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nContinuousParameterRange\\nService: Amazon SageMaker Service\\nA list of continuous hyperparameters to tune.\\nContents\\nMaxValue\\nThe maximum value for the hyperparameter. The tuning job uses ﬂoating-point values between\\nMinValue  value and this value for tuning.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nMinValue\\nThe minimum value for the hyperparameter. The tuning job uses ﬂoating-point values between this\\nvalue and MaxValue for tuning.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nName\\nThe name of the continuous hyperparameter to tune.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nScalingType\\nThe scale that hyperparameter tuning uses to search the hyperparameter range. For information\\nabout choosing a hyperparameter scale, see Hyperparameter Scaling . One of the following values:\\nAuto\\nAmazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.\\nLinear\\nHyperparameter tuning searches the values in the hyperparameter range by using a linear scale.\\nLogarithmic\\nHyperparameter tuning searches the values in the hyperparameter range by using a logarithmic\\nscale.\\nLogarithmic scaling works only for ranges that have only values greater than 0.\\n888Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nReverseLogarithmic\\nHyperparemeter tuning searches the values in the hyperparameter range by using a reverse\\nlogarithmic scale.\\nReverse logarithmic scaling works only for ranges that are entirely within the range 0<=x<1.0.\\nType: String\\nValid Values: Auto | Linear | Logarithmic | ReverseLogarithmic\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n889Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nContinuousParameterRangeSpeciﬁcation\\nService: Amazon SageMaker Service\\nDeﬁnes the possible values for a continuous hyperparameter.\\nContents\\nMaxValue\\nThe maximum ﬂoating-point value allowed.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nMinValue\\nThe minimum ﬂoating-point value allowed.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n890Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDataProcessing\\nService: Amazon SageMaker Service\\nThe data structure used to specify the data to be used for inference in a batch transform job and to\\nassociate the data that is relevant to the prediction results in the output. The input ﬁlter provided allows\\nyou to exclude input data that is not needed for inference in a batch transform job. The output ﬁlter\\nprovided allows you to include input data relevant to interpreting the predictions in the output from the\\njob. For more information, see Associate Prediction Results with their Corresponding Input Records.\\nContents\\nInputFilter\\nA JSONPath expression used to select a portion of the input data to pass to the algorithm. Use\\nthe InputFilter  parameter to exclude ﬁelds, such as an ID column, from the input. If you want\\nAmazon SageMaker to pass the entire input dataset to the algorithm, accept the default value $.\\nExamples: \"$\", \"$[1:]\" , \"$.features\"\\nType: String\\nLength Constraints: Minimum length of 0. Maximum length of 63.\\nRequired: No\\nJoinSource\\nSpeciﬁes the source of the data to join with the transformed data. The valid values are None  and\\nInput  The default value is None  which speciﬁes not to join the input with the transformed data.\\nIf you want the batch transform job to join the original input data with the transformed data, set\\nJoinSource  to Input .\\nFor JSON or JSONLines objects, such as a JSON array, Amazon SageMaker adds the transformed data\\nto the input JSON object in an attribute called SageMakerOutput . The joined result for JSON must\\nbe a key-value pair object. If the input is not a key-value pair object, Amazon SageMaker creates a\\nnew JSON ﬁle. In the new JSON ﬁle, and the input data is stored under the SageMakerInput  key\\nand the results are stored in SageMakerOutput .\\nFor CSV ﬁles, Amazon SageMaker combines the transformed data with the input data at the end of\\nthe input data and stores it in the output ﬁle. The joined data has the joined input data followed by\\nthe transformed data and the output is a CSV ﬁle.\\nType: String\\nValid Values: Input | None\\nRequired: No\\nOutputFilter\\nA JSONPath expression used to select a portion of the joined dataset to save in the output ﬁle for a\\nbatch transform job. If you want Amazon SageMaker to store the entire input dataset in the output\\nﬁle, leave the default value, $. If you specify indexes that aren\\'t within the dimension size of the\\njoined dataset, you get an error.\\nExamples: \"$\", \"$[0,5:]\" , \"$[\\'id\\',\\'SageMakerOutput\\']\"\\nType: String\\nLength Constraints: Minimum length of 0. Maximum length of 63.\\nRequired: No\\n891Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n892Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDataSource\\nService: Amazon SageMaker Service\\nDescribes the location of the channel data.\\nContents\\nFileSystemDataSource\\nThe ﬁle system that is associated with a channel.\\nType: FileSystemDataSource (p. 899) object\\nRequired: No\\nS3DataSource\\nThe S3 location of the data source that is associated with a channel.\\nType: S3DataSource (p. 994) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n893Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDeployedImage\\nService: Amazon SageMaker Service\\nGets the Amazon EC2 Container Registry path of the docker image of the model that is hosted in this\\nProductionVariant (p. 981).\\nIf you used the registry/repository[:tag]  form to specify the image path of the primary container\\nwhen you created the model hosted in this ProductionVariant , the path resolves to a path of the\\nform registry/repository[@digest] . A digest is a hash value that identiﬁes a speciﬁc version of an\\nimage. For information about Amazon ECR paths, see Pulling an Image  in the Amazon ECR User Guide.\\nContents\\nResolutionTime\\nThe date and time when the image path for the model resolved to the ResolvedImage\\nType: Timestamp\\nRequired: No\\nResolvedImage\\nThe speciﬁc digest path of the image hosted in this ProductionVariant .\\nType: String\\nLength Constraints: Maximum length of 255.\\nPattern: [\\\\S]+\\nRequired: No\\nSpeciﬁedImage\\nThe image path you speciﬁed when you created the model.\\nType: String\\nLength Constraints: Maximum length of 255.\\nPattern: [\\\\S]+\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n894Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nDesiredWeightAndCapacity\\nService: Amazon SageMaker Service\\nSpeciﬁes weight and capacity values for a production variant.\\nContents\\nDesiredInstanceCount\\nThe variant\\'s capacity.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: No\\nDesiredWeight\\nThe variant\\'s weight.\\nType: Float\\nValid Range: Minimum value of 0.\\nRequired: No\\nVariantName\\nThe name of the variant to update.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n895Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nEndpointConﬁgSummary\\nService: Amazon SageMaker Service\\nProvides summary information for an endpoint conﬁguration.\\nContents\\nCreationTime\\nA timestamp that shows when the endpoint conﬁguration was created.\\nType: Timestamp\\nRequired: Yes\\nEndpointConﬁgArn\\nThe Amazon Resource Name (ARN) of the endpoint conﬁguration.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint-config/.*\\nRequired: Yes\\nEndpointConﬁgName\\nThe name of the endpoint conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n896Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nEndpointSummary\\nService: Amazon SageMaker Service\\nProvides summary information for an endpoint.\\nContents\\nCreationTime\\nA timestamp that shows when the endpoint was created.\\nType: Timestamp\\nRequired: Yes\\nEndpointArn\\nThe Amazon Resource Name (ARN) of the endpoint.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:endpoint/.*\\nRequired: Yes\\nEndpointName\\nThe name of the endpoint.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nEndpointStatus\\nThe status of the endpoint.\\n•OutOfService : Endpoint is not available to take incoming requests.\\n•Creating : CreateEndpoint (p. 632) is executing.\\n•Updating : UpdateEndpoint  (p. 840) or UpdateEndpointWeightsAndCapacities (p. 842) is\\nexecuting.\\n•SystemUpdating : Endpoint is undergoing maintenance and cannot be updated or deleted or re-\\nscaled until it has completed. This maintenance operation does not change any customer-speciﬁed\\nvalues such as VPC conﬁg, KMS encryption, model, instance type, or instance count.\\n•RollingBack : Endpoint fails to scale up or down or change its variant weight and is in\\nthe process of rolling back to its previous conﬁguration. Once the rollback completes,\\nendpoint returns to an InService  status. This transitional status only applies to an\\nendpoint that has autoscaling enabled and is undergoing variant weight or capacity\\nchanges as part of an UpdateEndpointWeightsAndCapacities (p. 842) call or when the\\nUpdateEndpointWeightsAndCapacities (p. 842) operation is called explicitly.\\n•InService : Endpoint is available to process incoming requests.\\n•Deleting : DeleteEndpoint  (p. 683) is executing.\\n•Failed: Endpoint could not be created, updated, or re-scaled. Use\\nDescribeEndpoint:FailureReason (p. 711) for information about the failure.\\nDeleteEndpoint  (p. 683) is the only operation that can be performed on a failed endpoint.\\n897Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTo get a list of endpoints with a speciﬁed status, use the ListEndpoints:StatusEquals (p. 775) ﬁlter.\\nType: String\\nValid Values: OutOfService | Creating | Updating | SystemUpdating | RollingBack\\n| InService | Deleting | Failed\\nRequired: Yes\\nLastModiﬁedTime\\nA timestamp that shows when the endpoint was last modiﬁed.\\nType: Timestamp\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n898Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nFileSystemDataSource\\nService: Amazon SageMaker Service\\nSpeciﬁes a ﬁle system data source for a channel.\\nContents\\nDirectoryPath\\nThe full path to the directory to associate with the channel.\\nType: String\\nLength Constraints: Maximum length of 4096.\\nPattern: .*\\nRequired: Yes\\nFileSystemAccessMode\\nThe access mode of the mount of the directory associated with the channel. A directory can be\\nmounted either in ro (read-only) or rw (read-write) mode.\\nType: String\\nValid Values: rw | ro\\nRequired: Yes\\nFileSystemId\\nThe ﬁle system id.\\nType: String\\nLength Constraints: Minimum length of 11.\\nPattern: .*\\nRequired: Yes\\nFileSystemType\\nThe ﬁle system type.\\nType: String\\nValid Values: EFS | FSxLustre\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n899Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n900Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nFilter\\nService: Amazon SageMaker Service\\nA conditional statement for a search expression that includes a Boolean operator, a resource property,\\nand a value.\\nIf you don\\'t specify an Operator  and a Value, the ﬁlter searches for only the speciﬁed property. For\\nexample, deﬁning a Filter  for the FailureReason  for the TrainingJob  Resource  searches for\\ntraining job objects that have a value in the FailureReason  ﬁeld.\\nIf you specify a Value , but not an Operator , Amazon SageMaker uses the equals operator as the\\ndefault.\\nIn search, there are several property types:\\nMetrics\\nTo deﬁne a metric ﬁlter, enter a value using the form \"Metrics.<name>\" , where <name>  is a\\nmetric name. For example, the following ﬁlter searches for training jobs with an \"accuracy\"  metric\\ngreater than \"0.9\" :\\n{\\n\"Name\": \"Metrics.accuracy\",\\n\"Operator\": \"GREATER_THAN\",\\n\"Value\": \"0.9\"\\n}\\nHyperParameters\\nTo deﬁne a hyperparameter ﬁlter, enter a value with the form \"HyperParameters.<name>\" .\\nDecimal hyperparameter values are treated as a decimal in a comparison if the speciﬁed Value\\nis also a decimal value. If the speciﬁed Value is an integer, the decimal hyperparameter values\\nare treated as integers. For example, the following ﬁlter is satisﬁed by training jobs with a\\n\"learning_rate\"  hyperparameter that is less than \"0.5\" :\\n{\\n\"Name\": \"HyperParameters.learning_rate\",\\n\"Operator\": \"LESS_THAN\",\\n\"Value\": \"0.5\"\\n}\\nTags\\nTo deﬁne a tag ﬁlter, enter a value with the form \"Tags.<key>\" .\\nContents\\nName\\nA property name. For example, TrainingJobName . For the list of valid property names returned in\\na search result for each supported resource, see TrainingJob (p. 1009 ) properties. You must specify a\\nvalid property name for the resource.\\n901Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: Yes\\nOperator\\nA Boolean binary operator that is used to evaluate the ﬁlter. The operator ﬁeld contains one of the\\nfollowing values:\\nEquals\\nThe speciﬁed resource in Name  equals the speciﬁed Value .\\nNotEquals\\nThe speciﬁed resource in Name  does not equal the speciﬁed Value .\\nGreaterThan\\nThe speciﬁed resource in Name is greater than the speciﬁed Value. Not supported for text-\\nbased properties.\\nGreaterThanOrEqualTo\\nThe speciﬁed resource in Name is greater than or equal to the speciﬁed Value. Not supported\\nfor text-based properties.\\nLessThan\\nThe speciﬁed resource in Name  is less than the speciﬁed Value. Not supported for text-based\\nproperties.\\nLessThanOrEqualTo\\nThe speciﬁed resource in Name  is less than or equal to the speciﬁed Value. Not supported for\\ntext-based properties.\\nContains\\nOnly supported for text-based properties. The word-list of the property contains the speciﬁed\\nValue .\\nIf you have speciﬁed a ﬁlter Value , the default is Equals .\\nType: String\\nValid Values: Equals | NotEquals | GreaterThan | GreaterThanOrEqualTo |\\nLessThan | LessThanOrEqualTo | Contains\\nRequired: No\\nValue\\nA value used with Resource  and Operator  to determine if objects satisfy the ﬁlter\\'s condition. For\\nnumerical properties, Value must be an integer or ﬂoating-point decimal. For timestamp properties,\\nValue must be an ISO 8601 date-time string of the following format: YYYY-mm-dd\\'T\\'HH:MM:SS .\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: .+\\nRequired: No\\n902Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n903Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nFinalHyperParameterTuningJobObjectiveMetric\\nService: Amazon SageMaker Service\\nShows the ﬁnal value for the objective metric for a training job that was launched by a hyperparameter\\ntuning job. You deﬁne the objective metric in the HyperParameterTuningJobObjective  parameter\\nof HyperParameterTuningJobConﬁg (p. 922).\\nContents\\nMetricName\\nThe name of the objective metric.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: Yes\\nType\\nWhether to minimize or maximize the objective metric. Valid values are Minimize and Maximize.\\nType: String\\nValid Values: Maximize | Minimize\\nRequired: No\\nValue\\nThe value of the objective metric.\\nType: Float\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n904Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nGitConﬁg\\nService: Amazon SageMaker Service\\nSpeciﬁes conﬁguration details for a Git repository in your AWS account.\\nContents\\nBranch\\nThe default branch for the Git repository.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: [^ ~^:?*\\\\[]+\\nRequired: No\\nRepositoryUrl\\nThe URL where the Git repository is located.\\nType: String\\nPattern: ^https://([^/]+)/?(.*)$\\nRequired: Yes\\nSecretArn\\nThe Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the credentials\\nused to access the git repository. The secret must have a staging label of AWSCURRENT  and must be\\nin the following format:\\n{\"username\": UserName , \"password\": Password }\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:secretsmanager:[a-z0-9\\\\-]*:[0-9]{12}:secret:.*\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n905Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nGitConﬁgForUpdate\\nService: Amazon SageMaker Service\\nSpeciﬁes conﬁguration details for a Git repository when the repository is updated.\\nContents\\nSecretArn\\nThe Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains the credentials\\nused to access the git repository. The secret must have a staging label of AWSCURRENT  and must be\\nin the following format:\\n{\"username\": UserName , \"password\": Password }\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:secretsmanager:[a-z0-9\\\\-]*:[0-9]{12}:secret:.*\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n906Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHumanTaskConﬁg\\nService: Amazon SageMaker Service\\nInformation required for human workers to complete a labeling task.\\nContents\\nAnnotationConsolidationConﬁg\\nConﬁgures how labels are consolidated across human workers.\\nType: AnnotationConsolidationConﬁg  (p. 871) object\\nRequired: Yes\\nMaxConcurrentTaskCount\\nDeﬁnes the maximum number of data objects that can be labeled by human workers at the same\\ntime. Each object may have more than one worker at one time.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 1000.\\nRequired: No\\nNumberOfHumanWorkersPerDataObject\\nThe number of human workers that will label an object.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 9.\\nRequired: Yes\\nPreHumanTaskLambdaArn\\nThe Amazon Resource Name (ARN) of a Lambda function that is run before a data object is sent to a\\nhuman worker. Use this function to provide input to a custom labeling job.\\nFor the built-in bounding box, image classiﬁcation, semantic segmentation, and text classiﬁcation\\ntask types, Amazon SageMaker Ground Truth provides the following Lambda functions:\\nUS East (Northern Virginia) (us-east-1):\\n•arn:aws:lambda:us-east-1:432418664414:function:PRE-BoundingBox\\n•arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClass\\n•arn:aws:lambda:us-east-1:432418664414:function:PRE-SemanticSegmentation\\n•arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClass\\n•arn:aws:lambda:us-east-1:432418664414:function:PRE-NamedEntityRecognition\\nUS East (Ohio) (us-east-2):\\n•arn:aws:lambda:us-east-2:266458841044:function:PRE-BoundingBox\\n•arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClass\\n•arn:aws:lambda:us-east-2:266458841044:function:PRE-SemanticSegmentation\\n•arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClass\\n•arn:aws:lambda:us-east-2:266458841044:function:PRE-NamedEntityRecognition\\nUS West (Oregon) (us-west-2):\\n907Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•arn:aws:lambda:us-west-2:081040173940:function:PRE-BoundingBox\\n•arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClass\\n•arn:aws:lambda:us-west-2:081040173940:function:PRE-SemanticSegmentation\\n•arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClass\\n•arn:aws:lambda:us-west-2:081040173940:function:PRE-NamedEntityRecognition\\nCanada (Central) (ca-central-1):\\n•arn:awslambda:ca-central-1:918755190332:function:PRE-BoundingBox\\n•arn:awslambda:ca-central-1:918755190332:function:PRE-ImageMultiClass\\n•arn:awslambda:ca-central-1:918755190332:function:PRE-SemanticSegmentation\\n•arn:awslambda:ca-central-1:918755190332:function:PRE-TextMultiClass\\n•arn:awslambda:ca-central-1:918755190332:function:PRE-\\nNamedEntityRecognition\\nEU (Ireland) (eu-west-1):\\n•arn:aws:lambda:eu-west-1:568282634449:function:PRE-BoundingBox\\n•arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClass\\n•arn:aws:lambda:eu-west-1:568282634449:function:PRE-SemanticSegmentation\\n•arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClass\\n•arn:aws:lambda:eu-west-1:568282634449:function:PRE-NamedEntityRecognition\\nEU (London) (eu-west-2):\\n•arn:awslambda:eu-west-2:487402164563:function:PRE-BoundingBox\\n•arn:awslambda:eu-west-2:487402164563:function:PRE-ImageMultiClass\\n•arn:awslambda:eu-west-2:487402164563:function:PRE-SemanticSegmentation\\n•arn:awslambda:eu-west-2:487402164563:function:PRE-TextMultiClass\\n•arn:awslambda:eu-west-2:487402164563:function:PRE-NamedEntityRecognition\\nEU Frankfurt (eu-central-1):\\n•arn:awslambda:eu-central-1:203001061592:function:PRE-BoundingBox\\n•arn:awslambda:eu-central-1:203001061592:function:PRE-ImageMultiClass\\n•arn:awslambda:eu-central-1:203001061592:function:PRE-SemanticSegmentation\\n•arn:awslambda:eu-central-1:203001061592:function:PRE-TextMultiClass\\n•arn:awslambda:eu-central-1:203001061592:function:PRE-\\nNamedEntityRecognition\\nAsia Paciﬁc (Tokyo) (ap-northeast-1):\\n•arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-BoundingBox\\n•arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClass\\n•arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-\\nSemanticSegmentation\\n•arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClass\\n•arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-\\nNamedEntityRecognition\\nAsia Paciﬁc (Seoul) (ap-northeast-2):\\n•arn:awslambda:ap-northeast-2:845288260483:function:PRE-BoundingBox\\n•arn:awslambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClass\\n•arn:awslambda:ap-northeast-2:845288260483:function:PRE-\\nSemanticSegmentation\\n908Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•arn:awslambda:ap-northeast-2:845288260483:function:PRE-TextMultiClass\\n•arn:awslambda:ap-northeast-2:845288260483:function:PRE-\\nNamedEntityRecognition\\nAsia Paciﬁc (Mumbai) (ap-south-1):\\n•arn:awslambda:ap-south-1:565803892007:function:PRE-BoundingBox\\n•arn:awslambda:ap-south-1:565803892007:function:PRE-ImageMultiClass\\n•arn:awslambda:ap-south-1:565803892007:function:PRE-SemanticSegmentation\\n•arn:awslambda:ap-south-1:565803892007:function:PRE-TextMultiClass\\n•arn:awslambda:ap-south-1:565803892007:function:PRE-NamedEntityRecognition\\nAsia Paciﬁc (Singapore) (ap-southeast-1):\\n•arn:awslambda:ap-southeast-1:377565633583:function:PRE-BoundingBox\\n•arn:awslambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClass\\n•arn:awslambda:ap-southeast-1:377565633583:function:PRE-\\nSemanticSegmentation\\n•arn:awslambda:ap-southeast-1:377565633583:function:PRE-TextMultiClass\\n•arn:awslambda:ap-southeast-1:377565633583:function:PRE-\\nNamedEntityRecognition\\nAsia Paciﬁc (Sydney) (ap-southeast-2):\\n•arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-BoundingBox\\n•arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClass\\n•arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-\\nSemanticSegmentation\\n•arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClass\\n•arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-\\nNamedEntityRecognition\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:lambda:[a-z]{2}-[a-z]+-\\\\d{1}:\\\\d{12}:function:[a-zA-\\nZ0-9-_\\\\.]+(:(\\\\$LATEST|[a-zA-Z0-9-_]+))?\\nRequired: Yes\\nPublicWorkforceTaskPrice\\nThe price that you pay for each task performed by an Amazon Mechanical Turk worker.\\nType: PublicWorkforceTaskPrice (p. 987) object\\nRequired: No\\nTaskAvailabilityLifetimeInSeconds\\nThe length of time that a task remains available for labeling by human workers. If you choose the\\nAmazon Mechanical Turk workforce, the maximum is 12 hours (43200). For private and vendor\\nworkforces, the maximum is as listed.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 864000.\\nRequired: No\\n909Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTaskDescription\\nA description of the task for your human workers.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: Yes\\nTaskKeywords\\nKeywords used to describe the task so that workers on Amazon Mechanical Turk can discover the\\ntask.\\nType: Array of strings\\nArray Members: Minimum number of 1 item. Maximum number of 5 items.\\nLength Constraints: Minimum length of 1. Maximum length of 30.\\nPattern: ^[A-Za-z0-9]+( [A-Za-z0-9]+)*$\\nRequired: No\\nTaskTimeLimitInSeconds\\nThe amount of time that a worker has to complete a task.\\nType: Integer\\nValid Range: Minimum value of 30. Maximum value of 28800.\\nRequired: Yes\\nTaskTitle\\nA title for the task for your human workers.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 128.\\nPattern: ^[\\\\t\\\\n\\\\r -\\\\uD7FF\\\\uE000-\\\\uFFFD]*$\\nRequired: Yes\\nUiConﬁg\\nInformation about the user interface that workers use to complete the labeling task.\\nType: UiConﬁg  (p. 1036 ) object\\nRequired: Yes\\nWorkteamArn\\nThe Amazon Resource Name (ARN) of the work team assigned to complete the tasks.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:workteam/.*\\n910Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n911Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterAlgorithmSpeciﬁcation\\nService: Amazon SageMaker Service\\nSpeciﬁes which training algorithm to use for training jobs that a hyperparameter tuning job launches\\nand the metrics to monitor.\\nContents\\nAlgorithmName\\nThe name of the resource algorithm to use for the hyperparameter tuning job. If you specify a value\\nfor this parameter, do not specify a value for TrainingImage .\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 170.\\nPattern: (arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:[a-z\\\\-]*\\\\/)?([a-zA-\\nZ0-9]([a-zA-Z0-9-]){0,62})(?<!-)$\\nRequired: No\\nMetricDeﬁnitions\\nAn array of MetricDeﬁnition  (p. 956) objects that specify the metrics that the algorithm emits.\\nType: Array of MetricDeﬁnition  (p. 956) objects\\nArray Members: Minimum number of 0 items. Maximum number of 40 items.\\nRequired: No\\nTrainingImage\\nThe registry path of the Docker image that contains the training algorithm. For information about\\nDocker registry paths for built-in algorithms, see Algorithms Provided by Amazon SageMaker:\\nCommon Parameters. Amazon SageMaker supports both registry/repository[:tag]  and\\nregistry/repository[@digest]  image path formats. For more information, see Using Your\\nOwn Algorithms with Amazon SageMaker.\\nType: String\\nLength Constraints: Maximum length of 255.\\nPattern: .*\\nRequired: No\\nTrainingInputMode\\nThe input mode that the algorithm supports: File or Pipe. In File input mode, Amazon SageMaker\\ndownloads the training data from Amazon S3 to the storage volume that is attached to the training\\ninstance and mounts the directory to the Docker volume for the training container. In Pipe input\\nmode, Amazon SageMaker streams data directly from Amazon S3 to the container.\\nIf you specify File mode, make sure that you provision the storage volume that is attached to the\\ntraining instance with enough capacity to accommodate the training data downloaded from Amazon\\nS3, the model artifacts, and intermediate information.\\nFor more information about input modes, see Algorithms .\\nType: String\\n912Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Values: Pipe | File\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n913Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterSpeciﬁcation\\nService: Amazon SageMaker Service\\nDeﬁnes a hyperparameter to be used by an algorithm.\\nContents\\nDefaultValue\\nThe default value for this hyperparameter. If a default value is speciﬁed, a hyperparameter cannot\\nbe required.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: No\\nDescription\\nA brief description of the hyperparameter.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nRequired: No\\nIsRequired\\nIndicates whether this hyperparameter is required.\\nType: Boolean\\nRequired: No\\nIsTunable\\nIndicates whether this hyperparameter is tunable in a hyperparameter tuning job.\\nType: Boolean\\nRequired: No\\nName\\nThe name of this hyperparameter. The name must be unique.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nRequired: Yes\\nRange\\nThe allowed range for this hyperparameter.\\nType: ParameterRange (p. 978) object\\n914Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: No\\nType\\nThe type of this hyperparameter. The valid types are Integer , Continuous , Categorical , and\\nFreeText .\\nType: String\\nValid Values: Integer | Continuous | Categorical | FreeText\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n915Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterTrainingJobDeﬁnition\\nService: Amazon SageMaker Service\\nDeﬁnes the training jobs launched by a hyperparameter tuning job.\\nContents\\nAlgorithmSpeciﬁcation\\nThe HyperParameterAlgorithmSpeciﬁcation (p. 912) object that speciﬁes the resource algorithm to\\nuse for the training jobs that the tuning job launches.\\nType: HyperParameterAlgorithmSpeciﬁcation (p. 912) object\\nRequired: Yes\\nCheckpointConﬁg\\nContains information about the output location for managed spot training checkpoint data.\\nType: CheckpointConﬁg  (p. 880) object\\nRequired: No\\nEnableInterContainerTraﬃcEncryption\\nTo encrypt all communications between ML compute instances in distributed training, choose True .\\nEncryption provides greater security for distributed training, but training might take longer. How\\nlong it takes depends on the amount of communication between compute instances, especially if\\nyou use a deep learning algorithm in distributed training.\\nType: Boolean\\nRequired: No\\nEnableManagedSpotTraining\\nA Boolean indicating whether managed spot training is enabled ( True ) or not (False ).\\nType: Boolean\\nRequired: No\\nEnableNetworkIsolation\\nIsolates the training container. No inbound or outbound network calls can be made, except for\\ncalls between peers within a training cluster for distributed training. If network isolation is used\\nfor training jobs that are conﬁgured to use a VPC, Amazon SageMaker downloads and uploads\\ncustomer data and model artifacts through the speciﬁed VPC, but the training container does not\\nhave network access.\\nNote\\nThe Semantic Segmentation built-in algorithm does not support network isolation.\\nType: Boolean\\nRequired: No\\nInputDataConﬁg\\nAn array of Channel  (p. 876) objects that specify the input for the training jobs that the tuning job\\nlaunches.\\nType: Array of Channel  (p. 876) objects\\n916Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No\\nOutputDataConﬁg\\nSpeciﬁes the path to the Amazon S3 bucket where you store model artifacts from the training jobs\\nthat the tuning job launches.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: Yes\\nResourceConﬁg\\nThe resources, including the compute instances and storage volumes, to use for the training jobs\\nthat the tuning job launches.\\nStorage volumes store model artifacts and incremental states. Training algorithms might also use\\nstorage volumes for scratch space. If you want Amazon SageMaker to use the storage volume to\\nstore the training data, choose File  as the TrainingInputMode  in the algorithm speciﬁcation. For\\ndistributed training algorithms, specify an instance count greater than 1.\\nType: ResourceConﬁg (p. 991) object\\nRequired: Yes\\nRoleArn\\nThe Amazon Resource Name (ARN) of the IAM role associated with the training jobs that the tuning\\njob launches.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nStaticHyperParameters\\nSpeciﬁes the values of hyperparameters that do not change for the tuning job.\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nStoppingCondition\\nSpeciﬁes a limit to how long a model hyperparameter training job can run. It also speciﬁes how long\\nyou are willing to wait for a managed spot training job to complete. When the job reaches the a\\nlimit, Amazon SageMaker ends the training job. Use this API to cap model training costs.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\n917Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nVpcConﬁg\\nThe VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that you want the training jobs that this\\nhyperparameter tuning job launches to connect to. Control access to and from your training\\ncontainer by conﬁguring the VPC. For more information, see Protect Training Jobs by Using an\\nAmazon Virtual Private Cloud.\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n918Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterTrainingJobSummary\\nService: Amazon SageMaker Service\\nSpeciﬁes summary information about a training job.\\nContents\\nCreationTime\\nThe date and time that the training job was created.\\nType: Timestamp\\nRequired: Yes\\nFailureReason\\nThe reason that the training job failed.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nRequired: No\\nFinalHyperParameterTuningJobObjectiveMetric\\nThe FinalHyperParameterTuningJobObjectiveMetric (p. 904) object that speciﬁes the value of the\\nobjective metric of the tuning job that launched this training job.\\nType: FinalHyperParameterTuningJobObjectiveMetric (p. 904) object\\nRequired: No\\nObjectiveStatus\\nThe status of the objective metric for the training job:\\n•Succeeded: The ﬁnal objective metric for the training job was evaluated by the hyperparameter\\ntuning job and used in the hyperparameter tuning process.\\n•Pending: The training job is in progress and evaluation of its ﬁnal objective metric is pending.\\n•Failed: The ﬁnal objective metric for the training job was not evaluated, and was not used in the\\nhyperparameter tuning process. This typically occurs when the training job failed or did not emit\\nan objective metric.\\nType: String\\nValid Values: Succeeded | Pending | Failed\\nRequired: No\\nTrainingEndTime\\nSpeciﬁes the time when the training job ends on training instances. You are billed for the time\\ninterval between the value of TrainingStartTime  and this time. For successful jobs and stopped\\njobs, this is the time after model artifacts are uploaded. For failed jobs, this is the time when\\nAmazon SageMaker detects a job failure.\\nType: Timestamp\\nRequired: No\\nTrainingJobArn\\nThe Amazon Resource Name (ARN) of the training job.\\n919Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-job/.*\\nRequired: Yes\\nTrainingJobName\\nThe name of the training job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nTrainingJobStatus\\nThe status of the training job.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: Yes\\nTrainingStartTime\\nThe date and time that the training job started.\\nType: Timestamp\\nRequired: No\\nTunedHyperParameters\\nA list of the hyperparameters for which you speciﬁed ranges to search.\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: Yes\\nTuningJobName\\nThe HyperParameter tuning job that launched the training job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\n920Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n921Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterTuningJobConﬁg\\nService: Amazon SageMaker Service\\nConﬁgures a hyperparameter tuning job.\\nContents\\nHyperParameterTuningJobObjective\\nThe HyperParameterTuningJobObjective (p. 924) object that speciﬁes the objective metric for this\\ntuning job.\\nType: HyperParameterTuningJobObjective (p. 924) object\\nRequired: No\\nParameterRanges\\nThe ParameterRanges (p. 979) object that speciﬁes the ranges of hyperparameters that this tuning\\njob searches.\\nType: ParameterRanges (p. 979) object\\nRequired: No\\nResourceLimits\\nThe ResourceLimits (p. 993) object that speciﬁes the maximum number of training jobs and\\nparallel training jobs for this tuning job.\\nType: ResourceLimits (p. 993) object\\nRequired: Yes\\nStrategy\\nSpeciﬁes how hyperparameter tuning chooses the combinations of hyperparameter values to use for\\nthe training job it launches. To use the Bayesian search stategy, set this to Bayesian . To randomly\\nsearch, set it to Random. For information about search strategies, see How Hyperparameter Tuning\\nWorks.\\nType: String\\nValid Values: Bayesian | Random\\nRequired: Yes\\nTrainingJobEarlyStoppingType\\nSpeciﬁes whether to use early stopping for training jobs launched by the hyperparameter tuning job.\\nThis can be one of the following values (the default value is OFF):\\nOFF\\nTraining jobs launched by the hyperparameter tuning job do not use early stopping.\\nAUTO\\nAmazon SageMaker stops training jobs launched by the hyperparameter tuning job when they\\nare unlikely to perform better than previously completed training jobs. For more information,\\nsee Stop Training Jobs Early.\\nType: String\\nValid Values: Off | Auto\\n922Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n923Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterTuningJobObjective\\nService: Amazon SageMaker Service\\nDeﬁnes the objective metric for a hyperparameter tuning job. Hyperparameter tuning uses the value of\\nthis metric to evaluate the training jobs it launches, and returns the training job that results in either the\\nhighest or lowest value for this metric, depending on the value you specify for the Type parameter.\\nContents\\nMetricName\\nThe name of the metric to use for the objective metric.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: Yes\\nType\\nWhether to minimize or maximize the objective metric.\\nType: String\\nValid Values: Maximize | Minimize\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n924Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterTuningJobSummary\\nService: Amazon SageMaker Service\\nProvides summary information about a hyperparameter tuning job.\\nContents\\nCreationTime\\nThe date and time that the tuning job was created.\\nType: Timestamp\\nRequired: Yes\\nHyperParameterTuningEndTime\\nThe date and time that the tuning job ended.\\nType: Timestamp\\nRequired: No\\nHyperParameterTuningJobArn\\nThe Amazon Resource Name (ARN) of the tuning job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:hyper-parameter-\\ntuning-job/.*\\nRequired: Yes\\nHyperParameterTuningJobName\\nThe name of the tuning job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nHyperParameterTuningJobStatus\\nThe status of the tuning job.\\nType: String\\nValid Values: Completed | InProgress | Failed | Stopped | Stopping\\nRequired: Yes\\nLastModiﬁedTime\\nThe date and time that the tuning job was modiﬁed.\\nType: Timestamp\\nRequired: No\\n925Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nObjectiveStatusCounters\\nThe ObjectiveStatusCounters (p. 974) object that speciﬁes the numbers of training jobs,\\ncategorized by objective metric status, that this tuning job launched.\\nType: ObjectiveStatusCounters (p. 974) object\\nRequired: Yes\\nResourceLimits\\nThe ResourceLimits (p. 993) object that speciﬁes the maximum number of training jobs and\\nparallel training jobs allowed for this tuning job.\\nType: ResourceLimits (p. 993) object\\nRequired: No\\nStrategy\\nSpeciﬁes the search strategy hyperparameter tuning uses to choose which hyperparameters to use\\nfor each iteration. Currently, the only valid value is Bayesian.\\nType: String\\nValid Values: Bayesian | Random\\nRequired: Yes\\nTrainingJobStatusCounters\\nThe TrainingJobStatusCounters (p. 1017 ) object that speciﬁes the numbers of training jobs,\\ncategorized by status, that this tuning job launched.\\nType: TrainingJobStatusCounters (p. 1017 ) object\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n926Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameterTuningJobWarmStartConﬁg\\nService: Amazon SageMaker Service\\nSpeciﬁes the conﬁguration for a hyperparameter tuning job that uses one or more previous\\nhyperparameter tuning jobs as a starting point. The results of previous tuning jobs are used to inform\\nwhich combinations of hyperparameters to search over in the new tuning job.\\nAll training jobs launched by the new hyperparameter tuning job are evaluated by using the objective\\nmetric, and the training job that performs the best is compared to the best training jobs from the parent\\ntuning jobs. From these, the training job that performs the best as measured by the objective metric is\\nreturned as the overall best training job.\\nNote\\nAll training jobs launched by parent hyperparameter tuning jobs and the new hyperparameter\\ntuning jobs count against the limit of training jobs for the tuning job.\\nContents\\nParentHyperParameterTuningJobs\\nAn array of hyperparameter tuning jobs that are used as the starting point for the new\\nhyperparameter tuning job. For more information about warm starting a hyperparameter tuning job,\\nsee Using a Previous Hyperparameter Tuning Job as a Starting Point.\\nHyperparameter tuning jobs created before October 1, 2018 cannot be used as parent jobs for warm\\nstart tuning jobs.\\nType: Array of ParentHyperParameterTuningJob (p. 980) objects\\nArray Members: Minimum number of 1 item. Maximum number of 5 items.\\nRequired: Yes\\nWarmStartType\\nSpeciﬁes one of the following:\\nIDENTICAL_DATA_AND_ALGORITHM\\nThe new hyperparameter tuning job uses the same input data and training image as the parent\\ntuning jobs. You can change the hyperparameter ranges to search and the maximum number\\nof training jobs that the hyperparameter tuning job launches. You cannot use a new version\\nof the training algorithm, unless the changes in the new version do not aﬀect the algorithm\\nitself. For example, changes that improve logging or adding support for a diﬀerent data format\\nare allowed. You can also change hyperparameters from tunable to static, and from static to\\ntunable, but the total number of static plus tunable hyperparameters must remain the same as\\nit is in all parent jobs. The objective metric for the new tuning job must be the same as for all\\nparent jobs.\\nTRANSFER_LEARNING\\nThe new hyperparameter tuning job can include input data, hyperparameter ranges, maximum\\nnumber of concurrent training jobs, and maximum number of training jobs that are diﬀerent\\nthan those of its parent hyperparameter tuning jobs. The training image can also be a diﬀerent\\nversion from the version used in the parent hyperparameter tuning job. You can also change\\nhyperparameters from tunable to static, and from static to tunable, but the total number\\nof static plus tunable hyperparameters must remain the same as it is in all parent jobs. The\\nobjective metric for the new tuning job must be the same as for all parent jobs.\\nType: String\\nValid Values: IdenticalDataAndAlgorithm | TransferLearning\\n927Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n928Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nInferenceSpeciﬁcation\\nService: Amazon SageMaker Service\\nDeﬁnes how to perform inference generation after a training job is run.\\nContents\\nContainers\\nThe Amazon ECR registry path of the Docker image that contains the inference code.\\nType: Array of ModelPackageContainerDeﬁnition (p. 958) objects\\nArray Members: Fixed number of 1 item.\\nRequired: Yes\\nSupportedContentTypes\\nThe supported MIME types for the input data.\\nType: Array of strings\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nSupportedRealtimeInferenceInstanceTypes\\nA list of the instance types that are used to generate inferences in real-time.\\nType: Array of strings\\nValid Values: ml.t2.medium | ml.t2.large | ml.t2.xlarge | ml.t2.2xlarge\\n| ml.m4.xlarge | ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge |\\nml.m4.16xlarge | ml.m5.large | ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge\\n| ml.m5.12xlarge | ml.m5.24xlarge | ml.c4.large | ml.c4.xlarge |\\nml.c4.2xlarge | ml.c4.4xlarge | ml.c4.8xlarge | ml.p2.xlarge | ml.p2.8xlarge\\n| ml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge |\\nml.c5.large | ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge |\\nml.c5.18xlarge\\nRequired: Yes\\nSupportedResponseMIMETypes\\nThe supported MIME types for the output data.\\nType: Array of strings\\nLength Constraints: Maximum length of 1024.\\nPattern: ^[-\\\\w]+\\\\/.+$\\nRequired: Yes\\nSupportedTransformInstanceTypes\\nA list of the instance types on which a transformation job can be run or on which an endpoint can be\\ndeployed.\\nType: Array of strings\\n929Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nArray Members: Minimum number of 1 item.\\nValid Values: ml.m4.xlarge | ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge\\n| ml.m4.16xlarge | ml.c4.xlarge | ml.c4.2xlarge | ml.c4.4xlarge\\n| ml.c4.8xlarge | ml.p2.xlarge | ml.p2.8xlarge | ml.p2.16xlarge\\n| ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge | ml.c5.xlarge |\\nml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge | ml.c5.18xlarge | ml.m5.large\\n| ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge | ml.m5.12xlarge |\\nml.m5.24xlarge\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n930Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nInputConﬁg\\nService: Amazon SageMaker Service\\nContains information about the location of input model artifacts, the name and shape of the expected\\ndata inputs, and the framework in which the model was trained.\\nContents\\nDataInputConﬁg\\nSpeciﬁes the name and shape of the expected data inputs for your trained model with a JSON\\ndictionary form. The data inputs are InputConﬁg:Framework (p. 932) speciﬁc.\\n•TensorFlow : You must specify the name and shape (NHWC format) of the expected data inputs\\nusing a dictionary format for your trained model. The dictionary formats required for the console\\nand CLI are diﬀerent.\\n•Examples for one input:\\n•If using the console, {\"input\":[1,1024,1024,3]}\\n•If using the CLI, {\\\\\"input\\\\\":[1,1024,1024,3]}\\n•Examples for two inputs:\\n•If using the console, {\"data1\": [1,28,28,1], \"data2\":[1,28,28,1]}\\n•If using the CLI, {\\\\\"data1\\\\\": [1,28,28,1], \\\\\"data2\\\\\":[1,28,28,1]}\\n•MXNET/ONNX : You must specify the name and shape (NCHW format) of the expected data inputs\\nin order using a dictionary format for your trained model. The dictionary formats required for the\\nconsole and CLI are diﬀerent.\\n•Examples for one input:\\n•If using the console, {\"data\":[1,3,1024,1024]}\\n•If using the CLI, {\\\\\"data\\\\\":[1,3,1024,1024]}\\n•Examples for two inputs:\\n•If using the console, {\"var1\": [1,1,28,28], \"var2\":[1,1,28,28]}\\n•If using the CLI, {\\\\\"var1\\\\\": [1,1,28,28], \\\\\"var2\\\\\":[1,1,28,28]}\\n•PyTorch: You can either specify the name and shape (NCHW format) of expected data inputs in\\norder using a dictionary format for your trained model or you can specify the shape only using a\\nlist format. The dictionary formats required for the console and CLI are diﬀerent. The list formats\\nfor the console and CLI are the same.\\n•Examples for one input in dictionary format:\\n•If using the console, {\"input0\":[1,3,224,224]}\\n•If using the CLI, {\\\\\"input0\\\\\":[1,3,224,224]}\\n•Example for one input in list format: [[1,3,224,224]]\\n•Examples for two inputs in dictionary format:\\n•If using the console, {\"input0\":[1,3,224,224], \"input1\":[1,3,224,224]}\\n•If using the CLI, {\\\\\"input0\\\\\":[1,3,224,224], \\\\\"input1\\\\\":[1,3,224,224]}\\n•Example for two inputs in list format: [[1,3,224,224], [1,3,224,224]]\\n•XGBOOST: input data name and shape are not needed.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: [\\\\S\\\\s]+\\nRequired: Yes\\n931Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nFramework\\nIdentiﬁes the framework in which the model was trained. For example: TENSORFLOW.\\nType: String\\nValid Values: TENSORFLOW | MXNET | ONNX | PYTORCH | XGBOOST\\nRequired: Yes\\nS3Uri\\nThe S3 path where the model artifacts, which result from model training, are stored. This path must\\npoint to a single gzip compressed tar archive (.tar.gz suﬃx).\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n932Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nIntegerParameterRange\\nService: Amazon SageMaker Service\\nFor a hyperparameter of the integer type, speciﬁes the range that a hyperparameter tuning job searches.\\nContents\\nMaxValue\\nThe maximum value of the hyperparameter to search.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nMinValue\\nThe minimum value of the hyperparameter to search.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nName\\nThe name of the hyperparameter to search.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nScalingType\\nThe scale that hyperparameter tuning uses to search the hyperparameter range. For information\\nabout choosing a hyperparameter scale, see Hyperparameter Scaling . One of the following values:\\nAuto\\nAmazon SageMaker hyperparameter tuning chooses the best scale for the hyperparameter.\\nLinear\\nHyperparameter tuning searches the values in the hyperparameter range by using a linear scale.\\nLogarithmic\\nHyperparemeter tuning searches the values in the hyperparameter range by using a logarithmic\\nscale.\\nLogarithmic scaling works only for ranges that have only values greater than 0.\\nType: String\\n933Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nValid Values: Auto | Linear | Logarithmic | ReverseLogarithmic\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n934Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nIntegerParameterRangeSpeciﬁcation\\nService: Amazon SageMaker Service\\nDeﬁnes the possible values for an integer hyperparameter.\\nContents\\nMaxValue\\nThe maximum integer value allowed.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nMinValue\\nThe minimum integer value allowed.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n935Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelCounters\\nService: Amazon SageMaker Service\\nProvides a breakdown of the number of objects labeled.\\nContents\\nFailedNonRetryableError\\nThe total number of objects that could not be labeled due to an error.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nHumanLabeled\\nThe total number of objects labeled by a human worker.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nMachineLabeled\\nThe total number of objects labeled by automated data labeling.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nTotalLabeled\\nThe total number of objects labeled.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nUnlabeled\\nThe total number of objects not yet labeled.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n936Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n937Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelCountersForWorkteam\\nService: Amazon SageMaker Service\\nProvides counts for human-labeled tasks in the labeling job.\\nContents\\nHumanLabeled\\nThe total number of data objects labeled by a human worker.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nPendingHuman\\nThe total number of data objects that need to be labeled by a human worker.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nTotal\\nThe total number of tasks in the labeling job.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n938Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobAlgorithmsConﬁg\\nService: Amazon SageMaker Service\\nProvides conﬁguration information for auto-labeling of your data objects. A\\nLabelingJobAlgorithmsConfig  object must be supplied in order to use auto-labeling.\\nContents\\nInitialActiveLearningModelArn\\nAt the end of an auto-label job Amazon SageMaker Ground Truth sends the Amazon Resource Nam\\n(ARN) of the ﬁnal model used for auto-labeling. You can use this model as the starting point for\\nsubsequent similar jobs by providing the ARN of the model here.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model/.*\\nRequired: No\\nLabelingJobAlgorithmSpeciﬁcationArn\\nSpeciﬁes the Amazon Resource Name (ARN) of the algorithm used for auto-labeling. You must select\\none of the following ARNs:\\n•Image classiﬁcation\\narn:aws:sagemaker: region:027400017018:labeling-job-algorithm-\\nspecification/image-classification\\n•Text classiﬁcation\\narn:aws:sagemaker: region:027400017018:labeling-job-algorithm-\\nspecification/text-classification\\n•Object detection\\narn:aws:sagemaker: region:027400017018:labeling-job-algorithm-\\nspecification/object-detection\\n•Semantic Segmentation\\narn:aws:sagemaker: region:027400017018:labeling-job-algorithm-\\nspecification/semantic-segmentation\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:.*\\nRequired: Yes\\nLabelingJobResourceConﬁg\\nProvides conﬁguration information for a labeling job.\\nType: LabelingJobResourceConﬁg (p. 948) object\\nRequired: No\\n939Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n940Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobDataAttributes\\nService: Amazon SageMaker Service\\nAttributes of the data speciﬁed by the customer. Use these to describe the data to be labeled.\\nContents\\nContentClassiﬁers\\nDeclares that your content is free of personally identiﬁable information or adult content. Amazon\\nSageMaker may restrict the Amazon Mechanical Turk workers that can view your task based on this\\ninformation.\\nType: Array of strings\\nArray Members: Maximum number of 256 items.\\nValid Values: FreeOfPersonallyIdentifiableInformation | FreeOfAdultContent\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n941Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobDataSource\\nService: Amazon SageMaker Service\\nProvides information about the location of input data.\\nContents\\nS3DataSource\\nThe Amazon S3 location of the input data objects.\\nType: LabelingJobS3DataSource (p. 949) object\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n942Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobForWorkteamSummary\\nService: Amazon SageMaker Service\\nProvides summary information for a work team.\\nContents\\nCreationTime\\nThe date and time that the labeling job was created.\\nType: Timestamp\\nRequired: Yes\\nJobReferenceCode\\nA unique identiﬁer for a labeling job. You can use this to refer to a speciﬁc labeling job.\\nType: String\\nLength Constraints: Minimum length of 1.\\nPattern: .+\\nRequired: Yes\\nLabelCounters\\nProvides information about the progress of a labeling job.\\nType: LabelCountersForWorkteam (p. 938) object\\nRequired: No\\nLabelingJobName\\nThe name of the labeling job that the work team is assigned to.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nNumberOfHumanWorkersPerDataObject\\nThe conﬁgured number of workers per data object.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 9.\\nRequired: No\\nWorkRequesterAccountId\\nType: String\\nPattern: ^\\\\d+$\\nRequired: Yes\\n943Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n944Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobInputConﬁg\\nService: Amazon SageMaker Service\\nInput conﬁguration information for a labeling job.\\nContents\\nDataAttributes\\nAttributes of the data speciﬁed by the customer.\\nType: LabelingJobDataAttributes (p. 941) object\\nRequired: No\\nDataSource\\nThe location of the input data.\\nType: LabelingJobDataSource (p. 942) object\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n945Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobOutput\\nService: Amazon SageMaker Service\\nSpeciﬁes the location of the output produced by the labeling job.\\nContents\\nFinalActiveLearningModelArn\\nThe Amazon Resource Name (ARN) for the most recent Amazon SageMaker model trained as part of\\nautomated data labeling.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model/.*\\nRequired: No\\nOutputDatasetS3Uri\\nThe Amazon S3 bucket location of the manifest ﬁle for labeled data.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n946Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobOutputConﬁg\\nService: Amazon SageMaker Service\\nOutput conﬁguration information for a labeling job.\\nContents\\nKmsKeyId\\nThe AWS Key Management Service ID of the key used to encrypt the output data, if any.\\nIf you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role must\\ninclude permissions to call kms:Encrypt . If you don\\'t provide a KMS key ID, Amazon SageMaker\\nuses the default KMS key for Amazon S3 for your role\\'s account. Amazon SageMaker uses server-side\\nencryption with KMS-managed keys for LabelingJobOutputConfig . If you use a bucket policy\\nwith an s3:PutObject  permission that only allows objects with server-side encryption, set the\\ncondition key of s3:x-amz-server-side-encryption  to \"aws:kms\" . For more information, see\\nKMS-Managed Encryption Keys in the Amazon Simple Storage Service Developer Guide.\\nThe KMS key policy must grant permission to the IAM role that you specify in your\\nCreateLabelingJob  request. For more information, see Using Key Policies in AWS KMS in the AWS\\nKey Management Service Developer Guide.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nS3OutputPath\\nThe Amazon S3 location to write output data.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n947Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobResourceConﬁg\\nService: Amazon SageMaker Service\\nProvides conﬁguration information for labeling jobs.\\nContents\\nVolumeKmsKeyId\\nThe AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data\\non the storage volume attached to the ML compute instance(s) that run the training job. The\\nVolumeKmsKeyId  can be any of the following formats:\\n•// KMS Key ID\\n\"1234abcd-12ab-34cd-56ef-1234567890ab\"\\n•// Amazon Resource Name (ARN) of a KMS Key\\n\"arn:aws:kms:us-\\nwest-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n948Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobS3DataSource\\nService: Amazon SageMaker Service\\nThe Amazon S3 location of the input data objects.\\nContents\\nManifestS3Uri\\nThe Amazon S3 location of the manifest ﬁle that describes the input data objects.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n949Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobStoppingConditions\\nService: Amazon SageMaker Service\\nA set of conditions for stopping a labeling job. If any of the conditions are met, the job is automatically\\nstopped. You can use these conditions to control the cost of data labeling.\\nContents\\nMaxHumanLabeledObjectCount\\nThe maximum number of objects that can be labeled by human workers.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: No\\nMaxPercentageOfInputDatasetLabeled\\nThe maximum number of input data objects that should be labeled.\\nType: Integer\\nValid Range: Minimum value of 1. Maximum value of 100.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n950Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLabelingJobSummary\\nService: Amazon SageMaker Service\\nProvides summary information about a labeling job.\\nContents\\nAnnotationConsolidationLambdaArn\\nThe Amazon Resource Name (ARN) of the Lambda function used to consolidate the annotations\\nfrom individual workers into a label for a data object. For more information, see Annotation\\nConsolidation .\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:lambda:[a-z]{2}-[a-z]+-\\\\d{1}:\\\\d{12}:function:[a-zA-\\nZ0-9-_\\\\.]+(:(\\\\$LATEST|[a-zA-Z0-9-_]+))?\\nRequired: No\\nCreationTime\\nThe date and time that the job was created (timestamp).\\nType: Timestamp\\nRequired: Yes\\nFailureReason\\nIf the LabelingJobStatus  ﬁeld is Failed, this ﬁeld contains a description of the error.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nRequired: No\\nInputConﬁg\\nInput conﬁguration for the labeling job.\\nType: LabelingJobInputConﬁg  (p. 945) object\\nRequired: No\\nLabelCounters\\nCounts showing the progress of the labeling job.\\nType: LabelCounters  (p. 936) object\\nRequired: Yes\\nLabelingJobArn\\nThe Amazon Resource Name (ARN) assigned to the labeling job when it was created.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:labeling-job/.*\\n951Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: Yes\\nLabelingJobName\\nThe name of the labeling job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nLabelingJobOutput\\nThe location of the output produced by the labeling job.\\nType: LabelingJobOutput  (p. 946) object\\nRequired: No\\nLabelingJobStatus\\nThe current status of the labeling job.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: Yes\\nLastModiﬁedTime\\nThe date and time that the job was last modiﬁed (timestamp).\\nType: Timestamp\\nRequired: Yes\\nPreHumanTaskLambdaArn\\nThe Amazon Resource Name (ARN) of a Lambda function. The function is run before each data\\nobject is sent to a worker.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:lambda:[a-z]{2}-[a-z]+-\\\\d{1}:\\\\d{12}:function:[a-zA-\\nZ0-9-_\\\\.]+(:(\\\\$LATEST|[a-zA-Z0-9-_]+))?\\nRequired: Yes\\nWorkteamArn\\nThe Amazon Resource Name (ARN) of the work team assigned to the job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:workteam/.*\\nRequired: Yes\\n952Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n953Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nMemberDeﬁnition\\nService: Amazon SageMaker Service\\nDeﬁnes the Amazon Cognito user group that is part of a work team.\\nContents\\nCognitoMemberDeﬁnition\\nThe Amazon Cognito user group that is part of the work team.\\nType: CognitoMemberDeﬁnition  (p. 883) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n954Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nMetricData\\nService: Amazon SageMaker Service\\nThe name, value, and date and time of a metric that was emitted to Amazon CloudWatch.\\nContents\\nMetricName\\nThe name of the metric.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: No\\nTimestamp\\nThe date and time that the algorithm emitted the metric.\\nType: Timestamp\\nRequired: No\\nValue\\nThe value of the metric.\\nType: Float\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n955Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nMetricDeﬁnition\\nService: Amazon SageMaker Service\\nSpeciﬁes a metric that the training algorithm writes to stderr  or stdout . Amazon\\nSageMakerhyperparameter tuning captures all deﬁned metrics. You specify one metric that a\\nhyperparameter tuning job uses as its objective metric to choose the best training job.\\nContents\\nName\\nThe name of the metric.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: Yes\\nRegex\\nA regular expression that searches the output of a training job and gets the value of the metric. For\\nmore information about using regular expressions to deﬁne metrics, see Deﬁning Objective Metrics.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 500.\\nPattern: .+\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n956Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelArtifacts\\nService: Amazon SageMaker Service\\nProvides information about the location that is conﬁgured for storing model artifacts.\\nContents\\nS3ModelArtifacts\\nThe path of the S3 object that contains the model artifacts. For example, s3://bucket-name/\\nkeynameprefix/model.tar.gz .\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n957Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelPackageContainerDeﬁnition\\nService: Amazon SageMaker Service\\nDescribes the Docker container for the model package.\\nContents\\nContainerHostname\\nThe DNS host name for the Docker container.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nImage\\nThe Amazon EC2 Container Registry (Amazon ECR) path where inference code is stored.\\nIf you are using your own custom algorithm instead of an algorithm provided by Amazon SageMaker,\\nthe inference code must meet Amazon SageMaker requirements. Amazon SageMaker supports both\\nregistry/repository[:tag]  and registry/repository[@digest]  image path formats. For\\nmore information, see Using Your Own Algorithms with Amazon SageMaker.\\nType: String\\nLength Constraints: Maximum length of 255.\\nPattern: [\\\\S]+\\nRequired: Yes\\nImageDigest\\nAn MD5 hash of the training algorithm that identiﬁes the Docker image used for training.\\nType: String\\nLength Constraints: Maximum length of 72.\\nPattern: ^[Ss][Hh][Aa]256:[0-9a-fA-F]{64}$\\nRequired: No\\nModelDataUrl\\nThe Amazon S3 path where the model artifacts, which result from model training, are stored. This\\npath must point to a single gzip compressed tar archive (.tar.gz  suﬃx).\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: No\\nProductId\\nThe AWS Marketplace product ID of the model package.\\n958Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n959Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelPackageStatusDetails\\nService: Amazon SageMaker Service\\nSpeciﬁes the validation and image scan statuses of the model package.\\nContents\\nImageScanStatuses\\nThe status of the scan of the Docker image container for the model package.\\nType: Array of ModelPackageStatusItem (p. 961) objects\\nRequired: No\\nValidationStatuses\\nThe validation status of the model package.\\nType: Array of ModelPackageStatusItem (p. 961) objects\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n960Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelPackageStatusItem\\nService: Amazon SageMaker Service\\nRepresents the overall status of a model package.\\nContents\\nFailureReason\\nif the overall status is Failed, the reason for the failure.\\nType: String\\nRequired: No\\nName\\nThe name of the model package for which the overall status is being reported.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nStatus\\nThe current status.\\nType: String\\nValid Values: NotStarted | InProgress | Completed | Failed\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n961Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelPackageSummary\\nService: Amazon SageMaker Service\\nProvides summary information about a model package.\\nContents\\nCreationTime\\nA timestamp that shows when the model package was created.\\nType: Timestamp\\nRequired: Yes\\nModelPackageArn\\nThe Amazon Resource Name (ARN) of the model package.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model-package/.*\\nRequired: Yes\\nModelPackageDescription\\nA brief description of the model package.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: [\\\\p{L}\\\\p{M}\\\\p{Z}\\\\p{S}\\\\p{N}\\\\p{P}]*\\nRequired: No\\nModelPackageName\\nThe name of the model package.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nModelPackageStatus\\nThe overall status of the model package.\\nType: String\\nValid Values: Pending | InProgress | Completed | Failed | Deleting\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n962Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n963Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelPackageValidationProﬁle\\nService: Amazon SageMaker Service\\nContains data, such as the inputs and targeted instance types that are used in the process of validating\\nthe model package.\\nThe data provided in the validation proﬁle is made available to your buyers on AWS Marketplace.\\nContents\\nProﬁleName\\nThe name of the proﬁle for the model package.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*$\\nRequired: Yes\\nTransformJobDeﬁnition\\nThe TransformJobDefinition  object that describes the transform job used for the validation of\\nthe model package.\\nType: TransformJobDeﬁnition (p. 1026 ) object\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n964Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelPackageValidationSpeciﬁcation\\nService: Amazon SageMaker Service\\nSpeciﬁes batch transform jobs that Amazon SageMaker runs to validate your model package.\\nContents\\nValidationProﬁles\\nAn array of ModelPackageValidationProfile  objects, each of which speciﬁes a batch transform\\njob that Amazon SageMaker runs to validate your model package.\\nType: Array of ModelPackageValidationProﬁle (p. 964) objects\\nArray Members: Fixed number of 1 item.\\nRequired: Yes\\nValidationRole\\nThe IAM roles to be used for the validation of the model package.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n965Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelSummary\\nService: Amazon SageMaker Service\\nProvides summary information about a model.\\nContents\\nCreationTime\\nA timestamp that indicates when the model was created.\\nType: Timestamp\\nRequired: Yes\\nModelArn\\nThe Amazon Resource Name (ARN) of the model.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:model/.*\\nRequired: Yes\\nModelName\\nThe name of the model that you want a summary for.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n966Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNestedFilters\\nService: Amazon SageMaker Service\\nDeﬁnes a list of NestedFilters  objects. To satisfy the conditions speciﬁed in the NestedFilters  call,\\na resource must satisfy the conditions of all of the ﬁlters.\\nFor example, you could deﬁne a NestedFilters  using the training job\\'s InputDataConfig  property\\nto ﬁlter on Channel objects.\\nA NestedFilters  object contains multiple ﬁlters. For example, to ﬁnd all training jobs whose name\\ncontains train and that have cat/data  in their S3Uri  (speciﬁed in InputDataConfig ), you need\\nto create a NestedFilters  object that speciﬁes the InputDataConfig  property with the following\\nFilter objects:\\n•\\'{Name:\"InputDataConfig.ChannelName\", \"Operator\":\"EQUALS\", \"Value\":\"train\"}\\',\\n•\\'{Name:\"InputDataConfig.DataSource.S3DataSource.S3Uri\",\\n\"Operator\":\"CONTAINS\", \"Value\":\"cat/data\"}\\'\\nContents\\nFilters\\nA list of ﬁlters. Each ﬁlter acts on a property. Filters must contain at least one Filters value. For\\nexample, a NestedFilters  call might include a ﬁlter on the PropertyName  parameter of the\\nInputDataConfig  property: InputDataConfig.DataSource.S3DataSource.S3Uri .\\nType: Array of Filter  (p. 901) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: Yes\\nNestedPropertyName\\nThe name of the property to use in the nested ﬁlters. The value must match a listed property name,\\nsuch as InputDataConfig  .\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n967Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNotebookInstanceLifecycleConﬁgSummary\\nService: Amazon SageMaker Service\\nProvides a summary of a notebook instance lifecycle conﬁguration.\\nContents\\nCreationTime\\nA timestamp that tells when the lifecycle conﬁguration was created.\\nType: Timestamp\\nRequired: No\\nLastModiﬁedTime\\nA timestamp that tells when the lifecycle conﬁguration was last modiﬁed.\\nType: Timestamp\\nRequired: No\\nNotebookInstanceLifecycleConﬁgArn\\nThe Amazon Resource Name (ARN) of the lifecycle conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 256.\\nRequired: Yes\\nNotebookInstanceLifecycleConﬁgName\\nThe name of the lifecycle conﬁguration.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n968Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNotebookInstanceLifecycleHook\\nService: Amazon SageMaker Service\\nContains the notebook instance lifecycle conﬁguration script.\\nEach lifecycle conﬁguration script has a limit of 16384 characters.\\nThe value of the $PATH environment variable that is available to both scripts is /sbin:bin:/usr/\\nsbin:/usr/bin .\\nView CloudWatch Logs for notebook instance lifecycle conﬁgurations in log group /aws/sagemaker/\\nNotebookInstances  in log stream [notebook-instance-name]/[LifecycleConfigHook] .\\nLifecycle conﬁguration scripts cannot run for longer than 5 minutes. If a script runs for longer than 5\\nminutes, it fails and the notebook instance is not created or started.\\nFor information about notebook instance lifestyle conﬁgurations, see Step 2.1: (Optional) Customize a\\nNotebook Instance.\\nContents\\nContent\\nA base64-encoded string that contains a shell script for a notebook instance lifecycle conﬁguration.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 16384.\\nPattern: [\\\\S\\\\s]+\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n969Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNotebookInstanceSummary\\nService: Amazon SageMaker Service\\nProvides summary information for an Amazon SageMaker notebook instance.\\nContents\\nAdditionalCodeRepositories\\nAn array of up to three Git repositories associated with the notebook instance. These can be either\\nthe names of Git repositories stored as resources in your account, or the URL of Git repositories in\\nAWS CodeCommit or in any other Git repository. These repositories are cloned at the same level\\nas the default repository of your notebook instance. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: Array of strings\\nArray Members: Maximum number of 3 items.\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nCreationTime\\nA timestamp that shows when the notebook instance was created.\\nType: Timestamp\\nRequired: No\\nDefaultCodeRepository\\nThe Git repository associated with the notebook instance as its default code repository. This can\\nbe either the name of a Git repository stored as a resource in your account, or the URL of a Git\\nrepository in AWS CodeCommit or in any other Git repository. When you open a notebook instance,\\nit opens in the directory that contains this repository. For more information, see Associating Git\\nRepositories with Amazon SageMaker Notebook Instances.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 1024.\\nPattern: ^https://([^/]+)/?(.*)$|^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nInstanceType\\nThe type of ML compute instance that the notebook instance is running on.\\nType: String\\nValid Values: ml.t2.medium | ml.t2.large | ml.t2.xlarge | ml.t2.2xlarge |\\nml.t3.medium | ml.t3.large | ml.t3.xlarge | ml.t3.2xlarge | ml.m4.xlarge\\n| ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge | ml.m4.16xlarge\\n| ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge | ml.m5.12xlarge\\n| ml.m5.24xlarge | ml.c4.xlarge | ml.c4.2xlarge | ml.c4.4xlarge |\\nml.c4.8xlarge | ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge\\n| ml.c5.18xlarge | ml.c5d.xlarge | ml.c5d.2xlarge | ml.c5d.4xlarge\\n970Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n| ml.c5d.9xlarge | ml.c5d.18xlarge | ml.p2.xlarge | ml.p2.8xlarge |\\nml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge\\nRequired: No\\nLastModiﬁedTime\\nA timestamp that shows when the notebook instance was last modiﬁed.\\nType: Timestamp\\nRequired: No\\nNotebookInstanceArn\\nThe Amazon Resource Name (ARN) of the notebook instance.\\nType: String\\nLength Constraints: Maximum length of 256.\\nRequired: Yes\\nNotebookInstanceLifecycleConﬁgName\\nThe name of a notebook instance lifecycle conﬁguration associated with this notebook instance.\\nFor information about notebook instance lifestyle conﬁgurations, see Step 2.1: (Optional) Customize\\na Notebook Instance.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nNotebookInstanceName\\nThe name of the notebook instance that you want a summary for.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nNotebookInstanceStatus\\nThe status of the notebook instance.\\nType: String\\nValid Values: Pending | InService | Stopping | Stopped | Failed | Deleting |\\nUpdating\\nRequired: No\\nUrl\\nThe URL that you use to connect to the Jupyter instance running in your notebook instance.\\nType: String\\n971Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n972Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nNotiﬁcationConﬁguration\\nService: Amazon SageMaker Service\\nConﬁgures SNS notiﬁcations of available or expiring work items for work teams.\\nContents\\nNotiﬁcationTopicArn\\nThe ARN for the SNS topic to which notiﬁcations should be published.\\nType: String\\nPattern: arn:aws[a-z\\\\-]*:sns:[a-z0-9\\\\-]*:[0-9]{12}:[a-zA-Z0-9_.-]*\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n973Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nObjectiveStatusCounters\\nService: Amazon SageMaker Service\\nSpeciﬁes the number of training jobs that this hyperparameter tuning job launched, categorized by the\\nstatus of their objective metric. The objective metric status shows whether the ﬁnal objective metric for\\nthe training job has been evaluated by the tuning job and used in the hyperparameter tuning process.\\nContents\\nFailed\\nThe number of training jobs whose ﬁnal objective metric was not evaluated and used in the\\nhyperparameter tuning process. This typically occurs when the training job failed or did not emit an\\nobjective metric.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nPending\\nThe number of training jobs that are in progress and pending evaluation of their ﬁnal objective\\nmetric.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nSucceeded\\nThe number of training jobs whose ﬁnal objective metric was evaluated by the hyperparameter\\ntuning job and used in the hyperparameter tuning process.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n974Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nOutputConﬁg\\nService: Amazon SageMaker Service\\nContains information about the output location for the compiled model and the device (target) that the\\nmodel runs on.\\nContents\\nS3OutputLocation\\nIdentiﬁes the S3 path where you want Amazon SageMaker to store the model artifacts. For example,\\ns3://bucket-name/key-name-preﬁx.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nTargetDevice\\nIdentiﬁes the device that you want to run your model on after it has been compiled. For example:\\nml_c5.\\nType: String\\nValid Values: lambda | ml_m4 | ml_m5 | ml_c4 | ml_c5 | ml_p2 | ml_p3 |\\njetson_tx1 | jetson_tx2 | jetson_nano | rasp3b | deeplens | rk3399 | rk3288\\n| aisage | sbe_c | qcs605 | qcs603\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n975Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nOutputDataConﬁg\\nService: Amazon SageMaker Service\\nProvides information about how to store model training results (model artifacts).\\nContents\\nKmsKeyId\\nThe AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the\\nmodel artifacts at rest using Amazon S3 server-side encryption. The KmsKeyId  can be any of the\\nfollowing formats:\\n•// KMS Key ID\\n\"1234abcd-12ab-34cd-56ef-1234567890ab\"\\n•// Amazon Resource Name (ARN) of a KMS Key\\n\"arn:aws:kms:us-\\nwest-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"\\n•// KMS Key Alias\\n\"alias/ExampleAlias\"\\n•// Amazon Resource Name (ARN) of a KMS Key Alias\\n\"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias\"\\nIf you use a KMS key ID or an alias of your master key, the Amazon SageMaker execution role must\\ninclude permissions to call kms:Encrypt . If you don\\'t provide a KMS key ID, Amazon SageMaker\\nuses the default KMS key for Amazon S3 for your role\\'s account. Amazon SageMaker uses server-\\nside encryption with KMS-managed keys for OutputDataConfig . If you use a bucket policy with an\\ns3:PutObject  permission that only allows objects with server-side encryption, set the condition\\nkey of s3:x-amz-server-side-encryption  to \"aws:kms\" . For more information, see KMS-\\nManaged Encryption Keys in the Amazon Simple Storage Service Developer Guide.\\nThe KMS key policy must grant permission to the IAM role that you specify in your\\nCreateTrainingJob , CreateTransformJob , or CreateHyperParameterTuningJob  requests.\\nFor more information, see Using Key Policies in AWS KMS in the AWS Key Management Service\\nDeveloper Guide .\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nS3OutputPath\\nIdentiﬁes the S3 path where you want Amazon SageMaker to store the model artifacts. For example,\\ns3://bucket-name/key-name-prefix .\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\n976Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n977Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nParameterRange\\nService: Amazon SageMaker Service\\nDeﬁnes the possible values for categorical, continuous, and integer hyperparameters to be used by an\\nalgorithm.\\nContents\\nCategoricalParameterRangeSpeciﬁcation\\nA CategoricalParameterRangeSpecification  object that deﬁnes the possible values for a\\ncategorical hyperparameter.\\nType: CategoricalParameterRangeSpeciﬁcation (p. 875) object\\nRequired: No\\nContinuousParameterRangeSpeciﬁcation\\nA ContinuousParameterRangeSpecification  object that deﬁnes the possible values for a\\ncontinuous hyperparameter.\\nType: ContinuousParameterRangeSpeciﬁcation (p. 890) object\\nRequired: No\\nIntegerParameterRangeSpeciﬁcation\\nA IntegerParameterRangeSpecification  object that deﬁnes the possible values for an integer\\nhyperparameter.\\nType: IntegerParameterRangeSpeciﬁcation (p. 935) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n978Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nParameterRanges\\nService: Amazon SageMaker Service\\nSpeciﬁes ranges of integer, continuous, and categorical hyperparameters that a hyperparameter tuning\\njob searches. The hyperparameter tuning job launches training jobs with hyperparameter values within\\nthese ranges to ﬁnd the combination of values that result in the training job with the best performance\\nas measured by the objective metric of the hyperparameter tuning job.\\nNote\\nYou can specify a maximum of 20 hyperparameters that a hyperparameter tuning job can search\\nover. Every possible value of a categorical parameter range counts against this limit.\\nContents\\nCategoricalParameterRanges\\nThe array of CategoricalParameterRange (p. 874) objects that specify ranges of categorical\\nhyperparameters that a hyperparameter tuning job searches.\\nType: Array of CategoricalParameterRange (p. 874) objects\\nArray Members: Minimum number of 0 items. Maximum number of 20 items.\\nRequired: No\\nContinuousParameterRanges\\nThe array of ContinuousParameterRange (p. 888) objects that specify ranges of continuous\\nhyperparameters that a hyperparameter tuning job searches.\\nType: Array of ContinuousParameterRange (p. 888) objects\\nArray Members: Minimum number of 0 items. Maximum number of 20 items.\\nRequired: No\\nIntegerParameterRanges\\nThe array of IntegerParameterRange (p. 933) objects that specify ranges of integer hyperparameters\\nthat a hyperparameter tuning job searches.\\nType: Array of IntegerParameterRange (p. 933) objects\\nArray Members: Minimum number of 0 items. Maximum number of 20 items.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n979Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nParentHyperParameterTuningJob\\nService: Amazon SageMaker Service\\nA previously completed or stopped hyperparameter tuning job to be used as a starting point for a new\\nhyperparameter tuning job.\\nContents\\nHyperParameterTuningJobName\\nThe name of the hyperparameter tuning job to be used as a starting point for a new hyperparameter\\ntuning job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 32.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n980Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nProductionVariant\\nService: Amazon SageMaker Service\\nIdentiﬁes a model that you want to host and the resources to deploy for hosting it. If you are deploying\\nmultiple models, tell Amazon SageMaker how to distribute traﬃc among the models by specifying\\nvariant weights.\\nContents\\nAcceleratorType\\nThe size of the Elastic Inference (EI) instance to use for the production variant. EI instances provide\\non-demand GPU computing for inference. For more information, see Using Elastic Inference in\\nAmazon SageMaker.\\nType: String\\nValid Values: ml.eia1.medium | ml.eia1.large | ml.eia1.xlarge\\nRequired: No\\nInitialInstanceCount\\nNumber of instances to launch initially.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: Yes\\nInitialVariantWeight\\nDetermines initial traﬃc distribution among all of the models that you specify in the endpoint\\nconﬁguration. The traﬃc to a production variant is determined by the ratio of the VariantWeight\\nto the sum of all VariantWeight  values across all ProductionVariants. If unspeciﬁed, it defaults to\\n1.0.\\nType: Float\\nValid Range: Minimum value of 0.\\nRequired: No\\nInstanceType\\nThe ML compute instance type.\\nType: String\\nValid Values: ml.t2.medium | ml.t2.large | ml.t2.xlarge | ml.t2.2xlarge\\n| ml.m4.xlarge | ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge |\\nml.m4.16xlarge | ml.m5.large | ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge\\n| ml.m5.12xlarge | ml.m5.24xlarge | ml.c4.large | ml.c4.xlarge |\\nml.c4.2xlarge | ml.c4.4xlarge | ml.c4.8xlarge | ml.p2.xlarge | ml.p2.8xlarge\\n| ml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge |\\nml.c5.large | ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge |\\nml.c5.18xlarge\\nRequired: Yes\\n981Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nModelName\\nThe name of the model that you want to host. This is the name that you speciﬁed when creating the\\nmodel.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nVariantName\\nThe name of the production variant.\\nType: String\\nLength Constraints: Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n982Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nProductionVariantSummary\\nService: Amazon SageMaker Service\\nDescribes weight and capacities for a production variant associated with an endpoint. If you sent a\\nrequest to the UpdateEndpointWeightsAndCapacities  API and the endpoint status is Updating ,\\nyou get diﬀerent desired and current values.\\nContents\\nCurrentInstanceCount\\nThe number of instances associated with the variant.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: No\\nCurrentWeight\\nThe weight associated with the variant.\\nType: Float\\nValid Range: Minimum value of 0.\\nRequired: No\\nDeployedImages\\nAn array of DeployedImage  objects that specify the Amazon EC2 Container Registry paths of the\\ninference images deployed on instances of this ProductionVariant .\\nType: Array of DeployedImage (p. 894) objects\\nRequired: No\\nDesiredInstanceCount\\nThe number of instances requested in the UpdateEndpointWeightsAndCapacities  request.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: No\\nDesiredWeight\\nThe requested weight, as speciﬁed in the UpdateEndpointWeightsAndCapacities  request.\\nType: Float\\nValid Range: Minimum value of 0.\\nRequired: No\\nVariantName\\nThe name of the variant.\\nType: String\\nLength Constraints: Maximum length of 63.\\n983Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n984Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nPropertyNameQuery\\nService: Amazon SageMaker Service\\nA type of SuggestionQuery . A suggestion query for retrieving property names that match the speciﬁed\\nhint.\\nContents\\nPropertyNameHint\\nText that is part of a property\\'s name. The property names of hyperparameter, metric, and tag key\\nnames that begin with the speciﬁed text in the PropertyNameHint .\\nType: String\\nLength Constraints: Minimum length of 0. Maximum length of 100.\\nPattern: .*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n985Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nPropertyNameSuggestion\\nService: Amazon SageMaker Service\\nA property name returned from a GetSearchSuggestions  call that speciﬁes a value in the\\nPropertyNameQuery  ﬁeld.\\nContents\\nPropertyName\\nA suggested property name based on what you entered in the search textbox in the Amazon\\nSageMaker console.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 255.\\nPattern: .+\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n986Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nPublicWorkforceTaskPrice\\nService: Amazon SageMaker Service\\nDeﬁnes the amount of money paid to an Amazon Mechanical Turk worker for each task performed.\\nUse one of the following prices for bounding box tasks. Prices are in US dollars and should be based on\\nthe complexity of the task; the longer it takes in your initial testing, the more you should oﬀer.\\n•0.036\\n•0.048\\n•0.060\\n•0.072\\n•0.120\\n•0.240\\n•0.360\\n•0.480\\n•0.600\\n•0.720\\n•0.840\\n•0.960\\n•1.080\\n•1.200\\nUse one of the following prices for image classiﬁcation, text classiﬁcation, and custom tasks. Prices are in\\nUS dollars.\\n•0.012\\n•0.024\\n•0.036\\n•0.048\\n•0.060\\n•0.072\\n•0.120\\n•0.240\\n•0.360\\n•0.480\\n•0.600\\n•0.720\\n•0.840\\n•0.960\\n•1.080\\n•1.200\\nUse one of the following prices for semantic segmentation tasks. Prices are in US dollars.\\n•0.840\\n•0.960\\n•1.080\\n987Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•1.200\\nContents\\nAmountInUsd\\nDeﬁnes the amount of money paid to an Amazon Mechanical Turk worker in United States dollars.\\nType: USD  (p. 1038 ) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n988Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRenderableTask\\nService: Amazon SageMaker Service\\nContains input values for a task.\\nContents\\nInput\\nA JSON object that contains values for the variables deﬁned in the template. It is made available\\nto the template under the substitution variable task.input . For example, if you deﬁne a variable\\ntask.input.text  in your template, you can supply the variable in the JSON object as \"text\":\\n\"sample text\" .\\nType: String\\nLength Constraints: Minimum length of 2. Maximum length of 128000.\\nPattern: [\\\\S\\\\s]+\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n989Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRenderingError\\nService: Amazon SageMaker Service\\nA description of an error that occurred while rendering the template.\\nContents\\nCode\\nA unique identiﬁer for a speciﬁc class of errors.\\nType: String\\nRequired: Yes\\nMessage\\nA human-readable message describing the error.\\nType: String\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n990Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResourceConﬁg\\nService: Amazon SageMaker Service\\nDescribes the resources, including ML compute instances and ML storage volumes, to use for model\\ntraining.\\nContents\\nInstanceCount\\nThe number of ML compute instances to use. For distributed training, provide a value greater than 1.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: Yes\\nInstanceType\\nThe ML compute instance type.\\nType: String\\nValid Values: ml.m4.xlarge | ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge\\n| ml.m4.16xlarge | ml.m5.large | ml.m5.xlarge | ml.m5.2xlarge |\\nml.m5.4xlarge | ml.m5.12xlarge | ml.m5.24xlarge | ml.c4.xlarge |\\nml.c4.2xlarge | ml.c4.4xlarge | ml.c4.8xlarge | ml.p2.xlarge | ml.p2.8xlarge\\n| ml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge\\n| ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge |\\nml.c5.18xlarge | ml.p3dn.24xlarge\\nRequired: Yes\\nVolumeKmsKeyId\\nThe AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data\\non the storage volume attached to the ML compute instance(s) that run the training job. The\\nVolumeKmsKeyId  can be any of the following formats:\\n•// KMS Key ID\\n\"1234abcd-12ab-34cd-56ef-1234567890ab\"\\n•// Amazon Resource Name (ARN) of a KMS Key\\n\"arn:aws:kms:us-\\nwest-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nVolumeSizeInGB\\nThe size of the ML storage volume that you want to provision.\\nML storage volumes store model artifacts and incremental states. Training algorithms might also\\nuse the ML storage volume for scratch space. If you want to store the training data in the ML storage\\nvolume, choose File  as the TrainingInputMode  in the algorithm speciﬁcation.\\n991Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nYou must specify suﬃcient ML storage for your scenario.\\nNote\\nAmazon SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n992Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nResourceLimits\\nService: Amazon SageMaker Service\\nSpeciﬁes the maximum number of training jobs and parallel training jobs that a hyperparameter tuning\\njob can launch.\\nContents\\nMaxNumberOfTrainingJobs\\nThe maximum number of training jobs that a hyperparameter tuning job can launch.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: Yes\\nMaxParallelTrainingJobs\\nThe maximum number of concurrent training jobs that a hyperparameter tuning job can launch.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n993Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nS3DataSource\\nService: Amazon SageMaker Service\\nDescribes the S3 data source.\\nContents\\nAttributeNames\\nA list of one or more attribute names to use that are found in a speciﬁed augmented manifest ﬁle.\\nType: Array of strings\\nArray Members: Maximum number of 16 items.\\nLength Constraints: Minimum length of 1. Maximum length of 256.\\nPattern: .+\\nRequired: No\\nS3DataDistributionType\\nIf you want Amazon SageMaker to replicate the entire dataset on each ML compute instance that is\\nlaunched for model training, specify FullyReplicated .\\nIf you want Amazon SageMaker to replicate a subset of data on each ML compute instance that\\nis launched for model training, specify ShardedByS3Key . If there are n ML compute instances\\nlaunched for a training job, each instance gets approximately 1/n of the number of S3 objects. In\\nthis case, model training on each machine uses only the subset of training data.\\nDon\\'t choose more ML compute instances for training than available S3 objects. If you do, some\\nnodes won\\'t get any data and you will pay for nodes that aren\\'t getting any training data. This\\napplies in both File and Pipe modes. Keep this in mind when developing algorithms.\\nIn distributed training, where you use multiple ML compute EC2 instances, you might choose\\nShardedByS3Key . If the algorithm requires copying training data to the ML storage volume (when\\nTrainingInputMode  is set to File), this copies 1/n of the number of objects.\\nType: String\\nValid Values: FullyReplicated | ShardedByS3Key\\nRequired: No\\nS3DataType\\nIf you choose S3Prefix , S3Uri identiﬁes a key name preﬁx. Amazon SageMaker uses all objects\\nthat match the speciﬁed key name preﬁx for model training.\\nIf you choose ManifestFile , S3Uri identiﬁes an object that is a manifest ﬁle containing a list of\\nobject keys that you want Amazon SageMaker to use for model training.\\nIf you choose AugmentedManifestFile , S3Uri identiﬁes an object that is an augmented\\nmanifest ﬁle in JSON lines format. This ﬁle contains the data you want to use for model training.\\nAugmentedManifestFile  can only be used if the Channel\\'s input mode is Pipe .\\nType: String\\nValid Values: ManifestFile | S3Prefix | AugmentedManifestFile\\nRequired: Yes\\n994Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nS3Uri\\nDepending on the value speciﬁed for the S3DataType , identiﬁes either a key name preﬁx or a\\nmanifest. For example:\\n•A key name preﬁx might look like this: s3://bucketname/exampleprefix .\\n•A manifest might look like this: s3://bucketname/example.manifest\\nThe manifest is an S3 object which is a JSON ﬁle with the following format:\\n[\\n{\"prefix\": \"s3://customer_bucket/some/prefix/\"},\\n\"relative/path/to/custdata-1\",\\n\"relative/path/custdata-2\",\\n...\\n]\\nThe preceding JSON matches the following s3Uris :\\ns3://customer_bucket/some/prefix/relative/path/to/custdata-1\\ns3://customer_bucket/some/prefix/relative/path/custdata-2\\n...\\nThe complete set of s3uris in this manifest is the input data for the channel for this datasource.\\nThe object that each s3uris points to must be readable by the IAM role that Amazon SageMaker\\nuses to perform tasks on your behalf.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n995Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSearchExpression\\nService: Amazon SageMaker Service\\nA multi-expression that searches for the speciﬁed resource or resources in a search. All resource objects\\nthat satisfy the expression\\'s condition are included in the search results. You must specify at least one\\nsubexpression, ﬁlter, or nested ﬁlter. A SearchExpression  can contain up to twenty elements.\\nA SearchExpression  contains the following components:\\n•A list of Filter objects. Each ﬁlter deﬁnes a simple Boolean expression comprised of a resource\\nproperty name, Boolean operator, and value.\\n•A list of NestedFilter  objects. Each nested ﬁlter deﬁnes a list of Boolean expressions using a list\\nof resource properties. A nested ﬁlter is satisﬁed if a single object in the list satisﬁes all Boolean\\nexpressions.\\n•A list of SearchExpression  objects. A search expression object can be nested in a list of search\\nexpression objects.\\n•A Boolean operator: And or Or.\\nContents\\nFilters\\nA list of ﬁlter objects.\\nType: Array of Filter  (p. 901) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No\\nNestedFilters\\nA list of nested ﬁlter objects.\\nType: Array of NestedFilters  (p. 967) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No\\nOperator\\nA Boolean operator used to evaluate the search expression. If you want every conditional statement\\nin all lists to be satisﬁed for the entire search expression to be true, specify And. If only a single\\nconditional statement needs to be true for the entire search expression to be true, specify Or. The\\ndefault value is And.\\nType: String\\nValid Values: And | Or\\nRequired: No\\nSubExpressions\\nA list of search expression objects.\\nType: Array of SearchExpression (p. 996) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\n996Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n997Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSearchRecord\\nService: Amazon SageMaker Service\\nAn individual search result record that contains a single resource object.\\nContents\\nTrainingJob\\nA TrainingJob  object that is returned as part of a Search request.\\nType: TrainingJob (p. 1009 ) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n998Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSecondaryStatusTransition\\nService: Amazon SageMaker Service\\nAn array element of DescribeTrainingJob:SecondaryStatusTransitions (p. 749). It provides additional\\ndetails about a status that the training job has transitioned through. A training job can be in one of\\nseveral states, for example, starting, downloading, training, or uploading. Within each state, there are\\na number of intermediate states. For example, within the starting state, Amazon SageMaker could be\\nstarting the training job or launching the ML instances. These transitional states are referred to as the\\njob\\'s secondary status.\\nContents\\nEndTime\\nA timestamp that shows when the training job transitioned out of this secondary status state into\\nanother secondary status state or when the training job has ended.\\nType: Timestamp\\nRequired: No\\nStartTime\\nA timestamp that shows when the training job transitioned to the current secondary status state.\\nType: Timestamp\\nRequired: Yes\\nStatus\\nContains a secondary status information from a training job.\\nStatus might be one of the following secondary statuses:\\nInProgress\\n•Starting  - Starting the training job.\\n•Downloading  - An optional stage for algorithms that support File  training input mode. It\\nindicates that data is being downloaded to the ML storage volumes.\\n•Training  - Training is in progress.\\n•Uploading  - Training is complete and the model artifacts are being uploaded to the S3\\nlocation.\\nCompleted\\n•Completed  - The training job has completed.\\nFailed\\n•Failed - The training job has failed. The reason for the failure is returned in the\\nFailureReason  ﬁeld of DescribeTrainingJobResponse .\\nStopped\\n•MaxRuntimeExceeded  - The job stopped because it exceeded the maximum allowed\\nruntime.\\n•Stopped  - The training job has stopped.\\nStopping\\n•Stopping  - Stopping the training job.\\nWe no longer support the following secondary statuses:\\n•LaunchingMLInstances\\n•PreparingTrainingStack\\n999Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•DownloadingTrainingImage\\nType: String\\nValid Values: Starting | LaunchingMLInstances | PreparingTrainingStack |\\nDownloading | DownloadingTrainingImage | Training | Uploading | Stopping\\n| Stopped | MaxRuntimeExceeded | Completed | Failed | Interrupted |\\nMaxWaitTimeExceeded\\nRequired: Yes\\nStatusMessage\\nA detailed description of the progress within a secondary status.\\nAmazon SageMaker provides secondary statuses and status messages that apply to each of them:\\nStarting\\n•Starting the training job.\\n•Launching requested ML instances.\\n•Insuﬃcient capacity error from EC2 while launching instances, retrying!\\n•Launched instance was unhealthy, replacing it!\\n•Preparing the instances for training.\\nTraining\\n•Downloading the training image.\\n•Training image download completed. Training in progress.\\nImportant\\nStatus messages are subject to change. Therefore, we recommend not including them in\\ncode that programmatically initiates actions. For examples, don\\'t use status messages in if\\nstatements.\\nTo have an overview of your training job\\'s progress, view TrainingJobStatus  and\\nSecondaryStatus  in DescribeTrainingJob (p. 744), and StatusMessage  together. For example, at\\nthe start of a training job, you might see the following:\\n•TrainingJobStatus  - InProgress\\n•SecondaryStatus  - Training\\n•StatusMessage  - Downloading the training image\\nType: String\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1000Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nShuﬄeConﬁg\\nService: Amazon SageMaker Service\\nA conﬁguration for a shuﬄe option for input data in a channel. If you use S3Prefix  for S3DataType ,\\nthe results of the S3 key preﬁx matches are shuﬄed. If you use ManifestFile , the order of the S3\\nobject references in the ManifestFile  is shuﬄed. If you use AugmentedManifestFile , the order of\\nthe JSON lines in the AugmentedManifestFile  is shuﬄed. The shuﬄing order is determined using the\\nSeed  value.\\nFor Pipe input mode, shuﬄing is done at the start of every epoch. With large datasets, this\\nensures that the order of the training data is diﬀerent for each epoch, and it helps reduce bias\\nand possible overﬁtting. In a multi-node training job when ShuffleConfig  is combined with\\nS3DataDistributionType  of ShardedByS3Key , the data is shuﬄed across nodes so that the content\\nsent to a particular node on the ﬁrst epoch might be sent to a diﬀerent node on the second epoch.\\nContents\\nSeed\\nDetermines the shuﬄing order in ShuffleConfig  value.\\nType: Long\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1001Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSourceAlgorithm\\nService: Amazon SageMaker Service\\nSpeciﬁes an algorithm that was used to create the model package. The algorithm must be either an\\nalgorithm resource in your Amazon SageMaker account or an algorithm in AWS Marketplace that you are\\nsubscribed to.\\nContents\\nAlgorithmName\\nThe name of an algorithm that was used to create the model package. The algorithm must be either\\nan algorithm resource in your Amazon SageMaker account or an algorithm in AWS Marketplace that\\nyou are subscribed to.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 170.\\nPattern: (arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:[a-z\\\\-]*\\\\/)?([a-zA-\\nZ0-9]([a-zA-Z0-9-]){0,62})(?<!-)$\\nRequired: Yes\\nModelDataUrl\\nThe Amazon S3 path where the model artifacts, which result from model training, are stored. This\\npath must point to a single gzip compressed tar archive (.tar.gz  suﬃx).\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1002Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSourceAlgorithmSpeciﬁcation\\nService: Amazon SageMaker Service\\nA list of algorithms that were used to create a model package.\\nContents\\nSourceAlgorithms\\nA list of the algorithms that were used to create a model package.\\nType: Array of SourceAlgorithm (p. 1002 ) objects\\nArray Members: Fixed number of 1 item.\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1003Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nStoppingCondition\\nService: Amazon SageMaker Service\\nSpeciﬁes a limit to how long a model training or compilation job can run. It also speciﬁes how long you\\nare willing to wait for a managed spot training job to complete. When the job reaches the time limit,\\nAmazon SageMaker ends the training or compilation job. Use this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job termination\\nfor 120 seconds. Algorithms can use this 120-second window to save the model artifacts, so the results\\nof training are not lost.\\nThe training algorithms provided by Amazon SageMaker automatically save the intermediate results\\nof a model training job when possible. This attempt to save artifacts is only a best eﬀort case as model\\nmight not be in a state from which it can be saved. For example, if training has just started, the model\\nmight not be ready to save. When saved, this intermediate data is a valid model artifact. You can use it to\\ncreate a model with CreateModel .\\nNote\\nThe Neural Topic Model (NTM) currently does not support saving intermediate model artifacts.\\nWhen training NTMs, make sure that the maximum runtime is suﬃcient for the training job to\\ncomplete.\\nContents\\nMaxRuntimeInSeconds\\nThe maximum length of time, in seconds, that the training or compilation job can run. If job does not\\ncomplete during this time, Amazon SageMaker ends the job. If value is not speciﬁed, default value is\\n1 day. The maximum value is 28 days.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: No\\nMaxWaitTimeInSeconds\\nThe maximum length of time, in seconds, how long you are willing to wait for a managed spot\\ntraining job to complete. It is the amount of time spent waiting for Spot capacity plus the amount of\\ntime the training job runs. It must be equal to or greater than MaxRuntimeInSeconds .\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1004Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSubscribedWorkteam\\nService: Amazon SageMaker Service\\nDescribes a work team of a vendor that does the a labelling job.\\nContents\\nListingId\\nType: String\\nRequired: No\\nMarketplaceDescription\\nThe description of the vendor from the Amazon Marketplace.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 200.\\nPattern: .+\\nRequired: No\\nMarketplaceTitle\\nThe title of the service provided by the vendor in the Amazon Marketplace.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 200.\\nPattern: .+\\nRequired: No\\nSellerName\\nThe name of the vendor in the Amazon Marketplace.\\nType: String\\nRequired: No\\nWorkteamArn\\nThe Amazon Resource Name (ARN) of the vendor that you have subscribed.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:workteam/.*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n1005Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1006Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSuggestionQuery\\nService: Amazon SageMaker Service\\nLimits the property names that are included in the response.\\nContents\\nPropertyNameQuery\\nA type of SuggestionQuery . Deﬁnes a property name hint. Only property names that match the\\nspeciﬁed hint are included in the response.\\nType: PropertyNameQuery (p. 985) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1007Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTag\\nService: Amazon SageMaker Service\\nDescribes a tag.\\nContents\\nKey\\nThe tag key.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 128.\\nPattern: ^([\\\\p{L}\\\\p{Z}\\\\p{N}_.:/=+\\\\-@]*)$\\nRequired: Yes\\nValue\\nThe tag value.\\nType: String\\nLength Constraints: Minimum length of 0. Maximum length of 256.\\nPattern: ^([\\\\p{L}\\\\p{Z}\\\\p{N}_.:/=+\\\\-@]*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1008Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTrainingJob\\nService: Amazon SageMaker Service\\nContains information about a training job.\\nContents\\nAlgorithmSpeciﬁcation\\nInformation about the algorithm used for training, and algorithm metadata.\\nType: AlgorithmSpeciﬁcation  (p. 863) object\\nRequired: No\\nCreationTime\\nA timestamp that indicates when the training job was created.\\nType: Timestamp\\nRequired: No\\nEnableInterContainerTraﬃcEncryption\\nTo encrypt all communications between ML compute instances in distributed training, choose True .\\nEncryption provides greater security for distributed training, but training might take longer. How\\nlong it takes depends on the amount of communication between compute instances, especially if\\nyou use a deep learning algorithm in distributed training.\\nType: Boolean\\nRequired: No\\nEnableNetworkIsolation\\nIf the TrainingJob  was created with network isolation, the value is set to true. If network\\nisolation is enabled, nodes can\\'t communicate beyond the VPC they run in.\\nType: Boolean\\nRequired: No\\nFailureReason\\nIf the training job failed, the reason it failed.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nRequired: No\\nFinalMetricDataList\\nA list of ﬁnal metric values that are set when the training job completes. Used only if the training job\\nwas conﬁgured to use metrics.\\nType: Array of MetricData  (p. 955) objects\\nArray Members: Minimum number of 0 items. Maximum number of 40 items.\\nRequired: No\\n1009Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nHyperParameters\\nAlgorithm-speciﬁc parameters.\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nInputDataConﬁg\\nAn array of Channel objects that describes each data input channel.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: No\\nLabelingJobArn\\nThe Amazon Resource Name (ARN) of the labeling job.\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:labeling-job/.*\\nRequired: No\\nLastModiﬁedTime\\nA timestamp that indicates when the status of the training job was last modiﬁed.\\nType: Timestamp\\nRequired: No\\nModelArtifacts\\nInformation about the Amazon S3 location that is conﬁgured for storing model artifacts.\\nType: ModelArtifacts (p. 957) object\\nRequired: No\\nOutputDataConﬁg\\nThe S3 path where model artifacts that you conﬁgured when creating the job are stored. Amazon\\nSageMaker creates subfolders for model artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: No\\nResourceConﬁg\\nResources, including ML compute instances and ML storage volumes, that are conﬁgured for model\\ntraining.\\n1010Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: ResourceConﬁg (p. 991) object\\nRequired: No\\nRoleArn\\nThe AWS Identity and Access Management (IAM) role conﬁgured for the training job.\\nType: String\\nLength Constraints: Minimum length of 20. Maximum length of 2048.\\nPattern: ^arn:aws[a-z\\\\-]*:iam::\\\\d{12}:role/?[a-zA-Z_0-9+=,.@\\\\-_/]+$\\nRequired: No\\nSecondaryStatus\\nProvides detailed information about the state of the training job. For detailed information about the\\nsecondary status of the training job, see StatusMessage  under SecondaryStatusTransition (p. 999).\\nAmazon SageMaker provides primary statuses and secondary statuses that apply to each of them:\\nInProgress\\n•Starting  - Starting the training job.\\n•Downloading  - An optional stage for algorithms that support File  training input mode. It\\nindicates that data is being downloaded to the ML storage volumes.\\n•Training  - Training is in progress.\\n•Uploading  - Training is complete and the model artifacts are being uploaded to the S3\\nlocation.\\nCompleted\\n•Completed  - The training job has completed.\\nFailed\\n•Failed - The training job has failed. The reason for the failure is returned in the\\nFailureReason  ﬁeld of DescribeTrainingJobResponse .\\nStopped\\n•MaxRuntimeExceeded  - The job stopped because it exceeded the maximum allowed\\nruntime.\\n•Stopped  - The training job has stopped.\\nStopping\\n•Stopping  - Stopping the training job.\\nImportant\\nValid values for SecondaryStatus  are subject to change.\\nWe no longer support the following secondary statuses:\\n•LaunchingMLInstances\\n•PreparingTrainingStack\\n•DownloadingTrainingImage\\nType: String\\nValid Values: Starting | LaunchingMLInstances | PreparingTrainingStack |\\nDownloading | DownloadingTrainingImage | Training | Uploading | Stopping\\n| Stopped | MaxRuntimeExceeded | Completed | Failed | Interrupted |\\nMaxWaitTimeExceeded\\nRequired: No\\n1011Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSecondaryStatusTransitions\\nA history of all of the secondary statuses that the training job has transitioned through.\\nType: Array of SecondaryStatusTransition (p. 999) objects\\nRequired: No\\nStoppingCondition\\nSpeciﬁes a limit to how long a model training job can run. When the job reaches the time limit,\\nAmazon SageMaker ends the training job. Use this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job\\ntermination for 120 seconds. Algorithms can use this 120-second window to save the model\\nartifacts, so the results of training are not lost.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: No\\nTags\\nAn array of key-value pairs. For more information, see Using Cost Allocation Tags in the AWS Billing\\nand Cost Management User Guide .\\nType: Array of Tag (p. 1008 ) objects\\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\\nRequired: No\\nTrainingEndTime\\nIndicates the time when the training job ends on training instances. You are billed for the time\\ninterval between the value of TrainingStartTime  and this time. For successful jobs and stopped\\njobs, this is the time after model artifacts are uploaded. For failed jobs, this is the time when\\nAmazon SageMaker detects a job failure.\\nType: Timestamp\\nRequired: No\\nTrainingJobArn\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-job/.*\\nRequired: No\\nTrainingJobName\\nThe name of the training job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\n1012Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: No\\nTrainingJobStatus\\nThe status of the training job.\\nTraining job statuses are:\\n•InProgress  - The training is in progress.\\n•Completed  - The training job has completed.\\n•Failed - The training job has failed. To see the reason for the failure, see the FailureReason\\nﬁeld in the response to a DescribeTrainingJobResponse  call.\\n•Stopping  - The training job is stopping.\\n•Stopped  - The training job has stopped.\\nFor more detailed information, see SecondaryStatus .\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: No\\nTrainingStartTime\\nIndicates the time when the training job starts on training instances. You are billed for the time\\ninterval between this time and the value of TrainingEndTime . The start time in CloudWatch Logs\\nmight be later than this time. The diﬀerence is due to the time it takes to download the training data\\nand to the size of the training container.\\nType: Timestamp\\nRequired: No\\nTuningJobArn\\nThe Amazon Resource Name (ARN) of the associated hyperparameter tuning job if the training job\\nwas launched by a hyperparameter tuning job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:hyper-parameter-\\ntuning-job/.*\\nRequired: No\\nVpcConﬁg\\nA VpcConﬁg (p. 1039 ) object that speciﬁes the VPC that this training job has access to. For more\\ninformation, see Protect Training Jobs by Using an Amazon Virtual Private Cloud.\\nType: VpcConﬁg (p. 1039 ) object\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n1013Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1014Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTrainingJobDeﬁnition\\nService: Amazon SageMaker Service\\nDeﬁnes the input needed to run a training job using the algorithm.\\nContents\\nHyperParameters\\nThe hyperparameters used for the training job.\\nType: String to string map\\nKey Length Constraints: Maximum length of 256.\\nKey Pattern: .*\\nValue Length Constraints: Maximum length of 256.\\nValue Pattern: .*\\nRequired: No\\nInputDataConﬁg\\nAn array of Channel objects, each of which speciﬁes an input source.\\nType: Array of Channel  (p. 876) objects\\nArray Members: Minimum number of 1 item. Maximum number of 20 items.\\nRequired: Yes\\nOutputDataConﬁg\\nthe path to the S3 bucket where you want to store model artifacts. Amazon SageMaker creates\\nsubfolders for the artifacts.\\nType: OutputDataConﬁg  (p. 976) object\\nRequired: Yes\\nResourceConﬁg\\nThe resources, including the ML compute instances and ML storage volumes, to use for model\\ntraining.\\nType: ResourceConﬁg (p. 991) object\\nRequired: Yes\\nStoppingCondition\\nSpeciﬁes a limit to how long a model training job can run. When the job reaches the time limit,\\nAmazon SageMaker ends the training job. Use this API to cap model training costs.\\nTo stop a job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job\\ntermination for 120 seconds. Algorithms can use this 120-second window to save the model\\nartifacts.\\nType: StoppingCondition  (p. 1004 ) object\\nRequired: Yes\\n1015Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTrainingInputMode\\nThe input mode used by the algorithm for the training job. For the input modes that Amazon\\nSageMaker algorithms support, see Algorithms .\\nIf an algorithm supports the File input mode, Amazon SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage Volume, and mounts the directory to docker volume for\\ntraining container. If an algorithm supports the Pipe input mode, Amazon SageMaker streams data\\ndirectly from S3 to the container.\\nType: String\\nValid Values: Pipe | File\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1016Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTrainingJobStatusCounters\\nService: Amazon SageMaker Service\\nThe numbers of training jobs launched by a hyperparameter tuning job, categorized by status.\\nContents\\nCompleted\\nThe number of completed training jobs launched by the hyperparameter tuning job.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nInProgress\\nThe number of in-progress training jobs launched by a hyperparameter tuning job.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nNonRetryableError\\nThe number of training jobs that failed and can\\'t be retried. A failed training job can\\'t be retried if it\\nfailed because a client error occurred.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nRetryableError\\nThe number of training jobs that failed, but can be retried. A failed training job can be retried only if\\nit failed because an internal service error occurred.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nStopped\\nThe number of training jobs launched by a hyperparameter tuning job that were manually stopped.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n1017Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1018Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTrainingJobSummary\\nService: Amazon SageMaker Service\\nProvides summary information about a training job.\\nContents\\nCreationTime\\nA timestamp that shows when the training job was created.\\nType: Timestamp\\nRequired: Yes\\nLastModiﬁedTime\\nTimestamp when the training job was last modiﬁed.\\nType: Timestamp\\nRequired: No\\nTrainingEndTime\\nA timestamp that shows when the training job ended. This ﬁeld is set only if the training job has one\\nof the terminal statuses ( Completed , Failed , or Stopped ).\\nType: Timestamp\\nRequired: No\\nTrainingJobArn\\nThe Amazon Resource Name (ARN) of the training job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:training-job/.*\\nRequired: Yes\\nTrainingJobName\\nThe name of the training job that you want a summary for.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nTrainingJobStatus\\nThe status of the training job.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: Yes\\n1019Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1020Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTrainingSpeciﬁcation\\nService: Amazon SageMaker Service\\nDeﬁnes how the algorithm is used for a training job.\\nContents\\nMetricDeﬁnitions\\nA list of MetricDefinition  objects, which are used for parsing metrics generated by the\\nalgorithm.\\nType: Array of MetricDeﬁnition  (p. 956) objects\\nArray Members: Minimum number of 0 items. Maximum number of 40 items.\\nRequired: No\\nSupportedHyperParameters\\nA list of the HyperParameterSpecification  objects, that deﬁne the supported hyperparameters.\\nThis is required if the algorithm supports automatic model tuning.>\\nType: Array of HyperParameterSpeciﬁcation (p. 914) objects\\nArray Members: Minimum number of 0 items. Maximum number of 100 items.\\nRequired: No\\nSupportedTrainingInstanceTypes\\nA list of the instance types that this algorithm can use for training.\\nType: Array of strings\\nValid Values: ml.m4.xlarge | ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge\\n| ml.m4.16xlarge | ml.m5.large | ml.m5.xlarge | ml.m5.2xlarge |\\nml.m5.4xlarge | ml.m5.12xlarge | ml.m5.24xlarge | ml.c4.xlarge |\\nml.c4.2xlarge | ml.c4.4xlarge | ml.c4.8xlarge | ml.p2.xlarge | ml.p2.8xlarge\\n| ml.p2.16xlarge | ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge\\n| ml.c5.xlarge | ml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge |\\nml.c5.18xlarge | ml.p3dn.24xlarge\\nRequired: Yes\\nSupportedTuningJobObjectiveMetrics\\nA list of the metrics that the algorithm emits that can be used as the objective metric in a\\nhyperparameter tuning job.\\nType: Array of HyperParameterTuningJobObjective (p. 924) objects\\nRequired: No\\nSupportsDistributedTraining\\nIndicates whether the algorithm supports distributed training. If set to false, buyers can’t request\\nmore than one instance during training.\\nType: Boolean\\nRequired: No\\n1021Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTrainingChannels\\nA list of ChannelSpecification  objects, which specify the input sources to be used by the\\nalgorithm.\\nType: Array of ChannelSpeciﬁcation  (p. 878) objects\\nArray Members: Minimum number of 1 item. Maximum number of 8 items.\\nRequired: Yes\\nTrainingImage\\nThe Amazon ECR registry path of the Docker image that contains the training algorithm.\\nType: String\\nLength Constraints: Maximum length of 255.\\nPattern: [\\\\S]+\\nRequired: Yes\\nTrainingImageDigest\\nAn MD5 hash of the training algorithm that identiﬁes the Docker image used for training.\\nType: String\\nLength Constraints: Maximum length of 72.\\nPattern: ^[Ss][Hh][Aa]256:[0-9a-fA-F]{64}$\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1022Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTransformDataSource\\nService: Amazon SageMaker Service\\nDescribes the location of the channel data.\\nContents\\nS3DataSource\\nThe S3 location of the data source that is associated with a channel.\\nType: TransformS3DataSource (p. 1034 ) object\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1023Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTransformInput\\nService: Amazon SageMaker Service\\nDescribes the input source of a transform job and the way the transform job consumes it.\\nContents\\nCompressionType\\nIf your transform data is compressed, specify the compression type. Amazon SageMaker\\nautomatically decompresses the data for the transform job accordingly. The default value is None .\\nType: String\\nValid Values: None | Gzip\\nRequired: No\\nContentType\\nThe multipurpose internet mail extension (MIME) type of the data. Amazon SageMaker uses the\\nMIME type with each http call to transfer data to the transform job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: No\\nDataSource\\nDescribes the location of the channel data, which is, the S3 location of the input data that the model\\ncan consume.\\nType: TransformDataSource (p. 1023 ) object\\nRequired: Yes\\nSplitType\\nThe method to use to split the transform job\\'s data ﬁles into smaller batches. Splitting is necessary\\nwhen the total size of each object is too large to ﬁt in a single request. You can also use data\\nsplitting to improve performance by processing multiple concurrent mini-batches. The default value\\nfor SplitType  is None, which indicates that input data ﬁles are not split, and request payloads\\ncontain the entire contents of an input object. Set the value of this parameter to Line  to split\\nrecords on a newline character boundary. SplitType  also supports a number of record-oriented\\nbinary data formats.\\nWhen splitting is enabled, the size of a mini-batch depends on the values of the BatchStrategy\\nand MaxPayloadInMB  parameters. When the value of BatchStrategy  is MultiRecord , Amazon\\nSageMaker sends the maximum number of records in each request, up to the MaxPayloadInMB\\nlimit. If the value of BatchStrategy  is SingleRecord , Amazon SageMaker sends individual\\nrecords in each request.\\nNote\\nSome data formats represent a record as a binary payload wrapped with extra padding\\nbytes. When splitting is applied to a binary data format, padding is removed if the value\\nof BatchStrategy  is set to SingleRecord . Padding is not removed if the value of\\nBatchStrategy  is set to MultiRecord .\\n1024Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nFor more information about the RecordIO, see Data Format in the MXNet documentation.\\nFor more information about the TFRecord, see Consuming TFRecord data in the TensorFlow\\ndocumentation.\\nType: String\\nValid Values: None | Line | RecordIO | TFRecord\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1025Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTransformJobDeﬁnition\\nService: Amazon SageMaker Service\\nDeﬁnes the input needed to run a transform job using the inference speciﬁcation speciﬁed in the\\nalgorithm.\\nContents\\nBatchStrategy\\nA string that determines the number of records included in a single mini-batch.\\nSingleRecord  means only one record is used per mini-batch. MultiRecord  means a mini-batch is\\nset to contain as many records that can ﬁt within the MaxPayloadInMB  limit.\\nType: String\\nValid Values: MultiRecord | SingleRecord\\nRequired: No\\nEnvironment\\nThe environment variables to set in the Docker container. We support up to 16 key and values\\nentries in the map.\\nType: String to string map\\nKey Length Constraints: Maximum length of 1024.\\nKey Pattern: [a-zA-Z_][a-zA-Z0-9_]*\\nValue Length Constraints: Maximum length of 10240.\\nValue Pattern: [\\\\S\\\\s]*\\nRequired: No\\nMaxConcurrentTransforms\\nThe maximum number of parallel requests that can be sent to each instance in a transform job. The\\ndefault value is 1.\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nMaxPayloadInMB\\nThe maximum payload size allowed, in MB. A payload is the data portion of a record (without\\nmetadata).\\nType: Integer\\nValid Range: Minimum value of 0.\\nRequired: No\\nTransformInput\\nA description of the input source and the way the transform job consumes it.\\n1026Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nType: TransformInput (p. 1024 ) object\\nRequired: Yes\\nTransformOutput\\nIdentiﬁes the Amazon S3 location where you want Amazon SageMaker to save the results from the\\ntransform job.\\nType: TransformOutput (p. 1030 ) object\\nRequired: Yes\\nTransformResources\\nIdentiﬁes the ML compute instances for the transform job.\\nType: TransformResources (p. 1032 ) object\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1027Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTransformJobSummary\\nService: Amazon SageMaker Service\\nProvides a summary of a transform job. Multiple TransformJobSummary  objects are returned as a list\\nafter in response to a ListTransformJobs (p. 811) call.\\nContents\\nCreationTime\\nA timestamp that shows when the transform Job was created.\\nType: Timestamp\\nRequired: Yes\\nFailureReason\\nIf the transform job failed, the reason it failed.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nRequired: No\\nLastModiﬁedTime\\nIndicates when the transform job was last modiﬁed.\\nType: Timestamp\\nRequired: No\\nTransformEndTime\\nIndicates when the transform job ends on compute instances. For successful jobs and stopped jobs,\\nthis is the exact time recorded after the results are uploaded. For failed jobs, this is when Amazon\\nSageMaker detected that the job failed.\\nType: Timestamp\\nRequired: No\\nTransformJobArn\\nThe Amazon Resource Name (ARN) of the transform job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:transform-job/.*\\nRequired: Yes\\nTransformJobName\\nThe name of the transform job.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\n1028Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nRequired: Yes\\nTransformJobStatus\\nThe status of the transform job.\\nType: String\\nValid Values: InProgress | Completed | Failed | Stopping | Stopped\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1029Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTransformOutput\\nService: Amazon SageMaker Service\\nDescribes the results of a transform job.\\nContents\\nAccept\\nThe MIME type used to specify the output data. Amazon SageMaker uses the MIME type with each\\nhttp call to transfer data from the transform job.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: .*\\nRequired: No\\nAssembleWith\\nDeﬁnes how to assemble the results of the transform job as a single S3 object. Choose a format\\nthat is most convenient to you. To concatenate the results in binary format, specify None. To add a\\nnewline character at the end of every transformed record, specify Line .\\nType: String\\nValid Values: None | Line\\nRequired: No\\nKmsKeyId\\nThe AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt the\\nmodel artifacts at rest using Amazon S3 server-side encryption. The KmsKeyId  can be any of the\\nfollowing formats:\\n•// KMS Key ID\\n\"1234abcd-12ab-34cd-56ef-1234567890ab\"\\n•// Amazon Resource Name (ARN) of a KMS Key\\n\"arn:aws:kms:us-\\nwest-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"\\n•// KMS Key Alias\\n\"alias/ExampleAlias\"\\n•// Amazon Resource Name (ARN) of a KMS Key Alias\\n\"arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias\"\\nIf you don\\'t provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3 for\\nyour role\\'s account. For more information, see KMS-Managed Encryption Keys in the Amazon Simple\\nStorage Service Developer Guide.\\nThe KMS key policy must grant permission to the IAM role that you specify in your\\nCreateTramsformJob  request. For more information, see Using Key Policies in AWS KMS in the\\nAWS Key Management Service Developer Guide.\\nType: String\\n1030Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nS3OutputPath\\nThe Amazon S3 path where you want Amazon SageMaker to store the results of the transform job.\\nFor example, s3://bucket-name/key-name-prefix .\\nFor every S3 object used as input for the transform job, batch transform stores the transformed data\\nwith an .out suﬃx in a corresponding subfolder in the location in the output preﬁx. For example,\\nfor the input data stored at s3://bucket-name/input-name-prefix/dataset01/data.csv ,\\nbatch transform stores the transformed data at s3://bucket-name/output-name-prefix/\\ninput-name-prefix/data.csv.out . Batch transform doesn\\'t upload partially processed objects.\\nFor an input S3 object that contains multiple records, it creates an .out ﬁle only if the transform job\\nsucceeds on the entire ﬁle. When the input contains multiple S3 objects, the batch transform job\\nprocesses the listed S3 objects and uploads only the output for successfully processed objects. If any\\nobject fails in the transform job batch transform marks the job as failed to prompt investigation.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1031Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTransformResources\\nService: Amazon SageMaker Service\\nDescribes the resources, including ML instance types and ML instance count, to use for transform job.\\nContents\\nInstanceCount\\nThe number of ML compute instances to use in the transform job. For distributed transform jobs,\\nspecify a value greater than 1. The default value is 1.\\nType: Integer\\nValid Range: Minimum value of 1.\\nRequired: Yes\\nInstanceType\\nThe ML compute instance type for the transform job. If you are using built-in algorithms to\\ntransform moderately sized datasets, we recommend using ml.m4.xlarge or ml.m5.large  instance\\ntypes.\\nType: String\\nValid Values: ml.m4.xlarge | ml.m4.2xlarge | ml.m4.4xlarge | ml.m4.10xlarge\\n| ml.m4.16xlarge | ml.c4.xlarge | ml.c4.2xlarge | ml.c4.4xlarge\\n| ml.c4.8xlarge | ml.p2.xlarge | ml.p2.8xlarge | ml.p2.16xlarge\\n| ml.p3.2xlarge | ml.p3.8xlarge | ml.p3.16xlarge | ml.c5.xlarge |\\nml.c5.2xlarge | ml.c5.4xlarge | ml.c5.9xlarge | ml.c5.18xlarge | ml.m5.large\\n| ml.m5.xlarge | ml.m5.2xlarge | ml.m5.4xlarge | ml.m5.12xlarge |\\nml.m5.24xlarge\\nRequired: Yes\\nVolumeKmsKeyId\\nThe AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to encrypt data on\\nthe storage volume attached to the ML compute instance(s) that run the batch transform job. The\\nVolumeKmsKeyId  can be any of the following formats:\\n•// KMS Key ID\\n\"1234abcd-12ab-34cd-56ef-1234567890ab\"\\n•// Amazon Resource Name (ARN) of a KMS Key\\n\"arn:aws:kms:us-\\nwest-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\"\\nType: String\\nLength Constraints: Maximum length of 2048.\\nPattern: .*\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n1032Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1033Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nTransformS3DataSource\\nService: Amazon SageMaker Service\\nDescribes the S3 data source.\\nContents\\nS3DataType\\nIf you choose S3Prefix , S3Uri identiﬁes a key name preﬁx. Amazon SageMaker uses all objects\\nwith the speciﬁed key name preﬁx for batch transform.\\nIf you choose ManifestFile , S3Uri identiﬁes an object that is a manifest ﬁle containing a list of\\nobject keys that you want Amazon SageMaker to use for batch transform.\\nThe following values are compatible: ManifestFile , S3Prefix\\nThe following value is not compatible: AugmentedManifestFile\\nType: String\\nValid Values: ManifestFile | S3Prefix | AugmentedManifestFile\\nRequired: Yes\\nS3Uri\\nDepending on the value speciﬁed for the S3DataType , identiﬁes either a key name preﬁx or a\\nmanifest. For example:\\n•A key name preﬁx might look like this: s3://bucketname/exampleprefix .\\n•A manifest might look like this: s3://bucketname/example.manifest\\nThe manifest is an S3 object which is a JSON ﬁle with the following format:\\n[\\n{\"prefix\": \"s3://customer_bucket/some/prefix/\"},\\n\"relative/path/to/custdata-1\",\\n\"relative/path/custdata-2\",\\n...\\n]\\nThe preceding JSON matches the following S3Uris :\\ns3://customer_bucket/some/prefix/relative/path/to/custdata-1\\ns3://customer_bucket/some/prefix/relative/path/custdata-1\\n...\\nThe complete set of S3Uris in this manifest constitutes the input data for the channel for this\\ndatasource. The object that each S3Uris points to must be readable by the IAM role that Amazon\\nSageMaker uses to perform tasks on your behalf.\\nType: String\\nLength Constraints: Maximum length of 1024.\\n1034Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1035Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUiConﬁg\\nService: Amazon SageMaker Service\\nProvided conﬁguration information for the worker UI for a labeling job.\\nContents\\nUiTemplateS3Uri\\nThe Amazon S3 bucket location of the UI template. For more information about the contents of a UI\\ntemplate, see  Creating Your Custom Labeling Task Template.\\nType: String\\nLength Constraints: Maximum length of 1024.\\nPattern: ^(https|s3)://([^/]+)/?(.*)$\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1036Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUiTemplate\\nService: Amazon SageMaker Service\\nThe Liquid template for the worker user interface.\\nContents\\nContent\\nThe content of the Liquid template for the worker user interface.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 128000.\\nPattern: [\\\\S\\\\s]+\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1037Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nUSD\\nService: Amazon SageMaker Service\\nRepresents an amount of money in United States dollars/\\nContents\\nCents\\nThe fractional portion, in cents, of the amount.\\nType: Integer\\nValid Range: Minimum value of 0. Maximum value of 99.\\nRequired: No\\nDollars\\nThe whole number of dollars in the amount.\\nType: Integer\\nValid Range: Minimum value of 0. Maximum value of 1.\\nRequired: No\\nTenthFractionsOfACent\\nFractions of a cent, in tenths.\\nType: Integer\\nValid Range: Minimum value of 0. Maximum value of 9.\\nRequired: No\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1038Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nVpcConﬁg\\nService: Amazon SageMaker Service\\nSpeciﬁes a VPC that your training jobs and hosted models have access to. Control access to and from\\nyour training and model containers by conﬁguring the VPC. For more information, see Protect Endpoints\\nby Using an Amazon Virtual Private Cloud and Protect Training Jobs by Using an Amazon Virtual Private\\nCloud .\\nContents\\nSecurityGroupIds\\nThe VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups for the VPC that is\\nspeciﬁed in the Subnets  ﬁeld.\\nType: Array of strings\\nArray Members: Minimum number of 1 item. Maximum number of 5 items.\\nLength Constraints: Maximum length of 32.\\nPattern: [-0-9a-zA-Z]+\\nRequired: Yes\\nSubnets\\nThe ID of the subnets in the VPC to which you want to connect your training job or model.\\nNote\\nAmazon EC2 P3 accelerated computing instances are not available in the c/d/e availability\\nzones of region us-east-1. If you want to create endpoints with P3 instances in VPC mode in\\nregion us-east-1, create subnets in a/b/f availability zones instead.\\nType: Array of strings\\nArray Members: Minimum number of 1 item. Maximum number of 16 items.\\nLength Constraints: Maximum length of 32.\\nPattern: [-0-9a-zA-Z]+\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\n1039Amazon SageMaker Developer Guide\\nAmazon SageMaker Service\\nWorkteam\\nService: Amazon SageMaker Service\\nProvides details about a labeling work team.\\nContents\\nCreateDate\\nThe date and time that the work team was created (timestamp).\\nType: Timestamp\\nRequired: No\\nDescription\\nA description of the work team.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 200.\\nPattern: .+\\nRequired: Yes\\nLastUpdatedDate\\nThe date and time that the work team was last updated (timestamp).\\nType: Timestamp\\nRequired: No\\nMemberDeﬁnitions\\nThe Amazon Cognito user groups that make up the work team.\\nType: Array of MemberDeﬁnition  (p. 954) objects\\nArray Members: Minimum number of 1 item. Maximum number of 10 items.\\nRequired: Yes\\nNotiﬁcationConﬁguration\\nConﬁgures SNS notiﬁcations of available or expiring work items for work teams.\\nType: NotiﬁcationConﬁguration  (p. 973) object\\nRequired: No\\nProductListingIds\\nThe Amazon Marketplace identiﬁer for a vendor\\'s work team.\\nType: Array of strings\\nRequired: No\\nSubDomain\\nThe URI of the labeling job\\'s user interface. Workers open this URI to start labeling your data objects.\\nType: String\\n1040Amazon SageMaker Developer Guide\\nAmazon SageMaker Runtime\\nRequired: No\\nWorkteamArn\\nThe Amazon Resource Name (ARN) that identiﬁes the work team.\\nType: String\\nLength Constraints: Maximum length of 256.\\nPattern: arn:aws[a-z\\\\-]*:sagemaker:[a-z0-9\\\\-]*:[0-9]{12}:workteam/.*\\nRequired: Yes\\nWorkteamName\\nThe name of the work team.\\nType: String\\nLength Constraints: Minimum length of 1. Maximum length of 63.\\nPattern: ^[a-zA-Z0-9](-*[a-zA-Z0-9])*\\nRequired: Yes\\nSee Also\\nFor more information about using this API in one of the language-speciﬁc AWS SDKs, see the following:\\n•AWS SDK for C++\\n•AWS SDK for Go\\n•AWS SDK for Go - Pilot\\n•AWS SDK for Java\\n•AWS SDK for Ruby V2\\nAmazon SageMaker Runtime\\nCurrently Amazon SageMaker Runtime does not support any data types.\\nCommon Errors\\nThis section lists the errors common to the API actions of all AWS services. For errors speciﬁc to an API\\naction for this service, see the topic for that API action.\\nAccessDeniedException\\nYou do not have suﬃcient access to perform this action.\\nHTTP Status Code: 400\\nIncompleteSignature\\nThe request signature does not conform to AWS standards.\\nHTTP Status Code: 400\\n1041Amazon SageMaker Developer Guide\\nCommon Errors\\nInternalFailure\\nThe request processing has failed because of an unknown error, exception or failure.\\nHTTP Status Code: 500\\nInvalidAction\\nThe action or operation requested is invalid. Verify that the action is typed correctly.\\nHTTP Status Code: 400\\nInvalidClientTokenId\\nThe X.509 certiﬁcate or AWS access key ID provided does not exist in our records.\\nHTTP Status Code: 403\\nInvalidParameterCombination\\nParameters that must not be used together were used together.\\nHTTP Status Code: 400\\nInvalidParameterValue\\nAn invalid or out-of-range value was supplied for the input parameter.\\nHTTP Status Code: 400\\nInvalidQueryParameter\\nThe AWS query string is malformed or does not adhere to AWS standards.\\nHTTP Status Code: 400\\nMalformedQueryString\\nThe query string contains a syntax error.\\nHTTP Status Code: 404\\nMissingAction\\nThe request is missing an action or a required parameter.\\nHTTP Status Code: 400\\nMissingAuthenticationToken\\nThe request must contain either a valid (registered) AWS access key ID or X.509 certiﬁcate.\\nHTTP Status Code: 403\\nMissingParameter\\nA required parameter for the speciﬁed action is not supplied.\\nHTTP Status Code: 400\\nOptInRequired\\nThe AWS access key ID needs a subscription for the service.\\nHTTP Status Code: 403\\nRequestExpired\\nThe request reached the service more than 15 minutes after the date stamp on the request or more\\nthan 15 minutes after the request expiration date (such as for pre-signed URLs), or the date stamp\\non the request is more than 15 minutes in the future.\\n1042Amazon SageMaker Developer Guide\\nCommon Parameters\\nHTTP Status Code: 400\\nServiceUnavailable\\nThe request has failed due to a temporary failure of the server.\\nHTTP Status Code: 503\\nThrottlingException\\nThe request was denied due to request throttling.\\nHTTP Status Code: 400\\nValidationError\\nThe input fails to satisfy the constraints speciﬁed by an AWS service.\\nHTTP Status Code: 400\\nCommon Parameters\\nThe following list contains the parameters that all actions use for signing Signature Version 4 requests\\nwith a query string. Any action-speciﬁc parameters are listed in the topic for that action. For more\\ninformation about Signature Version 4, see Signature Version 4 Signing Process in the Amazon Web\\nServices General Reference.\\nAction\\nThe action to be performed.\\nType: string\\nRequired: Yes\\nVersion\\nThe API version that the request is written for, expressed in the format YYYY-MM-DD.\\nType: string\\nRequired: Yes\\nX-Amz-Algorithm\\nThe hash algorithm that you used to create the request signature.\\nCondition: Specify this parameter when you include authentication information in a query string\\ninstead of in the HTTP authorization header.\\nType: string\\nValid Values: AWS4-HMAC-SHA256\\nRequired: Conditional\\nX-Amz-Credential\\nThe credential scope value, which is a string that includes your access key, the date, the region you\\nare targeting, the service you are requesting, and a termination string (\"aws4_request\"). The value is\\nexpressed in the following format: access_key /YYYYMMDD/region /service/aws4_request.\\nFor more information, see Task 2: Create a String to Sign for Signature Version 4 in the Amazon Web\\nServices General Reference.\\n1043Amazon SageMaker Developer Guide\\nCommon Parameters\\nCondition: Specify this parameter when you include authentication information in a query string\\ninstead of in the HTTP authorization header.\\nType: string\\nRequired: Conditional\\nX-Amz-Date\\nThe date that is used to create the signature. The format must be ISO 8601 basic format\\n(YYYYMMDD\\'T\\'HHMMSS\\'Z\\'). For example, the following date time is a valid X-Amz-Date value:\\n20120325T120000Z .\\nCondition: X-Amz-Date is optional for all requests; it can be used to override the date used for\\nsigning requests. If the Date header is speciﬁed in the ISO 8601 basic format, X-Amz-Date is\\nnot required. When X-Amz-Date is used, it always overrides the value of the Date header. For\\nmore information, see Handling Dates in Signature Version 4 in the Amazon Web Services General\\nReference.\\nType: string\\nRequired: Conditional\\nX-Amz-Security-Token\\nThe temporary security token that was obtained through a call to AWS Security Token Service (AWS\\nSTS). For a list of services that support temporary security credentials from AWS Security Token\\nService, go to AWS Services That Work with IAM in the IAM User Guide .\\nCondition: If you\\'re using temporary security credentials from the AWS Security Token Service, you\\nmust include the security token.\\nType: string\\nRequired: Conditional\\nX-Amz-Signature\\nSpeciﬁes the hex-encoded signature that was calculated from the string to sign and the derived\\nsigning key.\\nCondition: Specify this parameter when you include authentication information in a query string\\ninstead of in the HTTP authorization header.\\nType: string\\nRequired: Conditional\\nX-Amz-SignedHeaders\\nSpeciﬁes all the HTTP headers that were included as part of the canonical request. For more\\ninformation about specifying signed headers, see  Task 1: Create a Canonical Request For Signature\\nVersion 4 in the  Amazon Web Services General Reference.\\nCondition: Specify this parameter when you include authentication information in a query string\\ninstead of in the HTTP authorization header.\\nType: string\\nRequired: Conditional\\n1044Amazon SageMaker Developer Guide\\nDocument History for Amazon\\nSageMaker\\nupdate-history-changeupdate-history-descriptionupdate-history-dateNew features re:Invent 2018Amazon SageMaker Ground\\nTruth, Using Elastic Inference\\nin Amazon SageMaker, Amazon\\nSageMaker Resources in\\nAWS Marketplace, Amazon\\nSageMaker Inference Pipelines,\\nAmazon SageMaker Neo,\\nManage Machine Learning\\nExperiments with Search , Use\\nReinforcement Learning in\\nAmazon SageMaker, Associating\\nGit Repositories with Amazon\\nSageMaker Notebook Instances,\\nSemantic Segmentation , Using\\nAugmented Manifest Files in\\nTrainingJobsNovember 28, 2018\\nConﬁguring notebook instancesYou can use shell scripts to\\nconﬁgure notebook instances\\nwhen you create or start them.\\nFor more information, see\\nCustomize a Notebook Instance.May 1, 2018\\nDisable direct internet accessYou can now disable direct\\ninternet access for notebook\\ninstances. For more information,\\nsee Notebook Instances Are\\nEnabled with Internet Access by\\nDefault .March 15, 2018\\nApplication Auto Scaling supportAmazon SageMaker now\\nsupports Application Auto\\nScaling for production\\nvariants. For information, see\\nAutomatically Scaling Amazon\\nSageMaker SageMaker ModelsFebruary 28, 2018\\nTensorFlow 1.5 and MXNet 1.0\\nsupport (p. 1045 )Amazon SageMaker Deep\\nLearning containers now support\\nTensorFlow 1.5 and Apache\\nMXNet 1.0.February 27, 2018\\nBlazingText algorithm Amazon SageMaker now\\nsupports the BlazingText\\nalgorithm.January 18, 2018\\n1045Amazon SageMaker Developer Guide\\nKMS encryption support for\\ntraining and hostingAmazon SageMaker now\\nsupports KMS encryption\\nfor hosting instances and\\ntraining model artifacts at rest.\\nYou can specify a AWS Key\\nManagement Service key that\\nAmazon SageMaker uses to\\nencrypt data on the storage\\nvolume attached to a hosting\\nendpoint by using the KmsKeyId\\nrequest parameter in a call to\\nCreateEndpointConﬁg. You can\\nspecify an AWS KMS key that\\nAmazon SageMaker uses to\\nencrypt training model artifacts\\nat rest by setting the KmsKeyId\\nﬁeld of the OutputDataConﬁg\\nobject you use to conﬁgure your\\ntraining job.January 17, 2018\\nCloudTrail supportAmazon SageMaker now\\nsupports logging with AWS\\nCloudTrail.January 11, 2018\\nDeepAR Forecasting algorithmAmazon SageMaker now\\nsupports the DeepAR  algorithm\\nfor time series forecasting.January 8, 2018\\n1046Amazon SageMaker Developer Guide\\nAWS Glossary\\nFor the latest AWS terminology, see the AWS Glossary in the AWS General Reference.\\n1047'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1917659"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !set PYTHONHTTPSVERIFY=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7NxZYb4Rps"
      },
      "source": [
        "Create the LangChain embedding and LLM objects for later usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TavS0AK2SLrL"
      },
      "outputs": [],
      "source": [
        "# Method 1\n",
        "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
        "embeddings = HuggingFaceEndpointEmbeddings()\n",
        "\n",
        "sentence = \"Hello when do you think a major epedemic like corona will come again\"\n",
        "\n",
        "query_result = embeddings.embed_query(sentence)\n",
        "print(len(query_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2\n",
        "import requests\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "url = \"https://ollama.aes.zdidata.com/api/embed\"\n",
        "\n",
        "payload = {\n",
        "        \"model\": \"llama3.2:3b\",\n",
        "        \"input\": \"Why is the sky blue?\"\n",
        "    }\n",
        "response = requests.post(url, json=payload, headers=headers)\n",
        "# print(response.json()['embeddings'])\n",
        "print(len(response.json()['embeddings'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Required method to create embeddings\n",
        "# from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "# ollama_emb = OllamaEmbeddings(base_url=\"https://ollama.aes.zdidata.com\",\n",
        "#     model=\"llama3.2:3b\",\n",
        "#     client_kwargs={\"verify\": False}\n",
        "# )\n",
        "\n",
        "from int_host_emd import ollama_emb\n",
        "\n",
        "r1 = ollama_emb.embed_documents(\n",
        "    [\n",
        "        \"Alpha is the first letter of Greek alphabet\",\n",
        "        \"Beta is the second letter of Greek alphabet\",\n",
        "    ]\n",
        ")\n",
        "r2 = ollama_emb.embed_query(\n",
        "    \"What is the second letter of Greek alphabet\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of embedding:  3072\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[-0.02017921,\n",
              " -0.013658828,\n",
              " -0.0008308421,\n",
              " -0.0026884815,\n",
              " 0.019890182,\n",
              " -0.0022861778,\n",
              " -0.0031233635,\n",
              " 0.025057241,\n",
              " -0.021075722,\n",
              " -0.0031690812,\n",
              " -0.003463068,\n",
              " -0.025344482,\n",
              " 0.03000001,\n",
              " 0.05506522,\n",
              " 0.0042035263,\n",
              " -0.022594823,\n",
              " 0.008170241,\n",
              " -0.008432729,\n",
              " 0.0011287716,\n",
              " 0.012668729,\n",
              " -0.013176354,\n",
              " -0.0028193383,\n",
              " 0.023240093,\n",
              " -0.007007826,\n",
              " -0.032376673,\n",
              " 0.003794477,\n",
              " 0.0056222444,\n",
              " -0.02154562,\n",
              " 0.0051820977,\n",
              " 0.005617853,\n",
              " 0.017775832,\n",
              " 0.013087684,\n",
              " -0.012885289,\n",
              " 0.0004963706,\n",
              " 0.003259529,\n",
              " -0.0029220874,\n",
              " 0.00057361525,\n",
              " 0.011833868,\n",
              " -0.021017304,\n",
              " -0.016396884,\n",
              " -0.026990136,\n",
              " -0.01683987,\n",
              " 0.029663743,\n",
              " -0.001968664,\n",
              " -0.014408622,\n",
              " -0.01553029,\n",
              " 0.018189482,\n",
              " -0.007003698,\n",
              " 0.00028999776,\n",
              " 0.011856442,\n",
              " 0.020064771,\n",
              " 0.0065921033,\n",
              " -0.021112548,\n",
              " -0.009763934,\n",
              " -0.007839793,\n",
              " 0.001783592,\n",
              " 0.022440184,\n",
              " -0.028106127,\n",
              " 0.0041524377,\n",
              " -0.0156511,\n",
              " 0.016636377,\n",
              " 0.03052028,\n",
              " 0.014065418,\n",
              " 0.0049007647,\n",
              " 0.06978776,\n",
              " -0.029013315,\n",
              " -0.0016942346,\n",
              " 0.027681623,\n",
              " -0.02395618,\n",
              " -0.013986571,\n",
              " 0.032440644,\n",
              " -0.0017015389,\n",
              " 0.00953883,\n",
              " -0.03020973,\n",
              " 0.0015635603,\n",
              " -0.005874417,\n",
              " -0.001124017,\n",
              " -0.013685861,\n",
              " 0.031060258,\n",
              " -0.0012118852,\n",
              " 0.006594124,\n",
              " -0.003405808,\n",
              " 0.00904432,\n",
              " 0.0042994376,\n",
              " 0.008828637,\n",
              " -0.0029501244,\n",
              " 0.037856583,\n",
              " -0.028348647,\n",
              " -0.010346839,\n",
              " -0.020252833,\n",
              " -0.006692339,\n",
              " 0.0070146145,\n",
              " 0.005693562,\n",
              " 0.0055497526,\n",
              " -0.0092651,\n",
              " -0.0051762136,\n",
              " 0.023679825,\n",
              " 0.0021631566,\n",
              " 0.0102701,\n",
              " 0.029789845,\n",
              " -0.0031925002,\n",
              " -0.0026013684,\n",
              " -0.00479514,\n",
              " -0.0019436041,\n",
              " -0.0021156804,\n",
              " 0.003268596,\n",
              " 0.02302339,\n",
              " -0.01890372,\n",
              " 0.0285138,\n",
              " -0.01853942,\n",
              " 0.020618275,\n",
              " -0.008513218,\n",
              " 0.018418178,\n",
              " -0.02127366,\n",
              " 0.007922179,\n",
              " 0.016399207,\n",
              " 0.013682031,\n",
              " 0.013330527,\n",
              " -0.0010632906,\n",
              " -0.023182161,\n",
              " 0.0013527796,\n",
              " -0.010842089,\n",
              " -0.0008315437,\n",
              " -0.0023534424,\n",
              " -0.018890297,\n",
              " 0.014831602,\n",
              " -0.0035804652,\n",
              " 0.0040532025,\n",
              " 0.008711166,\n",
              " 0.009622737,\n",
              " -0.013578413,\n",
              " -0.0376199,\n",
              " -0.025578788,\n",
              " 0.020428177,\n",
              " -0.018925646,\n",
              " -0.0044763517,\n",
              " 0.0005123493,\n",
              " 0.032561447,\n",
              " -0.00014685972,\n",
              " 0.00032398614,\n",
              " 0.0006935529,\n",
              " -0.027706373,\n",
              " 0.013958644,\n",
              " -0.005488393,\n",
              " 0.00014499972,\n",
              " -0.0099653555,\n",
              " 0.011306459,\n",
              " 0.024676902,\n",
              " -0.023678884,\n",
              " -0.018721608,\n",
              " 0.0032547317,\n",
              " -0.032583047,\n",
              " 0.029089846,\n",
              " -0.012602208,\n",
              " 0.0003277423,\n",
              " 0.01451434,\n",
              " 0.035307467,\n",
              " -0.008294864,\n",
              " 0.017977241,\n",
              " -0.010662798,\n",
              " -0.0028195938,\n",
              " 0.023910273,\n",
              " -0.009818873,\n",
              " 0.019357257,\n",
              " 0.019714141,\n",
              " 0.006223654,\n",
              " -0.012932127,\n",
              " 0.0011768456,\n",
              " -0.0053556543,\n",
              " -0.036551908,\n",
              " 0.0048049204,\n",
              " 0.007001457,\n",
              " -0.009212879,\n",
              " -0.021181807,\n",
              " -0.014542973,\n",
              " 0.0090765,\n",
              " -0.00028863404,\n",
              " 0.021976346,\n",
              " -0.013128003,\n",
              " -0.006514852,\n",
              " -0.0058046575,\n",
              " -0.0145248175,\n",
              " 0.001075049,\n",
              " 0.015969211,\n",
              " -0.017790757,\n",
              " -0.0056104898,\n",
              " 0.022167932,\n",
              " 0.014488265,\n",
              " 0.0013877577,\n",
              " 0.01988427,\n",
              " 0.018577483,\n",
              " -0.0002895424,\n",
              " -0.028196735,\n",
              " 0.0019847066,\n",
              " -0.004713226,\n",
              " -0.0225399,\n",
              " -0.0029055863,\n",
              " 0.0087955315,\n",
              " 0.017267298,\n",
              " -0.005551161,\n",
              " 0.007671345,\n",
              " -0.027142867,\n",
              " -0.01677701,\n",
              " 0.0056893644,\n",
              " -7.5384116e-05,\n",
              " -0.006471981,\n",
              " 0.02919473,\n",
              " -0.015325377,\n",
              " -0.021492958,\n",
              " -0.012239217,\n",
              " 0.008831372,\n",
              " -3.6666745e-05,\n",
              " -0.02534223,\n",
              " -0.008322954,\n",
              " 0.008218145,\n",
              " -0.07407363,\n",
              " 0.009004669,\n",
              " -0.015087844,\n",
              " 0.0003599099,\n",
              " 0.011527895,\n",
              " -0.0029602174,\n",
              " 0.03083372,\n",
              " 0.02100594,\n",
              " -0.0308359,\n",
              " -0.044378348,\n",
              " -0.02114946,\n",
              " 0.011601566,\n",
              " -0.0100038,\n",
              " 0.016076181,\n",
              " 0.0041294964,\n",
              " 0.00086027733,\n",
              " -0.014911666,\n",
              " -0.0126664825,\n",
              " -0.005352424,\n",
              " -0.003838739,\n",
              " 0.007467211,\n",
              " -0.01643457,\n",
              " 0.006052344,\n",
              " 0.009367098,\n",
              " -0.0077345828,\n",
              " -0.0074833077,\n",
              " -0.009499247,\n",
              " -0.009655125,\n",
              " -7.823648e-05,\n",
              " -0.012076618,\n",
              " -0.005802264,\n",
              " 0.021513416,\n",
              " -0.0025192262,\n",
              " 0.009499566,\n",
              " 0.0059317,\n",
              " 0.0036868374,\n",
              " 0.0017763765,\n",
              " 0.025582572,\n",
              " -0.0046017603,\n",
              " 0.005089335,\n",
              " -0.0024934602,\n",
              " 0.010330447,\n",
              " -0.01285127,\n",
              " 0.013282479,\n",
              " 0.001084819,\n",
              " -0.0012151347,\n",
              " -0.011211805,\n",
              " -0.011683293,\n",
              " -0.027027162,\n",
              " 0.015032745,\n",
              " -0.009527318,\n",
              " -0.0044109267,\n",
              " -0.037173413,\n",
              " 0.009797077,\n",
              " 0.008733304,\n",
              " -0.015317983,\n",
              " 0.009251778,\n",
              " 0.009354813,\n",
              " -0.007570642,\n",
              " 0.006458361,\n",
              " -0.00575207,\n",
              " -0.0070754625,\n",
              " 0.014513616,\n",
              " -0.036715627,\n",
              " 0.022778757,\n",
              " 0.0035566434,\n",
              " -0.0052020997,\n",
              " -0.0018095619,\n",
              " -0.011884142,\n",
              " -0.027273167,\n",
              " 0.011844567,\n",
              " 0.0029526239,\n",
              " 0.00017466738,\n",
              " 0.007529387,\n",
              " 0.022057293,\n",
              " 0.008146739,\n",
              " 0.004277073,\n",
              " 0.0085334545,\n",
              " -0.014840005,\n",
              " 0.02261479,\n",
              " -0.018632445,\n",
              " -0.022432307,\n",
              " 0.002800129,\n",
              " -0.009336068,\n",
              " 0.01963535,\n",
              " -0.0016232077,\n",
              " -0.027861577,\n",
              " -0.0053969757,\n",
              " 0.020396262,\n",
              " 0.0011123626,\n",
              " -0.010236813,\n",
              " 0.017827699,\n",
              " 0.023766743,\n",
              " 0.012557539,\n",
              " 0.015658032,\n",
              " 0.018012533,\n",
              " -0.011094087,\n",
              " -0.0070320945,\n",
              " 0.010827368,\n",
              " 0.011184977,\n",
              " 0.024021609,\n",
              " 0.010407602,\n",
              " -0.024758436,\n",
              " -0.022577733,\n",
              " 0.0057621305,\n",
              " 0.010421418,\n",
              " -0.0023374392,\n",
              " 0.01069886,\n",
              " -0.005534702,\n",
              " -0.030679116,\n",
              " 0.0028900162,\n",
              " -0.008348839,\n",
              " -0.014701052,\n",
              " 0.017435811,\n",
              " 0.011809766,\n",
              " -0.016868247,\n",
              " -0.0047582802,\n",
              " 0.0010536133,\n",
              " -0.012744382,\n",
              " -0.02186292,\n",
              " -0.01038146,\n",
              " 0.0038481168,\n",
              " 0.01157846,\n",
              " 0.027930304,\n",
              " 4.347672e-05,\n",
              " 0.006087529,\n",
              " -0.029342206,\n",
              " 0.030040007,\n",
              " -0.010547752,\n",
              " 0.006720758,\n",
              " -0.0063532726,\n",
              " 0.022253709,\n",
              " -0.013747754,\n",
              " 0.011921098,\n",
              " 0.0312179,\n",
              " 0.0217509,\n",
              " -0.007626012,\n",
              " 0.0017648982,\n",
              " 0.004899322,\n",
              " -0.01115243,\n",
              " -0.015085655,\n",
              " -0.008289426,\n",
              " 0.012159273,\n",
              " -0.0021893256,\n",
              " 0.029938253,\n",
              " -0.0050966055,\n",
              " -0.008811856,\n",
              " -0.0050448948,\n",
              " 0.011706315,\n",
              " -0.029159324,\n",
              " 0.016336704,\n",
              " 0.016480519,\n",
              " -0.004581709,\n",
              " 0.018278321,\n",
              " 0.0019687,\n",
              " 0.037071034,\n",
              " 0.011235198,\n",
              " -0.005986485,\n",
              " 0.0036496355,\n",
              " -0.0027292531,\n",
              " 0.022619074,\n",
              " 0.0019939987,\n",
              " -0.006622094,\n",
              " -0.022921784,\n",
              " 0.033332802,\n",
              " 0.022128413,\n",
              " 0.01607319,\n",
              " -0.020998271,\n",
              " 0.0069223684,\n",
              " 0.010514202,\n",
              " 0.0053366977,\n",
              " -0.021606013,\n",
              " -0.028956117,\n",
              " 0.005673937,\n",
              " 0.00018813489,\n",
              " -0.00450937,\n",
              " 0.007445209,\n",
              " -0.0095327,\n",
              " -0.02397492,\n",
              " 0.00043963362,\n",
              " 0.013552016,\n",
              " 0.019125856,\n",
              " 0.0019086624,\n",
              " 0.005063994,\n",
              " -0.0018074524,\n",
              " 0.006556343,\n",
              " 0.00422985,\n",
              " -0.0010734637,\n",
              " 0.015478599,\n",
              " -0.0092286505,\n",
              " 0.0026061619,\n",
              " -0.029633297,\n",
              " -0.018934367,\n",
              " 0.015616087,\n",
              " -0.006230772,\n",
              " -0.0046476456,\n",
              " 0.018526379,\n",
              " -0.017903902,\n",
              " 0.0046031256,\n",
              " -0.0024926576,\n",
              " 0.004549525,\n",
              " 0.007357537,\n",
              " 0.015257221,\n",
              " -0.010297528,\n",
              " 0.008516711,\n",
              " 0.026917329,\n",
              " -0.013528138,\n",
              " -0.0016124368,\n",
              " 0.025850825,\n",
              " 0.011270866,\n",
              " 0.0047891038,\n",
              " 0.008292747,\n",
              " 0.05423749,\n",
              " 0.001471479,\n",
              " -0.012353627,\n",
              " -0.0038902252,\n",
              " -0.025636613,\n",
              " -0.022732353,\n",
              " -0.00090447575,\n",
              " -0.01752641,\n",
              " 0.007880785,\n",
              " 0.0043180613,\n",
              " -0.006140409,\n",
              " -0.0024254492,\n",
              " -0.0057669817,\n",
              " 0.023955183,\n",
              " 0.02491631,\n",
              " -0.007217452,\n",
              " 0.01850603,\n",
              " -0.008690728,\n",
              " 0.008844666,\n",
              " 0.019621538,\n",
              " -0.010019262,\n",
              " -0.034863293,\n",
              " 0.007063735,\n",
              " -0.0059763533,\n",
              " -0.010195078,\n",
              " -0.0067396876,\n",
              " 0.02213322,\n",
              " -0.0010172417,\n",
              " 0.043937042,\n",
              " -0.0113520855,\n",
              " -0.030480424,\n",
              " 0.020616213,\n",
              " 0.025847092,\n",
              " -0.008484284,\n",
              " -0.0070076403,\n",
              " 0.0129933,\n",
              " -0.030035302,\n",
              " -0.0034072457,\n",
              " 0.013943754,\n",
              " -0.0014592997,\n",
              " -0.0061379806,\n",
              " -0.00085880444,\n",
              " -0.002002611,\n",
              " -0.0058308756,\n",
              " 0.019504212,\n",
              " 0.0056492714,\n",
              " -0.008527573,\n",
              " -0.020219348,\n",
              " -0.0049182135,\n",
              " -0.016127197,\n",
              " -0.0048249415,\n",
              " -0.023952838,\n",
              " 0.02757619,\n",
              " -0.0033369581,\n",
              " 0.0136218155,\n",
              " 0.0059420727,\n",
              " 0.014374441,\n",
              " 0.012993611,\n",
              " -0.016755713,\n",
              " 0.004455687,\n",
              " -0.0058943573,\n",
              " -0.019924644,\n",
              " 0.011475662,\n",
              " -0.009537721,\n",
              " 0.0024087194,\n",
              " -0.017122183,\n",
              " 0.023975782,\n",
              " -0.007960478,\n",
              " -0.006954155,\n",
              " 0.0051552206,\n",
              " -0.009683486,\n",
              " -0.006537144,\n",
              " -0.013124771,\n",
              " 0.0026449836,\n",
              " -0.015187497,\n",
              " 0.018620038,\n",
              " 0.023421735,\n",
              " 0.0029254148,\n",
              " -0.013705577,\n",
              " 0.03867075,\n",
              " 0.03463961,\n",
              " -0.004093768,\n",
              " 0.007823195,\n",
              " 0.0018444365,\n",
              " 0.019874996,\n",
              " -0.001523991,\n",
              " -0.0011658614,\n",
              " -0.010632669,\n",
              " -0.0016203931,\n",
              " 0.016818948,\n",
              " 0.0113807265,\n",
              " -0.007358137,\n",
              " -0.006291326,\n",
              " 0.011844677,\n",
              " 0.00083504827,\n",
              " 0.017503666,\n",
              " -0.018218158,\n",
              " 0.034294672,\n",
              " -0.020233396,\n",
              " -0.009969182,\n",
              " 0.0003157043,\n",
              " -0.011881279,\n",
              " 0.0047451137,\n",
              " 0.018383449,\n",
              " -0.0036032721,\n",
              " -0.0069543216,\n",
              " -0.04557262,\n",
              " 0.0019666692,\n",
              " 0.012685851,\n",
              " -0.017843822,\n",
              " -0.014447542,\n",
              " 0.025789374,\n",
              " -0.014030765,\n",
              " 0.021839567,\n",
              " 0.01621175,\n",
              " 0.029646708,\n",
              " 0.0010520054,\n",
              " 0.0002527954,\n",
              " -0.027054977,\n",
              " -0.017531421,\n",
              " -0.0154686095,\n",
              " 0.012799105,\n",
              " -0.02331603,\n",
              " -0.003493417,\n",
              " 0.0031982348,\n",
              " 0.0051062456,\n",
              " 0.011298843,\n",
              " 0.031270903,\n",
              " -0.011305009,\n",
              " 0.0025470234,\n",
              " -0.0029421742,\n",
              " -0.022226688,\n",
              " -0.006909474,\n",
              " 0.00083716837,\n",
              " -0.020758387,\n",
              " 0.0010826205,\n",
              " 0.007352865,\n",
              " -0.016293658,\n",
              " -0.017701438,\n",
              " 0.006869357,\n",
              " 0.023388796,\n",
              " 0.0019150969,\n",
              " 0.0153527735,\n",
              " 0.029883645,\n",
              " 0.003775624,\n",
              " 0.01271301,\n",
              " 0.039969735,\n",
              " 0.021468876,\n",
              " -0.005886222,\n",
              " -0.011728337,\n",
              " 0.0024367322,\n",
              " 0.01597801,\n",
              " -0.01702505,\n",
              " -0.0014132536,\n",
              " 0.03432548,\n",
              " 0.029221332,\n",
              " 0.0021409304,\n",
              " 0.0060338997,\n",
              " -0.005564499,\n",
              " -0.0062365015,\n",
              " -0.00045721798,\n",
              " 0.008450925,\n",
              " 0.016924601,\n",
              " -0.0035767027,\n",
              " 0.007422688,\n",
              " -0.010184141,\n",
              " -0.043639693,\n",
              " -0.00901136,\n",
              " 0.00618101,\n",
              " -0.009437697,\n",
              " 0.0012015534,\n",
              " 0.019196661,\n",
              " 0.0067046643,\n",
              " -0.013245149,\n",
              " 0.0042419634,\n",
              " -0.024645036,\n",
              " 0.0015718939,\n",
              " -0.007827198,\n",
              " 0.0048398976,\n",
              " -0.009235261,\n",
              " -0.021549342,\n",
              " 0.01115009,\n",
              " 0.004940923,\n",
              " -0.0061218846,\n",
              " -0.011447824,\n",
              " -0.008794383,\n",
              " -0.022659197,\n",
              " -0.016811343,\n",
              " 0.012438675,\n",
              " 0.0009772237,\n",
              " -0.013261916,\n",
              " 0.02078793,\n",
              " 0.016163202,\n",
              " -0.023391204,\n",
              " -0.0018210112,\n",
              " 0.014242935,\n",
              " -0.0139952265,\n",
              " -0.02041442,\n",
              " 0.009534866,\n",
              " -0.013518933,\n",
              " -0.022112135,\n",
              " -0.022940388,\n",
              " -0.010407321,\n",
              " -0.0324687,\n",
              " 0.018077567,\n",
              " 0.021919975,\n",
              " -0.003609926,\n",
              " 0.029286396,\n",
              " -0.006697773,\n",
              " -0.029180557,\n",
              " -0.009080018,\n",
              " 0.002810096,\n",
              " 2.9719042e-05,\n",
              " 0.023785496,\n",
              " -0.023784194,\n",
              " -0.015629318,\n",
              " -0.006151877,\n",
              " 0.019037554,\n",
              " -0.0045872135,\n",
              " -0.009407255,\n",
              " 0.026481291,\n",
              " 0.0007650005,\n",
              " -0.009151672,\n",
              " -0.014624422,\n",
              " 0.007655676,\n",
              " 0.0036786753,\n",
              " 0.012290847,\n",
              " 0.008189288,\n",
              " -0.015502922,\n",
              " 0.011540533,\n",
              " -0.0012487606,\n",
              " 0.011236263,\n",
              " 0.0003014285,\n",
              " 0.009235098,\n",
              " -0.014970265,\n",
              " 0.014319696,\n",
              " 0.00912395,\n",
              " 0.0057996004,\n",
              " 0.020141087,\n",
              " -0.013500221,\n",
              " 0.009444143,\n",
              " -0.024928689,\n",
              " -0.015733924,\n",
              " 0.045859803,\n",
              " -0.014705778,\n",
              " -0.007245035,\n",
              " -0.0011751942,\n",
              " 0.010984333,\n",
              " 0.003168935,\n",
              " 0.036809724,\n",
              " -0.0014384454,\n",
              " -0.015855616,\n",
              " -0.005897687,\n",
              " 0.017808178,\n",
              " 0.0005651845,\n",
              " -0.003570241,\n",
              " -0.0048974017,\n",
              " 0.026765782,\n",
              " -0.012466386,\n",
              " 0.016349517,\n",
              " -0.006572046,\n",
              " 0.013245615,\n",
              " 0.016546553,\n",
              " 0.025478115,\n",
              " 0.00060939154,\n",
              " -0.021678697,\n",
              " 0.020740064,\n",
              " 0.01784158,\n",
              " -0.011032569,\n",
              " -0.0031412344,\n",
              " 0.005996113,\n",
              " -0.0056166057,\n",
              " 0.00079289265,\n",
              " -0.0022470034,\n",
              " 0.010962353,\n",
              " 0.0327647,\n",
              " -0.028280888,\n",
              " -0.0049585844,\n",
              " 0.0071730074,\n",
              " 0.015935015,\n",
              " 0.010512035,\n",
              " 0.004143398,\n",
              " -0.009984717,\n",
              " 0.023307575,\n",
              " 0.009917737,\n",
              " 0.0075272894,\n",
              " -0.005032677,\n",
              " -0.016707782,\n",
              " 0.0058012367,\n",
              " -0.021445097,\n",
              " 0.017439242,\n",
              " 0.026400095,\n",
              " 0.0020450915,\n",
              " 0.01931039,\n",
              " 0.010559773,\n",
              " 0.019548044,\n",
              " 0.01097898,\n",
              " 0.03770611,\n",
              " 0.023980012,\n",
              " 0.0011911244,\n",
              " 0.013343065,\n",
              " 0.007571218,\n",
              " -0.0058961506,\n",
              " -0.037816864,\n",
              " 0.0034461825,\n",
              " -0.0044366396,\n",
              " 0.014677603,\n",
              " -0.023928544,\n",
              " -0.0019299112,\n",
              " -0.017331233,\n",
              " 0.0006994657,\n",
              " 0.034566708,\n",
              " -0.02483803,\n",
              " -0.010739408,\n",
              " 0.016995598,\n",
              " -0.005630247,\n",
              " -0.0026632296,\n",
              " 0.027974874,\n",
              " 0.017168483,\n",
              " 0.0007760944,\n",
              " -0.0011352188,\n",
              " -0.014633848,\n",
              " -0.000779679,\n",
              " -0.026135065,\n",
              " -0.0067988303,\n",
              " -0.019755099,\n",
              " 0.012139197,\n",
              " -0.0007603713,\n",
              " -0.0036259678,\n",
              " -0.022415586,\n",
              " -0.0021065332,\n",
              " -0.003686667,\n",
              " -0.015912876,\n",
              " -0.0022126972,\n",
              " 0.020118812,\n",
              " 0.0052407025,\n",
              " 0.011456132,\n",
              " 0.023126762,\n",
              " -0.011518038,\n",
              " -0.00039578273,\n",
              " -0.008667242,\n",
              " -0.028151445,\n",
              " 0.010918512,\n",
              " -0.0074344487,\n",
              " 0.03689798,\n",
              " 0.010322063,\n",
              " 0.002346509,\n",
              " 0.0017991818,\n",
              " 0.010958146,\n",
              " 0.01061594,\n",
              " -0.040976614,\n",
              " -0.013749468,\n",
              " -0.016548632,\n",
              " -0.0046173064,\n",
              " -0.004021854,\n",
              " -0.038605705,\n",
              " -0.0030879034,\n",
              " 0.02129523,\n",
              " -0.012250254,\n",
              " 0.011630019,\n",
              " 0.018302493,\n",
              " -0.017142061,\n",
              " 0.0045655435,\n",
              " 0.022256602,\n",
              " -0.015621505,\n",
              " -0.0024805728,\n",
              " 0.017662438,\n",
              " -0.021164821,\n",
              " -0.016413016,\n",
              " -0.0069098985,\n",
              " 0.0113543095,\n",
              " 0.018474106,\n",
              " -0.009394379,\n",
              " 0.02021281,\n",
              " -0.008374073,\n",
              " -0.00076480757,\n",
              " -0.016696643,\n",
              " 0.005982655,\n",
              " -0.01900133,\n",
              " -0.0005004246,\n",
              " -0.008110685,\n",
              " 0.039140306,\n",
              " 0.007556275,\n",
              " 0.005552309,\n",
              " -0.010132182,\n",
              " 0.0007677982,\n",
              " -0.039112817,\n",
              " -0.001545499,\n",
              " -0.006028709,\n",
              " -0.022322673,\n",
              " -0.013056778,\n",
              " 0.0119327875,\n",
              " 0.003300734,\n",
              " 0.008220362,\n",
              " 0.012097887,\n",
              " -0.025350483,\n",
              " 0.008911473,\n",
              " -0.008327628,\n",
              " 0.041049626,\n",
              " 0.006045286,\n",
              " -0.00925572,\n",
              " 0.027485155,\n",
              " 0.0058246674,\n",
              " -0.017739529,\n",
              " -0.027822519,\n",
              " -0.011288938,\n",
              " -0.011916875,\n",
              " -0.010880566,\n",
              " -0.034506194,\n",
              " 0.00043072214,\n",
              " 0.00069506717,\n",
              " -0.021053135,\n",
              " -0.041368965,\n",
              " -0.0053580347,\n",
              " 0.0056319465,\n",
              " 0.017366908,\n",
              " 0.0044205855,\n",
              " 0.0058111814,\n",
              " 0.0026826493,\n",
              " 0.02272867,\n",
              " -0.007843393,\n",
              " -0.016465558,\n",
              " 0.010499881,\n",
              " -0.0027996865,\n",
              " 0.021247283,\n",
              " -0.04406175,\n",
              " 0.018915119,\n",
              " 0.006631462,\n",
              " 0.012897664,\n",
              " 0.0070885955,\n",
              " -0.0012629858,\n",
              " 0.012115105,\n",
              " 0.04161984,\n",
              " -0.010309792,\n",
              " -0.0034399545,\n",
              " -0.03132006,\n",
              " -0.014298949,\n",
              " -0.01848714,\n",
              " 0.012969616,\n",
              " -0.019322036,\n",
              " 0.0070232353,\n",
              " -0.026798975,\n",
              " 0.017701508,\n",
              " 0.015201186,\n",
              " -0.0027144977,\n",
              " 0.008425306,\n",
              " -0.0072197733,\n",
              " -0.024475023,\n",
              " 0.017488021,\n",
              " 0.012698,\n",
              " 0.018987589,\n",
              " 0.008726479,\n",
              " 0.0121799335,\n",
              " 0.009328485,\n",
              " -0.032515742,\n",
              " 0.00012615162,\n",
              " 0.032219145,\n",
              " 0.0106469905,\n",
              " -0.0021037173,\n",
              " 0.035155524,\n",
              " -7.111431e-05,\n",
              " 0.003494222,\n",
              " -0.007031808,\n",
              " 0.004728757,\n",
              " -0.00032162928,\n",
              " -0.018603941,\n",
              " 0.0026125005,\n",
              " -0.010706142,\n",
              " -0.005791044,\n",
              " 0.0066901967,\n",
              " 0.020668948,\n",
              " 0.083679356,\n",
              " 0.014856725,\n",
              " -0.028808052,\n",
              " 0.028355947,\n",
              " 0.002083927,\n",
              " -0.011662713,\n",
              " -0.004264642,\n",
              " 0.0038152952,\n",
              " 0.005766289,\n",
              " 0.0031134326,\n",
              " 0.01213662,\n",
              " -0.006032352,\n",
              " -0.019866012,\n",
              " -0.006153554,\n",
              " 0.03634926,\n",
              " 0.03458365,\n",
              " -0.00896116,\n",
              " -0.0026016156,\n",
              " 0.0034977465,\n",
              " 0.010833894,\n",
              " -0.014524083,\n",
              " -0.0029865338,\n",
              " -0.009862927,\n",
              " -0.03680141,\n",
              " 0.0014418882,\n",
              " 0.024027916,\n",
              " -0.002346373,\n",
              " 0.0065050093,\n",
              " -0.013278422,\n",
              " -0.014102177,\n",
              " -0.00032615193,\n",
              " -0.0075160367,\n",
              " 0.031300224,\n",
              " 0.024160232,\n",
              " -0.027638378,\n",
              " -0.0036715013,\n",
              " 0.011281723,\n",
              " -0.018812155,\n",
              " -0.0032726543,\n",
              " -0.018015329,\n",
              " -0.07598368,\n",
              " 0.024886616,\n",
              " 0.010885008,\n",
              " -0.02588735,\n",
              " -0.008193709,\n",
              " -0.007566755,\n",
              " 0.006045722,\n",
              " -0.0133984145,\n",
              " 0.030745372,\n",
              " 0.0101499185,\n",
              " -0.011944025,\n",
              " 0.004649249,\n",
              " -0.02784401,\n",
              " -0.010587681,\n",
              " -0.013462388,\n",
              " -0.0018326605,\n",
              " -0.011907731,\n",
              " 0.0052812323,\n",
              " -0.010788504,\n",
              " -0.027205411,\n",
              " -0.016810479,\n",
              " -0.02183338,\n",
              " -0.01976204,\n",
              " 0.013250397,\n",
              " 0.0386811,\n",
              " -0.01276599,\n",
              " 0.019024396,\n",
              " -0.029940749,\n",
              " -0.032536704,\n",
              " 0.011633665,\n",
              " 0.0005022044,\n",
              " -0.014176826,\n",
              " -0.0038734803,\n",
              " -0.0067659807,\n",
              " 0.015566211,\n",
              " -0.023447225,\n",
              " -0.026946029,\n",
              " -0.010513632,\n",
              " 0.014677387,\n",
              " -0.0036090126,\n",
              " 0.0110003175,\n",
              " -0.008813437,\n",
              " -0.013226535,\n",
              " 0.008249069,\n",
              " 0.0033508725,\n",
              " -0.027472194,\n",
              " 0.03101097,\n",
              " -0.004281215,\n",
              " -0.011209756,\n",
              " -0.008687782,\n",
              " -0.0012170129,\n",
              " 0.008667745,\n",
              " 0.022853862,\n",
              " -0.031194756,\n",
              " 0.002108008,\n",
              " 0.006534667,\n",
              " -0.0054587326,\n",
              " -0.0016893,\n",
              " 0.020863276,\n",
              " -0.019821864,\n",
              " 0.0058585447,\n",
              " 0.00474163,\n",
              " ...]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Length of embedding: \", len(r2))\n",
        "r2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HMMx5Pm4Rpt"
      },
      "source": [
        "Create your LangChain vector store ... backed by Chroma DB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9FMAhKr77AVO"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3204"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BDHAyT7Gjr",
        "outputId": "7833f6ac-bd97-40d6-fcbe-94a81b4dd6ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Amazon SageMaker\\nDeveloper Guide\\nAmazon SageMaker Developer Guide\\nAmazon SageMaker: Developer Guide\\nCopyright © 2019 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not\\nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or\\ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may\\nor may not be aﬃliated with, connected to, or sponsored by Amazon.Amazon SageMaker Developer Guide\\nTable of Contents\\nWhat Is Amazon SageMaker?...............................................................................................................1\",\n",
              " 'Table of Contents\\nWhat Is Amazon SageMaker?...............................................................................................................1\\nAre You a First-time User of Amazon SageMaker?..........................................................................1\\nHow It Works....................................................................................................................................2\\nMachine Learning with Amazon SageMaker...................................................................................2\\nHow It Works: Next Topic...................................................................................................3',\n",
              " 'How It Works: Next Topic...................................................................................................3\\nExplore and Preprocess Data.......................................................................................................4\\nHow It Works: Next Topic...................................................................................................4\\nModel Training...........................................................................................................................4\\nHow It Works: Next Topic....................................................................................................7\\nModel Deployment.....................................................................................................................7',\n",
              " 'Model Deployment.....................................................................................................................7\\nHosting Services................................................................................................................7\\nBatch Transform...............................................................................................................10\\nValidating Models.............................................................................................................11\\nProgramming Model.........................................................................................................12\\nSet Up Amazon SageMaker...............................................................................................................14',\n",
              " 'Set Up Amazon SageMaker...............................................................................................................14\\nStep 1: Create an AWS Account..................................................................................................14\\nStep 2: Create an IAM Administrator User and Group....................................................................14\\nGet Started.....................................................................................................................................16\\nStep 1: Create an Amazon S3 Bucket..........................................................................................17\\nNext Step........................................................................................................................17',\n",
              " 'Next Step........................................................................................................................17\\nStep 2: Create an Amazon SageMaker Notebook Instance..............................................................17\\nNext Step........................................................................................................................18\\nStep 3: Create a Jupyter Notebook.............................................................................................18\\n......................................................................................................................................19\\nStep 4: Download, Explore, and Transform Data...........................................................................19',\n",
              " 'Step 4: Download, Explore, and Transform Data...........................................................................19\\nStep 4.1: Download the Dataset.........................................................................................19\\nStep 4.2: Explore the Dataset............................................................................................20\\nStep 4.3: Transform Dataset and Upload to S3.....................................................................21\\nStep 5: Train a Model...............................................................................................................21\\nChoose the Training Algorithm...........................................................................................22',\n",
              " 'Choose the Training Algorithm...........................................................................................22\\nCreate and Run a Training Job (Amazon SageMaker Python SDK)............................................22\\nCreate and Run a Training Job (AWS SDK for Python (Boto 3))...............................................23\\nStep 6: Deploy the Model..........................................................................................................26\\nStep 6.1: Hosting Services.................................................................................................26\\nStep 6.2: Batch Transform.................................................................................................28',\n",
              " 'Step 6.2: Batch Transform.................................................................................................28\\nStep 7: Validate the Model........................................................................................................30\\nStep 7.1: Validate a Model Deployed to Amazon SageMaker Hosting Services...........................30\\nStep 7.2: Validate a Model Deployed with Batch Transform....................................................33\\nStep 8: Clean Up ......................................................................................................................35\\nStep 9: Integrating Amazon SageMaker Endpoints into Internet-facing Applications..........................35',\n",
              " 'Step 9: Integrating Amazon SageMaker Endpoints into Internet-facing Applications..........................35\\nUsing Notebook Instances.................................................................................................................36\\nCreate a Notebook Instance.......................................................................................................36\\nAccess Notebook Instances........................................................................................................39\\nControl Root Access to a Notebook Instance........................................................................40\\nCustomize a Notebook Instance.................................................................................................40',\n",
              " 'Customize a Notebook Instance.................................................................................................40\\nLifecycle Conﬁguration Best Practices.................................................................................41\\nUse Example Notebooks ............................................................................................................42\\nUse or View Example Notebooks in Jupyter Classic...............................................................42\\nUse or View Example Notebooks in Jupyterlab.....................................................................43\\nNotebook Instance Software Updates.........................................................................................44',\n",
              " 'Notebook Instance Software Updates.........................................................................................44\\nSet the Notebook Kernel...........................................................................................................44\\nInstall External Libraries and Kernels in Notebook Instances...........................................................45\\nMaintain a Sandboxed Python Environment.........................................................................45\\nAssociate Git Repositories with Amazon SageMaker Notebook Instances..........................................46\\niiiAmazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account.....................................................47',\n",
              " 'iiiAmazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account.....................................................47\\nCreate a Notebook Instance with an Associated Git Repository...............................................49\\nAssociate a CodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance.........51\\nUse Git Repositories in a Notebook Instance........................................................................52\\nGet Notebook Instance Metadata...............................................................................................54\\nMonitor Jupyter Logs in Amazon CloudWatch Logs.......................................................................54',\n",
              " 'Monitor Jupyter Logs in Amazon CloudWatch Logs.......................................................................54\\nBuild a Model ..................................................................................................................................56\\nUse Built-in Algorithms.............................................................................................................56\\nCommon Information .......................................................................................................58\\nBlazingText......................................................................................................................74\\nDeepAR Forecasting..........................................................................................................83',\n",
              " 'DeepAR Forecasting..........................................................................................................83\\nFactorization Machines......................................................................................................98\\nImage Classiﬁcation Algorithm .........................................................................................108\\nIP Insights .....................................................................................................................131\\nK-Means Algorithm.........................................................................................................141\\nK-Nearest Neighbors (k-NN) Algorithm..............................................................................148',\n",
              " 'K-Nearest Neighbors (k-NN) Algorithm..............................................................................148\\nLatent Dirichlet Allocation (LDA).......................................................................................157\\nLinear Learner Algorithm .................................................................................................162\\nNeural Topic Model (NTM) Algorithm................................................................................177\\nObject2Vec....................................................................................................................183\\nObject Detection Algorithm.............................................................................................199',\n",
              " 'Object Detection Algorithm.............................................................................................199\\nPrincipal Component Analysis (PCA) Algorithm ...................................................................222\\nRandom Cut Forest (RCF) Algorithm..................................................................................226\\nSemantic Segmentation ..................................................................................................234\\nSequence to Sequence (seq2seq)......................................................................................242\\nXGBoost Algorithm.........................................................................................................255',\n",
              " 'XGBoost Algorithm.........................................................................................................255\\nTrain a Model.................................................................................................................................276\\nMonitor and Analyze Training Jobs Using Metrics.......................................................................276\\nSample Notebooks .........................................................................................................276\\nDeﬁning Training Metrics.................................................................................................277\\nMonitoring Training Job Metrics ( Console).........................................................................279',\n",
              " 'Monitoring Training Job Metrics ( Console).........................................................................279\\nMonitoring Training Job Metrics (Amazon SageMaker Console).............................................279\\nExample: Viewing a Training and Validation Curve..............................................................281\\nIncremental Training...............................................................................................................282\\nPerform Incremental Training (Console).............................................................................283\\nPerform Incremental Training (API)...................................................................................285',\n",
              " 'Perform Incremental Training (API)...................................................................................285\\nManaged Spot Training...........................................................................................................287\\nUsing Managed Spot Training..........................................................................................287\\nManaged Spot Training Lifecycle......................................................................................288\\nUsing Checkpoints ..................................................................................................................288\\nAutomatic Model Tuning.........................................................................................................288',\n",
              " 'Automatic Model Tuning.........................................................................................................288\\nHow Hyperparameter Tuning Works..................................................................................289\\nDeﬁne Metrics ................................................................................................................290\\nDeﬁne Hyperparameter Ranges ........................................................................................292\\nExample: Hyperparameter Tuning Job...............................................................................293\\nStop Training Jobs Early..................................................................................................302',\n",
              " 'Stop Training Jobs Early..................................................................................................302\\nRun a Warm Start Hyperparameter Tuning Job..................................................................303\\nAutomatic Model Tuning Resource Limits...........................................................................307\\nBest Practices for Hyperparameter Tuning.........................................................................308\\nUsing Augmented Manifest Files ..............................................................................................308\\nAugmented Manifest File format ......................................................................................309',\n",
              " 'Augmented Manifest File format ......................................................................................309\\nAugmented Manifest File format ......................................................................................310\\nUse an Augmented Manifest File (Console)........................................................................310\\nUse an Augmented Manifest File (API) ...............................................................................311\\nDeploy a Model..............................................................................................................................313\\nPrerequisites..........................................................................................................................313',\n",
              " 'Prerequisites..........................................................................................................................313\\nWhat do you want to do?........................................................................................................313\\nivAmazon SageMaker Developer Guide\\nManage Model Deployments....................................................................................................313\\nDeploy Your Own Inference Code.............................................................................................314\\nGuide to Amazon SageMaker...................................................................................................314',\n",
              " 'Guide to Amazon SageMaker...................................................................................................314\\nInference Pipelines..................................................................................................................314\\nSample Notebooks .........................................................................................................315\\nProcess Features with Spark ML and Scikit-learn.................................................................315\\nCreate a Pipeline Model..................................................................................................316\\nReal-time Inference.........................................................................................................318',\n",
              " 'Real-time Inference.........................................................................................................318\\nBatch Transform.............................................................................................................320\\nLogs and Metrics ............................................................................................................321\\nTroubleshooting.............................................................................................................326\\nCompile and Deploy Models with Neo.......................................................................................328\\nSample Notebooks .........................................................................................................329',\n",
              " 'Sample Notebooks .........................................................................................................329\\nCompile Models ..............................................................................................................329\\nDeploy Models...............................................................................................................334\\nRequest Inferences..........................................................................................................342\\nTroubleshoot Errors........................................................................................................342\\nBatch Transform.....................................................................................................................348',\n",
              " 'Batch Transform.....................................................................................................................348\\nUse Batch Transform with Large Datasets..........................................................................349\\nSpeed Up a Batch Transform Job.....................................................................................350\\nUse Batch Transform to Test Production Variants................................................................350\\nBatch Transform Errors...................................................................................................350\\nSample Notebooks .........................................................................................................350',\n",
              " 'Sample Notebooks .........................................................................................................350\\nAssociate Prediction Results with Input.............................................................................351\\nElastic Inference.....................................................................................................................355\\nHow EI Works................................................................................................................356\\nChoose an EI Accelerator Type.........................................................................................356\\nUse EI in a Amazon SageMaker Notebook Instance.............................................................356',\n",
              " 'Use EI in a Amazon SageMaker Notebook Instance.............................................................356\\nUse EI on a Hosted Endpoint ...........................................................................................357\\nFrameworks that Support EI............................................................................................357\\nUse EI with Amazon SageMaker Built-in Algorithms............................................................357\\nEI Sample Notebooks ......................................................................................................357\\nSet Up to Use EI ............................................................................................................358',\n",
              " 'Set Up to Use EI ............................................................................................................358\\nAttaching EI to a Notebook Instance.................................................................................361\\nEndpoints with Elastic Inference.......................................................................................363\\nAutomatically Scale Amazon SageMaker Models.........................................................................365\\nAutomatic Scaling Components ........................................................................................366\\nBefore You Begin............................................................................................................368',\n",
              " 'Before You Begin............................................................................................................368\\nRelated Topics................................................................................................................369\\nConﬁgure Automatic Scaling for a Production Variant.........................................................369\\nEdit a Scaling Policy.......................................................................................................375\\nDelete a Scaling Policy....................................................................................................375\\nUpdate Endpoints that Use Automatic Scaling ....................................................................377',\n",
              " 'Update Endpoints that Use Automatic Scaling ....................................................................377\\nLoad Testing..................................................................................................................377\\nAdditional Considerations................................................................................................378\\nTroubleshoot..........................................................................................................................380\\nCPU Detection Errors with a JVM......................................................................................380\\nBest Practices.........................................................................................................................381',\n",
              " 'Best Practices.........................................................................................................................381\\nDeploy Multiple Instances................................................................................................381\\nHosting Instance Storage Volumes............................................................................................381\\nUse Your Own Algorithms or Models................................................................................................384\\nScenarios and Guidance...........................................................................................................384\\nDocker Container Basics..........................................................................................................385',\n",
              " 'Docker Container Basics..........................................................................................................385\\nAmazon SageMaker Containers................................................................................................386\\nEnvironmental Variables - Entrypoints...............................................................................388\\nEnvironmental Variables - User Scripts..............................................................................389\\nEnvironmental Variable - Reference..................................................................................392\\nvAmazon SageMaker Developer Guide\\nGet Information for a Script ............................................................................................395',\n",
              " 'vAmazon SageMaker Developer Guide\\nGet Information for a Script ............................................................................................395\\nGet Started with Containers....................................................................................................396\\nPre-built Docker Images - Deep Learning...................................................................................398\\nPre-built Docker Images - Scikit-learn and Spark ML...................................................................401\\nExample Notebooks ................................................................................................................402\\nUse Your Own Training Algorithms...........................................................................................404',\n",
              " 'Use Your Own Training Algorithms...........................................................................................404\\nRun Your Training Image.................................................................................................404\\nProvide Training Information............................................................................................405\\nSignal Success or Failure.................................................................................................407\\nTraining Output..............................................................................................................408\\nUse Your Own Inference Code..................................................................................................408',\n",
              " 'Use Your Own Inference Code..................................................................................................408\\nWith Hosting Services.....................................................................................................408\\nWith Batch Transform.....................................................................................................411\\nCreate Algorithm and Model Package Resources.........................................................................413\\nCreate an Algorithm Resource..........................................................................................413\\nCreate a Model Package Resource.....................................................................................417',\n",
              " 'Create a Model Package Resource.....................................................................................417\\nUse Algorithm and Model Package Resources.............................................................................419\\nUse an Algorithm to Run a Training Job............................................................................420\\nUse an Algorithm to Run a Hyperparameter Tuning Job......................................................423\\nUse a Model Package to Create a Model............................................................................425\\nAmazon SageMaker in AWS Marketplace...........................................................................................428',\n",
              " 'Amazon SageMaker in AWS Marketplace...........................................................................................428\\nTopics...................................................................................................................................428\\nAmazon SageMaker Algorithms................................................................................................428\\nAmazon SageMaker Model Packages.........................................................................................428\\nSell Amazon SageMaker Algorithms and Model Packages............................................................429\\nTopics...........................................................................................................................429',\n",
              " 'Topics...........................................................................................................................429\\nDevelop Algorithms and Models in Amazon SageMaker.......................................................429\\nList Your Algorithm or Model Package on AWS Marketplace.................................................431\\nFind and Subscribe to Algorithms and Model Packages on AWS Marketplace..................................431\\nUse Algorithms and Model Packages.................................................................................432\\nManage ML Experiments with Amazon SageMaker Model Tracking Capability.........................................433',\n",
              " 'Manage ML Experiments with Amazon SageMaker Model Tracking Capability.........................................433\\nSample Notebooks .................................................................................................................433\\nUse Model Tracking to Find, Organize, and Evaluate Training Jobs (Console)...................................434\\nUse Tags to Track Training Jobs (Console).........................................................................434\\nFind Training Jobs (Console)...........................................................................................435\\nEvaluate Models Returned by a Search (Console)................................................................435',\n",
              " 'Evaluate Models Returned by a Search (Console)................................................................435\\nUse Model Tracking to Find and Evaluate Training Jobs (API)........................................................436\\nUse Search to Find Training Jobs Tagged with Speciﬁc Values (API).......................................436\\nEvaluate Models (API) .....................................................................................................436\\nGet Suggestions for a Search (API)...................................................................................437\\nVerify the Contents of Your Training Jobs..................................................................................438',\n",
              " 'Verify the Contents of Your Training Jobs..................................................................................438\\nTrace the Lineage of your Models.............................................................................................438\\nUse Single-click on the Amazon SageMaker Console to Trace the Lineage of Your Models\\n(Console).......................................................................................................................438\\nUse Code to Trace the Lineage of Your Models (API)...........................................................439\\nUse Machine Learning Frameworks with Amazon SageMaker................................................................440',\n",
              " 'Use Machine Learning Frameworks with Amazon SageMaker................................................................440\\nUsing Apache Spark ................................................................................................................440\\nDownload the Amazon SageMaker Spark Library................................................................440\\nIntegrate Your Apache Spark Application with Amazon SageMaker........................................441\\nExample 1: Amazon SageMaker with Apache Spark.............................................................442\\nAdditional Examples: Amazon SageMaker with Apache Spark...............................................449',\n",
              " 'Additional Examples: Amazon SageMaker with Apache Spark...............................................449\\nUsing TensorFlow...................................................................................................................449\\nUse TensorFlow Version 1.11 and Later.............................................................................449\\nUse TensorFlow Legacy Mode for Versions 1.11 and Earlier..................................................450\\nUsing Apache MXNet ..............................................................................................................450\\nWhat do you want to do?................................................................................................450',\n",
              " 'What do you want to do?................................................................................................450\\nUsing Scikit-learn...................................................................................................................451\\nviAmazon SageMaker Developer Guide\\nWhat do you want to do?................................................................................................451\\nUsing PyTorch........................................................................................................................451\\nWhat do you want to do?................................................................................................451',\n",
              " 'What do you want to do?................................................................................................451\\nUsing Chainer ........................................................................................................................452\\nWhat do you want to do?................................................................................................452\\nUse SparkML Serving..............................................................................................................453\\nReinforcement Learning with Amazon SageMaker RL..........................................................................454\\nWhy is Reinforcement Learning Important?................................................................................454',\n",
              " 'Why is Reinforcement Learning Important?................................................................................454\\nMarkov Decision Process (MDP)................................................................................................454\\nKey Features of Amazon SageMaker RL.....................................................................................455\\nSample RL Workﬂow Using Amazon SageMaker RL.....................................................................457\\nRL Environments in Amazon SageMaker....................................................................................458\\nUse OpenAI Gym Interface for Environments in Amazon SageMaker RL..................................459',\n",
              " 'Use OpenAI Gym Interface for Environments in Amazon SageMaker RL..................................459\\nUse Open Source Environments........................................................................................459\\nUse Commercial Environments.........................................................................................459\\nDistributed Training with Amazon SageMaker RL........................................................................459\\nHyperparameter Tuning with Amazon SageMaker RL...................................................................460\\nMonitoring .....................................................................................................................................461']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1WK54-74Rpt"
      },
      "source": [
        "### Load the dataset into the vector store\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x2317d814580>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from int_host_emd import ollama_emb\n",
        "\n",
        "vectordb=Chroma.from_texts(texts=texts[:10], embedding=ollama_emb)\n",
        "vectordb\n",
        "\n",
        "# To create a persistent directory\n",
        "# db = Chroma.from_texts(texts=texts[:100], embedding=ollama_emb, persist_directory=\"./chroma_db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160\n"
          ]
        }
      ],
      "source": [
        "print(len(vectordb.get()[\"documents\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "•Use a Jupyter notebook on an Amazon SageMaker notebook instance. You can also use the notebook\n",
            "instance to do the following:\n",
            "•Write code to create model training jobs\n",
            "•Deploy models to Amazon SageMaker hosting\n",
            "•Test or validate your models\n",
            "For more information, see Use Notebook Instances (p. 36)\n",
            "•You can use a model to transform data by using Amazon SageMaker batch transform. For more\n",
            "information, see Step 6.2: Deploy the Model with Batch Transform (p. 28).\n",
            "How It Works: Next Topic\n",
            "Train a Model with Amazon SageMaker  (p. 4)\n",
            "Train a Model with Amazon SageMaker\n",
            "The following diagram shows how you train and deploy a model with Amazon SageMaker:\n",
            "4Amazon SageMaker Developer Guide\n",
            "Model Training\n",
            "The area labeled Amazon SageMaker highlights the two components of Amazon SageMaker: model\n"
          ]
        }
      ],
      "source": [
        "## query the database\n",
        "query = \"How to use ML pipeline in Sagemaker\"\n",
        "docs = vectordb.similarity_search(query)\n",
        "\n",
        "print(len(docs))\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX5BECsdSUUM",
        "outputId": "cdff3467-8af3-45cd-f750-f3174bc521fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 50 headlines.\n"
          ]
        }
      ],
      "source": [
        "# To add other data as well to vector db\n",
        "vectordb.add_texts(texts[100:150])\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts[100:150]))\n",
        "\n",
        "vectordb_index = VectorStoreIndexWrapper(vectorstore=vectordb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data from a stored chroma db "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ids': ['c4a0256f-7e13-46b1-bede-c00f59bcb96d', '4f86ff62-7ffd-41fb-858e-e9dfe22ae4d8', 'ebe6bbb3-f2fe-4e38-a1bc-20476930eb15', '76c9e93c-b6f8-4382-a1d6-6fc0a5c1ff4f', '5ae63c9f-043c-4c5a-b19e-de71004d87bf', 'e05b9237-4afe-4eca-934c-71edde2df4f4', '2789b5de-e541-423b-b095-d1881444250b', '2bd36fcc-7e0d-4d5c-a2d4-3f2ed4d1d39b', 'bf0b18d5-78a0-45fd-9e92-030abd0da15a', '23b43fda-abc6-4eec-b730-c6b6a51b8ca4', 'cd926745-b2c1-4080-b9f6-86e29bd488ad', '9047947b-28a8-468c-b09f-00f5afd4bdf2', 'e652c881-a93e-402e-84d4-2f745bebc9f8', 'e92723cc-ca5f-4511-9776-fefb2efb3155', '3cbecfec-6b8b-481d-8c4f-f7b15323269a', 'ddd31977-3b76-473d-80da-32f160fdfb29', 'c40939e7-5819-4676-aee2-1b811fb435e7', '24d0f698-2572-490c-af31-f57b58838a31', '6b6b8d30-3b8f-4416-a4f7-88c883c87577', '62c5ec5e-3aff-4255-b4f3-11df423e590c', '908e9b1c-0b98-4540-8236-80d33a8b7f95', 'ef1762fa-e6cf-4656-abeb-2ca21cc5129f', '54c49bef-0888-4ee1-8da8-10ce1da35a60', 'ea035f26-bd6a-4426-ab6b-e74031e5dd7d', 'bfaa35ec-a63e-4b43-9cf4-8d1e20e8d492', '3c34bac9-50be-4d37-8e83-f65470327f08', '6c9fc742-d9d8-4c3d-bbbb-9b2308e90c0a', 'b40f84dc-0703-46fe-9dda-1349401ce693', '16ce279c-9df6-4c97-b0e1-8a7bfe07ab47', '78e04443-2ff0-462b-9a59-12da8f04fee3', 'e0be0fda-99b1-4b9d-b062-750e2861b6a1', '09714462-08b6-4ce2-864c-d97cdeec3101', 'b671ab88-c61e-4eb5-92ff-c4eb0a264ad0', '43bc8e59-dd4d-4b66-8a5b-7a6befe1bcb7', '11e71f8f-c8e2-4c52-8d19-a74530ab5d11', 'c023963b-f9fb-4a8c-9ba5-bba96d15dae1', 'c7196f6c-215a-40a3-b1ed-6c2137af9e13', '402451cb-a4e1-4fd4-9451-0b2a652a35f6', 'dfca2b8e-d82a-4800-bcb7-6f95ba281cfc', '63a83eba-a2bb-4b7f-832b-bcf58eb9813f', '62c69e36-1ff5-4d8b-a15f-3406c202994a', '44d2daa9-221a-4f1c-bbe8-346e2e3c3007', '85afda56-4f25-493b-8d45-20c8fae3e39e', 'b9440e72-eca9-4603-8ce9-e3340b5c0a00', '90ae9fad-471c-4bfe-ab1e-73d0f60ec3e3', '2758a8a1-9f73-49b1-9c35-998bc9347edd', 'ace52a20-9486-4e57-a1a5-a7ba44351e96', 'f2c4d531-2e91-4218-898a-59869be3e659', '386e0a81-3bc3-4000-a534-b265318145e0', 'c52d6263-05b8-4398-a64e-8ff99c6182d7', '3353e683-d519-40f5-9ff2-f9a3d542c8e8', '68a29713-3aae-4be5-a2c6-8d455568ccd5', '7f1cc891-7929-43e8-a5df-9c0167ac717d', '5d3c8fd0-adc9-4c2d-a0f3-2d556fe8e927', 'e2bd59ad-9cc0-4ded-80a4-cedb98307d49', '195d5800-2146-458b-82eb-b9d161c0569e', '61a67c24-7685-41f6-8a57-e724844a21f2', '98c133e6-0b3f-4856-8922-a32ec973bd02', '7cd727ea-922a-4464-a419-2f161ffa8925', '4c0e6a0f-8043-491f-8954-41ca114b955a', '1852627e-8cba-4e56-902f-76ccfeafb218', '11179a60-72ed-4dd9-aa61-f28eec40eb6c', '6675b284-ede4-46d6-9871-23ba124c3692', 'f7bcc618-f40c-4b8c-9768-ab96fac5c171', 'a090a174-471c-4e7f-8a67-4cedd5939511', '79b5f26c-33e5-4da5-b2b5-46215011d500', 'dcfd8108-1d07-4726-bb2c-c61b911c54a2', '14c7aead-b107-4080-b13b-b97c5e7d4a97', 'be7a2973-f1e9-4c8c-9ff4-6fdd52be3ee3', '479d9e1e-a3e4-4d47-9ec4-5654fd4b6fa8', '70d062da-550c-4897-b53f-8e290adea7fc', '16070b9e-1a09-41fe-b8c4-7b90aede806f', '2e942ed3-865f-4a3f-b041-474f5a2340fd', 'a639e070-6b7d-49b8-94b2-863e901e73c8', 'aad41444-9e2d-4b73-ab64-59134798581d', '92952762-8650-417f-9369-fd3e4d9b7937', '7640c109-e9d4-42ea-ba30-b9ececbc2454', 'd1335296-fa25-4be1-813f-4a59dec33e64', '1f817559-a4d8-43a4-8195-5a50e7498983', '576c0eff-0b8f-4efd-a4ad-d6250c0089c4', 'd6bd44e7-896b-4d94-a39e-32e754fc6d92', '94c834e2-22a7-47dc-8fce-c5ee79eb5f99', 'c0e61f28-612a-440a-86d5-ea3bf42f89c8', '145f1063-b95a-4b96-9885-42d50b3060ac', '6a0b5a24-3672-4d4d-92b0-6c51be1403c9', '04d90999-5686-4775-acf9-f214ec55efb0', '4b7befc6-65ae-4211-98c4-6309f18d0dcc', 'ba5dae30-9088-49ab-b0c8-a9fa3198d3f5', '3432684a-7ae9-4545-a81a-1bcd788b22af', '4ecd2470-b3b8-4a93-bd80-4f33f3a6d112', 'b3b6f228-972c-42db-b089-ef6cfd438214', 'af28d4f9-f0a4-4d25-b32f-b66722b25caf', '57948f5c-99cf-4331-b476-6ba36f7b2a9a', '388a11d0-5d1c-4903-85ee-68ff0531f50d', '002944d9-ca8a-4343-9f4f-7665e7a8672b', 'dc5776d7-550a-47a0-a111-b99856d0d586', '488c1088-f167-4989-a8ae-73cb9a1cfe66', 'ee803a7d-1263-469a-bbf9-53f3ee60bfcb', '2845c49c-7b2a-499c-a2f6-0e8c1f39b292', '9f7334ff-d722-4c5c-934e-6aee6b02aa0b', '43f64708-db3b-4aa8-b4fa-817bfb443bfb', '846843aa-86d8-46aa-80e3-cb63472d6535', '9291110f-0fc1-4e66-8248-c987ff6c781b', 'fa2dee97-1b3a-486c-8e9d-09ade2d90fa8', '9451a709-3b74-426d-a6ff-7d863d544a36', '866f54a4-3fb4-4054-98e0-2da5e335757a', '5e870ea9-b24f-4036-8973-a1e3e020eb16', '95fcaee9-fcf4-4e38-a88a-e6a4b6f9cda2', '399f2f42-e294-4463-af2f-d57b0502c7ba', '7c9d9793-4fa4-409a-af60-2c5eda47f942', '258082a1-3ffd-4fbc-bfcd-48db92e6779b', '1a7bc409-45d0-492a-8ce3-e93f0ccecc05', 'abf5eb76-b621-4fac-b17d-784bee12d8a4', '13286868-ff32-4af3-8544-d72a953731b5', '84e8fd36-3e92-4271-a0b5-def4a4b17573', '1d48fe23-5967-4737-b3a6-2c7661805288', '49a4fbce-e941-4249-9ec5-456999b5c826', '4c77d40e-f653-4a0e-ba1d-225ba6d1a9fb', 'd8acfc2a-24fb-48fc-8d69-15cf5f1abc1f', 'be4e7199-c22f-4b1e-8d08-1abac155b5cd', 'b94c0428-74ba-4c9c-bd4f-434a71b60961', '456465f9-53cd-4b01-ade2-34389a95879b', '9643365e-8b68-4a15-89f4-7991d45fb872', '82a0ed4d-4bea-481a-b8d4-35b43445452d', 'f46aa104-6467-49c4-8627-72036a07ad89', 'a5ede1f1-1339-423e-8922-abdead4bfb98', 'e4c21715-a5ec-4b3f-a4c2-63ae38caefcf', '6d437c36-2195-43ed-b49b-69fc610708c1', '4d45fe22-4bf2-4e01-a9fa-511cc723f646', '7c3a34f5-cd07-44f5-9acd-458b7c411ea8', '92779e49-ac98-4623-ad2e-d9091276aab9', '8c328c6b-d131-410b-85c6-66f69e4d2f90', 'a89bc044-8c1e-4834-b248-2adb3fed580d', '08b4a0ec-afa2-4025-b2d0-d17e3572817e', '0da94f01-4d61-4e12-9bce-c888026e934e', '237d76f4-4792-4587-9dac-64aaba3bd40f', '22487484-b31c-41e8-9227-862c0e0d8966', '773311ca-45b3-4341-9bc4-bb30500e5cbd', '125a2610-97a5-490f-a226-c2f4651dd1b6', '93ce18a8-c3d9-4fe6-b620-92b83e93a0aa', 'e9202708-afb9-4752-8505-8d85abb70c00', 'ae797d08-5e8c-4eeb-8079-656ad85fa53b', 'ef50576d-88e8-4c07-9961-1a3cadd15a4f', '5152015f-6175-4354-964a-cbfda75d84fa', '365c4715-5648-4ed2-9d75-daf912ffc7bf', '24c56b85-6419-4ec8-bc4e-f382a2461b0f', 'c72c0c36-2941-46e2-b3ae-2bdd6752edd2', '1f33cd97-0552-4528-9503-7a0d96116dca', '79974998-4961-4b44-ae31-e89b4553e115', 'e7c54276-75be-41b3-86cd-603c0daf3622', 'd560c119-e64b-43ab-bcbb-47a6dd1cab51', '0a099fbc-bd75-4062-987a-21787e818198', '280a6fee-0757-4392-aa63-db7a96399563', '32543169-7c90-407a-809f-3bffdf79c729', '080fc5e7-d89d-4252-80fa-acf3bf3e87e1', 'cf9356d7-e20a-402b-9a13-b0bed0ceccc4', '320f6295-e55f-42d1-9d46-7b88cdf4eb7b', '3f09ee73-d1b1-464a-b639-41057b5a3167', '63f1b3e2-811d-453b-80bc-60580c847c7a', '34666e44-7c0b-4573-af0c-374cdd500b8c', 'c461d228-ab77-469d-b5a6-21017fa7d43d', '1f24cfea-1219-4011-bfd7-09675e6a36b8', '42bde083-7cc2-41d2-9f99-f98dca48adc4', 'f3847303-d0a9-4eb0-9f21-d8ddc8b91478', 'bcae741d-4d2c-417f-a83c-923b4f63ef64', '9a91ec2e-84cb-4c6d-9561-88dcb359be24', '99252997-39ed-41bb-9c3b-83ed82a4e2f4', '939a369c-835e-4278-9243-5e2ed04dd9c7', '7fcb7edb-cbbd-4d82-a70c-4c2c2ff6a9e3', '0546ab4d-e381-4a3d-bd1d-11f58d38a156', '891c65b7-cb27-44d2-9f17-c54f53e5d1ea', '3f051704-aaae-49e6-b18e-6f0eb36d978e', '374e3dfa-16c3-45be-8694-49f6e3d63818', 'b4026c2d-2da7-4fac-a9fb-a0831fc0c231', '51175316-0f03-4a1e-914d-0bdc3fd0fad4', '4418d574-65fe-4f42-8c85-633c028fb8eb', 'f0df8f22-7f30-4341-8749-269a7d4b6174', '7e2a21d2-3c60-4be8-9429-75d3489a5bf5', '81b8bfa7-2bc7-4cb2-9275-5e00a2c87597', '3ae0636f-c38f-4094-a3ef-94d7639ec988', 'e15860ac-aa2e-4c4e-97c8-b95eb619baf8', '1f2bf071-2211-48b4-850a-9a1c499bd2c8', '5c34868e-3d87-43e1-9e8e-908ecc25e25c', 'b4b65860-f9ec-49f4-9092-30de29920aee', 'd29b760f-b988-41e2-bb2b-63ee098de20a', 'b53f8778-d235-4409-aed3-b6016d83f1d8', '0f4f82f2-8eeb-4b48-aa85-3e3560bf05b2', '8274a4b5-d751-4721-9d30-2334db00c987', '0b4d2594-0592-4ab2-9782-5a37530c6c74', '8d5bf240-d435-403d-84c5-4b88572e2c90', '9d14077c-4d35-4e05-aee1-223d115380fa', '4321249d-73bd-4679-b95d-b6a6cbebbe8e', '511e4bcf-dd29-4b05-afcc-ef36007c7d59', '67d93f5a-397c-41c1-94e6-d7db04c162d0', 'f1facb34-c839-4cd7-9946-e8e98fcd5a81', 'acafc9cc-0a50-4cd2-b933-c04bfc94c6c8', 'edbd1dcf-47d5-4310-b7ee-1513824636d4', '52d778d9-413d-443f-bd5b-2c1fce467de1', '39460d14-cb9e-459c-8c01-6d0edb562a23', 'f500cdfd-3155-473d-838e-6a078c5b30e5', '7ccbb0d2-5dd7-4397-ae8b-976a5913ceac', 'b2298659-0000-4cbf-a54b-95484a73f990', '71bb7fea-1856-489f-95ba-80bcaa2cf321', '458b0247-ba61-44da-9e0a-768552063dad', 'a58081bf-731f-47c2-872c-90ed706a0b80', 'cbfee4f9-c5d0-4c14-9e86-2c611b43e26d', 'e572c19d-7dbd-4a2c-ae8e-9c842db3de88', '7bb4592e-3125-4191-ae2b-c89334ce2856', 'cda61ca7-9c10-497b-a579-ab7dfefd1793', 'daeab163-eb57-4026-9e48-8ad3bef5fb99', 'dc6a95d4-4cd0-4660-b4ad-1867a39a253c', '61a519f1-d35e-4022-b895-11ebe5643f9f', '1b661c6f-acf3-4074-a4df-ee0e461839d5', '81877109-57ac-4169-a422-1132b67f2654', 'bcf4a952-7086-4670-8cc6-20457ca9a147', 'dcfb0e9d-1c03-448f-984a-72509e93bc49', '16e76c92-d37a-44ed-9e66-52455e37777d', '29051cf0-1080-4649-8f7a-6c501aa9446b', 'a31ac261-5ea4-458d-913b-dde809d6617a', '5cddd10c-9dfc-4f60-9d2e-c06413b8285f', '4f76cd01-2900-4982-abea-8d06ff149a6b', '74b8f64d-9a6e-433c-931a-c5e1f3b60ccc', 'eafcca66-ecd0-4e2a-be59-f3bf01fda4ad', '2436dc43-068a-4192-8629-a06ac7d622f4', 'fe0cd373-c884-4da2-b513-71aa5c997b71', '3a55eefb-a72d-4d2f-995d-46fcfda33a6b', '1fe7cbf1-af59-43ab-9520-d263c6cdf473', 'aa458d3d-9c34-4c5e-8e3b-574c6108d019', '3fcb166d-6362-4f7f-a1da-dcc96767a004', 'beba9529-d024-4f0c-b94b-515025f18725', 'fd88e67b-b74f-452e-92e3-df68d2034b8a', '8e2b295c-c5a1-4a16-995d-8d702ec1296a', '589b462e-f105-4f46-827b-9a66354359a4', '999eb1e5-1541-4017-ab62-9e990e70a918', '6da53873-f44c-4709-a933-b48e2d3111f9', '76cc18fa-bb65-4b01-970a-68d72709a37d', 'fc077ef9-c4f8-45c4-a625-25d1f674155c', 'b41d9eac-5f6e-4d5e-9afa-032d6ad8e88d', 'a3450e0a-b27a-41d7-b077-51b474632193', '3fa8247c-2fb9-4da5-bf21-f76cc600bf8b', '47147c71-375e-4ef0-9d9a-d078cc987fb2', '7c3ff4a0-bec1-4bb2-b7c9-ebf2fdd8d91e', 'fcdf7606-c08b-44b2-84a8-2fa47708f29b', '660533b1-3be2-4625-a214-f6cf5475562c', 'ec9ba366-3411-455e-9514-4012111c3369', '63a0f0e3-cc74-4070-a452-26028b4ece71', 'ce50bc50-ac38-4739-82cf-d62327179076', '0ec0daf7-4bcc-48a0-b05a-808834fcdb1a', 'a4ee151e-4a41-4f31-9f02-19c5a7577e90', '63f78743-05c0-459f-b848-2681d138416e', 'ec6bd924-fcf8-44d6-8755-e70e243779b3', 'a20579fa-6e3b-4cc4-b697-55c2c6e9c10e', 'c1ad2cfa-4856-4dde-91c5-2867395b5e1b', '1e4f4eb5-bb02-454a-8c73-43026170c3a8', 'f5a5d905-7d45-4b6e-ad58-cde08dd89064', 'd63b7712-56d3-4f77-a9d2-7e1ea2ad0fc6', '069d1283-5a69-403a-acdc-599ba72a19ee', '866792c4-7d40-44fb-9305-96d4efa69bd8', '8d4a97f9-18a5-47de-ac6b-038870975faa', '3bd3420f-173d-4e97-b9f8-1c0f7f5928f6', '5f8573db-6779-41fc-b069-12b153694c67', '9c256f99-5769-4152-b533-83f8cf21f59a', 'eb942e66-0b8c-4bc5-9bb7-43a2592d22d1', 'd3c4a240-d46a-4514-80ff-56f3f31d1dfa', '5c8baa6d-dbe1-4a95-b9b2-964f5e094f91', '9aa979c9-fbcc-4a73-b946-cf8d6f34bf90', 'a3bd6df4-59d1-4ee9-884b-4e9da476fd98', '490f45df-e371-464c-b1be-f4285caf70c9', '5782ae0e-104b-412d-9a69-d1fc17e64388', '70720293-8b25-4273-92da-e9306b4320f2', '8974b96e-ad81-4a52-a9cf-a931ed1e6801', '0342083e-8e3b-4928-a485-43701863dd5b', '9af67e7b-d1d2-411c-a841-39f14bce611c', '0046ed6a-129f-4835-a490-a7d39e2070fb', 'ffd6ad8f-9df8-4665-a2af-b572bd63c89f', '1a55fd9d-c406-4df5-9304-111c6e7d1b74', '03ddc334-415f-49bc-a755-8ff6a5b392da', '090f1814-3306-4fce-8729-d2b6b5d50d3b', 'a1246065-cf68-4225-ba04-6a6dd40e5ac9', '19ef0aca-4276-4e32-849a-95705d2e9d73', 'c30941fa-e3bf-422b-a0c3-44b75138b80f', 'd8877e3a-782d-4926-8a76-c76c0f9a5cfd', 'be8a2fe7-ce78-4596-a1ef-6691378ff23b', 'ce77f9f2-ed5f-4adb-a056-572993b19c64', 'f21d4819-85ea-43b7-a316-127170925f6d', 'd06d8115-223d-4a49-8248-043fd6b017e2', 'c33863de-56df-4ee1-876f-adf7aaea38f1', 'c548864a-7ddb-42aa-bf0e-e09d5543fbcb', '75301820-2046-4264-86f8-da68ccd9ab4a', 'e2426a29-0947-4dca-b263-159d74b2042f', '0d53b626-55db-4f48-9310-562b34edfebf', '78dd6bdf-102e-410e-82f4-6e4331e07863', '0ae3995b-a314-4350-8632-334f4b58bbc8', '30f1fdd9-9d92-4f24-a8a7-f1a83d513dc9', '099b0c04-2429-4724-8ba2-7ed0bc151ce1', '578ff2c9-193d-4a1a-8163-86a0629d9b55', 'e830d09d-f18a-4548-bdcf-e21f6f0e2da8', 'a2d17dfa-333c-4286-899b-942f403237b7', '13ba5d72-0209-47a6-ae77-b4d343d287b3', '982fbea8-3432-41f3-9711-26e3996d3cf2'], 'embeddings': None, 'documents': [\"Amazon SageMaker\\nDeveloper Guide\\nAmazon SageMaker Developer Guide\\nAmazon SageMaker: Developer Guide\\nCopyright © 2019 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not\\nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or\\ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may\\nor may not be aﬃliated with, connected to, or sponsored by Amazon.Amazon SageMaker Developer Guide\\nTable of Contents\\nWhat Is Amazon SageMaker?...............................................................................................................1\", 'Table of Contents\\nWhat Is Amazon SageMaker?...............................................................................................................1\\nAre You a First-time User of Amazon SageMaker?..........................................................................1\\nHow It Works....................................................................................................................................2\\nMachine Learning with Amazon SageMaker...................................................................................2\\nHow It Works: Next Topic...................................................................................................3', 'How It Works: Next Topic...................................................................................................3\\nExplore and Preprocess Data.......................................................................................................4\\nHow It Works: Next Topic...................................................................................................4\\nModel Training...........................................................................................................................4\\nHow It Works: Next Topic....................................................................................................7\\nModel Deployment.....................................................................................................................7', 'Model Deployment.....................................................................................................................7\\nHosting Services................................................................................................................7\\nBatch Transform...............................................................................................................10\\nValidating Models.............................................................................................................11\\nProgramming Model.........................................................................................................12\\nSet Up Amazon SageMaker...............................................................................................................14', 'Set Up Amazon SageMaker...............................................................................................................14\\nStep 1: Create an AWS Account..................................................................................................14\\nStep 2: Create an IAM Administrator User and Group....................................................................14\\nGet Started.....................................................................................................................................16\\nStep 1: Create an Amazon S3 Bucket..........................................................................................17\\nNext Step........................................................................................................................17', 'Next Step........................................................................................................................17\\nStep 2: Create an Amazon SageMaker Notebook Instance..............................................................17\\nNext Step........................................................................................................................18\\nStep 3: Create a Jupyter Notebook.............................................................................................18\\n......................................................................................................................................19\\nStep 4: Download, Explore, and Transform Data...........................................................................19', 'Step 4: Download, Explore, and Transform Data...........................................................................19\\nStep 4.1: Download the Dataset.........................................................................................19\\nStep 4.2: Explore the Dataset............................................................................................20\\nStep 4.3: Transform Dataset and Upload to S3.....................................................................21\\nStep 5: Train a Model...............................................................................................................21\\nChoose the Training Algorithm...........................................................................................22', 'Choose the Training Algorithm...........................................................................................22\\nCreate and Run a Training Job (Amazon SageMaker Python SDK)............................................22\\nCreate and Run a Training Job (AWS SDK for Python (Boto 3))...............................................23\\nStep 6: Deploy the Model..........................................................................................................26\\nStep 6.1: Hosting Services.................................................................................................26\\nStep 6.2: Batch Transform.................................................................................................28', 'Step 6.2: Batch Transform.................................................................................................28\\nStep 7: Validate the Model........................................................................................................30\\nStep 7.1: Validate a Model Deployed to Amazon SageMaker Hosting Services...........................30\\nStep 7.2: Validate a Model Deployed with Batch Transform....................................................33\\nStep 8: Clean Up ......................................................................................................................35\\nStep 9: Integrating Amazon SageMaker Endpoints into Internet-facing Applications..........................35', 'Step 9: Integrating Amazon SageMaker Endpoints into Internet-facing Applications..........................35\\nUsing Notebook Instances.................................................................................................................36\\nCreate a Notebook Instance.......................................................................................................36\\nAccess Notebook Instances........................................................................................................39\\nControl Root Access to a Notebook Instance........................................................................40\\nCustomize a Notebook Instance.................................................................................................40', 'Customize a Notebook Instance.................................................................................................40\\nLifecycle Conﬁguration Best Practices.................................................................................41\\nUse Example Notebooks ............................................................................................................42\\nUse or View Example Notebooks in Jupyter Classic...............................................................42\\nUse or View Example Notebooks in Jupyterlab.....................................................................43\\nNotebook Instance Software Updates.........................................................................................44', 'Notebook Instance Software Updates.........................................................................................44\\nSet the Notebook Kernel...........................................................................................................44\\nInstall External Libraries and Kernels in Notebook Instances...........................................................45\\nMaintain a Sandboxed Python Environment.........................................................................45\\nAssociate Git Repositories with Amazon SageMaker Notebook Instances..........................................46\\niiiAmazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account.....................................................47', 'iiiAmazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account.....................................................47\\nCreate a Notebook Instance with an Associated Git Repository...............................................49\\nAssociate a CodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance.........51\\nUse Git Repositories in a Notebook Instance........................................................................52\\nGet Notebook Instance Metadata...............................................................................................54\\nMonitor Jupyter Logs in Amazon CloudWatch Logs.......................................................................54', 'Monitor Jupyter Logs in Amazon CloudWatch Logs.......................................................................54\\nBuild a Model ..................................................................................................................................56\\nUse Built-in Algorithms.............................................................................................................56\\nCommon Information .......................................................................................................58\\nBlazingText......................................................................................................................74\\nDeepAR Forecasting..........................................................................................................83', 'DeepAR Forecasting..........................................................................................................83\\nFactorization Machines......................................................................................................98\\nImage Classiﬁcation Algorithm .........................................................................................108\\nIP Insights .....................................................................................................................131\\nK-Means Algorithm.........................................................................................................141\\nK-Nearest Neighbors (k-NN) Algorithm..............................................................................148', 'K-Nearest Neighbors (k-NN) Algorithm..............................................................................148\\nLatent Dirichlet Allocation (LDA).......................................................................................157\\nLinear Learner Algorithm .................................................................................................162\\nNeural Topic Model (NTM) Algorithm................................................................................177\\nObject2Vec....................................................................................................................183\\nObject Detection Algorithm.............................................................................................199', 'Object Detection Algorithm.............................................................................................199\\nPrincipal Component Analysis (PCA) Algorithm ...................................................................222\\nRandom Cut Forest (RCF) Algorithm..................................................................................226\\nSemantic Segmentation ..................................................................................................234\\nSequence to Sequence (seq2seq)......................................................................................242\\nXGBoost Algorithm.........................................................................................................255', 'XGBoost Algorithm.........................................................................................................255\\nTrain a Model.................................................................................................................................276\\nMonitor and Analyze Training Jobs Using Metrics.......................................................................276\\nSample Notebooks .........................................................................................................276\\nDeﬁning Training Metrics.................................................................................................277\\nMonitoring Training Job Metrics ( Console).........................................................................279', 'Monitoring Training Job Metrics ( Console).........................................................................279\\nMonitoring Training Job Metrics (Amazon SageMaker Console).............................................279\\nExample: Viewing a Training and Validation Curve..............................................................281\\nIncremental Training...............................................................................................................282\\nPerform Incremental Training (Console).............................................................................283\\nPerform Incremental Training (API)...................................................................................285', 'Perform Incremental Training (API)...................................................................................285\\nManaged Spot Training...........................................................................................................287\\nUsing Managed Spot Training..........................................................................................287\\nManaged Spot Training Lifecycle......................................................................................288\\nUsing Checkpoints ..................................................................................................................288\\nAutomatic Model Tuning.........................................................................................................288', 'Automatic Model Tuning.........................................................................................................288\\nHow Hyperparameter Tuning Works..................................................................................289\\nDeﬁne Metrics ................................................................................................................290\\nDeﬁne Hyperparameter Ranges ........................................................................................292\\nExample: Hyperparameter Tuning Job...............................................................................293\\nStop Training Jobs Early..................................................................................................302', 'Stop Training Jobs Early..................................................................................................302\\nRun a Warm Start Hyperparameter Tuning Job..................................................................303\\nAutomatic Model Tuning Resource Limits...........................................................................307\\nBest Practices for Hyperparameter Tuning.........................................................................308\\nUsing Augmented Manifest Files ..............................................................................................308\\nAugmented Manifest File format ......................................................................................309', 'Augmented Manifest File format ......................................................................................309\\nAugmented Manifest File format ......................................................................................310\\nUse an Augmented Manifest File (Console)........................................................................310\\nUse an Augmented Manifest File (API) ...............................................................................311\\nDeploy a Model..............................................................................................................................313\\nPrerequisites..........................................................................................................................313', 'Prerequisites..........................................................................................................................313\\nWhat do you want to do?........................................................................................................313\\nivAmazon SageMaker Developer Guide\\nManage Model Deployments....................................................................................................313\\nDeploy Your Own Inference Code.............................................................................................314\\nGuide to Amazon SageMaker...................................................................................................314', 'Guide to Amazon SageMaker...................................................................................................314\\nInference Pipelines..................................................................................................................314\\nSample Notebooks .........................................................................................................315\\nProcess Features with Spark ML and Scikit-learn.................................................................315\\nCreate a Pipeline Model..................................................................................................316\\nReal-time Inference.........................................................................................................318', 'Real-time Inference.........................................................................................................318\\nBatch Transform.............................................................................................................320\\nLogs and Metrics ............................................................................................................321\\nTroubleshooting.............................................................................................................326\\nCompile and Deploy Models with Neo.......................................................................................328\\nSample Notebooks .........................................................................................................329', 'Sample Notebooks .........................................................................................................329\\nCompile Models ..............................................................................................................329\\nDeploy Models...............................................................................................................334\\nRequest Inferences..........................................................................................................342\\nTroubleshoot Errors........................................................................................................342\\nBatch Transform.....................................................................................................................348', 'Batch Transform.....................................................................................................................348\\nUse Batch Transform with Large Datasets..........................................................................349\\nSpeed Up a Batch Transform Job.....................................................................................350\\nUse Batch Transform to Test Production Variants................................................................350\\nBatch Transform Errors...................................................................................................350\\nSample Notebooks .........................................................................................................350', 'Sample Notebooks .........................................................................................................350\\nAssociate Prediction Results with Input.............................................................................351\\nElastic Inference.....................................................................................................................355\\nHow EI Works................................................................................................................356\\nChoose an EI Accelerator Type.........................................................................................356\\nUse EI in a Amazon SageMaker Notebook Instance.............................................................356', 'Use EI in a Amazon SageMaker Notebook Instance.............................................................356\\nUse EI on a Hosted Endpoint ...........................................................................................357\\nFrameworks that Support EI............................................................................................357\\nUse EI with Amazon SageMaker Built-in Algorithms............................................................357\\nEI Sample Notebooks ......................................................................................................357\\nSet Up to Use EI ............................................................................................................358', 'Set Up to Use EI ............................................................................................................358\\nAttaching EI to a Notebook Instance.................................................................................361\\nEndpoints with Elastic Inference.......................................................................................363\\nAutomatically Scale Amazon SageMaker Models.........................................................................365\\nAutomatic Scaling Components ........................................................................................366\\nBefore You Begin............................................................................................................368', 'Before You Begin............................................................................................................368\\nRelated Topics................................................................................................................369\\nConﬁgure Automatic Scaling for a Production Variant.........................................................369\\nEdit a Scaling Policy.......................................................................................................375\\nDelete a Scaling Policy....................................................................................................375\\nUpdate Endpoints that Use Automatic Scaling ....................................................................377', 'Update Endpoints that Use Automatic Scaling ....................................................................377\\nLoad Testing..................................................................................................................377\\nAdditional Considerations................................................................................................378\\nTroubleshoot..........................................................................................................................380\\nCPU Detection Errors with a JVM......................................................................................380\\nBest Practices.........................................................................................................................381', 'Best Practices.........................................................................................................................381\\nDeploy Multiple Instances................................................................................................381\\nHosting Instance Storage Volumes............................................................................................381\\nUse Your Own Algorithms or Models................................................................................................384\\nScenarios and Guidance...........................................................................................................384\\nDocker Container Basics..........................................................................................................385', 'Docker Container Basics..........................................................................................................385\\nAmazon SageMaker Containers................................................................................................386\\nEnvironmental Variables - Entrypoints...............................................................................388\\nEnvironmental Variables - User Scripts..............................................................................389\\nEnvironmental Variable - Reference..................................................................................392\\nvAmazon SageMaker Developer Guide\\nGet Information for a Script ............................................................................................395', 'vAmazon SageMaker Developer Guide\\nGet Information for a Script ............................................................................................395\\nGet Started with Containers....................................................................................................396\\nPre-built Docker Images - Deep Learning...................................................................................398\\nPre-built Docker Images - Scikit-learn and Spark ML...................................................................401\\nExample Notebooks ................................................................................................................402\\nUse Your Own Training Algorithms...........................................................................................404', 'Use Your Own Training Algorithms...........................................................................................404\\nRun Your Training Image.................................................................................................404\\nProvide Training Information............................................................................................405\\nSignal Success or Failure.................................................................................................407\\nTraining Output..............................................................................................................408\\nUse Your Own Inference Code..................................................................................................408', 'Use Your Own Inference Code..................................................................................................408\\nWith Hosting Services.....................................................................................................408\\nWith Batch Transform.....................................................................................................411\\nCreate Algorithm and Model Package Resources.........................................................................413\\nCreate an Algorithm Resource..........................................................................................413\\nCreate a Model Package Resource.....................................................................................417', 'Create a Model Package Resource.....................................................................................417\\nUse Algorithm and Model Package Resources.............................................................................419\\nUse an Algorithm to Run a Training Job............................................................................420\\nUse an Algorithm to Run a Hyperparameter Tuning Job......................................................423\\nUse a Model Package to Create a Model............................................................................425\\nAmazon SageMaker in AWS Marketplace...........................................................................................428', 'Amazon SageMaker in AWS Marketplace...........................................................................................428\\nTopics...................................................................................................................................428\\nAmazon SageMaker Algorithms................................................................................................428\\nAmazon SageMaker Model Packages.........................................................................................428\\nSell Amazon SageMaker Algorithms and Model Packages............................................................429\\nTopics...........................................................................................................................429', 'Topics...........................................................................................................................429\\nDevelop Algorithms and Models in Amazon SageMaker.......................................................429\\nList Your Algorithm or Model Package on AWS Marketplace.................................................431\\nFind and Subscribe to Algorithms and Model Packages on AWS Marketplace..................................431\\nUse Algorithms and Model Packages.................................................................................432\\nManage ML Experiments with Amazon SageMaker Model Tracking Capability.........................................433', 'Manage ML Experiments with Amazon SageMaker Model Tracking Capability.........................................433\\nSample Notebooks .................................................................................................................433\\nUse Model Tracking to Find, Organize, and Evaluate Training Jobs (Console)...................................434\\nUse Tags to Track Training Jobs (Console).........................................................................434\\nFind Training Jobs (Console)...........................................................................................435\\nEvaluate Models Returned by a Search (Console)................................................................435', 'Evaluate Models Returned by a Search (Console)................................................................435\\nUse Model Tracking to Find and Evaluate Training Jobs (API)........................................................436\\nUse Search to Find Training Jobs Tagged with Speciﬁc Values (API).......................................436\\nEvaluate Models (API) .....................................................................................................436\\nGet Suggestions for a Search (API)...................................................................................437\\nVerify the Contents of Your Training Jobs..................................................................................438', 'Verify the Contents of Your Training Jobs..................................................................................438\\nTrace the Lineage of your Models.............................................................................................438\\nUse Single-click on the Amazon SageMaker Console to Trace the Lineage of Your Models\\n(Console).......................................................................................................................438\\nUse Code to Trace the Lineage of Your Models (API)...........................................................439\\nUse Machine Learning Frameworks with Amazon SageMaker................................................................440', 'Use Machine Learning Frameworks with Amazon SageMaker................................................................440\\nUsing Apache Spark ................................................................................................................440\\nDownload the Amazon SageMaker Spark Library................................................................440\\nIntegrate Your Apache Spark Application with Amazon SageMaker........................................441\\nExample 1: Amazon SageMaker with Apache Spark.............................................................442\\nAdditional Examples: Amazon SageMaker with Apache Spark...............................................449', 'Additional Examples: Amazon SageMaker with Apache Spark...............................................449\\nUsing TensorFlow...................................................................................................................449\\nUse TensorFlow Version 1.11 and Later.............................................................................449\\nUse TensorFlow Legacy Mode for Versions 1.11 and Earlier..................................................450\\nUsing Apache MXNet ..............................................................................................................450\\nWhat do you want to do?................................................................................................450', 'What do you want to do?................................................................................................450\\nUsing Scikit-learn...................................................................................................................451\\nviAmazon SageMaker Developer Guide\\nWhat do you want to do?................................................................................................451\\nUsing PyTorch........................................................................................................................451\\nWhat do you want to do?................................................................................................451', 'What do you want to do?................................................................................................451\\nUsing Chainer ........................................................................................................................452\\nWhat do you want to do?................................................................................................452\\nUse SparkML Serving..............................................................................................................453\\nReinforcement Learning with Amazon SageMaker RL..........................................................................454\\nWhy is Reinforcement Learning Important?................................................................................454', 'Why is Reinforcement Learning Important?................................................................................454\\nMarkov Decision Process (MDP)................................................................................................454\\nKey Features of Amazon SageMaker RL.....................................................................................455\\nSample RL Workﬂow Using Amazon SageMaker RL.....................................................................457\\nRL Environments in Amazon SageMaker....................................................................................458\\nUse OpenAI Gym Interface for Environments in Amazon SageMaker RL..................................459', 'Use OpenAI Gym Interface for Environments in Amazon SageMaker RL..................................459\\nUse Open Source Environments........................................................................................459\\nUse Commercial Environments.........................................................................................459\\nDistributed Training with Amazon SageMaker RL........................................................................459\\nHyperparameter Tuning with Amazon SageMaker RL...................................................................460\\nMonitoring .....................................................................................................................................461', 'Monitoring .....................................................................................................................................461\\nMonitoring with CloudWatch....................................................................................................461\\nLogging with CloudWatch........................................................................................................466\\nLog Amazon SageMaker API Calls with AWS CloudTrail................................................................467\\nAmazon SageMaker Information in CloudTrail....................................................................468\\nOperations Performed by Automatic Model Tuning.............................................................468', 'Operations Performed by Automatic Model Tuning.............................................................468\\nUnderstanding Amazon SageMaker Log File Entries............................................................468\\nReact to Amazon SageMaker Job Status Changes with CloudWatch Events.....................................470\\nSecurity.........................................................................................................................................471\\nData Protection......................................................................................................................471\\nProtecting Data at Rest Using Encryption..........................................................................472', 'Protecting Data at Rest Using Encryption..........................................................................472\\nProtecting Data in Transit with Encryption.........................................................................473\\nKey Management............................................................................................................475\\nInternetwork Traﬃc Privacy.............................................................................................475\\nIdentity and Access Management..............................................................................................475\\nAudience.......................................................................................................................475', 'Audience.......................................................................................................................475\\nAuthenticating With Identities ..........................................................................................476\\nManaging Access Using Policies........................................................................................478\\nHow Amazon SageMaker Works with IAM..........................................................................479\\nIdentity-Based Policy Examples........................................................................................481\\nAmazon SageMaker Roles................................................................................................496', 'Amazon SageMaker Roles................................................................................................496\\nAWS Managed (Predeﬁned) Policies for Amazon SageMaker.................................................507\\nAmazon SageMaker API Permissions Reference...................................................................508\\nTroubleshooting.............................................................................................................512\\nLogging and Monitoring ..........................................................................................................514\\nCompliance Validation.............................................................................................................514', 'Compliance Validation.............................................................................................................514\\nResilience..............................................................................................................................515\\nInfrastructure Security.............................................................................................................515\\nConnect a Notebook Instance to Resources in a VPC...........................................................516\\nTraining and Inference Containers Run in Internet-Free Mode...............................................516\\nAmazon SageMaker Scans AWS Marketplace Training and Inference Containers for Security', 'Training and Inference Containers Run in Internet-Free Mode...............................................516\\nAmazon SageMaker Scans AWS Marketplace Training and Inference Containers for Security\\nVulnerabilities................................................................................................................517\\nConnect to Amazon SageMaker Through a VPC Interface Endpoint.......................................517\\nGive Amazon SageMaker Training Jobs Access to Resources in Your Amazon VPC.....................522\\nGive Amazon SageMaker Hosted Endpoints Access to Resources in Your Amazon VPC...............525\\nGive Batch Transform Jobs Access to Resources in Your Amazon VPC.....................................529', 'Give Amazon SageMaker Hosted Endpoints Access to Resources in Your Amazon VPC...............525\\nGive Batch Transform Jobs Access to Resources in Your Amazon VPC.....................................529\\nAmazon SageMaker Ground Truth....................................................................................................532\\nAre You a First-time User of Ground Truth?...............................................................................532\\nGetting started.......................................................................................................................533\\nStep 1: Before You Begin.................................................................................................533\\nviiAmazon SageMaker Developer Guide', 'Step 1: Before You Begin.................................................................................................533\\nviiAmazon SageMaker Developer Guide\\nStep 2: Create a Labeling Job..........................................................................................534\\nStep 3: Select Workers....................................................................................................535\\nStep 4: Conﬁgure the Bounding Box Tool...........................................................................535\\nStep 5: Monitoring Your Labeling Job...............................................................................536\\nData Labeling .........................................................................................................................537', 'Data Labeling .........................................................................................................................537\\nBatches for Labeling Tasks...............................................................................................537\\nAnnotation Consolidation ................................................................................................537\\nUsing Automated Data Labeling .......................................................................................539\\nChaining labeling jobs .....................................................................................................540\\nUsing Input and Output Data ...................................................................................................543', 'Using Input and Output Data ...................................................................................................543\\nInput Data .....................................................................................................................543\\nOutput Data ..................................................................................................................545\\nCreating Instruction Pages.......................................................................................................549\\nShort Instructions...........................................................................................................550\\nFull Instructions.............................................................................................................551', 'Full Instructions.............................................................................................................551\\nAdd example images to your instructions..........................................................................551\\nManaging Your Workforce.......................................................................................................551\\nUsing the Amazon Mechanical Turk Workforce...................................................................552\\nManaging Vendor Workforces..........................................................................................553\\nManaging a Private Workforce.........................................................................................553', 'Managing a Private Workforce.........................................................................................553\\nCreate and manage Amazon SNS topics for your work teams...............................................556\\nCreating Custom Labeling Workﬂows........................................................................................557\\nNext..............................................................................................................................557\\nStep 1: Setting up your workforce....................................................................................557\\nStep 2: Creating your custom labeling task template...........................................................558', 'Step 2: Creating your custom labeling task template...........................................................558\\nDemo: Image Annotation with crowd-bounding-box ........................................................563\\nDemo: Text Intent with crowd-classifier .....................................................................567\\nStep 3: Processing with AWS Lambda...............................................................................574\\nCustom Workﬂows via the API.........................................................................................577\\nHTML Elements Reference...............................................................................................577', 'HTML Elements Reference...............................................................................................577\\nLimits and Supported Regions.........................................................................................................615\\nAPI Reference.................................................................................................................................616\\nActions..................................................................................................................................616\\nAmazon SageMaker Service.............................................................................................618\\nAmazon SageMaker Runtime............................................................................................852', 'Amazon SageMaker Runtime............................................................................................852\\nData Types............................................................................................................................856\\nAmazon SageMaker Service.............................................................................................859\\nAmazon SageMaker Runtime..........................................................................................1041\\nCommon Errors....................................................................................................................1041\\nCommon Parameters.............................................................................................................1043', 'Common Parameters.............................................................................................................1043\\nDocument History.........................................................................................................................1045\\nAWS Glossary...............................................................................................................................1047\\nviiiAmazon SageMaker Developer Guide\\nAre You a First-time User of Amazon SageMaker?\\nWhat Is Amazon SageMaker?\\nAmazon SageMaker is a fully managed machine learning service. With Amazon SageMaker, data\\nscientists and developers can quickly and easily build and train machine learning models, and then', \"Amazon SageMaker is a fully managed machine learning service. With Amazon SageMaker, data\\nscientists and developers can quickly and easily build and train machine learning models, and then\\ndirectly deploy them into a production-ready hosted environment. It provides an integrated Jupyter\\nauthoring notebook instance for easy access to your data sources for exploration and analysis, so you\\ndon't have to manage servers. It also provides common machine learning algorithms that are optimized\\nto run eﬃciently against extremely large data in a distributed environment. With native support for\\nbring-your-own-algorithms and frameworks, Amazon SageMaker oﬀers ﬂexible distributed training\\noptions that adjust to your speciﬁc workﬂows. Deploy a model into a secure and scalable environment by\", 'bring-your-own-algorithms and frameworks, Amazon SageMaker oﬀers ﬂexible distributed training\\noptions that adjust to your speciﬁc workﬂows. Deploy a model into a secure and scalable environment by\\nlaunching it with a single click from the Amazon SageMaker console. Training and hosting are billed by\\nminutes of usage, with no minimum fees and no upfront commitments.\\nThis is a HIPAA Eligible Service. For more information about AWS, U.S. Health Insurance Portability and\\nAccountability Act of 1996 (HIPAA), and using AWS services to process, store, and transmit protected\\nhealth information (PHI), see HIPAA Overview.\\nAre You a First-time User of Amazon SageMaker?\\nIf you are a ﬁrst-time user of Amazon SageMaker, we recommend that you do the following:', 'health information (PHI), see HIPAA Overview.\\nAre You a First-time User of Amazon SageMaker?\\nIf you are a ﬁrst-time user of Amazon SageMaker, we recommend that you do the following:\\n1.Read How Amazon SageMaker Works (p. 2) – This section provides an overview of Amazon\\nSageMaker, explains key concepts, and describes the core components involved in building AI solutions\\nwith Amazon SageMaker. We recommend that you read this topic in the order presented.\\n2.Read Get Started (p. 16) – This section explains how to set up your account and create your ﬁrst\\nAmazon SageMaker notebook instance.\\n3.Try a model training exercise – This exercise walks you through training your ﬁrst model. You use\\ntraining algorithms provided by Amazon SageMaker. For more information, see Get Started (p. 16).', '3.Try a model training exercise – This exercise walks you through training your ﬁrst model. You use\\ntraining algorithms provided by Amazon SageMaker. For more information, see Get Started (p. 16).\\n4.Explore other topics – Depending on your needs, do the following:\\n•Submit Python code to train with deep learning frameworks – In Amazon SageMaker, you can use\\nyour own training scripts to train models. For information, see Use Machine Learning Frameworks\\nwith Amazon SageMaker (p. 440).\\n•Use Amazon SageMaker directly from Apache Spark – For information, see Use Apache Spark with\\nAmazon SageMaker (p. 440).\\n•Use Amazon AI to train and/or deploy your own custom algorithms – Package your custom\\nalgorithms with Docker so you can train and/or deploy them in Amazon SageMaker. See Use Your', '•Use Amazon AI to train and/or deploy your own custom algorithms – Package your custom\\nalgorithms with Docker so you can train and/or deploy them in Amazon SageMaker. See Use Your\\nOwn Algorithms or Models with Amazon SageMaker  (p. 384) to learn how Amazon SageMaker\\ninteracts with Docker containers, and for the Amazon SageMaker requirements for Docker images.\\n5.See the API Reference (p. 616) – This section describes the Amazon SageMaker API operations.\\n1Amazon SageMaker Developer Guide\\nMachine Learning with Amazon SageMaker\\nHow Amazon SageMaker Works\\nAmazon SageMaker is a fully managed service that enables you to quickly and easily integrate machine\\nlearning-based models into your applications. This section provides an overview of machine learning', 'Amazon SageMaker is a fully managed service that enables you to quickly and easily integrate machine\\nlearning-based models into your applications. This section provides an overview of machine learning\\nand explains how Amazon SageMaker works. If you are a ﬁrst-time user of Amazon SageMaker, we\\nrecommend that you read the following sections in order:\\nTopics\\n•Machine Learning with Amazon SageMaker (p. 2)\\n•Explore and Preprocess Data (p. 4)\\n•Train a Model with Amazon SageMaker  (p. 4)\\n•Deploy a Model in Amazon SageMaker (p. 7)\\nHow It Works: Next Topic\\nMachine Learning with Amazon SageMaker (p. 2)\\nMachine Learning with Amazon SageMaker\\nThis section describes a typical machine learning workﬂow and summarizes how you accomplish those\\ntasks with Amazon SageMaker.', 'Machine Learning with Amazon SageMaker\\nThis section describes a typical machine learning workﬂow and summarizes how you accomplish those\\ntasks with Amazon SageMaker.\\nIn machine learning, you \"teach\" a computer to make predictions, or inferences. First, you use an\\nalgorithm and example data to train a model. Then you integrate your model into your application to\\ngenerate inferences in real time and at scale. In a production environment, a model typically learns from\\nmillions of example data items and produces inferences in hundreds to less than 20 milliseconds.\\nThe following diagram illustrates the typical workﬂow for creating a machine learning model:\\nAs the diagram illustrates, you typically perform the following activities:', 'The following diagram illustrates the typical workﬂow for creating a machine learning model:\\nAs the diagram illustrates, you typically perform the following activities:\\n1.Generate example data—To train a model, you need example data. The type of data that you need\\ndepends on the business problem that you want the model to solve (the inferences that you want\\n2Amazon SageMaker Developer Guide\\nHow It Works: Next Topic\\nthe model to generate). For example, suppose that you want to create a model to predict a number\\ngiven an input image of a handwritten digit. To train such a model, you need example images of\\nhandwritten numbers.\\nData scientists often spend a lot of time exploring and preprocessing, or \"wrangling,\" example data', 'handwritten numbers.\\nData scientists often spend a lot of time exploring and preprocessing, or \"wrangling,\" example data\\nbefore using it for model training. To preprocess data, you typically do the following:\\na.Fetch the data— You might have in-house example data repositories, or you might use datasets\\nthat are publicly available. Typically, you pull the dataset or datasets into a single repository.\\nb.Clean the data—To improve model training, inspect the data and clean it as needed. For example, if\\nyour data has a country name  attribute with values United States  and US, you might want to\\nedit the data to be consistent.\\nc.Prepare or transform the data —To improve performance, you might perform additional data', 'edit the data to be consistent.\\nc.Prepare or transform the data —To improve performance, you might perform additional data\\ntransformations. For example, you might choose to combine attributes. If your model predicts the\\nconditions that require de-icing an aircraft, instead of using temperature and humidity attributes\\nseparately, you might combine those attributes into a new attribute to get a better model.\\nIn Amazon SageMaker, you preprocess example data in a Jupyter notebook on your notebook\\ninstance. You use your notebook to fetch your dataset, explore it, and prepare it for model training.\\nFor more information, see Explore and Preprocess Data (p. 4). For more information about\\npreparing data in AWS Marketplace, see data preparation.', 'For more information, see Explore and Preprocess Data (p. 4). For more information about\\npreparing data in AWS Marketplace, see data preparation.\\n2.Train a model—Model training includes both training and evaluating the model, as follows:\\n•Training the model— To train a model, you need an algorithm. The algorithm you choose depends\\non a number of factors. For a quick, out-of-the-box solution, you might be able to use one of\\nthe algorithms that Amazon SageMaker provides. For a list of algorithms provided by Amazon\\nSageMaker and related considerations, see Use Amazon SageMaker Built-in Algorithms  (p. 56).\\n\\xa0\\nYou also need compute resources for training. Depending on the size of your training dataset and', \"SageMaker and related considerations, see Use Amazon SageMaker Built-in Algorithms  (p. 56).\\n\\xa0\\nYou also need compute resources for training. Depending on the size of your training dataset and\\nhow quickly you need the results, you can use resources ranging from a single general-purpose\\ninstance to a distributed cluster of GPU instances. For more information, see Train a Model with\\nAmazon SageMaker  (p. 4).\\n\\xa0\\n•Evaluating the model —After you've trained your model, you evaluate it to determine whether the\\naccuracy of the inferences is acceptable. In Amazon SageMaker, you use either the AWS SDK for\\nPython (Boto) or the high-level Python library that Amazon SageMaker provides to send requests to\\nthe model for inferences.\", 'Python (Boto) or the high-level Python library that Amazon SageMaker provides to send requests to\\nthe model for inferences.\\nYou use a Jupyter notebook in your Amazon SageMaker notebook instance to train and evaluate\\nyour model.\\n3.Deploy the model— You traditionally re-engineer a model before you integrate it with your\\napplication and deploy it. With Amazon SageMaker hosting services, you can deploy your model\\nindependently, decoupling it from your application code. For more information, see Deploy a Model on\\nAmazon SageMaker Hosting Services (p. 7).\\nMachine learning is a continuous cycle. After deploying a model, you monitor the inferences, collect\\n\"ground truth,\" and evaluate the model to identify drift. You then increase the accuracy of your', 'Machine learning is a continuous cycle. After deploying a model, you monitor the inferences, collect\\n\"ground truth,\" and evaluate the model to identify drift. You then increase the accuracy of your\\ninferences by updating your training data to include the newly collected ground truth. You do this by\\nretraining the model with the new dataset. As more and more example data becomes available, you\\ncontinue retraining your model to increase accuracy.\\nHow It Works: Next Topic\\nExplore and Preprocess Data (p. 4)\\n3Amazon SageMaker Developer Guide\\nExplore and Preprocess Data\\nExplore and Preprocess Data\\nBefore using a dataset to train a model, data scientists typically explore and preprocess it. For example,', '3Amazon SageMaker Developer Guide\\nExplore and Preprocess Data\\nExplore and Preprocess Data\\nBefore using a dataset to train a model, data scientists typically explore and preprocess it. For example,\\nin one of the exercises in this guide, you use the MNIST dataset, a commonly available dataset of\\nhandwritten numbers, for model training. Before you begin training, you transform the data into a\\nformat that is more eﬃcient for training. For more information, see Step 4.3: Transform the Training\\nDataset and Upload It to Amazon S3 (p. 21).\\nTo preprocess data use one of the following methods:\\n•Use a Jupyter notebook on an Amazon SageMaker notebook instance. You can also use the notebook\\ninstance to do the following:\\n•Write code to create model training jobs', '•Use a Jupyter notebook on an Amazon SageMaker notebook instance. You can also use the notebook\\ninstance to do the following:\\n•Write code to create model training jobs\\n•Deploy models to Amazon SageMaker hosting\\n•Test or validate your models\\nFor more information, see Use Notebook Instances (p. 36)\\n•You can use a model to transform data by using Amazon SageMaker batch transform. For more\\ninformation, see Step 6.2: Deploy the Model with Batch Transform (p. 28).\\nHow It Works: Next Topic\\nTrain a Model with Amazon SageMaker  (p. 4)\\nTrain a Model with Amazon SageMaker\\nThe following diagram shows how you train and deploy a model with Amazon SageMaker:\\n4Amazon SageMaker Developer Guide\\nModel Training\\nThe area labeled Amazon SageMaker highlights the two components of Amazon SageMaker: model', \"4Amazon SageMaker Developer Guide\\nModel Training\\nThe area labeled Amazon SageMaker highlights the two components of Amazon SageMaker: model\\ntraining and model deployment.\\nTo train a model in Amazon SageMaker, you create a training job. The training job includes the following\\ninformation:\\n•The URL of the Amazon Simple Storage Service (Amazon S3) bucket where you've stored the training\\ndata.\\n•The compute resources that you want Amazon SageMaker to use for model training. Compute\\nresources are ML compute instances that are managed by Amazon SageMaker.\\n•The URL of the S3 bucket where you want to store the output of the job.\\n•The Amazon Elastic Container Registry path where the training code is stored. For more information,\\nsee Common Parameters for Built-In Algorithms  (p. 58).\", \"•The Amazon Elastic Container Registry path where the training code is stored. For more information,\\nsee Common Parameters for Built-In Algorithms  (p. 58).\\nYou have the following options for a training algorithm:\\n•Use an algorithm provided by Amazon SageMaker—Amazon SageMaker provides training\\nalgorithms. If one of these meets your needs, it's a great out-of-the-box solution for quick model\\n5Amazon SageMaker Developer Guide\\nModel Training\\ntraining. For a list of algorithms provided by Amazon SageMaker, see Use Amazon SageMaker Built-in\\nAlgorithms  (p. 56). To try an exercise that uses an algorithm provided by Amazon SageMaker, see\\nGet Started (p. 16).\\n•Use Apache Spark with Amazon SageMaker—Amazon SageMaker provides a library that you can\", 'Get Started (p. 16).\\n•Use Apache Spark with Amazon SageMaker—Amazon SageMaker provides a library that you can\\nuse in Apache Spark to train models with Amazon SageMaker. Using the library provided by Amazon\\nSageMaker is similar to using Apache Spark MLLib. For more information, see Use Apache Spark with\\nAmazon SageMaker (p. 440).\\n•Submit custom code to train with deep learning frameworks—You can submit custom Python code\\nthat uses TensorFlow or Apache MXNet for model training. For more information, see Use TensorFlow\\nwith Amazon SageMaker (p. 449) and Use Apache MXNet with Amazon SageMaker (p. 450).\\n•Use your own custom algorithms—Put your code together as a Docker image and specify the registry\\npath of the image in an Amazon SageMaker CreateTrainingJob  API call. For more information, see', '•Use your own custom algorithms—Put your code together as a Docker image and specify the registry\\npath of the image in an Amazon SageMaker CreateTrainingJob  API call. For more information, see\\nUse Your Own Algorithms or Models with Amazon SageMaker  (p. 384).\\n•Use an algorithm that you subscribe to from AWS Marketplace—For information, see Find and\\nSubscribe to Algorithms and Model Packages on AWS Marketplace (p. 431).\\nAfter you create the training job, Amazon SageMaker launches the ML compute instances and uses the\\ntraining code and the training dataset to train the model. It saves the resulting model artifacts and other\\noutput in the S3 bucket you speciﬁed for that purpose.\\nYou can create a training job with the Amazon SageMaker console or the API. For information about', 'output in the S3 bucket you speciﬁed for that purpose.\\nYou can create a training job with the Amazon SageMaker console or the API. For information about\\ncreating a training job with the API, see the CreateTrainingJob (p. 667) API.\\nWhen you create a training job with the API, Amazon SageMaker replicates the entire dataset on ML\\ncompute instances by default. To make Amazon SageMaker replicate a subset of the data on each\\nML compute instance, you must set the S3DataDistributionType  ﬁeld to ShardedByS3Key . You\\ncan set this ﬁeld using the low-level SDK. For more information, see S3DataDistributionType  in\\nS3DataSource (p. 994).\\nImportant\\nTo prevent your algorithm container from contending for memory, you should reserve some', 'S3DataSource (p. 994).\\nImportant\\nTo prevent your algorithm container from contending for memory, you should reserve some\\nmemory for Amazon SageMaker critical system processes on your ML compute instances. If the\\nalgorithm container is allowed to use memory needed for system processes, it can trigger a\\nsystem failure.\\n6Amazon SageMaker Developer Guide\\nHow It Works: Next Topic\\nHow It Works: Next Topic\\nDeploy a Model in Amazon SageMaker (p. 7)\\nDeploy a Model in Amazon SageMaker\\nAfter you train your model, you can deploy it to get predictions in one of two ways:\\n•To set up a persistent endpoint to get one prediction at a time, use Amazon SageMaker hosting\\nservices.\\n•To get predictions for an entire dataset, use Amazon SageMaker batch transform.\\nTopics', '•To set up a persistent endpoint to get one prediction at a time, use Amazon SageMaker hosting\\nservices.\\n•To get predictions for an entire dataset, use Amazon SageMaker batch transform.\\nTopics\\n•Deploy a Model on Amazon SageMaker Hosting Services (p. 7)\\n•Get Inferences for an Entire Dataset with Batch Transform (p. 10)\\n•Validate a Machine Learning Model (p. 11)\\n•The Amazon SageMaker Programming Model  (p. 12)\\nDeploy a Model on Amazon SageMaker Hosting\\nServices\\nAmazon SageMaker also provides model hosting services for model deployment, as shown in the\\nfollowing diagram. Amazon SageMaker provides an HTTPS endpoint where your machine learning model\\nis available to provide inferences.\\n7Amazon SageMaker Developer Guide\\nHosting Services', 'following diagram. Amazon SageMaker provides an HTTPS endpoint where your machine learning model\\nis available to provide inferences.\\n7Amazon SageMaker Developer Guide\\nHosting Services\\nDeploying a model using Amazon SageMaker hosting services is a three-step process:\\n1. Create a model in Amazon SageMaker—By creating a model, you tell Amazon SageMaker where it\\ncan ﬁnd the model components. This includes the S3 path where the model artifacts are stored and\\nthe Docker registry path for the image that contains the inference code. In subsequent deployment\\nsteps, you specify the model by name. For more information, see the CreateModel (p. 648) API.\\n2. Create an endpoint conﬁguration for an HTTPS endpoint—You specify the name of one or more', 'steps, you specify the model by name. For more information, see the CreateModel (p. 648) API.\\n2. Create an endpoint conﬁguration for an HTTPS endpoint—You specify the name of one or more\\nmodels in production variants and the ML compute instances that you want Amazon SageMaker to\\nlaunch to host each production variant.\\nWhen hosting models in production, you can conﬁgure the endpoint to elastically scale the\\ndeployed ML compute instances. For each production variant, you specify the number of\\nML compute instances that you want to deploy. When you specify two or more instances,\\nAmazon SageMaker launches them in multiple Availability Zones. This ensures continuous\\navailability. Amazon SageMaker manages deploying the instances. For more information, see the\\nCreateEndpointConﬁg (p. 635) API.', 'availability. Amazon SageMaker manages deploying the instances. For more information, see the\\nCreateEndpointConﬁg (p. 635) API.\\n3. Create an HTTPS endpoint—Provide the endpoint conﬁguration to Amazon SageMaker. The\\nservice launches the ML compute instances and deploys the model or models as speciﬁed in the\\nconﬁguration. For more information, see the CreateEndpoint (p. 632) API. To get inferences from\\n8Amazon SageMaker Developer Guide\\nHosting Services\\nthe model, client applications send requests to the Amazon SageMaker Runtime HTTPS endpoint.\\nFor more information about the API, see the InvokeEndpoint (p. 853) API.\\nNote\\nWhen you create an endpoint, Amazon SageMaker attaches an Amazon EBS storage volume to', \"For more information about the API, see the InvokeEndpoint (p. 853) API.\\nNote\\nWhen you create an endpoint, Amazon SageMaker attaches an Amazon EBS storage volume to\\neach ML compute instance that hosts the endpoint. The size of the storage volume depends on\\nthe instance type. For a list of instance types that Amazon SageMaker hosting service supports,\\nsee AWS Service Limits. For a list of the sizes of the storage volumes that Amazon SageMaker\\nattaches to each instance, see Hosting Instance Storage Volumes (p. 381).\\nTo increase a model's accuracy, you might choose to save the user's input data and ground truth, if\\navailable, as part of the training data. You can then retrain the model periodically with a larger, improved\\ntraining dataset.\", 'available, as part of the training data. You can then retrain the model periodically with a larger, improved\\ntraining dataset.\\nBest Practices for Deploying Models on Amazon SageMaker\\nHosting Services\\nWhen hosting models using Amazon SageMaker hosting services, consider the following:\\n•Typically, a client application sends requests to the Amazon SageMaker HTTPS endpoint to obtain\\ninferences from a deployed model. You can also send requests to this endpoint from your Jupyter\\nnotebook during testing.\\n\\xa0\\n•You can deploy a model trained with Amazon SageMaker to your own deployment target. To do that,\\nyou need to know the algorithm-speciﬁc format of the model artifacts that were generated by model\\ntraining. For more information about output formats, see the section corresponding to the algorithm', \"you need to know the algorithm-speciﬁc format of the model artifacts that were generated by model\\ntraining. For more information about output formats, see the section corresponding to the algorithm\\nyou are using in  Training Data Formats  (p. 65).\\n\\xa0\\n•You can deploy multiple variants of a model to the same Amazon SageMaker HTTPS endpoint.\\nThis is useful for testing variations of a model in production. For example, suppose that you've\\ndeployed a model into production. You want to test a variation of the model by directing a small\\namount of traﬃc, say 5%, to the new model. To do this, create an endpoint conﬁguration that\\ndescribes both variants of the model. You specify the ProductionVariant  in your request to the\\nCreateEndPointConfig . For more information, see ProductionVariant (p. 981).\", 'describes both variants of the model. You specify the ProductionVariant  in your request to the\\nCreateEndPointConfig . For more information, see ProductionVariant (p. 981).\\n\\xa0\\n•You can conﬁgure a ProductionVariant  to use Application Auto Scaling. For information about\\nconﬁguring automatic scaling, see Automatically Scale Amazon SageMaker Models (p. 365).\\n\\xa0\\n•You can modify an endpoint without taking models that are already deployed into production\\nout of service. For example, you can add new model variants, update the ML Compute instance\\nconﬁgurations of existing model variants, or change the distribution of traﬃc among model variants.\\nTo modify an endpoint, you provide a new endpoint conﬁguration. Amazon SageMaker implements', 'conﬁgurations of existing model variants, or change the distribution of traﬃc among model variants.\\nTo modify an endpoint, you provide a new endpoint conﬁguration. Amazon SageMaker implements\\nthe changes without any downtime. For more information see, UpdateEndpoint  (p. 840) and\\nUpdateEndpointWeightsAndCapacities (p. 842).\\n\\xa0\\n•Changing or deleting model artifacts or changing inference code after deploying a model produces\\nunpredictable results. If you need to change or delete model artifacts or change inference code,\\nmodify the endpoint by providing a new endpoint conﬁguration. Once you provide the new endpoint\\nconﬁguration, you can change or delete the model artifacts corresponding to the old endpoint\\nconﬁguration.\\n9Amazon SageMaker Developer Guide\\nBatch Transform', 'conﬁguration, you can change or delete the model artifacts corresponding to the old endpoint\\nconﬁguration.\\n9Amazon SageMaker Developer Guide\\nBatch Transform\\n\\xa0\\n•If you want to get inferences on entire datasets, consider using batch transform as an alternative\\nto hosting services. For information, see Get Inferences for an Entire Dataset with Batch\\nTransform (p. 10)\\nHow It Works: Next Topic\\nValidate a Machine Learning Model (p. 11)\\nGet Inferences for an Entire Dataset with Batch\\nTransform\\nTo get inferences for an entire dataset, use batch transform. With batch transform, you create a batch\\ntransform job using a trained model and the dataset, which must be stored in Amazon S3. Amazon\\nSageMaker saves the inferences in an S3 bucket that you specify when you create the batch transform', \"transform job using a trained model and the dataset, which must be stored in Amazon S3. Amazon\\nSageMaker saves the inferences in an S3 bucket that you specify when you create the batch transform\\njob. Batch transform manages all of the compute resources required to get inferences. This includes\\nlaunching instances and deleting them after the batch transform job has completed. Batch transform\\nmanages interactions between the data and the model with an object within the instance node called an\\nagent.\\nUse batch transform when you:\\n•Want to get inferences for an entire dataset and index them to serve inferences in real time\\n•Don't need a persistent endpoint that applications (for example, web or mobile apps) can call to get\\ninferences\", \"•Don't need a persistent endpoint that applications (for example, web or mobile apps) can call to get\\ninferences\\n•Don't need the subsecond latency that Amazon SageMaker hosted endpoints provide\\nYou can also use batch transform to preprocess your data before using it to train a new model or\\ngenerate inferences.\\nThe following diagram shows the workﬂow of a batch transform job:\\nTo perform a batch transform, create a batch transform job using either the Amazon SageMaker console\\nor the API. Provide the following:\\n•The path to the S3 bucket where you've stored the data that you want to transform.\\n•The compute resources that you want Amazon SageMaker to use for the transform job. Compute\\nresources  are machine learning (ML) compute instances that are managed by Amazon SageMaker.\", '•The compute resources that you want Amazon SageMaker to use for the transform job. Compute\\nresources  are machine learning (ML) compute instances that are managed by Amazon SageMaker.\\n10Amazon SageMaker Developer Guide\\nValidating Models\\n•The path to the S3 bucket where you want to store the output of the job.\\n•The name of the Amazon SageMaker model that you want to use to create inferences. You must use a\\nmodel that you have already created either with the CreateModel (p. 648) operation or the console.\\nThe following is an example of what a dataset ﬁle might look like.\\nAn example of input file content:\\n                Record1-Attribute1, Record1-Attribute2, Record1-Attribute3, ..., Record1-\\nAttributeM\\n                Record2-Attribute1, Record2-Attribute2, Record2-Attribute3, ..., Record2-', 'Record1-Attribute1, Record1-Attribute2, Record1-Attribute3, ..., Record1-\\nAttributeM\\n                Record2-Attribute1, Record2-Attribute2, Record2-Attribute3, ..., Record2-\\nAttributeM\\n                Record3-Attribute1, Record3-Attribute2, Record3-Attribute3, ..., Record3-\\nAttributeM\\n                ...\\n                RecordN-Attribute1, RecordN-Attribute2, RecordN-Attribute3, ..., RecordN-\\nAttributeM\\n            \\nA record is a single input data unit, for information on how to delimit records for batch transform jobs,\\nsee SplitType  in TransformInput (p. 1024 ).\\nFor an example of how to use batch transform, see Step 6.2: Deploy the Model with Batch\\nTransform (p. 28).\\nHow It Works: Next Topic\\nValidate a Machine Learning Model (p. 11)\\nValidate a Machine Learning Model', \"Transform (p. 28).\\nHow It Works: Next Topic\\nValidate a Machine Learning Model (p. 11)\\nValidate a Machine Learning Model\\nAfter training a model, evaluate it to determine whether its performance and accuracy allow you to\\nachieve your business goals. You might generate multiple models using diﬀerent methods and evaluate\\neach. For example, you could apply diﬀerent business rules for each model, and then apply various\\nmeasures to determine each model's suitability. You might consider whether your model needs to be\\nmore sensitive than speciﬁc (or vice versa).\\nYou can evaluate your model using historical data (oﬄine) or live data:\\n•Oﬄine testing —Use historical, not live, data to send requests to the model for inferences.\", 'You can evaluate your model using historical data (oﬄine) or live data:\\n•Oﬄine testing —Use historical, not live, data to send requests to the model for inferences.\\n\\xa0\\nDeploy your trained model to an alpha endpoint, and use historical data to send inference requests to\\nit. To send the requests, use a Jupyter notebook in your Amazon SageMaker notebook instance and\\neither the AWS SDK for Python (Boto) or the high-level Python library provided by Amazon SageMaker.\\n\\xa0\\n•Online testing with live data—Amazon SageMaker supports deploying multiple models (called\\nproduction variants) to a single Amazon SageMaker endpoint. You conﬁgure the production variants\\nso that a small portion of the live traﬃc goes to the model that you want to validate. For example, you', 'production variants) to a single Amazon SageMaker endpoint. You conﬁgure the production variants\\nso that a small portion of the live traﬃc goes to the model that you want to validate. For example, you\\nmight choose to send 10% of the traﬃc to a model variant for evaluation. After you are satisﬁed with\\nthe model\\'s performance, you can route 100% traﬃc to the updated model.\\nFor more information, see articles and books about how to evaluate models, for example, Evaluating\\nMachine Learning Models .\\nOptions for oﬄine model evaluation include:\\n11Amazon SageMaker Developer Guide\\nProgramming Model \\n•Validating using a \"holdout set\"—Machine learning practitioners often set aside a part of the data as\\na \"holdout set.\" They don’t use this data for model training.', 'Programming Model \\n•Validating using a \"holdout set\"—Machine learning practitioners often set aside a part of the data as\\na \"holdout set.\" They don’t use this data for model training.\\nWith this approach, you evaluate how well your model provides inferences on the holdout set. You\\nthen assess how eﬀectively the model generalizes what it learned in the initial training, as opposed to\\nusing model \"memory.\" This approach to validation gives you an idea of how often the model is able to\\ninfer the correct answer.\\n\\xa0\\nIn some ways, this approach is similar to teaching elementary school students. First, you provide them\\nwith a set of examples to learn, and then test their ability to generalize from their learning. With', 'with a set of examples to learn, and then test their ability to generalize from their learning. With\\nhomework and tests, you pose problems that were not included in the initial learning and determine\\nwhether they are able to generalize eﬀectively. Students with perfect memories could memorize the\\nproblems, instead of learning the rules.\\n\\xa0\\nTypically, the holdout dataset is of 20-30% of the training data.\\n\\xa0\\n•k-fold validation—In this validation approach, you split the example dataset into k parts. You treat\\neach of these parts as a holdout set for k training runs, and use the other k-1 parts as the training set\\nfor that run. You produce k models using a similar process, and aggregate the models to generate your\\nﬁnal model. The value k is typically in the range of 5-10.', \"for that run. You produce k models using a similar process, and aggregate the models to generate your\\nﬁnal model. The value k is typically in the range of 5-10.\\nHow It Works: Next Topic\\nThe Amazon SageMaker Programming Model  (p. 12)\\nThe Amazon SageMaker Programming Model\\nAmazon SageMaker provides APIs that you can use to create and manage notebook instances and train\\nand deploy models. For more information, see API Reference (p. 616).\\nMaking API calls directly from code is cumbersome, and requires you to write code to authenticate your\\nrequests. Amazon SageMaker provides the following alternatives:\\n•Use the Amazon SageMaker console—With the console, you don't write any code. You use the console\", \"requests. Amazon SageMaker provides the following alternatives:\\n•Use the Amazon SageMaker console—With the console, you don't write any code. You use the console\\nUI to start model training or deploy a model. The console works well for simple jobs, where you use a\\nbuilt-in training algorithm and you don't need to preprocess training data.\\n\\xa0\\n•Modify the example Jupyter notebooks—Amazon SageMaker provides several Jupyter notebooks\\nthat train and deploy models using speciﬁc algorithms and datasets. Start with a notebook that has a\\nsuitable algorithm and modify it to accommodate your data source and speciﬁc needs.\\n\\xa0\\n•Write model training and inference code from scratch—Amazon SageMaker provides both an AWS\", 'suitable algorithm and modify it to accommodate your data source and speciﬁc needs.\\n\\xa0\\n•Write model training and inference code from scratch—Amazon SageMaker provides both an AWS\\nSDK and a high-level Python library that you can use in your code to start model training jobs and\\ndeploy the resulting models.\\n\\xa0\\n•The high-level Python library—The Python library simpliﬁes model training and deployment. In\\naddition to authenticating your requests, the library abstracts platform speciﬁcs by providing simple\\nmethods and default parameters. For example:\\n12Amazon SageMaker Developer Guide\\nProgramming Model \\n\\xa0\\n•To deploy your model, you call only the deploy()  method. The method creates an Amazon\\nSageMaker model, an endpoint conﬁguration, and an endpoint.', 'Programming Model \\n\\xa0\\n•To deploy your model, you call only the deploy()  method. The method creates an Amazon\\nSageMaker model, an endpoint conﬁguration, and an endpoint.\\n\\xa0\\n•If you use a custom framework script for model training, you call the fit()  method. The method\\ncreates a .gzip ﬁle of your script, uploads it to an Amazon S3 location, and then runs it for model\\ntraining, and other tasks. For more information, see Use Machine Learning Frameworks with\\nAmazon SageMaker (p. 440).\\n\\xa0\\n•The AWS SDK —The SDKs provide methods that correspond to the Amazon SageMaker API (see\\nActions (p. 616)). Use the SDKs to programmatically start a model training job and host the model\\nin Amazon SageMaker. SDK clients authenticate your requests by using your access keys, so you', \"Actions (p. 616)). Use the SDKs to programmatically start a model training job and host the model\\nin Amazon SageMaker. SDK clients authenticate your requests by using your access keys, so you\\ndon't need to write authentication code. They are available in multiple languages and platforms. For\\nmore information, see SDKs .\\n\\xa0\\nIn Get Started (p. 16), you train and deploy a model using an algorithm provided by Amazon\\nSageMaker. That exercise shows how to use both of these libraries. For more information, see Get\\nStarted (p. 16).\\n\\xa0\\n•Integrate Amazon SageMaker into your Apache Spark workﬂow—Amazon SageMaker provides\\na library for calling its APIs from Apache Spark. With it, you can use Amazon SageMaker-based\", \"Started (p. 16).\\n\\xa0\\n•Integrate Amazon SageMaker into your Apache Spark workﬂow—Amazon SageMaker provides\\na library for calling its APIs from Apache Spark. With it, you can use Amazon SageMaker-based\\nestimators in an Apache Spark pipeline. For more information, see Use Apache Spark with Amazon\\nSageMaker (p. 440).\\nHow It Works: Next Topic\\nGet Started (p. 16)\\n13Amazon SageMaker Developer Guide\\nStep 1: Create an AWS Account\\nSet Up Amazon SageMaker\\nIn this section, you sign up for an AWS account and then create an IAM user, a security group, and create\\nan Amazon S3 bucket.\\nIf you're new to Amazon SageMaker, we recommend that you read How Amazon SageMaker Works (p. 2).\\nTopics\\n•Step 1: Create an AWS Account (p. 14)\\n•Step 2: Create an IAM Administrator User and Group  (p. 14)\", \"Topics\\n•Step 1: Create an AWS Account (p. 14)\\n•Step 2: Create an IAM Administrator User and Group  (p. 14)\\nStep 1: Create an AWS Account\\nIn this section, you sign up for an AWS account. If you already have an AWS account, skip this step.\\nWhen you sign up for Amazon Web Services (AWS), your AWS account is automatically signed up for all\\nAWS services, including Amazon SageMaker. You are charged only for the services that you use.\\nTo create an AWS account\\n1. Open https://portal.aws.amazon.com/billing/signup.\\n2. Follow the online instructions.\\nPart of the sign-up procedure involves receiving a phone call and entering a veriﬁcation code on the\\nphone keypad.\\nWrite down your AWS account ID because you'll need it for the next task.\\nStep 2: Create an IAM Administrator User and\\nGroup\", \"phone keypad.\\nWrite down your AWS account ID because you'll need it for the next task.\\nStep 2: Create an IAM Administrator User and\\nGroup\\nWhen you create an AWS account, you get a single sign-in identity that has complete access to all of the\\nAWS services and resources in the account. This identity is called the AWS account root user . Signing in\\nto the AWS console using the email address and password that you used to create the account gives you\\ncomplete access to all of the AWS resources in your account.\\nWe strongly recommend that you not use the root user for everyday tasks, even the administrative\\nones. Instead, adhere to the Create Individual IAM Users, an AWS Identity and Access Management (IAM)\", 'We strongly recommend that you not use the root user for everyday tasks, even the administrative\\nones. Instead, adhere to the Create Individual IAM Users, an AWS Identity and Access Management (IAM)\\nadministrator user. Then securely lock away the root user credentials and use them to perform only a few\\naccount and service management tasks.\\nTo create an administrator user and sign in to the console\\n1. Create an administrator user in your AWS account. For instructions, see Creating Your First IAM User\\nand Administrators Group in the IAM User Guide .\\nNote\\nWe assume that you use administrator user credentials for the exercises and procedures\\nin this guide. If you choose to create and use another IAM user, grant that user minimum', 'Note\\nWe assume that you use administrator user credentials for the exercises and procedures\\nin this guide. If you choose to create and use another IAM user, grant that user minimum\\npermissions. For more information, see Authenticating With Identities  (p. 476).\\n14Amazon SageMaker Developer Guide\\nStep 2: Create an IAM Administrator User and Group \\n2. Sign in to the AWS Management Console.\\nTo sign in to the AWS console as a IAM user, you must use a special URL. For more information, see\\nHow Users Sign In to Your Account in the IAM User Guide .\\nNext Step\\nStep 1: Create an Amazon S3 Bucket (p. 17)\\n15Amazon SageMaker Developer Guide\\nGet Started\\nThe best way to learn how to use Amazon SageMaker is to create, train, and deploy a simple machine\\nlearning model. To do this, you need the following:', '15Amazon SageMaker Developer Guide\\nGet Started\\nThe best way to learn how to use Amazon SageMaker is to create, train, and deploy a simple machine\\nlearning model. To do this, you need the following:\\n•A dataset. You use the MNIST (Modiﬁed National Institute of Standards and Technology database)\\ndataset of images of handwritten, single digit numbers. This dataset provides a training set of 50,000\\nexample images of handwritten single-digit numbers, a validation set of 10,000 images, and a test\\ndataset of 10,000 images. You provide this dataset to the algorithm for model training. For more\\ninformation about the MNIST dataset, see MNIST Dataset .\\n•An algorithm. You use the XGBoost algorithm provided by Amazon SageMaker to train the model', 'information about the MNIST dataset, see MNIST Dataset .\\n•An algorithm. You use the XGBoost algorithm provided by Amazon SageMaker to train the model\\nusing the MNIST dataset. During model training, the algorithm assigns example data of handwritten\\nnumbers into 10 clusters: one for each number, 0 through 9. For more information about the\\nalgorithm, see XGBoost Algorithm (p. 255).\\nYou also need a few resources for storing your data and running the code in this exercise:\\n•An Amazon Simple Storage Service (Amazon S3) bucket to store the training data and the model\\nartifacts that Amazon SageMaker creates when it trains the model.\\n•An Amazon SageMaker notebook instance to prepare and process data and to train and deploy a\\nmachine learning model.', \"artifacts that Amazon SageMaker creates when it trains the model.\\n•An Amazon SageMaker notebook instance to prepare and process data and to train and deploy a\\nmachine learning model.\\n•A Jupyter notebook to use with the notebook instance to prepare your training data and train and\\ndeploy the model.\\nIn this exercise, you learn how to create all of the resources that you need to create, train, and deploy a\\nmodel.\\nImportant\\nFor model training, deployment, and validation, you can use either of the following:\\n•The high-level Amazon SageMaker Python SDK\\n•The AWS SDK for Python (Boto 3)\\nThe Amazon SageMaker Python SDK abstracts several implementation details, and is easy\\nto use. This exercise provides code examples for both libraries. If you're a ﬁrst-time Amazon\", \"The Amazon SageMaker Python SDK abstracts several implementation details, and is easy\\nto use. This exercise provides code examples for both libraries. If you're a ﬁrst-time Amazon\\nSageMaker user, we recommend that you use the Amazon SageMaker Python SDK. For more\\ninformation, see https://sagemaker.readthedocs.io/en/stable/overview.html.\\nIf you're new to Amazon SageMaker, we recommend that you read How Amazon SageMaker Works (p. 2)\\nbefore starting this exercise.\\nTopics\\n•Step 1: Create an Amazon S3 Bucket (p. 17)\\n•Step 2: Create an Amazon SageMaker Notebook Instance (p. 17)\\n•Step 3: Create a Jupyter Notebook (p. 18)\\n•Step 4: Download, Explore, and Transform the Training Data (p. 19)\\n•Step 5: Train a Model (p. 21)\\n•Step 6: Deploy the Model to Amazon SageMaker (p. 26)\", '•Step 3: Create a Jupyter Notebook (p. 18)\\n•Step 4: Download, Explore, and Transform the Training Data (p. 19)\\n•Step 5: Train a Model (p. 21)\\n•Step 6: Deploy the Model to Amazon SageMaker (p. 26)\\n•Step 7: Validate the Model (p. 30)\\n16Amazon SageMaker Developer Guide\\nStep 1: Create an Amazon S3 Bucket\\n•Step 8: Clean Up  (p. 35)\\n•Step 9: Integrating Amazon SageMaker Endpoints into Internet-facing Applications (p. 35)\\nStep 1: Create an Amazon S3 Bucket\\nTraining a model produces the following\\n•The model training data\\n•Model artifacts, which Amazon SageMaker generates during model training\\nYou save these in an Amazon Simple Storage Service (Amazon S3) bucket: You can store datasets that\\nyou use as your training data and model artifacts that are the output of a training job in a single bucket', 'you use as your training data and model artifacts that are the output of a training job in a single bucket\\nor in two separate buckets. For this exercise and others in this guide, one bucket is suﬃcient. If you\\nalready have S3 buckets, you can use them, or you can create new ones.\\nTo create a bucket, follow the instructions in Create a Bucket in the Amazon Simple Storage Service\\nConsole User Guide . Include sagemaker  in the bucket name. For example, sagemaker- datetime .\\nNote\\nAmazon SageMaker needs permission to access these buckets. You grant permission with an\\nIAM role, which you create in the next step when you create an Amazon SageMaker notebook\\ninstance. This IAM role automatically gets permissions to access any bucket that has sagemaker', 'IAM role, which you create in the next step when you create an Amazon SageMaker notebook\\ninstance. This IAM role automatically gets permissions to access any bucket that has sagemaker\\nin the name. It gets these permissions through the AmazonSageMakerFullAccess  policy,\\nwhich Amazon SageMaker attaches to the role. If you add a policy to the role that grants the\\nSageMaker service principal S3FullAccess  permission, the name of the bucket does not need\\nto contain sagemaker .\\nNext Step\\nStep 2: Create an Amazon SageMaker Notebook Instance (p. 17)\\nStep 2: Create an Amazon SageMaker Notebook\\nInstance\\nAn Amazon SageMaker notebook instance is a fully managed machine learning (ML) Amazon Elastic\\nCompute Cloud (Amazon EC2) compute instance that runs the Jupyter Notebook App. You use the', 'Instance\\nAn Amazon SageMaker notebook instance is a fully managed machine learning (ML) Amazon Elastic\\nCompute Cloud (Amazon EC2) compute instance that runs the Jupyter Notebook App. You use the\\nnotebook instance to create and manage Jupyter notebooks that you can use to prepare and process\\ndata and to train and deploy machine learning models. For more information, see Explore and Preprocess\\nData  (p. 4).\\nNote\\nIf necessary, you can change the notebook instance settings, including the ML compute instance\\ntype, later.\\nTo create an Amazon SageMaker notebook instance\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances, then choose Create notebook instance.', 'To create an Amazon SageMaker notebook instance\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances, then choose Create notebook instance.\\n3. On the Create notebook instance page, provide the following information (if a ﬁeld is not\\nmentioned, leave the default values):\\n17Amazon SageMaker Developer Guide\\nNext Step\\na. For Notebook instance name, type a name for your notebook instance.\\nb. For Instance type, choose ml.t2.medium . This is the least expensive instance type that\\nnotebook instances support, and it suﬃces for this exercise.\\nc. For IAM role, choose Create a new role, then choose Create role.\\nd. Choose Create notebook instance.\\nIn a few minutes, Amazon SageMaker launches an ML compute instance—in this case, a', 'c. For IAM role, choose Create a new role, then choose Create role.\\nd. Choose Create notebook instance.\\nIn a few minutes, Amazon SageMaker launches an ML compute instance—in this case, a\\nnotebook instance—and attaches an ML storage volume to it. The notebook instance has a\\npreconﬁgured Jupyter notebook server and a set of Anaconda libraries.\\nNext Step\\nStep 3: Create a Jupyter Notebook (p. 18).\\nStep 3: Create a Jupyter Notebook\\nCreate a Jupyter notebook in the notebook instance you created in Step 2: Create an Amazon SageMaker\\nNotebook Instance (p. 17), and create a cell that gets the IAM role that your notebook needs to run\\nAmazon SageMaker APIs and speciﬁes the name of the Amazon S3 bucket that you will use to store the', 'Notebook Instance (p. 17), and create a cell that gets the IAM role that your notebook needs to run\\nAmazon SageMaker APIs and speciﬁes the name of the Amazon S3 bucket that you will use to store the\\ndatasets that you use for your training data and the model artifacts that a Amazon SageMaker training\\njob outputs.\\nTo create a Jupyter notebook\\n1. Open the notebook instance.\\na. Sign in to the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\nb. Open the notebook instance, by choosing either Open Jupyter for classic Juypter view or\\nOpen JupyterLab for JupyterLab view next to the name of the notebook instance. The Jupyter\\nnotebook server page appears:\\n2. Create a notebook.\\na. If you opened the notebook in Jupyter classic view, on the Files tab, choose New , and', 'notebook server page appears:\\n2. Create a notebook.\\na. If you opened the notebook in Jupyter classic view, on the Files tab, choose New , and\\nconda_python3. This preinstalled environment includes the default Anaconda installation and\\nPython 3.\\nb. If you opened the notebook in JupyterLab view, on the File menu, choose New , and then choose\\nNotebook. . For Select Kernel, choose conda_python3. This preinstalled environment includes\\nthe default Anaconda installation and Python 3.\\n3. In the Jupyter notebook, choose File and Save as, and name the notebook.\\n4. Copy the following Python code and paste it into the ﬁrst cell in your notebook. Add the name\\nof the S3 bucket that you created in Set Up Amazon SageMaker (p. 14), and run the code. The', \"4. Copy the following Python code and paste it into the ﬁrst cell in your notebook. Add the name\\nof the S3 bucket that you created in Set Up Amazon SageMaker (p. 14), and run the code. The\\nget_execution_role  function retrieves the IAM role you created when you created your notebook\\ninstance.\\nimport os\\nimport boto3\\nimport re\\nimport copy\\nimport time\\nfrom time import gmtime, strftime\\nfrom sagemaker import get_execution_role\\n18Amazon SageMaker Developer Guide\\nStep 4: Download, Explore, and Transform Data\\nrole = get_execution_role()\\nregion = boto3.Session().region_name\\nbucket=' bucket-name ' # Replace with your s3 bucket name\\nprefix = 'sagemaker/xgboost-mnist' # Used as part of the path in the bucket where you\\n store data\", \"region = boto3.Session().region_name\\nbucket=' bucket-name ' # Replace with your s3 bucket name\\nprefix = 'sagemaker/xgboost-mnist' # Used as part of the path in the bucket where you\\n store data\\nbucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket) # The URL to\\n access the bucket\\nNext Step\\nStep 4: Download, Explore, and Transform the Training Data (p. 19)\\nStep 4: Download, Explore, and Transform the\\nTraining Data\\nDownload the MNIST dataset to your notebook instance, review the data, transform it, and upload it to\\nyour S3 bucket.\\nYou transform the data by changing its format from numpy.array  to comma-separated values (CSV).\\nThe XGBoost Algorithm (p. 255) expects input in either the LIBSVM or CSV format. LIBSVM is an open\", 'You transform the data by changing its format from numpy.array  to comma-separated values (CSV).\\nThe XGBoost Algorithm (p. 255) expects input in either the LIBSVM or CSV format. LIBSVM is an open\\nsource machine learning library. In this exercise , you use CSV format because it\\'s simpler.\\nTopics\\n•Step 4.1: Download the MNIST Dataset  (p. 19)\\n•Step 4.2: Explore the Training Dataset (p. 20)\\n•Step 4.3: Transform the Training Dataset and Upload It to Amazon S3 (p. 21)\\nStep 4.1: Download the MNIST Dataset\\nTo download the MNIST dataset, copy and paste the following code into the notebook and run it:.\\n%%time \\nimport pickle, gzip, urllib.request, json\\nimport numpy as np\\n# Load the dataset\\nurllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\",\\n \"mnist.pkl.gz\")', '%%time \\nimport pickle, gzip, urllib.request, json\\nimport numpy as np\\n# Load the dataset\\nurllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\",\\n \"mnist.pkl.gz\")\\nwith gzip.open(\\'mnist.pkl.gz\\', \\'rb\\') as f:\\n    train_set, valid_set, test_set = pickle.load(f, encoding=\\'latin1\\')\\nprint(train_set[0].shape)\\nThe code does the following:\\n1.Downloads the MNIST dataset (mnist.pkl.gz ) from the MNIST Database website to your notebook.\\n2.Unzips the ﬁle and reads the following datasets into the notebook\\'s memory:\\n•train_set  – You use these images of handwritten numbers to train a model.\\n•valid_set  – The XGBoost Algorithm (p. 255) uses these images to evaluate the progress of the\\nmodel during training.\\n19Amazon SageMaker Developer Guide\\nStep 4.2: Explore the Dataset', '•valid_set  – The XGBoost Algorithm (p. 255) uses these images to evaluate the progress of the\\nmodel during training.\\n19Amazon SageMaker Developer Guide\\nStep 4.2: Explore the Dataset\\n•test_set  – You use this set to get inferences to test the deployed model.\\nNext Step\\nStep 4.2: Explore the Training Dataset (p. 20)\\nStep 4.2: Explore the Training Dataset\\nTypically, you explore training data to determine what you need to clean up and which transformations\\nto apply to improve model training. For this exercise, you don\\'t need to clean up the MNIST dataset.\\nTo explore the dataset\\n• Type the following code in a cell in your notebook and run the cell to display the ﬁrst 10 images in\\ntrain_set :.\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nplt.rcParams[\"figure.figsize\"] = (2,10)', 'train_set :.\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\nplt.rcParams[\"figure.figsize\"] = (2,10)\\nfor i in range(0, 10):\\n    img = train_set[0][i]\\n    label = train_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')\\n    print(\\'This is a {}\\'.format(label))\\n    plt.show()\\ntrain_set  contains the following structures:\\n•train_set[0]  – Contains images.\\n•train_set[1]  – Contains labels.\\nThe code uses the matplotlib  library to get and display the ﬁrst 10 images from the training\\ndataset.\\nNext Step\\nStep 4.3: Transform the Training Dataset and Upload It to Amazon S3 (p. 21)\\n20Amazon SageMaker Developer Guide\\nStep 4.3: Transform Dataset and Upload to S3\\nStep 4.3: Transform the Training Dataset and Upload\\nIt to Amazon S3', \"20Amazon SageMaker Developer Guide\\nStep 4.3: Transform Dataset and Upload to S3\\nStep 4.3: Transform the Training Dataset and Upload\\nIt to Amazon S3\\nThe XGBoost Algorithm (p. 255) expects comma-separated values (CSV) for its training input. The\\nformat of the training dataset is numpy.array. Transform the dataset from numpy.array format to the\\nCSV format. Then upload it to the Amazon S3 bucket that you created in Step 1: Create an Amazon S3\\nBucket (p. 17)\\nTo convert the dataset to CSV format and upload it\\n• Type the following code into a cell in your notebook and then run the cell.\\n%%time\\nimport struct\\nimport io\\nimport csv\\nimport boto3\\n        \\ndef convert_data():\\n    data_partitions = [('train', train_set), ('validation', valid_set), ('test',\\n test_set)]\", \"%%time\\nimport struct\\nimport io\\nimport csv\\nimport boto3\\n        \\ndef convert_data():\\n    data_partitions = [('train', train_set), ('validation', valid_set), ('test',\\n test_set)]\\n    for data_partition_name, data_partition in data_partitions:\\n        print('{}: {} {}'.format(data_partition_name, data_partition[0].shape,\\n data_partition[1].shape))\\n        labels = [t.tolist() for t in data_partition[1]]\\n        features = [t.tolist() for t in data_partition[0]]\\n        \\n        if data_partition_name != 'test':\\n            examples = np.insert(features, 0, labels, axis=1)\\n        else:\\n            examples = features\\n        #print(examples[50000,:])\\n        \\n        \\n        np.savetxt('data.csv', examples, delimiter=',')\", 'else:\\n            examples = features\\n        #print(examples[50000,:])\\n        \\n        \\n        np.savetxt(\\'data.csv\\', examples, delimiter=\\',\\')\\n        \\n        \\n        \\n        key = \"{}/{}/examples\".format(prefix,data_partition_name)\\n        url = \\'s3://{}/{}\\'.format(bucket, key)\\n       \\n boto3.Session().resource(\\'s3\\').Bucket(bucket).Object(key).upload_file(\\'data.csv\\')\\n        print(\\'Done writing to {}\\'.format(url))\\n        \\nconvert_data()\\nAfter it converts the dataset to the CSV format, ,the code uploads the CSV ﬁle to the S3 bucket.\\nNext Step\\nStep 5: Train a Model (p. 21)\\nStep 5: Train a Model\\nTo train, deploy, and validate a model in Amazon SageMaker, you can use either the Amazon SageMaker', \"Next Step\\nStep 5: Train a Model (p. 21)\\nStep 5: Train a Model\\nTo train, deploy, and validate a model in Amazon SageMaker, you can use either the Amazon SageMaker\\nPython SDK or the AWS SDK for Python (Boto 3). (You can also use the console, but for this exercise,\\n21Amazon SageMaker Developer Guide\\nChoose the Training Algorithm\\nyou will use the notebook instance and one of the SDKs.) This exercise provides code examples for each\\nlibrary.\\nThe Amazon SageMaker Python SDK abstracts several implementation details, and is easy to use. If\\nyou're a ﬁrst-time Amazon SageMaker user, we recommend that you use it to train, deploy, and validate\\nthe model. For more information, see https://sagemaker.readthedocs.io/en/stable/overview.html.\\nTopics\\n•Choose the Training Algorithm (p. 22)\", 'the model. For more information, see https://sagemaker.readthedocs.io/en/stable/overview.html.\\nTopics\\n•Choose the Training Algorithm (p. 22)\\n•Create and Run a Training Job (Amazon SageMaker Python SDK) (p. 22)\\n•Create and Run a Training Job (AWS SDK for Python (Boto 3)) (p. 23)\\nChoose the Training Algorithm\\nTo choose the right algorithm for your model, you typically follow an evaluation process. For this\\nexercise, you use the XGBoost Algorithm (p. 255) provided by Amazon SageMaker, so no evaluation is\\nrequired. For information about choosing algorithms, see Use Amazon SageMaker Built-in Algorithms\\n (p. 56).\\nCreate and Run a Training Job (Amazon SageMaker\\nPython SDK)\\nThe Amazon SageMaker Python SDK includes the sagemaker.estimator.Estimator  estimator. You', \"(p. 56).\\nCreate and Run a Training Job (Amazon SageMaker\\nPython SDK)\\nThe Amazon SageMaker Python SDK includes the sagemaker.estimator.Estimator  estimator. You\\ncan use this class, in the sagemaker.estimator  module, with any algorithm. For more information, see\\nhttps://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.\\nTo run a model training job (Amazon SageMaker Python SDK)\\n1. Import the Amazon SageMaker Python SDK and get the XGBoost container.\\nimport sagemaker\\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\\ncontainer = get_image_uri(boto3.Session().region_name, 'xgboost')\\n2. Download the training and validation data from the Amazon S3 location where you uploaded it in\", \"container = get_image_uri(boto3.Session().region_name, 'xgboost')\\n2. Download the training and validation data from the Amazon S3 location where you uploaded it in\\nStep 4.3: Transform the Training Dataset and Upload It to Amazon S3 (p. 21), and set the location\\nwhere you store the training output.\\ntrain_data = 's3://{}/{}/{}'.format(bucket, prefix, 'train')\\nvalidation_data = 's3://{}/{}/{}'.format(bucket, prefix, 'validation')\\ns3_output_location = 's3://{}/{}/{}'.format(bucket, prefix, 'xgboost_model_sdk')\\nprint(train_data)\\n3. Create an instance of the sagemaker.estimator.Estimator  class.\\nxgb_model = sagemaker.estimator.Estimator(container,\\n                                         role, \\n                                         train_instance_count=1,\", \"xgb_model = sagemaker.estimator.Estimator(container,\\n                                         role, \\n                                         train_instance_count=1, \\n                                         train_instance_type='ml.m4.xlarge',\\n                                         train_volume_size = 5,\\n                                         output_path=s3_output_location,\\n                                         sagemaker_session=sagemaker.Session())\\n22Amazon SageMaker Developer Guide\\nCreate and Run a Training Job\\n(AWS SDK for Python (Boto 3))\\nIn the constructor, you specify the following parameters:\\n•role – The AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume\", '(AWS SDK for Python (Boto 3))\\nIn the constructor, you specify the following parameters:\\n•role – The AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume\\nto perform tasks on your behalf (for example, reading training results, called model artifacts, from\\nthe S3 bucket and writing training results to Amazon S3). This is the role that you got in Step 3:\\nCreate a Jupyter Notebook (p. 18).\\n•train_instance_count  and train_instance_type  – The type and number of ML compute\\ninstances to use for model training. For this exercise, you use only a single training instance.\\n•train_volume_size  – The size, in GB, of the Amazon Elastic Block Store (Amazon EBS) storage\\nvolume to attach to the training instance. This must be large enough to store training data if you', '•train_volume_size  – The size, in GB, of the Amazon Elastic Block Store (Amazon EBS) storage\\nvolume to attach to the training instance. This must be large enough to store training data if you\\nuse File  mode (File  mode is the default).\\n•output_path  – The path to the S3 bucket where Amazon SageMaker stores the training results.\\n•sagemaker_session  – The session object that manages interactions with Amazon SageMaker\\nAPIs and any other AWS service that the training job uses.\\n4. Set the hyperparameter values for the XGBoost training job by calling the set_hyperparameters\\nmethod of the estimator. For a description of XGBoost hyperparameters, see XGBoost\\nHyperparameters  (p. 258).\\nxgb_model.set_hyperparameters(max_depth = 5,\\n                              eta = .2,', 'method of the estimator. For a description of XGBoost hyperparameters, see XGBoost\\nHyperparameters  (p. 258).\\nxgb_model.set_hyperparameters(max_depth = 5,\\n                              eta = .2,\\n                              gamma = 4,\\n                              min_child_weight = 6,\\n                              silent = 0,\\n                              objective = \"multi:softmax\",\\n                              num_class = 10,\\n                              num_round = 10)\\n5. Create the training channels to use for the training job. For this example, we use both train  and\\nvalidation  channels.\\ntrain_channel = sagemaker.session.s3_input(train_data, content_type=\\'text/csv\\')\\nvalid_channel = sagemaker.session.s3_input(validation_data, content_type=\\'text/csv\\')', \"validation  channels.\\ntrain_channel = sagemaker.session.s3_input(train_data, content_type='text/csv')\\nvalid_channel = sagemaker.session.s3_input(validation_data, content_type='text/csv')\\ndata_channels = {'train': train_channel, 'validation': valid_channel}\\n6. To start model training, call the estimator's fit method.\\nxgb_model.fit(inputs=data_channels,  logs=True)\\nThis is a synchronous operation. The method displays progress logs and waits until training\\ncompletes before returning. For more information about model training, see Train a Model with\\nAmazon SageMaker  (p. 4).\\nModel training for this exercise can take up to 15 minutes.\\nNext Step\\nStep 6: Deploy the Model to Amazon SageMaker (p. 26)\\nCreate and Run a Training Job (AWS SDK for Python\\n(Boto 3))\", 'Model training for this exercise can take up to 15 minutes.\\nNext Step\\nStep 6: Deploy the Model to Amazon SageMaker (p. 26)\\nCreate and Run a Training Job (AWS SDK for Python\\n(Boto 3))\\nTo train a model, Amazon SageMaker uses the CreateTrainingJob (p. 667) API. The AWS SDK for Python\\n(Boto 3) provides the corresponding create_training_job  method.\\n23Amazon SageMaker Developer Guide\\nCreate and Run a Training Job\\n(AWS SDK for Python (Boto 3))\\nWhen using this method, you provide the following information:\\n•The training algorithm – Specify the registry path of the Docker image that contains the training code.\\nFor the registry paths for the algorithms provided by Amazon SageMaker, see Common Parameters for\\nBuilt-In Algorithms  (p. 58).', 'For the registry paths for the algorithms provided by Amazon SageMaker, see Common Parameters for\\nBuilt-In Algorithms  (p. 58).\\n•Algorithm-speciﬁc hyperparameters – Specify algorithm-speciﬁc hyperparameters to inﬂuence the\\nﬁnal quality of the model. For information, see XGBoost Hyperparameters (p. 258).\\n•The input and output conﬁguration – Provide the S3 bucket where training data is stored and where\\nAmazon SageMaker saves the results of model training (the model artifacts).\\nTo run a model training job (AWS SDK for Python (Boto 3))\\n1. Import the get_image_url  utility function Amazon SageMaker Python SDK and get the location of\\nthe XGBoost container.\\nimport sagemaker\\nfrom sagemaker.amazon.amazon_estimator import get_image_uri', '1. Import the get_image_url  utility function Amazon SageMaker Python SDK and get the location of\\nthe XGBoost container.\\nimport sagemaker\\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\\ncontainer = get_image_uri(boto3.Session().region_name, \\'xgboost\\')\\n2. Set up the training information for the job. You pass this information when you call\\ncreate_training_job . For more information about the information that you need to send to a\\ntraining job, see the section called “CreateTrainingJob” (p. 667).\\n#Ensure that the train and validation data folders generated above are reflected in the\\n \"InputDataConfig\" parameter below.\\ncommon_training_params = \\\\\\n{\\n    \"AlgorithmSpecification\": {\\n        \"TrainingImage\": container,\\n        \"TrainingInputMode\": \"File\"\\n    },\\n    \"RoleArn\": role,', '\"InputDataConfig\" parameter below.\\ncommon_training_params = \\\\\\n{\\n    \"AlgorithmSpecification\": {\\n        \"TrainingImage\": container,\\n        \"TrainingInputMode\": \"File\"\\n    },\\n    \"RoleArn\": role,\\n    \"OutputDataConfig\": {\\n        \"S3OutputPath\": bucket_path + \"/\"+ prefix + \"/xgboost\"\\n    },\\n    \"ResourceConfig\": {\\n        \"InstanceCount\": 1,   \\n        \"InstanceType\": \"ml.m4.xlarge\",\\n        \"VolumeSizeInGB\": 5\\n    },\\n    \"HyperParameters\": {\\n        \"max_depth\":\"5\",\\n        \"eta\":\"0.2\",\\n        \"gamma\":\"4\",\\n        \"min_child_weight\":\"6\",\\n        \"silent\":\"0\",\\n        \"objective\": \"multi:softmax\",\\n        \"num_class\": \"10\",\\n        \"num_round\": \"10\"\\n    },\\n    \"StoppingCondition\": {\\n        \"MaxRuntimeInSeconds\": 86400\\n    },\\n    \"InputDataConfig\": [\\n        {', '\"num_class\": \"10\",\\n        \"num_round\": \"10\"\\n    },\\n    \"StoppingCondition\": {\\n        \"MaxRuntimeInSeconds\": 86400\\n    },\\n    \"InputDataConfig\": [\\n        {\\n            \"ChannelName\": \"train\",\\n            \"DataSource\": {\\n                \"S3DataSource\": {\\n                    \"S3DataType\": \"S3Prefix\",\\n24Amazon SageMaker Developer Guide\\nCreate and Run a Training Job\\n(AWS SDK for Python (Boto 3))\\n                    \"S3Uri\": bucket_path + \"/\"+ prefix+ \\'/train/\\',\\n                    \"S3DataDistributionType\": \"FullyReplicated\" \\n                }\\n            },\\n            \"ContentType\": \"text/csv\",\\n            \"CompressionType\": \"None\"\\n        },\\n        {\\n            \"ChannelName\": \"validation\",\\n            \"DataSource\": {\\n                \"S3DataSource\": {', '\"ContentType\": \"text/csv\",\\n            \"CompressionType\": \"None\"\\n        },\\n        {\\n            \"ChannelName\": \"validation\",\\n            \"DataSource\": {\\n                \"S3DataSource\": {\\n                    \"S3DataType\": \"S3Prefix\",\\n                    \"S3Uri\": bucket_path + \"/\"+ prefix+ \\'/validation/\\',\\n                    \"S3DataDistributionType\": \"FullyReplicated\"\\n                }\\n            },\\n            \"ContentType\": \"text/csv\",\\n            \"CompressionType\": \"None\"\\n        }\\n    ]\\n}\\n3. Name your training job, and ﬁnish conﬁguring the parameters that you send to it.\\n#training job params\\ntraining_job_name = \\'xgboost-mnist\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nprint(\"Job name is:\", training_job_name)\\ntraining_job_params = copy.deepcopy(common_training_params)', '#training job params\\ntraining_job_name = \\'xgboost-mnist\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nprint(\"Job name is:\", training_job_name)\\ntraining_job_params = copy.deepcopy(common_training_params)\\ntraining_job_params[\\'TrainingJobName\\'] = training_job_name\\ntraining_job_params[\\'ResourceConfig\\'][\\'InstanceCount\\'] = 1\\n4. Call create_training_job  to start the training job, and wait for it to complete. If the training job\\nfails, print the reason that it failed.\\n%%time\\nregion = boto3.Session().region_name\\nsm = boto3.Session().client(\\'sagemaker\\')\\nsm.create_training_job(**training_job_params)\\nstatus = sm.describe_training_job(TrainingJobName=training_job_name)\\n[\\'TrainingJobStatus\\']\\nprint(status)\\nsm.get_waiter(\\'training_job_completed_or_stopped\\').wait(TrainingJobName=training_job_name)', 'status = sm.describe_training_job(TrainingJobName=training_job_name)\\n[\\'TrainingJobStatus\\']\\nprint(status)\\nsm.get_waiter(\\'training_job_completed_or_stopped\\').wait(TrainingJobName=training_job_name)\\nstatus = sm.describe_training_job(TrainingJobName=training_job_name)\\n[\\'TrainingJobStatus\\']\\nprint(\"Training job ended with status: \" + status)\\nif status == \\'Failed\\':\\n    message = sm.describe_training_job(TrainingJobName=training_job_name)\\n[\\'FailureReason\\']\\n    print(\\'Training failed with the following error: {}\\'.format(message))\\n    raise Exception(\\'Training job failed\\')\\nYou now have a trained model. Amazon SageMaker stores the resulting artifacts in your S3 bucket.\\nNext Step\\nStep 6: Deploy the Model to Amazon SageMaker (p. 26)\\n25Amazon SageMaker Developer Guide\\nStep 6: Deploy the Model', 'Next Step\\nStep 6: Deploy the Model to Amazon SageMaker (p. 26)\\n25Amazon SageMaker Developer Guide\\nStep 6: Deploy the Model\\nStep 6: Deploy the Model to Amazon SageMaker\\nTo get predictions, deploy your model. The method you use depends on how you want to generate\\ninferences:\\n•To get one inference at a time in real time, set up a persistent endpoint using Amazon SageMaker\\nhosting services.\\n•To get inferences for an entire dataset, use Amazon SageMaker batch transform.\\nTopics\\n•Step 6.1: Deploy the Model to Amazon SageMaker Hosting Services  (p. 26)\\n•Step 6.2: Deploy the Model with Batch Transform (p. 28)\\nStep 6.1: Deploy the Model to Amazon SageMaker\\nHosting Services\\nTo deploy a model in Amazon SageMaker, hosting services, you can use either the Amazon SageMaker', \"Step 6.1: Deploy the Model to Amazon SageMaker\\nHosting Services\\nTo deploy a model in Amazon SageMaker, hosting services, you can use either the Amazon SageMaker\\nPython SDK or the AWS SDK for Python (Boto 3). This exercise provides code examples for both libraries.\\nThe Amazon SageMaker Python SDK abstracts several implementation details, and is easy to use. If\\nyou're a ﬁrst-time Amazon SageMaker user, we recommend that you use it. For more information, see\\nhttps://sagemaker.readthedocs.io/en/stable/overview.html.\\nTopics\\n•Deploy the Model to Amazon SageMaker Hosting Services (Amazon SageMaker Python\\nSDK)  (p. 26)\\n•Deploy the Model to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto 3).) (p. 27)\\nDeploy the Model to Amazon SageMaker Hosting Services\\n(Amazon SageMaker Python SDK)\", \"SDK)  (p. 26)\\n•Deploy the Model to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto 3).) (p. 27)\\nDeploy the Model to Amazon SageMaker Hosting Services\\n(Amazon SageMaker Python SDK)\\nDeploy the model that you trained in Create and Run a Training Job (Amazon SageMaker Python\\nSDK)  (p. 22) by calling the deploy  method of the sagemaker.estimator.Estimator  object. This\\nis the same object that you used to train the model. When you call the deploy method, specify the\\nnumber and type of ML instances that you want to use to host the endpoint.\\nxgb_predictor = xgb_model.deploy(initial_instance_count=1,\\n                                instance_type='ml.m4.xlarge',\\n                                )\\nThe deploy method creates the deployable model, conﬁgures the Amazon SageMaker hosting\", \"instance_type='ml.m4.xlarge',\\n                                )\\nThe deploy method creates the deployable model, conﬁgures the Amazon SageMaker hosting\\nservices endpoint, and launches the endpoint to host the model. For more information, see https://\\nsagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.deploy.\\nIt also returns a sagemaker.predictor.RealTimePredictor  object, which you can use to\\nget inferences from the model. For information, see https://sagemaker.readthedocs.io/en/stable/\\npredictors.html#sagemaker.predictor.RealTimePredictor.\\nNext Step\\n26Amazon SageMaker Developer Guide\\nStep 6.1: Hosting Services\\nStep 7: Validate the Model (p. 30)\\nDeploy the Model to Amazon SageMaker Hosting Services (AWS\\nSDK for Python (Boto 3).)\", 'Next Step\\n26Amazon SageMaker Developer Guide\\nStep 6.1: Hosting Services\\nStep 7: Validate the Model (p. 30)\\nDeploy the Model to Amazon SageMaker Hosting Services (AWS\\nSDK for Python (Boto 3).)\\nDeploying a model using the AWS SDK for Python (Boto 3) is a three-step process:\\n1.Create a model in Amazon SageMaker – Send a CreateModel (p. 648) request to provide information\\nsuch as the location of the S3 bucket that contains your model artifacts and the registry path of the\\nimage that contains inference code.\\n2.Create an endpoint conﬁguration – Send a CreateEndpointConﬁg (p. 635) request to provide the\\nresource conﬁguration for hosting. This includes the type and number of ML compute instances to\\nlaunch to deploy the model.', \"resource conﬁguration for hosting. This includes the type and number of ML compute instances to\\nlaunch to deploy the model.\\n3.Create an endpoint – Send a CreateEndpoint (p. 632) request to create an endpoint. Amazon\\nSageMaker launches the ML compute instances and deploys the model. Amazon SageMaker returns an\\nendpoint. Applications can send requests for inference to this endpoint.\\nTo deploy the model (AWS SDK for Python (Boto 3))\\nFor each of the following steps, paste the code in a cell in the Jupyter notebook you created in Step 3:\\nCreate a Jupyter Notebook (p. 18) and run the cell.\\n1. Create a deployable model by identifying the location of model artifacts and the Docker image that\\ncontains the inference code.\\nmodel_name = training_job_name + '-mod'\", '1. Create a deployable model by identifying the location of model artifacts and the Docker image that\\ncontains the inference code.\\nmodel_name = training_job_name + \\'-mod\\'\\ninfo = sm.describe_training_job(TrainingJobName=training_job_name)\\nmodel_data = info[\\'ModelArtifacts\\'][\\'S3ModelArtifacts\\']\\nprint(model_data)\\nprimary_container = {\\n    \\'Image\\': container,\\n    \\'ModelDataUrl\\': model_data\\n}\\ncreate_model_response = sm.create_model(\\n    ModelName = model_name,\\n    ExecutionRoleArn = role,\\n    PrimaryContainer = primary_container)\\nprint(create_model_response[\\'ModelArn\\'])\\n2. Create an Amazon SageMaker endpoint conﬁguration by specifying the ML compute instances that\\nyou want to deploy your model to.\\nendpoint_config_name = \\'DEMO-XGBoostEndpointConfig-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\",\\n gmtime())', 'you want to deploy your model to.\\nendpoint_config_name = \\'DEMO-XGBoostEndpointConfig-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\",\\n gmtime())\\nprint(endpoint_config_name)\\ncreate_endpoint_config_response = sm.create_endpoint_config(\\n    EndpointConfigName = endpoint_config_name,\\n    ProductionVariants=[{\\n        \\'InstanceType\\':\\'ml.m4.xlarge\\',\\n        \\'InitialVariantWeight\\':1,\\n        \\'InitialInstanceCount\\':1,\\n        \\'ModelName\\':model_name,\\n        \\'VariantName\\':\\'AllTraffic\\'}])\\nprint(\"Endpoint Config Arn: \" + create_endpoint_config_response[\\'EndpointConfigArn\\'])\\n27Amazon SageMaker Developer Guide\\nStep 6.2: Batch Transform\\n3. Create an Amazon SageMaker endpoint.\\n%%time\\nimport time\\nendpoint_name = \\'DEMO-XGBoostEndpoint-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nprint(endpoint_name)', 'Step 6.2: Batch Transform\\n3. Create an Amazon SageMaker endpoint.\\n%%time\\nimport time\\nendpoint_name = \\'DEMO-XGBoostEndpoint-\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nprint(endpoint_name)\\ncreate_endpoint_response = sm.create_endpoint(\\n    EndpointName=endpoint_name,\\n    EndpointConfigName=endpoint_config_name)\\nprint(create_endpoint_response[\\'EndpointArn\\'])\\nresp = sm.describe_endpoint(EndpointName=endpoint_name)\\nstatus = resp[\\'EndpointStatus\\']\\nprint(\"Status: \" + status)\\nwhile status==\\'Creating\\':\\n    time.sleep(60)\\n    resp = sm.describe_endpoint(EndpointName=endpoint_name)\\n    status = resp[\\'EndpointStatus\\']\\n    print(\"Status: \" + status)\\nprint(\"Arn: \" + resp[\\'EndpointArn\\'])\\nprint(\"Status: \" + status)', 'resp = sm.describe_endpoint(EndpointName=endpoint_name)\\n    status = resp[\\'EndpointStatus\\']\\n    print(\"Status: \" + status)\\nprint(\"Arn: \" + resp[\\'EndpointArn\\'])\\nprint(\"Status: \" + status)\\nThis code continuously calls the describe_endpoint  command in a while  loop until the endpoint\\neither fails or is in service, and then prints the status of the endpoint. When the status changes to\\nInService , the endpoint is ready to serve inference requests.\\nNext Step\\nStep 7: Validate the Model (p. 30)\\nStep 6.2: Deploy the Model with Batch Transform\\nTo get inference for an entire dataset, use batch transform. Amazon SageMaker stores the results in\\nAmazon S3.\\nFor information about batch transforms, see Get Inferences for an Entire Dataset with Batch', 'Amazon S3.\\nFor information about batch transforms, see Get Inferences for an Entire Dataset with Batch\\nTransform (p. 10). For an example that uses batch transform, see the batch transform sample\\nnotebook at https://github.com/awslabs/amazon-sagemaker-examples/tree/master/\\nsagemaker_batch_transform/introduction_to_batch_transform.\\nTopics\\n•Deploy a Model with Batch Transform (Amazon SageMaker High-level Python Library) (p. 28)\\n•Deploy a Model with Batch Transform (SDK for Python (Boto 3)) (p. 29)\\nDeploy a Model with Batch Transform (Amazon SageMaker\\nHigh-level Python Library)\\nThe following code creates a sagemaker.transformer.Transformer  object from the model\\nthat you trained in Create and Run a Training Job (Amazon SageMaker Python SDK) (p. 22).', \"The following code creates a sagemaker.transformer.Transformer  object from the model\\nthat you trained in Create and Run a Training Job (Amazon SageMaker Python SDK) (p. 22).\\nThen it calls that object's transform  method to create a transform job. When you create the\\nsagemaker.transformer.Transformer  object, you specify the number and type of ML instances\\nto use to perform the batch transform job, and the location in Amazon S3 where you want to store the\\ninferences.\\n28Amazon SageMaker Developer Guide\\nStep 6.2: Batch Transform\\nPaste the following code in a cell in the Jupyter notebook you created in Step 3: Create a Jupyter\\nNotebook  (p. 18) and run the cell.\\nbatch_input =\\n                's3://{}/{}/test/examples'.format(bucket, prefix) # The location of the\\n test dataset\", \"Notebook  (p. 18) and run the cell.\\nbatch_input =\\n                's3://{}/{}/test/examples'.format(bucket, prefix) # The location of the\\n test dataset\\nbatch_output = 's3://{}/{}/batch-inference'.format(bucket, prefix) # The location to store\\n the\\nresults of the batch transform job\\ntransformer = xgb_model.transformer(instance_count=1, instance_type='ml.m4.xlarge',\\n output_path=batch_output)\\ntransformer.transform(data=batch_input, data_type='S3Prefix', content_type='text/csv',\\n split_type='Line')\\ntransformer.wait()\\nFor more information, see https://sagemaker.readthedocs.io/en/stable/transformer.html.\\nNext Step\\nStep 7: Validate the Model (p. 30)\\nDeploy a Model with Batch Transform (SDK for Python (Boto 3))\", 'For more information, see https://sagemaker.readthedocs.io/en/stable/transformer.html.\\nNext Step\\nStep 7: Validate the Model (p. 30)\\nDeploy a Model with Batch Transform (SDK for Python (Boto 3))\\nTo run a batch transform job, call the create_transform_job . method using the model that you\\ntrained in Create and Run a Training Job (AWS SDK for Python (Boto 3)) (p. 23).\\nTo create a batch transform job (SDK for Python (Boto 3))\\nFor each of the following steps, paste the code in a cell in the Jupyter notebook you created in Step 3:\\nCreate a Jupyter Notebook (p. 18) and run the cell.\\n1. Name the batch transform job and specify where the input data (the test dataset) is stored and\\nwhere to store the job\\'s output.\\nbatch_job_name = \\'xgboost-mnist-batch\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())', 'where to store the job\\'s output.\\nbatch_job_name = \\'xgboost-mnist-batch\\' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\\nbatch_input = \\'s3://{}/{}/test/examples\\'.format(bucket, prefix)\\nprint(batch_input)\\nbatch_output = \\'s3://{}/{}/batch-inference\\'.format(bucket, prefix)\\n2. Conﬁgure the parameters that you pass when you call the create_transform_job  method.\\nrequest = \\\\\\n{\\n    \"TransformJobName\": batch_job_name,\\n    \"ModelName\": model_name,\\n    \"BatchStrategy\": \"MultiRecord\",\\n    \"TransformOutput\": {\\n        \"S3OutputPath\": batch_output\\n    },\\n    \"TransformInput\": {\\n        \"DataSource\": {\\n            \"S3DataSource\": {\\n                \"S3DataType\": \"S3Prefix\",\\n                \"S3Uri\": batch_input \\n            }\\n        },\\n29Amazon SageMaker Developer Guide\\nStep 7: Validate the Model', '\"S3DataSource\": {\\n                \"S3DataType\": \"S3Prefix\",\\n                \"S3Uri\": batch_input \\n            }\\n        },\\n29Amazon SageMaker Developer Guide\\nStep 7: Validate the Model\\n        \"ContentType\": \"text/csv\",\\n        \"SplitType\": \"Line\",\\n        \"CompressionType\": \"None\"\\n    },\\n    \"TransformResources\": {\\n            \"InstanceType\": \"ml.m4.xlarge\",\\n            \"InstanceCount\": 1\\n    }\\n}\\nFor more information about the parameters, see the section called “CreateTransformJob” (p. 673).\\n3. Call the create_transform_job  method, passing in the parameters that you conﬁgured in the\\nprevious step. Then call the describe_transform_job  method in a loop until it completes.\\nPaste the following code in a cell in the Jupyter notebook you created in Step 3: Create a Jupyter', 'previous step. Then call the describe_transform_job  method in a loop until it completes.\\nPaste the following code in a cell in the Jupyter notebook you created in Step 3: Create a Jupyter\\nNotebook  (p. 18) and run the cell.\\nsm.create_transform_job(**request)\\n                            \\nwhile(True):\\n    response = sm.describe_transform_job(TransformJobName=batch_job_name)\\n    status = response[\\'TransformJobStatus\\']\\n    if  status == \\'Completed\\':\\n        print(\"Transform job ended with status: \" + status)\\n        break\\n    if status == \\'Failed\\':\\n        message = response[\\'FailureReason\\']\\n        print(\\'Transform failed with the following error: {}\\'.format(message))\\n        raise Exception(\\'Transform job failed\\') \\n    print(\"Transform job is still in status: \" + status)', 'print(\\'Transform failed with the following error: {}\\'.format(message))\\n        raise Exception(\\'Transform job failed\\') \\n    print(\"Transform job is still in status: \" + status)    \\n    time.sleep(30) \\nNext Step\\nStep 7: Validate the Model (p. 30)\\nStep 7: Validate the Model\\nNow that you have trained and deployed a model in Amazon SageMaker, validate it to ensure that it\\ngenerates accurate predictions on new data. That is, on data that is diﬀerent from the data that the\\nmodel was trained on. For this, use the test dataset that you created in Step 4: Download, Explore, and\\nTransform the Training Data (p. 19).\\nTopics\\n•Step 7.1: Validate a Model Deployed to Amazon SageMaker Hosting Services (p. 30)\\n•Step 7.2: Validate a Model Deployed with Batch Transform (p. 33)', 'Transform the Training Data (p. 19).\\nTopics\\n•Step 7.1: Validate a Model Deployed to Amazon SageMaker Hosting Services (p. 30)\\n•Step 7.2: Validate a Model Deployed with Batch Transform (p. 33)\\nStep 7.1: Validate a Model Deployed to Amazon\\nSageMaker Hosting Services\\nIf you deployed a model to Amazon SageMaker hosting services in Step 6.1: Deploy the Model to\\nAmazon SageMaker Hosting Services  (p. 26), you now have an endpoint that you can invoke to get\\ninferences in real time. To validate the model, invoke the endpoint with example images from the test\\ndataset and check whether the inferences you get match the actual labels of the images.\\n30Amazon SageMaker Developer Guide\\nStep 7.1: Validate a Model Deployed to\\nAmazon SageMaker Hosting Services\\nTopics', '30Amazon SageMaker Developer Guide\\nStep 7.1: Validate a Model Deployed to\\nAmazon SageMaker Hosting Services\\nTopics\\n•Validate a Model Deployed to Amazon SageMaker Hosting Services (Amazon SageMaker Python\\nSDK)  (p. 31)\\n•Validate a Model Deployed to Amazon SageMaker Hosting Services (AWS SDK for Python (Boto\\n3)) (p. 32)\\nValidate a Model Deployed to Amazon SageMaker Hosting\\nServices (Amazon SageMaker Python SDK)\\nTo validate the model by using the Amazon SageMaker Python SDK, use the\\nsagemaker.predictor.RealTimePredictor  object that you created in Deploy the Model to Amazon\\nSageMaker Hosting Services (Amazon SageMaker Python SDK) (p. 26). For information, see https://\\nsagemaker.readthedocs.io/en/stable/predictors.html#sagemaker.predictor.RealTimePredictor.', 'SageMaker Hosting Services (Amazon SageMaker Python SDK) (p. 26). For information, see https://\\nsagemaker.readthedocs.io/en/stable/predictors.html#sagemaker.predictor.RealTimePredictor.\\nTo validate the model (Amazon SageMaker Python SDK)\\n1. Download the test data from Amazon S3.\\ns3 = boto3.resource(\\'s3\\')\\ntest_key = \"{}/test/examples\".format(prefix)\\ns3.Bucket(bucket).download_file(test_key, \\'test_data\\')\\n2. Plot the ﬁrst 10 images from the test dataset with their labels.\\n%matplotlib inline\\n                        \\nfor i in range (0, 10):\\n    img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')\\n    print(\\'This is a {}\\'.format(label))\\n    plt.show()', \"img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap='gray')\\n    print('This is a {}'.format(label))\\n    plt.show()\\n3. To get inferences for the ﬁrst 10 examples in the test dataset, call the predict  method of the\\nsagemaker.predictor.RealTimePredictor  object.\\n31Amazon SageMaker Developer Guide\\nStep 7.1: Validate a Model Deployed to\\nAmazon SageMaker Hosting Services\\nwith open('test_data', 'r') as f:\\n    for j in range(0,10):\\n        single_test = f.readline()\\n        result = xgb_predictor.predict(single_test)\\n        print(result)\\nTo see if the model is making accurate predictions, check the output from this step against the\\nnumbers that you plotted in the previous step.\", 'print(result)\\nTo see if the model is making accurate predictions, check the output from this step against the\\nnumbers that you plotted in the previous step.\\nYou have now trained, deployed, and validated your ﬁrst model in Amazon SageMaker.\\nNext Step\\nStep 8: Clean Up  (p. 35)\\nValidate a Model Deployed to Amazon SageMaker Hosting\\nServices (AWS SDK for Python (Boto 3))\\nTo use the AWS SDK for Python (Boto 3) to validate the model, call the invoke_endpoint  method. This\\nmethod corresponds to the InvokeEndpoint (p. 853) API provided by the Amazon SageMaker runtime.\\nTo validate the model (AWS SDK for Python (Boto 3))\\n1. Download the test data from Amazon S3.\\ns3 = boto3.resource(\\'s3\\')\\ntest_key = \"{}/test/examples\".format(prefix)\\ns3.Bucket(bucket).download_file(test_key, \\'test_data\\')', '1. Download the test data from Amazon S3.\\ns3 = boto3.resource(\\'s3\\')\\ntest_key = \"{}/test/examples\".format(prefix)\\ns3.Bucket(bucket).download_file(test_key, \\'test_data\\')\\n2. Plot the ﬁrst 10 images from the test dataset with their labels.\\n%matplotlib inline\\n                        \\nfor i in range (0, 10):\\n    img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')\\n    print(\\'This is a {}\\'.format(label))\\n    plt.show()\\n32Amazon SageMaker Developer Guide\\nStep 7.2: Validate a Model Deployed with Batch Transform\\n3. Get the Amazon SageMaker runtime client, which provides the invoke_endpoint  method.\\nruntime_client = boto3.client(\\'runtime.sagemaker\\')', \"Step 7.2: Validate a Model Deployed with Batch Transform\\n3. Get the Amazon SageMaker runtime client, which provides the invoke_endpoint  method.\\nruntime_client = boto3.client('runtime.sagemaker')\\n4. Get inferences from the ﬁrst 10 examples in the test dataset by calling invoke_endpoint .\\nwith open('test_data', 'r') as f:\\n    \\n    for i in range(0,10):\\n        single_test = f.readline()\\n        response = runtime_client.invoke_endpoint(EndpointName = endpoint_name,\\n                                         ContentType = 'text/csv',\\n                                         Body = single_test)\\n        result = response['Body'].read().decode('ascii')\\n        print('Predicted label is {}.'.format(result))\", \"Body = single_test)\\n        result = response['Body'].read().decode('ascii')\\n        print('Predicted label is {}.'.format(result))\\n5. To see if the model is making accurate predictions, check the output from this step against the\\nnumbers you plotted in the previous step.\\nYou have now trained, deployed, and validated your ﬁrst model in Amazon SageMaker.\\nNext Step\\nStep 8: Clean Up  (p. 35)\\nStep 7.2: Validate a Model Deployed with Batch\\nTransform\\nYou now have a ﬁle in Amazon S3 that contains inferences that you got by running a batch transform job\\nin Step 6.2: Deploy the Model with Batch Transform (p. 28). To validate the model, check a subset of\\nthe inferences from the ﬁle to see whether they match the actual numbers from the test dataset.\", 'in Step 6.2: Deploy the Model with Batch Transform (p. 28). To validate the model, check a subset of\\nthe inferences from the ﬁle to see whether they match the actual numbers from the test dataset.\\nTo validate the batch transform inferences\\n1. Download the test data from Amazon S3.\\ns3 = boto3.resource(\\'s3\\')\\n33Amazon SageMaker Developer Guide\\nStep 7.2: Validate a Model Deployed with Batch Transform\\ntest_key = \"{}/test/examples\".format(prefix)\\ns3.Bucket(bucket).download_file(test_key, \\'test_data\\')\\n2. Plot the ﬁrst 10 images from the test dataset with their labels.\\n%matplotlib inline\\n                    \\nfor i in range (0, 10):\\n    img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap=\\'gray\\')', \"for i in range (0, 10):\\n    img = test_set[0][i]\\n    label = test_set[1][i]\\n    img_reshape = img.reshape((28,28))\\n    imgplot = plt.imshow(img_reshape, cmap='gray')\\n    print('This is a {}'.format(label))\\n    plt.show()\\n3. Download the output from the batch transform job from Amazon S3 to a local ﬁle.\\ns3.Bucket(bucket).download_file(prefix + '/batch-inference/examples.out', \\n 'batch_results')\\n4. Get the ﬁrst 10 results from the batch transform job.\\nwith open('batch_results') as f:\\n    results = f.readlines()\\nfor j in range (0, 10):\\n    print(results[j])\\n5. To see if the batch transform job made accurate predictions, check the output from this step against\\nthe numbers that you plotted from the test data.\", 'for j in range (0, 10):\\n    print(results[j])\\n5. To see if the batch transform job made accurate predictions, check the output from this step against\\nthe numbers that you plotted from the test data.\\nYou have now trained, deployed, and validated your ﬁrst model in Amazon SageMaker.\\nNext Step\\nStep 8: Clean Up  (p. 35)\\n34Amazon SageMaker Developer Guide\\nStep 8: Clean Up\\nStep 8: Clean Up\\nTo avoid incurring unnecessary charges, use the AWS Management Console to delete the resources that\\nyou created for this exercise.\\nNote\\nIf you plan to explore other exercises in this guide, you might want to keep some of these\\nresources, such as your notebook instance, S3 bucket, and IAM role.\\n1.Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/ and delete the\\nfollowing resources:', 'resources, such as your notebook instance, S3 bucket, and IAM role.\\n1.Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/ and delete the\\nfollowing resources:\\n•The endpoint. Deleting the endpoint also deletes the ML compute instance or instances that\\nsupport it.\\n•The endpoint conﬁguration.\\n•The model.\\n•The notebook instance. Before deleting the notebook instance, stop it.\\n2.Open the Amazon S3 console at https://console.aws.amazon.com/s3/ and delete the bucket that you\\ncreated for storing model artifacts and the training dataset.\\n3.Open the IAM console at https://console.aws.amazon.com/iam/ and delete the IAM role. If you\\ncreated permission policies, you can delete them, too.', '3.Open the IAM console at https://console.aws.amazon.com/iam/ and delete the IAM role. If you\\ncreated permission policies, you can delete them, too.\\n4.Open the Amazon CloudWatch console at https://console.aws.amazon.com/cloudwatch/ and delete\\nall of the log groups that have names starting with /aws/sagemaker/ .\\nStep 9: Integrating Amazon SageMaker Endpoints\\ninto Internet-facing Applications\\nIn a production environment, you might have an internet-facing application sending requests to the\\nendpoint for inference. The following high-level example shows how to integrate your model endpoint\\ninto your application.\\n1. Create an IAM role that the AWS Lambda service principal can assume. Give the role permissions to\\ncall the Amazon SageMaker InvokeEndpoint  API.', 'into your application.\\n1. Create an IAM role that the AWS Lambda service principal can assume. Give the role permissions to\\ncall the Amazon SageMaker InvokeEndpoint  API.\\n2. Create a Lambda function that calls the Amazon SageMaker InvokeEndpoint  API.\\n3. Call the Lambda function from a mobile application. For an example of how to call a Lambda\\nfunction from a mobile application using Amazon Cognito for credentials, see Tutorial: Using AWS\\nLambda as Mobile Application Backend.\\n35Amazon SageMaker Developer Guide\\nCreate a Notebook Instance\\nUse Notebook Instances\\nAn Amazon SageMaker notebook instance  is a fully managed ML compute instance running the Jupyter\\nNotebook App. Amazon SageMaker manages creating the instance and related resources. Use Jupyter', 'An Amazon SageMaker notebook instance  is a fully managed ML compute instance running the Jupyter\\nNotebook App. Amazon SageMaker manages creating the instance and related resources. Use Jupyter\\nnotebooks in your notebook instance to prepare and process data, write code to train models, deploy\\nmodels to Amazon SageMaker hosting, and test or validate your models.\\nTopics\\n•Create a Notebook Instance (p. 36)\\n•Access Notebook Instances  (p. 39)\\n•Customize a Notebook Instance  (p. 40)\\n•Use Example Notebooks  (p. 42)\\n•Notebook Instance Software Updates (p. 44)\\n•Set the Notebook Kernel (p. 44)\\n•Install External Libraries and Kernels in Notebook Instances (p. 45)\\n•Associate Git Repositories with Amazon SageMaker Notebook Instances (p. 46)\\n•Get Notebook Instance Metadata (p. 54)', '•Install External Libraries and Kernels in Notebook Instances (p. 45)\\n•Associate Git Repositories with Amazon SageMaker Notebook Instances (p. 46)\\n•Get Notebook Instance Metadata (p. 54)\\n•Monitor Jupyter Logs in Amazon CloudWatch Logs (p. 54)\\nCreate a Notebook Instance\\nTo create a notebook instance, use either the Amazon SageMaker console or the\\nCreateNotebookInstance (p. 656) API.\\nAfter receiving the request, Amazon SageMaker does the following:\\n•Creates a network interface—If you choose the optional VPC conﬁguration, it creates the network\\ninterface in your VPC. It uses the subnet ID that you provide in the request to determine which\\nAvailability Zone to create the subnet in. Amazon SageMaker associates the security group that you', 'interface in your VPC. It uses the subnet ID that you provide in the request to determine which\\nAvailability Zone to create the subnet in. Amazon SageMaker associates the security group that you\\nprovide in the request with the subnet. For more information, see Connect a Notebook Instance to\\nResources in a VPC (p. 516).\\n•Launches an ML compute instance—Amazon SageMaker launches an ML compute instance in an\\nAmazon SageMaker VPC. Amazon SageMaker performs the conﬁguration tasks that allow it to manage\\nyour notebook instance, and if you speciﬁed your VPC, it enables traﬃc between your VPC and the\\nnotebook instance.\\n•Installs Anaconda packages and libraries for common deep learning platforms—Amazon\\nSageMaker installs all of the Anaconda packages that are included in the installer. For more', \"notebook instance.\\n•Installs Anaconda packages and libraries for common deep learning platforms—Amazon\\nSageMaker installs all of the Anaconda packages that are included in the installer. For more\\ninformation, see Anaconda package list. In addition, Amazon SageMaker installs the TensorFlow and\\nApache MXNet deep learning libraries.\\n•Attaches an ML storage volume—Amazon SageMaker attaches an ML storage volume to the ML\\ncompute instance. You can use the volume to clean up the training dataset or to temporarily store\\nother data to work with. Choose any size between 5 GB and 16384 GB, in 1 GB increments, for\\nthe volume. The default is 5 GB. ML storage volumes are encrypted, so Amazon SageMaker can't\\ndetermine the amount of available free space on the volume. Because of this, you can increase the\", \"the volume. The default is 5 GB. ML storage volumes are encrypted, so Amazon SageMaker can't\\ndetermine the amount of available free space on the volume. Because of this, you can increase the\\nvolume size when you update a notebook instance, but you can't decrease the volume size. If you want\\nto decrease the size of the ML storage volume in use, create a new notebook instance with the desired\\nsize.\\n36Amazon SageMaker Developer Guide\\nCreate a Notebook Instance\\nImportant\\nOnly ﬁles and data saved within the /home/ec2-user/SageMaker  folder persist between\\nnotebook instance sessions. Files and data that are saved outside this directory are\\noverwritten when the notebook instance stops and restarts.\\nNote\\nEach notebook instance's /tmp directory provides a minimum of 10 GB of storage in an\", \"overwritten when the notebook instance stops and restarts.\\nNote\\nEach notebook instance's /tmp directory provides a minimum of 10 GB of storage in an\\ninstant store. An instance store is temporary, block-level storage that isn't persistent. When\\nthe instance is stopped or restarted, Amazon SageMaker deletes the directory's contents. This\\ntemporary storage is part of the root volume of the notebook instance.\\n•Copies example Jupyter notebooks— These Python code examples illustrate model training and\\nhosting exercises using various algorithms and training datasets.\\nTo create a notebook instance:\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances, then choose Create notebook instance.\", 'To create a notebook instance:\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances, then choose Create notebook instance.\\n3. On the Create notebook instance page, provide the following information:\\na. For Notebook instance name, type a name for your notebook instance.\\nb. For Instance type, choose an instance type for your notebook instance. For a list of supported\\ninstance types, see Amazon SageMaker Limits.\\nc. For Elastic Inference, choose an inference accelerator type to associate with the notebook\\ninstance, or choose none . For information about elastic inference, see Amazon SageMaker\\nElastic Inference (EI)  (p. 355).\\nd. For IAM role, choose either an existing IAM role in your account that has the necessary', \"Elastic Inference (EI)  (p. 355).\\nd. For IAM role, choose either an existing IAM role in your account that has the necessary\\npermissions to access Amazon SageMaker resources or Create a new role. If you choose Create\\na new role, for Create an IAM role:\\ni. If you want to use S3 buckets other than the one you created in Step 1: Create an Amazon\\nS3 Bucket (p. 17) to store your input data and output, choose them.\\nThe IAM role automatically has permissions to use any bucket that has sagemaker  as\\npart of its name. The AmazonSageMakerFullAccess  policy, which Amazon SageMaker\\nattaches to the role, gives the role those permissions.\\nTo give access to other S3 buckets from your notebook instance\\n•If you're not concerned about users in your AWS account accessing your data, choose Any\\nS3 bucket.\", \"To give access to other S3 buckets from your notebook instance\\n•If you're not concerned about users in your AWS account accessing your data, choose Any\\nS3 bucket.\\n•If your account has sensitive data (such as Human Resources information), restrict access\\nto certain buckets by choosing Speciﬁc S3 buckets. You can update the permissions\\npolicy attached to the role you are creating later.\\n•To explicitly control access, restrict access by choosing None . Use bucket and object\\nnames and tags as supported by the AmazonSageMakerFullAccess  policy. For more\\ninformation, see AmazonSageMakerFullAccess Policy (p. 506).\\nii. Choose Create role.\\nAmazon SageMaker creates an IAM role named AmazonSageMaker-\\nExecutionRole- YYYYMMDD THHmmSS. For example, AmazonSageMaker-\\nExecutionRole-20171125T090800 .\", 'ii. Choose Create role.\\nAmazon SageMaker creates an IAM role named AmazonSageMaker-\\nExecutionRole- YYYYMMDD THHmmSS. For example, AmazonSageMaker-\\nExecutionRole-20171125T090800 .\\nTo see the policies that are attached to the role, use the IAM console.\\nOpen the IAM console at https://console.aws.amazon.com/iam/.\\n37Amazon SageMaker Developer Guide\\nCreate a Notebook Instance\\nYou can see that the following policies are attached to the role:\\n•A trust policy that allows Amazon SageMaker to assume the role.\\n•The AmazonSageMakerFullAccess  AWS managed policy.\\n•If you gave access to additional S3 bucket(s) when creating this role, the customer\\nmanaged policy attached to the role. The name of the customer managed policy is\\nAmazonSageMaker-ExecutionPolicy- YYYYMMDD THHmmSS .', 'managed policy attached to the role. The name of the customer managed policy is\\nAmazonSageMaker-ExecutionPolicy- YYYYMMDD THHmmSS .\\nFor more information about creating your own IAM role, see Amazon SageMaker Roles\\n (p. 496).\\ne. For Root access, to enable root access for all notebook instance users,choose Enabled. To\\ndisable root access for users, choose Disabled.If you enable root access, all notebook instance\\nusers have administrator privileges and can access and edit all ﬁles on it.\\nNote\\nIf you disable root access, you will still be able to set up lifecycle conﬁgurations, as\\ndescribed later in this procedure.\\nf.(Optional) Allow access to resources in your Virtual Private Cloud (VPC).\\nTo access resources in your VPC from the notebook instance\\ni. Choose the VPC and a SubnetId .', \"f.(Optional) Allow access to resources in your Virtual Private Cloud (VPC).\\nTo access resources in your VPC from the notebook instance\\ni. Choose the VPC and a SubnetId .\\nii. For Security Group, choose your VPC's default security group. For this exercise and others\\nin this guide) the inbound and outbound rules of the default security group are suﬃcient.\\niii. To allow connecting to a resource in your VPC, ensure that the resource resolves to a private\\nIP address in your VPC. For example, to ensure that an Amazon Redshift DNS name resolves\\nto a private IP address, do one of the following:\\n•Ensure that the Amazon Redshift cluster is not publicly accessible.\\n•If the Amazon Redshift cluster is publicly accessible, set the DNS resolution  and DNS\", \"•Ensure that the Amazon Redshift cluster is not publicly accessible.\\n•If the Amazon Redshift cluster is publicly accessible, set the DNS resolution  and DNS\\nhostnames  VPC parameters to true. For more information, see Managing Clusters in an\\nAmazon Virtual Private Cloud (VPC)\\niv.By default, a notebook instance can't connect to on-premises resources or to a peer\\nVPC. You can create a lifecycle conﬁguration that creates an entry in your route table\\nthat enables connection to on-premises resources or to a peer VPC. For information, see\\nUnderstanding Amazon SageMaker notebook instance networking conﬁgurations and\\nadvanced routing options.\\ng. If you allowed access to resources from your VPC, enable direct internet access. For Direct\", \"Understanding Amazon SageMaker notebook instance networking conﬁgurations and\\nadvanced routing options.\\ng. If you allowed access to resources from your VPC, enable direct internet access. For Direct\\ninternet access, choose Enable. Without internet access, you can't train or host models from\\nnotebooks on this notebook instance unless your VPC has a NAT gateway and your security\\ngroup allows outbound connections. For more information, see Connect a Notebook Instance to\\nResources in a VPC (p. 516).\\nh. (Optional) To use shell scripts that run when you create or start the instance, specify a lifecycle\\nconﬁguration. For information, see Customize a Notebook Instance  (p. 40)\\ni. (Optional) If you want Amazon SageMaker to use an AWS Key Management Service (AWS KMS)\", 'conﬁguration. For information, see Customize a Notebook Instance  (p. 40)\\ni. (Optional) If you want Amazon SageMaker to use an AWS Key Management Service (AWS KMS)\\nkey to encrypt data in the ML storage volume attached to the notebook instance, specify the\\nkey.\\nj. Specify the size, in GB, of the ML storage volume that is attached to the notebook instance. You\\ncan choose a size between 5 GB and 16,384 GB, in 1 GB increments. You can use the volume to\\nclean up the training dataset when you no longer need it or to temporarily store other data to\\nwork with.\\n38Amazon SageMaker Developer Guide\\nAccess Notebook Instances \\nk. (Optional) To associate Git repositories with the notebook instance, choose a default repository', 'work with.\\n38Amazon SageMaker Developer Guide\\nAccess Notebook Instances \\nk. (Optional) To associate Git repositories with the notebook instance, choose a default repository\\nand up to three additional repositories. For more information, see Associate Git Repositories\\nwith Amazon SageMaker Notebook Instances (p. 46).\\nl. Choose Create notebook instance.\\nIn a few minutes, Amazon SageMaker launches an ML compute instance—in this case, a\\nnotebook instance—and attaches an ML storage volume to it. The notebook instance has a\\npreconﬁgured Jupyter notebook server and a set of Anaconda libraries. For more information,\\nsee the CreateNotebookInstance (p. 656) API.\\n4. When the status of the notebook instance is InService , choose Open Jupyter next to its name to', 'see the CreateNotebookInstance (p. 656) API.\\n4. When the status of the notebook instance is InService , choose Open Jupyter next to its name to\\nopen the classic Jupyter dashboard, or choose Open JupyterLab to open the JupyterLab dashboard.\\nFor more information, see Access Notebook Instances  (p. 39).\\nThe dashboard provides access to:\\n•Sample notebooks. Amazon SageMaker provides sample notebooks that contain complete code\\nwalkthroughs. These walkthroughs show how to use Amazon SageMaker to perform common\\nmachine learning tasks. For more information, see Use Example Notebooks  (p. 42).\\n•The kernels for Jupyter, including those that provide support for Python 2 and 3, Apache MXNet,\\nTensorFlow, PySpark, and R. To create a new notebook and choose a kernel for that notebook, use\\nthe New  menu.', 'TensorFlow, PySpark, and R. To create a new notebook and choose a kernel for that notebook, use\\nthe New  menu.\\nFor more information about Jupyter notebooks, see The Jupyter notebook.\\nAccess Notebook Instances\\nTo access your Amazon SageMaker notebook instances, choose one of the following options:\\n•Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\nChoose Notebook instances. The console displays a list of notebook instances in your account. To\\nopen a notebook instance with a standard Jupyter interface, choose Open Jupyter for that instance.\\nTo open a notebook instance with a JupyterLab interface, choose Open JupyterLab for that instance.\\nThe console uses your sign-in credentials to send a CreatePresignedNotebookInstanceUrl (p. 665) API', 'To open a notebook instance with a JupyterLab interface, choose Open JupyterLab for that instance.\\nThe console uses your sign-in credentials to send a CreatePresignedNotebookInstanceUrl (p. 665) API\\nrequest to Amazon SageMaker. Amazon SageMaker returns the URL for your notebook instance, and\\nthe console opens the URL in another browser tab and displays the Jupyter notebook dashboard.\\nNote\\nThe URL that you get from a call to CreatePresignedNotebookInstanceUrl (p. 665) is valid\\nonly for 5 minutes. If you try to use the URL after the 5-minute limit expires, you are directed\\nto the AWS Management Console sign-in page.\\n•Use the API.\\nTo get the URL for the notebook instance, call the CreatePresignedNotebookInstanceUrl (p. 665) API', 'to the AWS Management Console sign-in page.\\n•Use the API.\\nTo get the URL for the notebook instance, call the CreatePresignedNotebookInstanceUrl (p. 665) API\\nand use the URL that the API returns to open the notebook instance.\\n39Amazon SageMaker Developer Guide\\nControl Root Access to a Notebook Instance\\nUse the Jupyter notebook dashboard to create and manage notebooks and to write code. For more\\ninformation about Jupyter notebooks, see http://jupyter.org/documentation.html.\\nControl Root Access to a Notebook Instance\\nBy default, when you create a notebook instance, users that log into that notebook instance have root\\naccess. Data science is an iterative process that might require the data scientist to test and use diﬀerent', \"access. Data science is an iterative process that might require the data scientist to test and use diﬀerent\\nsoftware tools and packages, so many notebook instance users need to have root access to be able to\\ninstall these tools and packages. Because users with root access have administrator privileges, users can\\naccess and edit all ﬁles on a notebook instance with root access enabled.\\nIf you don't want users to have root access to a notebook instance, when you call\\nCreateNotebookInstance (p. 656) or UpdateNotebookInstance (p. 844) operations, set the\\nRootAccess  ﬁeld to Disabled . You can also disable root access for users when you create or update\\na notebook instance in the Amazon SageMaker console. For information, see Step 2: Create an Amazon\\nSageMaker Notebook Instance (p. 17).\\nNote\", 'a notebook instance in the Amazon SageMaker console. For information, see Step 2: Create an Amazon\\nSageMaker Notebook Instance (p. 17).\\nNote\\nLifecycle conﬁgurations need root access to be able to set up a notebook instance. Because of\\nthis, lifecycle conﬁgurations associated with a notebook instance always run with root access\\neven if you disable root access for users.\\nCustomize a Notebook Instance\\nTo install packages or sample notebooks on your notebook instance, conﬁgure networking and security\\nfor it, or otherwise use a shell script to customize it, use a lifecycle conﬁguration. A lifecycle conﬁguration\\nprovides shell scripts that run only when you create the notebook instance or whenever you start one.', 'provides shell scripts that run only when you create the notebook instance or whenever you start one.\\nWhen you create a notebook instance, you can create a new lifecycle conﬁguration and the scripts it uses\\nor apply one that you already have.\\nThe Amazon SageMaker team maintains a public repository of notebook intance lifecycle conﬁgurations\\nthat address common use cases for customizing notebook instances at https://github.com/aws-samples/\\namazon-sagemaker-notebook-instance-lifecycle-conﬁguration-samples.\\nNote\\nEach script has a limit of 16384 characters.\\nThe value of the $PATH environment variable that is available to both scripts is /usr/local/\\nsbin:/usr/local/bin:/usr/bin:/usr/sbin:/sbin:/bin . The working directory, which\\nis the value of the $PWD environment variable, is /.', 'sbin:/usr/local/bin:/usr/bin:/usr/sbin:/sbin:/bin . The working directory, which\\nis the value of the $PWD environment variable, is /.\\nView CloudWatch Logs for notebook instance lifecycle conﬁgurations in log group /\\naws/sagemaker/NotebookInstances  in log stream [notebook-instance-name]/\\n[LifecycleConfigHook] .\\nScripts cannot run for longer than 5 minutes. If a script runs for longer than 5 minutes, it fails\\nand the notebook instance is not created or started. To help decrease the run time of scripts, try\\nthe following:\\n•Cut down on necessary steps. For example, limit which conda environments in which to install\\nlarge packages.\\n•Run tasks in parallel processes.\\n•Use the nohup command in your script.\\nTo create a lifecycle conﬁguration', 'large packages.\\n•Run tasks in parallel processes.\\n•Use the nohup command in your script.\\nTo create a lifecycle conﬁguration\\n1. For Lifecycle conﬁguration - Optional , choose Create a new lifecycle conﬁguration.\\n40Amazon SageMaker Developer Guide\\nLifecycle Conﬁguration Best Practices\\n2. For Name , type a name.\\n3. (Optional) To create a script that runs when you create the notebook and every time you start it,\\nchoose Start notebook.\\n4. In the Start notebook editor, type the script.\\n5. (Optional) To create a script that runs only once, when you create the notebook, choose Create\\nnotebook .\\n6. In the Create notebook  editor, type the script conﬁgure networking.\\n7. Choose Create conﬁguration.\\nYou can see a list of notebook instance lifecycle conﬁgurations you previously created by choosing', '7. Choose Create conﬁguration.\\nYou can see a list of notebook instance lifecycle conﬁgurations you previously created by choosing\\nLifecycle conﬁguration in the Amazon SageMaker console. From there, you can view, edit, delete\\nexisting lifecycle conﬁgurations. You can create a new notebook instance lifecycle conﬁguration by\\nchoosing Create conﬁguration. These notebook instance lifecycle conﬁgurations are available when you\\ncreate a new notebook instance.\\nLifecycle Conﬁguration Best Practices\\nThe following are best practices for using lifecycle conﬁgurations:\\n•Lifecycle conﬁgurations run as the root user. If your script makes any changes within the /home/ec2-\\nuser/SageMaker  directory, (for example, installing a package with pip), use the command sudo -u', '•Lifecycle conﬁgurations run as the root user. If your script makes any changes within the /home/ec2-\\nuser/SageMaker  directory, (for example, installing a package with pip), use the command sudo -u\\nec2-user  command to run as the ec2-user  user. This is the same user that Amazon SageMaker runs\\nas.\\n•Amazon SageMaker notebook instances use conda environments to implement diﬀerent kernels for\\nJupyter notebooks. If you want to install packages that are available to one or more notebook kernels,\\nenclose the commands to install the packages with conda environment commands that activate the\\nconda environment that contains the kernel where you want to install the packages.\\nFor example, if you want to install a package only in for the python3 environment, use the following\\ncode:\\n#!/bin/bash', 'For example, if you want to install a package only in for the python3 environment, use the following\\ncode:\\n#!/bin/bash\\nsudo -u ec2-user -i <<\\'EOF\\'\\n# This will affect only the Jupyter kernel called \"conda_python3\".\\nsource activate python3\\n# Replace myPackage  with the name of the package you want to install.\\npip install myPackage\\n# You can also perform \"conda install\" here as well.\\nsource deactivate\\nEOF\\nIf you want to install a package in all conda environments in the notebook instance, use the following\\ncode:\\n#!/bin/bash\\nsudo -u ec2-user -i <<\\'EOF\\'\\n# Note that \"base\" is special environment name, include it there as well.\\nfor env in base /home/ec2-user/anaconda3/envs/*; do\\n    source /home/ec2-user/anaconda3/bin/activate $(basename \"$env\")', '# Note that \"base\" is special environment name, include it there as well.\\nfor env in base /home/ec2-user/anaconda3/envs/*; do\\n    source /home/ec2-user/anaconda3/bin/activate $(basename \"$env\")\\n    # Installing packages in the Jupyter system environment can affect stability of your\\n SageMaker\\n41Amazon SageMaker Developer Guide\\nUse Example Notebooks\\n    # Notebook Instance.  You can remove this check if you\\'d like to install Jupyter\\n extensions, etc.\\n    if [ $env = \\'JupyterSystemEnv\\' ]; then\\n      continue\\n    fi\\n    # Replace myPackage  with the name of the package you want to install.\\n    pip install --upgrade --quiet myPackage\\n    # You can also perform \"conda install\" here as well.\\n    source /home/ec2-user/anaconda3/bin/deactivate\\ndone\\nEOF\\nImportant', 'pip install --upgrade --quiet myPackage\\n    # You can also perform \"conda install\" here as well.\\n    source /home/ec2-user/anaconda3/bin/deactivate\\ndone\\nEOF\\nImportant\\nWhen you create or change a script ﬁle, we recommend you use Create notebook  editor or\\na text editor that allows for Unix style line breaks. Copying text from a non Linux operating\\nsystem might include incompatible line breaks and result in an unexpected error.\\nUse Example Notebooks\\nYour notebook instance contains example notebooks provided by Amazon SageMaker. The example\\nnotebooks contain code that shows how to apply machine learning solutions by using Amazon\\nSageMaker. Notebook instances use the nbexamples  Jupyter extension, which enables you to view a', 'notebooks contain code that shows how to apply machine learning solutions by using Amazon\\nSageMaker. Notebook instances use the nbexamples  Jupyter extension, which enables you to view a\\nread-only version of an example notebook or create a copy of it so that you can modify and run it. For\\nmore information about the nbexamples  extension, see https://github.com/danielballan/nbexamples.\\nNote\\nExample notebooks typically download datasets from the internet. If you disable Amazon\\nSageMaker-provided internet access when you create you notebook instance, example\\nnotebooks might not work. For more information, see Connect a Notebook Instance to\\nResources in a VPC (p. 516).\\nUse or View Example Notebooks in Jupyter Classic', \"notebooks might not work. For more information, see Connect a Notebook Instance to\\nResources in a VPC (p. 516).\\nUse or View Example Notebooks in Jupyter Classic\\nTo view or use the example notebooks in the classic Jupyter view, choose the SageMaker Examples tab.\\nTo view a read-only version of an example notebook in the Jupyter classic view, on the SageMaker\\nExamples tab, choose Preview  for that notebook. To create a copy of an example notebook in the home\\ndirectory of your notebook instance, choose Use. In the dialog box, you can change the notebook's name\\nbefore saving it.\\n42Amazon SageMaker Developer Guide\\nUse or View Example Notebooks in Jupyterlab\\nUse or View Example Notebooks in Jupyterlab\", 'before saving it.\\n42Amazon SageMaker Developer Guide\\nUse or View Example Notebooks in Jupyterlab\\nUse or View Example Notebooks in Jupyterlab\\nTo view or use the example notebooks in the Jupyterlab view, choose the examples icon in the left\\nnavigation panel.\\n43Amazon SageMaker Developer Guide\\nNotebook Instance Software Updates\\nTo view a read-only version of an example notebook, choose the name of the notebook. This opens the\\nnotebook as a tab in the main area. To create a copy of an example notebook in the home directory of\\nyour notebook instance, choose Create a Copy in the top banner. In the dialog box, type a name for the\\nnotebook and then choose CREATE COPY.\\nFor more information about the example notebooks, see the Amazon SageMaker examples GitHub\\nrepository.', 'notebook and then choose CREATE COPY.\\nFor more information about the example notebooks, see the Amazon SageMaker examples GitHub\\nrepository.\\nNotebook Instance Software Updates\\nAmazon SageMaker periodically tests and releases software that is installed on notebook instances. This\\nincludes:\\n•Kernel updates\\n•Security patches\\n•AWS SDK updates\\n•Amazon SageMaker Python SDK updates\\n•Open source software updates\\nAmazon SageMaker does not automatically update software on a notebook instance when it is in service.\\nTo ensure that you have the most recent software updates, stop and restart your notebook instance,\\neither in the Amazon SageMaker console or by calling StopNotebookInstance (p. 832) followd by\\nStartNotebookInstance (p. 824).', 'either in the Amazon SageMaker console or by calling StopNotebookInstance (p. 832) followd by\\nStartNotebookInstance (p. 824).\\nYou can also manually update software installed on your notebook instance while it is running by using\\nupdate commands in a terminal or in a notebook.\\nNote\\nUpdating kernels and some packages might depend on whether root access is enabled\\nfor the notebook instance. For more information, see Control Root Access to a Notebook\\nInstance (p. 40).\\nNotebook instances do not notify you if you are running outdated software. You can check the Personal\\nHealth Dashboard or the security bulletin at https://aws.amazon.com/security/security-bulletins/  for\\nupdates.\\nSet the Notebook Kernel', 'Health Dashboard or the security bulletin at https://aws.amazon.com/security/security-bulletins/  for\\nupdates.\\nSet the Notebook Kernel\\nAmazon SageMaker provides several kernels for Jupyter that provide support for Python 2 and 3, Apache\\nMXNet, TensorFlow, and PySpark. To set a kernel for a new notebook in the Jupyter notebook dashboard,\\nchoose New , and then choose the kernel from the list.\\n44Amazon SageMaker Developer Guide\\nInstall External Libraries and Kernels in Notebook Instances\\nInstall External Libraries and Kernels in Notebook\\nInstances\\nAmazon SageMaker notebook instances come with multiple environments already installed. These\\nenvironments contain Jupyter kernels and Python packages including: scikit, Pandas, NumPy,', 'Instances\\nAmazon SageMaker notebook instances come with multiple environments already installed. These\\nenvironments contain Jupyter kernels and Python packages including: scikit, Pandas, NumPy,\\nTensorFlow, and MXNet. These environments, along with all ﬁles in the sample-notebooks  folder, are\\nrefreshed when you stop and start a notebook instance. You can also install your own environments\\nthat contain your choice of packages and kernels. This is typically done using conda install  or pip\\ninstall .\\nThe diﬀerent Jupyter kernels in Amazon SageMaker notebook instances are separate conda\\nenvironments. For information about conda environments, see Managing environments in the Conda\\ndocumentation. If you want to use an external library in a speciﬁc kernel, install the library in the', 'environments. For information about conda environments, see Managing environments in the Conda\\ndocumentation. If you want to use an external library in a speciﬁc kernel, install the library in the\\nenvironment for that kernel. You can do this either in the terminal or in a notebook cell. The following\\nprocedures show how to install Theano so that you can use it in a notebook with a conda_mxnet_p36\\nkernel.\\nTo install Theano from a terminal\\n1. Open a notebook instance.\\n2. In the Jupyter dashboard, choose New , and then choose Terminal.\\n3. In the terminal, type the following commands:\\nconda install -n mxnet_p36 -c conda-forge theano\\n   python\\n   import theano\\nTo install Theano from a Jupyter notebook cell\\n1. Open a notebook instance.', '3. In the terminal, type the following commands:\\nconda install -n mxnet_p36 -c conda-forge theano\\n   python\\n   import theano\\nTo install Theano from a Jupyter notebook cell\\n1. Open a notebook instance.\\n2. In the Jupyter dashboard, choose New , and then choose conda_mxnet_p36.\\n3. In a cell in the new notebook, type the following command:\\n!pip install theano\\nMaintain a Sandboxed Python Environment\\nAmazon SageMaker periodically updates the Python and dependency versions in the environments\\ninstalled on a notebook instance when it is stopped and restarted. For more information, see Notebook\\nInstance Software Updates (p. 44). To maintain an isolated Python environment that does not change\\nversions, create a lifecycle conﬁguration that runs each time you start your notebook instance. For', 'Instance Software Updates (p. 44). To maintain an isolated Python environment that does not change\\nversions, create a lifecycle conﬁguration that runs each time you start your notebook instance. For\\ninformation about creating lifecycle conﬁgurations, see Customize a Notebook Instance  (p. 40).\\nThe following example lifecycle conﬁguration script installs Miniconda on your notebook instance.\\nThis allows you to create environments in your notebook instance with speciﬁc versions of Python and\\ndependencies that Amazon SageMaker does not update:\\n#!/bin/bash\\nset -e\\nWORKING_DIR=/home/ec2-user/.myproject\\n45Amazon SageMaker Developer Guide\\nAssociate Git Repositories with Amazon\\nSageMaker Notebook Instances\\nmkdir -p \"$WORKING_DIR\"\\n# Install Miniconda to get a separate python and pip', '45Amazon SageMaker Developer Guide\\nAssociate Git Repositories with Amazon\\nSageMaker Notebook Instances\\nmkdir -p \"$WORKING_DIR\"\\n# Install Miniconda to get a separate python and pip\\nwget https://repo.anaconda.com/miniconda/Miniconda3-4.5.12-Linux-x86_64.sh -O\\n \"$WORKING_DIR/miniconda.sh\"\\n# Install Miniconda into the working directory\\nbash \"$WORKING_DIR/miniconda.sh\" -b -u -p \"$WORKING_DIR/miniconda\"\\n# Install pinned versions of any dependencies\\nsource \"$WORKING_DIR/miniconda/bin/activate\"\\npip install boto3==1.9.86\\npip install requests==2.21.0\\n# Bootstrapping code\\n# Cleanup\\nsource \"$WORKING_DIR/miniconda/bin/deactivate\"\\nrm -rf \"$WORKING_DIR/miniconda.sh\"\\nYou can also add a sandboxed Python installation as a kernel that you can use in a Jupyter notebook by', '# Cleanup\\nsource \"$WORKING_DIR/miniconda/bin/deactivate\"\\nrm -rf \"$WORKING_DIR/miniconda.sh\"\\nYou can also add a sandboxed Python installation as a kernel that you can use in a Jupyter notebook by\\nincluding the following code to the above lifecycle conﬁguration:\\nsource \"$WORKING_DIR/miniconda/bin/activate\" \\n# If required, add this as a kernel\\npip install ipykernel \\npython -m ipykernel install --user --name MyProjectEnv --display-name \"Python\\n (myprojectenv)\"\\nsource \"$WORKING_DIR/miniconda/bin/deactivate\"\\nAssociate Git Repositories with Amazon SageMaker\\nNotebook Instances\\nAssociate Git repositories with your notebook instance to save your notebooks in a source control\\nenvironment that persists even if you stop or delete your notebook instance. You can associate one', 'Associate Git repositories with your notebook instance to save your notebooks in a source control\\nenvironment that persists even if you stop or delete your notebook instance. You can associate one\\ndefault repository and up to three additional repositories with a notebook instance. The repositories can\\nbe hosted in AWS CodeCommit, GitHub or on any other Git server. Associating Git repositories with your\\nnotebook instance can be useful for:\\n•Persistence - Notebooks in a notebook instance are stored on durable Amazon EBS volumes, but they\\ndo not persist beyond the life of your notebook instance. Storing notebooks in a Git repository enables\\nyou to store and use notebooks even if you stop or delete your notebook instance.', 'do not persist beyond the life of your notebook instance. Storing notebooks in a Git repository enables\\nyou to store and use notebooks even if you stop or delete your notebook instance.\\n•Collaboration - Peers on a team often work on machine learning projects together. Storing your\\nnotebooks in Git repositories allows peers working in diﬀerent notebook instances to share notebooks\\nand collaborate on them in a source-control environment.\\n•Learning - Many Jupyter notebooks that demonstrate machine learning techniques are available in\\npublicly hosted Git repositories, such as on GitHub. You can associate your notebook instance with a\\nrepository to easily load Jupyter notebooks contained in that repository.\\nThere are two ways to associate a Git repository with a notebook instance:', 'repository to easily load Jupyter notebooks contained in that repository.\\nThere are two ways to associate a Git repository with a notebook instance:\\n•Add a Git repository as a resource in your Amazon SageMaker account. Then, to access the repository,\\nyou can specify an AWS Secrets Manager secret that contains credentials. That way, you can access\\nrepositories that require authentication.\\n46Amazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account\\n•Associate a public Git repository that is not a resource in your account. If you do this, you cannot\\nspecify credentials to access the repository.\\nTopics\\n•Add a Git Repository to Your Amazon SageMaker Account (p. 47)\\n•Create a Notebook Instance with an Associated Git Repository (p. 49)', 'specify credentials to access the repository.\\nTopics\\n•Add a Git Repository to Your Amazon SageMaker Account (p. 47)\\n•Create a Notebook Instance with an Associated Git Repository (p. 49)\\n•Associate a CodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance (p. 51)\\n•Use Git Repositories in a Notebook Instance (p. 52)\\nAdd a Git Repository to Your Amazon SageMaker\\nAccount\\nTo manage your GitHub repositories, easily associate them with your notebook instances, and associate\\ncredentials for repositories that require authentication, add the repositories as resources in your Amazon\\nSageMaker account. You can view a list of repositories that are stored in your account and details about\\neach repository in the Amazon SageMaker console and by using the API.', 'SageMaker account. You can view a list of repositories that are stored in your account and details about\\neach repository in the Amazon SageMaker console and by using the API.\\nYou can add Git repositories to your Amazon SageMaker account in the Amazon SageMaker console or by\\nusing the AWS CLI.\\nNote\\nYou can use the Amazon SageMaker API CreateCodeRepository (p. 627) to add Git repositories\\nto your Amazon SageMaker account, but step-by-step instructions are not provided here.\\nAdd a Git Repository to Your Amazon SageMaker Account\\n(Console)\\nTo add a Git repository as a resource in your Amazon SageMaker account\\n1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Git repositories , then choose Add repository.', '1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\\n2. Choose Git repositories , then choose Add repository.\\n3. To add an CodeCommit repository, choose AWS CodeCommit.\\na. To use an existing CodeCommit repository:\\ni. Choose Use existing repository.\\nii. For Repository, choose a repository from the list.\\niii. Enter a name to use for the repository in Amazon SageMaker. The name must be 1 to 63\\ncharacters. Valid characters are a-z, A-Z, 0-9, and - (hyphen).\\niv.Choose Add repository.\\nb. To create a new CodeCommit repository:\\ni. Choose Create new repository.\\nii. Enter a name for the repository that you can use in both CodeCommit and Amazon\\nSageMaker. The name must be 1 to 63 characters. Valid characters are a-z, A-Z, 0-9, and -\\n(hyphen).', 'ii. Enter a name for the repository that you can use in both CodeCommit and Amazon\\nSageMaker. The name must be 1 to 63 characters. Valid characters are a-z, A-Z, 0-9, and -\\n(hyphen).\\niii. Choose Create repository.\\n4. To add a Git repository hosted somewhere other than CodeCommit :\\na. Choose GitHub/Other Git-based repo.\\nb. Enter a name to use for the repository in Amazon SageMaker. The name must be 1 to 63\\ncharacters. Valid characters are a-z, A-Z, 0-9, and - (hyphen).\\n47Amazon SageMaker Developer Guide\\nAdd a Git Repository to Your Amazon SageMaker Account\\nc. Enter the URL for the repository.\\nNote\\nDo not provide a user name in the URL. Add the username and password in AWS\\nSecrets Manager as described in the next step.', 'c. Enter the URL for the repository.\\nNote\\nDo not provide a user name in the URL. Add the username and password in AWS\\nSecrets Manager as described in the next step.\\nd. For Git credentials , choose the credentials to use to authenticate to the repository. This is\\nnecessary only if the Git repository is private.\\nNote\\nIf you have two-factor authentication enabled for your Git repository, use a personal\\naccess token generated by your Git service provider instead of a password.\\ni. To use an existing AWS Secrets Manager secret, choose Use existing secret , and then\\nchoose a secret from the list. For information about creating and storing a secret, see\\nCreating a Basic Secret in the AWS Secrets Manager User Guide. The name of the secret you\\nuse must contain the string sagemaker .\\nNote', 'Creating a Basic Secret in the AWS Secrets Manager User Guide. The name of the secret you\\nuse must contain the string sagemaker .\\nNote\\nThe secret must have a staging label of AWSCURRENT  and must be in the following\\nformat:\\n{\"username\": UserName , \"password\": Password }\\nFor GitHub repositories, we recommend using a personal access token instead of\\nyour account password. For information, see https://help.github.com/articles/\\ncreating-a-personal-access-token-for-the-command-line/.\\nii. To create a new AWS Secrets Manager secret, choose Create secret , enter a name for the\\nsecret, and then enter the username and password to use to authenticate to the repository.\\nThe name for the secret must contain the string sagemaker .\\nNote\\nThe IAM role you use to create the secret must have the', 'The name for the secret must contain the string sagemaker .\\nNote\\nThe IAM role you use to create the secret must have the\\nsecretsmanager:GetSecretValue  permission in its IAM policy.\\nThe secret must have a staging label of AWSCURRENT  and must be in the following\\nformat:\\n{\"username\": UserName , \"password\": Password }\\nFor GitHub repositories, we recommend using a personal access token instead of\\nyour account password.\\niii. To not use any credentials, choose No secret .\\ne. Choose Create secret .\\nAdd a Git Repository to Your Amazon SageMaker Account (CLI)\\nUse the create-code-repository  AWS CLI command. Specify a name for the repository as the value\\nof the code-repository-name  argument. The name must be 1 to 63 characters. Valid characters are a-', 'Use the create-code-repository  AWS CLI command. Specify a name for the repository as the value\\nof the code-repository-name  argument. The name must be 1 to 63 characters. Valid characters are a-\\nz, A-Z, 0-9, and - (hyphen). Also specify the following:\\n•The default branch\\n•The URL of the Git repository\\nNote\\nDo not provide a user name in the URL. Add the username and password in AWS Secrets\\nManager as described in the next step.\\n•The Amazon Resource Name (ARN) of an AWS Secrets Manager secret that contains the credentials to\\nuse to authenticate the repository as the value of the git-config  argument\\nFor information about creating and storing a secret, see Creating a Basic Secret in the AWS Secrets\\nManager User Guide . The following command creates a new repository named MyRespository  in', 'For information about creating and storing a secret, see Creating a Basic Secret in the AWS Secrets\\nManager User Guide . The following command creates a new repository named MyRespository  in\\n48Amazon SageMaker Developer Guide\\nCreate a Notebook Instance with\\nan Associated Git Repository\\nyour Amazon SageMaker account that points to a Git repository hosted at https://github.com/\\nmyprofile/my-repo\" .\\nFor Linux, OS X, or Unix:\\naws sagemaker create-code-repository \\\\\\n                    --code-repository-name \"MyRepository\" \\\\\\n                    --git-config \\'{\"Branch\":\"master\", \"RepositoryUrl\" :\\n                    \"https://github.com/myprofile/my-repo\", \"SecretArn\" :\\n \"arn:aws:secretsmanager:us-east-2:012345678901:secret:my-secret-ABc0DE\"}\\'\\nFor Windows:\\naws sagemaker create-code-repository ^', '\"https://github.com/myprofile/my-repo\", \"SecretArn\" :\\n \"arn:aws:secretsmanager:us-east-2:012345678901:secret:my-secret-ABc0DE\"}\\'\\nFor Windows:\\naws sagemaker create-code-repository ^\\n                    --code-repository-name \"MyRepository\" ^\\n                    --git-config \"{\\\\\"Branch\\\\\":\\\\\"master\\\\\", \\\\\"RepositoryUrl\\\\\" :\\n                    \\\\\"https://github.com/myprofile/my-repo\\\\\", \\\\\"SecretArn\\\\\" :\\n \\\\\"arn:aws:secretsmanager:us-east-2:012345678901:secret:my-secret-ABc0DE\\\\\"}\"\\nNote\\nThe secret must have a staging label of AWSCURRENT  and must be in the following format:\\n{\"username\": UserName , \"password\": Password }\\nFor GitHub repositories, we recommend using a personal access token instead of your account\\npassword.\\nCreate a Notebook Instance with an Associated Git\\nRepository', 'For GitHub repositories, we recommend using a personal access token instead of your account\\npassword.\\nCreate a Notebook Instance with an Associated Git\\nRepository\\nYou can associate Git repositories with a notebook instance when you create the notebook instance by\\nusing the AWS Management Console, or the AWS CLI.\\nNote\\nYou can use the Amazon SageMaker API CreateNotebookInstance (p. 656) to associate Git\\nrepositories with a notebook instance, but step-by-step instructions are not provided here.\\nNote\\nIf you want to use a CodeCommit repository that is in a diﬀerent AWS than the notebook\\ninstance,set up cross-account access for the repository. For information, see Associate a\\nCodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance (p. 51).\\nTopics', 'instance,set up cross-account access for the repository. For information, see Associate a\\nCodeCommit Repository in a Diﬀerent AWS Account with a Notebook Instance (p. 51).\\nTopics\\n•Create a Notebook Instance with an Associated Git Repository (Console) (p. 49)\\n•Create a Notebook Instance with an Associated Git Repository (CLI) (p. 50)\\nCreate a Notebook Instance with an Associated Git Repository\\n(Console)\\nTo create a notebook instance and associate Git repositories in the AWS Management\\nConsole\\n1. Follow the instructions at Step 2: Create an Amazon SageMaker Notebook Instance (p. 17).\\n2. For Git repositories , choose Git repositories to associate with the notebook instance.\\na. For Default repository, choose a repository that you want to use as your default repository.', '2. For Git repositories , choose Git repositories to associate with the notebook instance.\\na. For Default repository, choose a repository that you want to use as your default repository.\\nAmazon SageMaker clones this repository as a subdirectory in the Jupyter startup directory\\n49Amazon SageMaker Developer Guide\\nCreate a Notebook Instance with\\nan Associated Git Repository\\nat /home/ec2-user/SageMaker . When you open your notebook instance, it opens in this\\nrepository. To choose a repository that is stored as a resource in your account, choose its\\nname from the list. To add a new repository as a resource in your account, choose Add a\\nrepository to Amazon SageMaker (opens the Add repository ﬂow in a new window) and', 'name from the list. To add a new repository as a resource in your account, choose Add a\\nrepository to Amazon SageMaker (opens the Add repository ﬂow in a new window) and\\nthen follow the instructions at Create a Notebook Instance with an Associated Git Repository\\n(Console) (p. 49). To clone a public repository that is not stored in your account, choose\\nClone a public Git repository to this notebook instance only, and then specify the URL for that\\nrepository.\\nb. For Additional repository 1, choose a repository that you want to add as an additional\\ndirectory. Amazon SageMaker clones this repository as a subdirectory in the Jupyter startup\\ndirectory at /home/ec2-user/SageMaker . To choose a repository that is stored as a resource', 'directory. Amazon SageMaker clones this repository as a subdirectory in the Jupyter startup\\ndirectory at /home/ec2-user/SageMaker . To choose a repository that is stored as a resource\\nin your account, choose its name from the list. To add a new repository as a resource in your\\naccount, choose Add a repository to Amazon SageMaker (opens the Add repository ﬂow\\nin a new window) and then follow the instructions at Create a Notebook Instance with an\\nAssociated Git Repository (Console) (p. 49). To clone a repository that is not stored in your\\naccount, choose Clone a public Git repository to this notebook instance only, and then specify\\nthe URL for that repository.\\nRepeat this step up to three times to add up to three additional repositories to your notebook\\ninstance.', 'the URL for that repository.\\nRepeat this step up to three times to add up to three additional repositories to your notebook\\ninstance.\\nCreate a Notebook Instance with an Associated Git Repository\\n(CLI)\\nTo create a notebook instance and associate Git repositories by using the AWS CLI, use the create-\\nnotebook-instance  command as follows:\\n•Specify the repository that you want to use as your default repository as the value of the default-\\ncode-repository  argument. Amazon SageMaker clones this repository as a subdirectory in the\\nJupyter startup directory at /home/ec2-user/SageMaker . When you open your notebook instance,\\nit opens in this repository. To use a repository that is stored as a resource in your Amazon SageMaker', 'Jupyter startup directory at /home/ec2-user/SageMaker . When you open your notebook instance,\\nit opens in this repository. To use a repository that is stored as a resource in your Amazon SageMaker\\naccount, specify the name of the repository as the value of the default-code-repository\\nargument. To use a repository that is not stored in your account, specify the URL of the repository as\\nthe value of the default-code-repository  argument.\\n•Specify up to three additional repositories as the value of the additional-code-repositories\\nargument. Amazon SageMaker clones this repository as a subdirectory in the Jupyter startup directory\\nat /home/ec2-user/SageMaker , and the repository is excluded from the default repository by', 'argument. Amazon SageMaker clones this repository as a subdirectory in the Jupyter startup directory\\nat /home/ec2-user/SageMaker , and the repository is excluded from the default repository by\\nadding it to the .git/info/exclude  directory of the default repository. To use repositories that\\nare stored as resources in your Amazon SageMaker account, specify the names of the repositories\\nas the value of the additional-code-repositories  argument. To use repositories that are not\\nstored in your account, specify the URLs of the repositories as the value of the additional-code-\\nrepositories  argument.\\nFor example, the following command creates a notebook instance that has a repository named\\nMyGitRepo , that is stored as a resource in your Amazon SageMaker account, as a default repository, and', 'For example, the following command creates a notebook instance that has a repository named\\nMyGitRepo , that is stored as a resource in your Amazon SageMaker account, as a default repository, and\\nan additional repository that is hosted on GitHub:\\naws sagemaker create-notebook-instance \\\\\\n                    --notebook-instance-name \"MyNotebookInstance\" \\\\\\n                    --instance-type \"ml.t2.medium\" \\\\\\n                    --role-arn \"arn:aws:iam::012345678901:role/service-role/\\nAmazonSageMaker-ExecutionRole-20181129T121390\" \\\\\\n                    --default-code-repository \"MyGitRepo\" \\\\\\n                    --additional-code-repositories \"https://github.com/myprofile/my-other-\\nrepo\"\\n50Amazon SageMaker Developer Guide\\nAssociate a CodeCommit Repository in a', '--additional-code-repositories \"https://github.com/myprofile/my-other-\\nrepo\"\\n50Amazon SageMaker Developer Guide\\nAssociate a CodeCommit Repository in a\\nDiﬀerent AWS Account with a Notebook Instance\\nNote\\nIf you use an AWS CodeCommit repository that does not contain \"SageMaker\" in its name, add\\nthe codecommit:GitPull  and codecommit:GitPush  permissions to the role that you pass\\nas the role-arn  argument to the create-notebook-instance  command. For information\\nabout how to add permissions to a role, see Adding and Removing IAM Policies in the AWS\\nIdentity and Access Management User Guide .\\nAssociate a CodeCommit Repository in a Diﬀerent\\nAWS Account with a Notebook Instance\\nTo associate a CodeCommit repository in a diﬀerent AWS account with your notebook instance, set up', 'Associate a CodeCommit Repository in a Diﬀerent\\nAWS Account with a Notebook Instance\\nTo associate a CodeCommit repository in a diﬀerent AWS account with your notebook instance, set up\\ncross-account access for the CodeCommit repository.\\nTo set up cross-account access for a CodeCommit repository and associate it with a notebook\\ninstance:\\n1. In the AWS account that contains the CodeCommit repository, create an IAM policy that allows\\naccess to the repository from users in the account that contains your notebook instance. For\\ninformation, see Step 1: Create a Policy for Repository Access in AccountA in the CodeCommit User\\nGuide .\\n2. In the AWS account that contains the CodeCommit repository, create an IAM role, and attach the', 'Guide .\\n2. In the AWS account that contains the CodeCommit repository, create an IAM role, and attach the\\npolicy that you created in the previous step to that role. For information, see Step 2: Create a Role\\nfor Repository Access in AccountA in the CodeCommit User Guide .\\n3. Create a proﬁle in the notebook instance that uses the role that you created in the previous step:\\na. Open the notebook instance.\\nb. Open a terminal in the notebook instance.\\nc. Edit a new proﬁle by typing the following in the terminal:\\nvi /home/ec2-user/.aws/config\\nd. Edit the ﬁle with the following proﬁle information:\\n[profile CrossAccountAccessProfile ]\\nregion = us-west-2\\nrole_arn =\\n arn:aws:iam:: CodeCommitAccount :role/CrossAccountRepositoryContributorRole\\ncredential_source=Ec2InstanceMetadata\\noutput = json', '[profile CrossAccountAccessProfile ]\\nregion = us-west-2\\nrole_arn =\\n arn:aws:iam:: CodeCommitAccount :role/CrossAccountRepositoryContributorRole\\ncredential_source=Ec2InstanceMetadata\\noutput = json\\nWhere CodeCommitAccount  is the account that contains the CodeCommit\\nrepository, CrossAccountAccessProfile  is the name of the new proﬁle, and\\nCrossAccountRepositoryContributorRole  is the name of the role you created in the\\nprevious step.\\n4. On the notebook instance, conﬁgure git to use the proﬁle you created in the previous step:\\na. Open the notebook instance.\\nb. Open a terminal in the notebook instance.\\nc. Edit the Git conﬁguration ﬁle typing the following in the terminal:\\nvi /home/ec2-user/.gitconfig\\nd. Edit the ﬁle with the following proﬁle information:\\n51Amazon SageMaker Developer Guide', 'c. Edit the Git conﬁguration ﬁle typing the following in the terminal:\\nvi /home/ec2-user/.gitconfig\\nd. Edit the ﬁle with the following proﬁle information:\\n51Amazon SageMaker Developer Guide\\nUse Git Repositories in a Notebook Instance\\n[credential]\\n        helper = !aws codecommit credential-helper --\\nprofile CrossAccountAccessProfile  $@\\n        UseHttpPath = true\\nWhere CrossAccountAccessProfile  is the name of the proﬁle that you created in the\\nprevious step.\\nUse Git Repositories in a Notebook Instance\\nWhen you open a notebook instance that has Git repositories associated with it, it opens in the default\\nrepository, which is installed in your notebook instance directly under /home/ec2-user/SageMaker .', 'repository, which is installed in your notebook instance directly under /home/ec2-user/SageMaker .\\nYou can open and create notebooks, and you can manually run Git commands in a notebook cell. For\\nexample:\\n!git pull origin master\\nTo open any of the additional repositories, navigate up one folder. The additional repositories are also\\ninstalled as directories under /home/ec2-user/SageMaker .\\nIf you open the notebook instance with a JupyterLab interface, the jupyter-git extension is installed and\\navailable to use. For information about the jupyter-git extension for JupyterLab, see https://github.com/\\njupyterlab/jupyterlab-git.\\nWhen you open a notebook instance in JupyterLab, you see the git repositories associated with it on the\\nleft menu:\\n52Amazon SageMaker Developer Guide', 'jupyterlab/jupyterlab-git.\\nWhen you open a notebook instance in JupyterLab, you see the git repositories associated with it on the\\nleft menu:\\n52Amazon SageMaker Developer Guide\\nUse Git Repositories in a Notebook Instance\\nYou can use the jupyter-git extension to manage git visually, instead of using the command line:\\n53Amazon SageMaker Developer Guide\\nGet Notebook Instance Metadata\\nGet Notebook Instance Metadata\\nWhen you create a notebook instance, Amazon SageMaker creates a JSON ﬁle on the instance at the\\nlocation /opt/ml/metadata/resource-metadata.json  that contains the ResourceName  and\\nResourceArn  of the notebook instance. You can access this metadata from anywhere within the\\nnotebook instance, including in lifecycle conﬁgurations. For information about notebook instance', 'ResourceArn  of the notebook instance. You can access this metadata from anywhere within the\\nnotebook instance, including in lifecycle conﬁgurations. For information about notebook instance\\nlifecycle conﬁgurations, see Customize a Notebook Instance  (p. 40).\\nThe resource-metadata.json  ﬁle has the following structure:\\n{\\n    \"ResourceArn\": \" NotebookInstanceArn \",\\n    \"ResourceName\": \" NotebookInstanceName \"\\n}\\nYou can use this metadata from within the notebook instance to get other information about the\\nnotebook instance. For example, the following commands get the tags associated with the notebook\\ninstance:\\nNOTEBOOK_ARN=$(jq \\'.ResourceArn\\'\\n            /opt/ml/metadata/resource-metadata.json --raw-output)\\naws sagemaker list-tags --resource-arn $NOTEBOOK_ARN', 'instance:\\nNOTEBOOK_ARN=$(jq \\'.ResourceArn\\'\\n            /opt/ml/metadata/resource-metadata.json --raw-output)\\naws sagemaker list-tags --resource-arn $NOTEBOOK_ARN\\nThe out put looks like the following:\\n{\\n    \"Tags\": [\\n        {\\n            \"Key\": \"test\",\\n            \"Value\": \"true\"\\n        }\\n    ]\\n}\\nMonitor Jupyter Logs in Amazon CloudWatch Logs\\nJupyter logs include important information such as events, metrics, and health information that provide\\nactionable insights when running Amazon SageMaker notebooks. By importing Jupyter logs into\\nCloudWatch Logs, customers can use CloudWatch Logs to detect anomalous behaviors, set alarms, and\\ndiscover insights to keep the Amazon SageMaker notebooks running more smoothly. You can access the', 'CloudWatch Logs, customers can use CloudWatch Logs to detect anomalous behaviors, set alarms, and\\ndiscover insights to keep the Amazon SageMaker notebooks running more smoothly. You can access the\\nlogs even when the Amazon EC2 instance that hosts the notebook is unresponsive, and use the logs to\\ntroubleshoot the unresponsive notebook. Sensitive information such as AWS account IDs, secret keys,\\nand authentication tokens in presigned URLs are removed so that customers can share logs without\\nleaking private information.\\nTo view Jupyter logs for a notebook instance:\\n1. Sign in to the AWS Management Console and open the Amazon SageMaker console at https://\\nconsole.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances.', '1. Sign in to the AWS Management Console and open the Amazon SageMaker console at https://\\nconsole.aws.amazon.com/sagemaker/.\\n2. Choose Notebook instances.\\n3. In the list of notebook instances, choose the notebook instance for which you want to view Jupyter\\nlogs.\\n4. Under Monitor  on the notebook instance details page, choose View logs.\\n54Amazon SageMaker Developer Guide\\nMonitor Jupyter Logs in Amazon CloudWatch Logs\\n5. In the CloudWatch console, choose the log stream for your notebook intance. Its name is in the form\\nNotebookInstanceName /jupyter.log .\\nFor more information about monitoring CloudWatch logs for Amazon SageMaker, see Log Amazon\\nSageMaker Events with Amazon CloudWatch (p. 466).\\n55Amazon SageMaker Developer Guide\\nUse Built-in Algorithms\\nBuild a Model', 'SageMaker Events with Amazon CloudWatch (p. 466).\\n55Amazon SageMaker Developer Guide\\nUse Built-in Algorithms\\nBuild a Model\\nTo build a machine learning model in Amazon SageMaker, you have the following options:\\n•Use one of the built-in algorithims. Amazon SageMaker provides several built-in machine learning\\nalgorithms that you can use for a variety of problem types. For more information, see Use Amazon\\nSageMaker Built-in Algorithms  (p. 56).\\n•Write a custom training script in a machine learning framework that Amazon SageMaker supports, and\\nuse one of the pre-built framework containers to run it in Amazon SageMaker. For information, see Use\\nMachine Learning Frameworks with Amazon SageMaker (p. 440).', 'use one of the pre-built framework containers to run it in Amazon SageMaker. For information, see Use\\nMachine Learning Frameworks with Amazon SageMaker (p. 440).\\n•Bring your own algorithm or model to train or host in Amazon SageMaker. For information, see Use\\nYour Own Algorithms or Models with Amazon SageMaker  (p. 384).\\n•Use an algorithm that you subscribe to from AWS Marketplace. For information, see Amazon\\nSageMaker Resources in AWS Marketplace (p. 428).\\nTopics\\n•Use Amazon SageMaker Built-in Algorithms  (p. 56)\\nUse Amazon SageMaker Built-in Algorithms\\nA machine learning algorithm uses example data to create a generalized solution (a model ) that\\naddresses the business question you are trying to answer. After you create a model using example data,', 'A machine learning algorithm uses example data to create a generalized solution (a model ) that\\naddresses the business question you are trying to answer. After you create a model using example data,\\nyou can use it to answer the same business question for a new set of data. This is also referred to as\\nobtaining inferences.\\nAmazon SageMaker provides several built-in machine learning algorithms that you can use for a variety\\nof problem types.\\nBecause you create a model to address a business question, your ﬁrst step is to understand the problem\\nthat you want to solve. Speciﬁcally, the format of the answer that you are looking for inﬂuences the\\nalgorithm that you choose. For example, suppose that you are a bank marketing manager, and that', 'that you want to solve. Speciﬁcally, the format of the answer that you are looking for inﬂuences the\\nalgorithm that you choose. For example, suppose that you are a bank marketing manager, and that\\nyou want to conduct a direct mail campaign to attract new customers. Consider the potential types of\\nanswers that you\\'re looking for:\\n•Answers that ﬁt into discrete categories—For example, answers to these questions:\\n\\xa0\\n•\"Based on past customer responses, should I mail this particular customer?\" Answers to this question\\nfall into two categories, \"yes\" or \"no.\" In this case, you use the answer to narrow the recipients of the\\nmail campaign.\\n\\xa0\\n•\"Based on past customer segmentation, which segment does this customer fall into?\" Answers might', 'mail campaign.\\n\\xa0\\n•\"Based on past customer segmentation, which segment does this customer fall into?\" Answers might\\nfall into categories such as \"empty nester,\" \"suburban family,\" or \"urban professional.\" You could use\\nthese segments to decide who should receive the mailing.\\n\\xa0\\n56Amazon SageMaker Developer Guide\\nUse Built-in Algorithms\\nFor this type of discrete classiﬁcation problem, Amazon SageMaker provides two algorithms:\\nLinear Learner Algorithm  (p. 162) and the XGBoost Algorithm (p. 255). You set the following\\nhyperparameters to direct these algorithms to produce discrete results:\\n\\xa0\\n•For the Linear Learner algorithm, set the predictor_type  hyperparameter to\\nbinary_classifier .\\n\\xa0\\n•For the XGBoost algorithm, set the objective  hyperparameter to reg:logistic .', '•For the Linear Learner algorithm, set the predictor_type  hyperparameter to\\nbinary_classifier .\\n\\xa0\\n•For the XGBoost algorithm, set the objective  hyperparameter to reg:logistic .\\n\\xa0\\n•Answers that are quantitative—Consider this question: \"Based on the return on investment (ROI)\\nfrom past mailings, what is the ROI for mailing this customer?” In this case, you use the ROI to target\\ncustomers for the mail campaign. For these quantitative analysis problems, you can also use the Linear\\nLearner Algorithm  (p. 162) or the XGBoost Algorithm (p. 255) algorithms. You set the following\\nhyperparameters to direct these algorithms to produce quantitative results:\\n\\xa0\\n•For the Linear Learner algorithm, set the predictor_type  hyperparameter to regressor .', 'hyperparameters to direct these algorithms to produce quantitative results:\\n\\xa0\\n•For the Linear Learner algorithm, set the predictor_type  hyperparameter to regressor .\\n\\xa0\\n•For the XGBoost algorithm, set the objective  hyperparameter to reg:linear .\\n\\xa0\\n•Answers in the form of discrete recommendations—Consider this question: \"Based on past responses\\nto mailings, what is the recommended content for each customer?\" In this case, you are looking for\\na recommendation on what to mail, not whether to mail, the customer. For this problem, Amazon\\nSageMaker provides the Factorization Machines Algorithm (p. 98) algorithm.\\n\\xa0\\nAll of the questions in the preceding examples rely on having example data that includes answers. There', 'SageMaker provides the Factorization Machines Algorithm (p. 98) algorithm.\\n\\xa0\\nAll of the questions in the preceding examples rely on having example data that includes answers. There\\nare times that you don\\'t need, or can\\'t get, example data with answers. This is true for problems whose\\nanswers identify groups. For example:\\n•\"I want to group current and prospective customers into 10 groups based on their attributes. How\\nshould I group them? \" You might choose to send the mailing to customers in the group that has the\\nhighest percentage of current customers. That is, prospective customers that most resemble current\\ncustomers based on the same set of attributes. For this type of question, Amazon SageMaker provides\\nthe K-Means Algorithm (p. 141).', 'customers based on the same set of attributes. For this type of question, Amazon SageMaker provides\\nthe K-Means Algorithm (p. 141).\\n\\xa0\\n•\"What are the attributes that diﬀerentiate these customers, and what are the values for each customer\\nalong those dimensions.\" You use these answers to simplify the view of current and prospective\\ncustomers, and, maybe, to better understand these customer attributes. For this type of question,\\nAmazon SageMaker provides the Principal Component Analysis (PCA) Algorithm  (p. 222) algorithm.\\nIn addition to these general-purpose algorithms, Amazon SageMaker provides algorithms that are\\ntailored to speciﬁc use cases. These include:\\n•Image Classiﬁcation Algorithm  (p. 108)—Use this algorithm to classify images. It uses example data', \"tailored to speciﬁc use cases. These include:\\n•Image Classiﬁcation Algorithm  (p. 108)—Use this algorithm to classify images. It uses example data\\nwith answers (referred to as supervised algorithm).\\n\\xa0\\n57Amazon SageMaker Developer Guide\\nCommon Information\\n•Sequence-to-Sequence Algorithm (p. 242)—This supervised algorithm is commonly used for neural\\nmachine translation.\\n\\xa0\\n•Latent Dirichlet Allocation (LDA) Algorithm (p. 157)—This algorithm is suitable for determining\\ntopics in a set of documents. It is an unsupervised algorithm, which means that it doesn't use example\\ndata with answers during training.\\n\\xa0\\n•Neural Topic Model (NTM) Algorithm (p. 177)—Another unsupervised technique for determining\\ntopics in a set of documents, using a neural network approach.\\nTopics\", 'data with answers during training.\\n\\xa0\\n•Neural Topic Model (NTM) Algorithm (p. 177)—Another unsupervised technique for determining\\ntopics in a set of documents, using a neural network approach.\\nTopics\\n•Common Elements of Built-in Algorithms  (p. 58)\\n•BlazingText Algorithm (p. 74)\\n•DeepAR Forecasting Algorithm (p. 83)\\n•Factorization Machines Algorithm (p. 98)\\n•Image Classiﬁcation Algorithm  (p. 108)\\n•IP Insights Algorithm  (p. 131)\\n•K-Means Algorithm (p. 141)\\n•K-Nearest Neighbors (k-NN) Algorithm (p. 148)\\n•Latent Dirichlet Allocation (LDA) Algorithm (p. 157)\\n•Linear Learner Algorithm  (p. 162)\\n•Neural Topic Model (NTM) Algorithm (p. 177)\\n•Object2Vec Algorithm (p. 183)\\n•Object Detection Algorithm (p. 199)\\n•Principal Component Analysis (PCA) Algorithm  (p. 222)', '•Neural Topic Model (NTM) Algorithm (p. 177)\\n•Object2Vec Algorithm (p. 183)\\n•Object Detection Algorithm (p. 199)\\n•Principal Component Analysis (PCA) Algorithm  (p. 222)\\n•Random Cut Forest (RCF) Algorithm (p. 226)\\n•Semantic Segmentation Algorithm  (p. 234)\\n•Sequence-to-Sequence Algorithm (p. 242)\\n•XGBoost Algorithm (p. 255)\\nCommon Elements of Built-in Algorithms\\nThe following topics provide information common to all of the algorithms provided by Amazon\\nSageMaker.\\nTopics\\n•Common Parameters for Built-In Algorithms  (p. 58)\\n•Common Data Formats for Built-in Algorithms  (p. 64)\\n•Instance Types for Built-in Algorithms  (p. 72)\\n•Logs for Built-In Algorithms  (p. 73)\\nCommon Parameters for Built-In Algorithms', '•Common Data Formats for Built-in Algorithms  (p. 64)\\n•Instance Types for Built-in Algorithms  (p. 72)\\n•Logs for Built-In Algorithms  (p. 73)\\nCommon Parameters for Built-In Algorithms\\nThe following table lists parameters for each of the algorithms provided by Amazon SageMaker.\\n58Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm\\nNameChannel\\nNameTraining Image and\\nInference Image Registry\\nPathTraining\\nInput\\nModeFile TypeInstance\\nClassParallelizable\\nBlazingTexttrain <ecr_path> /\\nblazingtext:<tag>File or\\nPipeText ﬁle\\n(one\\nsentence\\nper line\\nwith\\nspace-\\nseparated\\ntokens)GPU\\n(single\\ninstance\\nonly) or\\nCPUNo\\nDeepAR\\nForecastingtrain and\\n(optionally)\\ntest<ecr_path> /forecasting-\\ndeepar:<tag>FileJSON\\nLines or\\nParquetGPU or\\nCPUYes\\nFactorization\\nMachinestrain and\\n(optionally)', '(single\\ninstance\\nonly) or\\nCPUNo\\nDeepAR\\nForecastingtrain and\\n(optionally)\\ntest<ecr_path> /forecasting-\\ndeepar:<tag>FileJSON\\nLines or\\nParquetGPU or\\nCPUYes\\nFactorization\\nMachinestrain and\\n(optionally)\\ntest<ecr_path> /factorization-\\nmachines: <tag>File or\\nPiperecordIO-\\nprotobufCPU (GPU\\nfor dense\\ndata)Yes\\nImage\\nClassiﬁcationtrain and\\nvalidation,\\n(optionally)\\ntrain_lst,\\nvalidation_lst,\\nand\\nmodel<ecr_path> /image-\\nclassiﬁcation: <tag>File or\\nPiperecordIO\\nor image\\nﬁles (.jpg\\nor .png)GPUYes\\nIP\\nInsightstrain and\\n(optionally)\\nvalidation<ecr_path> /\\nipinsights: <tag>FileCSV CPU or\\nGPUYes\\nk-means train and\\n(optionally)\\ntest<ecr_path> /kmeans:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPUCommon\\n(single\\nGPU\\ndevice\\non one\\nor more\\ninstances)No\\nk-nearest-\\nneighbor\\n(k-NN)train and\\n(optionally)', '(optionally)\\ntest<ecr_path> /kmeans:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPUCommon\\n(single\\nGPU\\ndevice\\non one\\nor more\\ninstances)No\\nk-nearest-\\nneighbor\\n(k-NN)train and\\n(optionally)\\ntest<ecr_path> /knn:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPU\\n(single\\nGPU\\ndevice\\non one\\nor more\\ninstances)Yes\\nLDA train and\\n(optionally)\\ntest<ecr_path> /lda:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU\\n(single\\ninstance\\nonly)No\\n59Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm\\nNameChannel\\nNameTraining Image and\\nInference Image Registry\\nPathTraining\\nInput\\nModeFile TypeInstance\\nClassParallelizable\\nLinear\\nLearnertrain and\\n(optionally)\\nvalidation,\\ntest, or\\nboth<ecr_path> /linear-\\nlearner:<tag>File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPUYes\\nNeural\\nTopic\\nModeltrain and', 'ClassParallelizable\\nLinear\\nLearnertrain and\\n(optionally)\\nvalidation,\\ntest, or\\nboth<ecr_path> /linear-\\nlearner:<tag>File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPU or\\nGPUYes\\nNeural\\nTopic\\nModeltrain and\\n(optionally)\\nvalidation,\\ntest, or\\nboth<ecr_path> /ntm:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVGPU or\\nCPUYes\\nObject2Vectrain and\\n(optionally)\\nvalidation,\\ntest, or\\nboth<ecr_path> /\\nobject2vec:<tag>FileJSON\\nLinesGPU\\nor CPU\\n(single\\ninstance\\nonly)No\\nObject\\nDetectiontrain and\\nvalidation,\\n(optionally)\\ntrain_annotation,\\nvalidation_annotation,\\nand\\nmodel<ecr_path> /object-\\ndetection:<tag>File or\\nPiperecordIO\\nor image\\nﬁles (.jpg\\nor .png)GPUYes\\nPCA train and\\n(optionally)\\ntest<ecr_path> /pca:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVGPU or\\nCPUYes\\nRandom\\nCut Foresttrain and\\n(optionally)\\ntest<ecr_path> /', 'or image\\nﬁles (.jpg\\nor .png)GPUYes\\nPCA train and\\n(optionally)\\ntest<ecr_path> /pca:<tag> File or\\nPiperecordIO-\\nprotobuf\\nor CSVGPU or\\nCPUYes\\nRandom\\nCut Foresttrain and\\n(optionally)\\ntest<ecr_path> /\\nrandomcutforest:<tag>File or\\nPiperecordIO-\\nprotobuf\\nor CSVCPUYes\\nSemantic\\nSegmentationtrain and\\nvalidation,\\ntrain_annotation,\\nvalidation_annotation,\\nand\\n(optionally)\\nlabel_map\\nand\\nmodel<ecr_path> /semantic-\\nsegmentation: <tag>File or\\nPipeimage\\nﬁlesGPU\\n(single\\ninstance\\nonly)No\\nSeq2Seq\\nModelingtrain,\\nvalidation,\\nand\\nvocab<ecr_path> /seq2seq:<tag> FilerecordIO-\\nprotobufGPU\\n(single\\ninstance\\nonly)No\\nXGBoost train and\\n(optionally)\\nvalidation<ecr_path> /xgboost:<tag> FileCSV or\\nLibSVMCPUYes\\n60Amazon SageMaker Developer Guide\\nCommon Information', 'protobufGPU\\n(single\\ninstance\\nonly)No\\nXGBoost train and\\n(optionally)\\nvalidation<ecr_path> /xgboost:<tag> FileCSV or\\nLibSVMCPUYes\\n60Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithms that are parallelizable  can be deployed on multiple compute instances for distributed\\ntraining. For the Training Image and Inference Image Registry Path column, use the :1 version tag\\nto ensure that you are using a stable version of the algorithm. You can reliably host a model trained\\nusing an image with the :1 tag on an inference image that has the :1 tag. Using the :latest  tag in the\\nregistry path provides you with the most up-to-date version of the algorithm, but might cause problems\\nwith backward compatibility. Avoid using the :latest tag for production purposes.', 'registry path provides you with the most up-to-date version of the algorithm, but might cause problems\\nwith backward compatibility. Avoid using the :latest tag for production purposes.\\nFor the Training Image and Inference Image Registry Path column, depending on algorithm and region\\nuse one of the following values for <ecr_path>.\\nAlgorithm Name AWS Region Training Image and Inference Image Registry Path\\nus-west-1 632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2 174872318107.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1 382416733822.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2 404615174143.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-east-1 286214385809.dkr.ecr.ap-east-1.amazonaws.com\\nap-northeast-1351501993468.dkr.ecr.ap-', 'us-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-east-1 286214385809.dkr.ecr.ap-east-1.amazonaws.com\\nap-northeast-1351501993468.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2835164637446.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1 991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2712309505854.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1 469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1 664544806723.dkr.ecr.eu-central-1.amazonaws.com\\neu-north-1 669576153137.dkr.ecr.eu-north-1.amazonaws.com\\neu-west-1 438346466558.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2 644912444149.dkr.ecr.eu-west-2.amazonaws.com', 'eu-north-1 669576153137.dkr.ecr.eu-north-1.amazonaws.com\\neu-west-1 438346466558.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2 644912444149.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3 749696950732.dkr.ecr.eu-west-3.amazonaws.comFactorization Machines,\\nIP Insights, k-means, k-\\nnearest-neighbor, Linear\\nLearner, Object2Vec,\\nNeural Topic Model,PCA,\\nand Random Cut Forest\\nsa-east-1 855470959533.dkr.ecr.sa-east-1.amazonaws.com\\nus-west-1 632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2 266724342769.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1 766337827248.dkr.ecr.us-east-1.amazonaws.comLDA\\nus-east-2 999911452149.dkr.ecr.us-east-2.amazonaws.com\\n61Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path', 'us-east-2 999911452149.dkr.ecr.us-east-2.amazonaws.com\\n61Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-northeast-1258307448986.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2293181348795.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2297031611018.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1353608530281.dkr.ecr.eu-central-1.amazonaws.com\\neu-west-1999678624901.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com', 'eu-central-1353608530281.dkr.ecr.eu-central-1.amazonaws.com\\neu-west-1999678624901.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com\\nus-west-1632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2433757028032.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1811284229777.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2825641698319.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-east-1286214385809.dkr.ecr.ap-east-1.amazonaws.com\\nap-northeast-1501404015308.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2306986355934.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2544295431143.dkr.ecr.ap-', 'northeast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2544295431143.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1813361260812.dkr.ecr.eu-central-1.amazonaws.com\\neu-north-1669576153137.dkr.ecr.eu-north-1.amazonaws.comBlazingText, Image\\nClassiﬁcation, Object\\nDetection, Semantic\\nSegmentation, Seq2Seq,\\nand XGBoost (0.72)\\neu-west-1685385470294.dkr.ecr.eu-west-1.amazonaws.com\\n62Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3749696950732.dkr.ecr.eu-west-3.amazonaws.com', 'Common Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3749696950732.dkr.ecr.eu-west-3.amazonaws.com\\nsa-east-1855470959533.dkr.ecr.sa-east-1.amazonaws.com\\nus-west-1746614075791.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2246618743249.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1683313688378.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2257758044811.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1414596584902.dkr.ecr.us-gov-\\nwest-1.amazonaws.com\\nap-northeast-1354813040037.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2366743142698.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-southeast-1121021644041.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2783357654285.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com', 'ap-northeast-2366743142698.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-southeast-1121021644041.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2783357654285.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nap-south-1720646828776.dkr.ecr.ap-south-1.amazonaws.com\\nap-east-1651117190479.dkr.ecr.ap-east-1.amazonaws.com\\nca-central-1341280168497.dkr.ecr.ca-central-1.amazonaws.com\\neu-central-1492215442770.dkr.ecr.eu-central-1.amazonaws.com\\neu-north-1662702820516.dkr.ecr.eu-north-1.amazonaws.com\\neu-west-1141502667606.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2764974769150.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3659782779980.dkr.ecr.eu-west-3.amazonaws.comXGBoost (0.90)\\nsa-east-1737474898029.dkr.ecr.sa-east-1.amazonaws.com\\nus-west-1632365934929.dkr.ecr.us-west-1.amazonaws.com', 'eu-west-3659782779980.dkr.ecr.eu-west-3.amazonaws.comXGBoost (0.90)\\nsa-east-1737474898029.dkr.ecr.sa-east-1.amazonaws.com\\nus-west-1632365934929.dkr.ecr.us-west-1.amazonaws.com\\nus-west-2156387875391.dkr.ecr.us-west-2.amazonaws.com\\nus-east-1522234722520.dkr.ecr.us-east-1.amazonaws.com\\nus-east-2566113047672.dkr.ecr.us-east-2.amazonaws.com\\nus-gov-west-1226302683700.dkr.ecr.us-gov-\\nwest-1.amazonaws.comDeepAR Forecasting\\nap-east-1286214385809.dkr.ecr.ap-east-1.amazonaws.com\\n63Amazon SageMaker Developer Guide\\nCommon Information\\nAlgorithm NameAWS RegionTraining Image and Inference Image Registry Path\\nap-northeast-1633353088612.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2204372634319.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com', 'ap-northeast-1633353088612.dkr.ecr.ap-\\nnortheast-1.amazonaws.com\\nap-northeast-2204372634319.dkr.ecr.ap-\\nnortheast-2.amazonaws.com\\nap-south-1991648021394.dkr.ecr.ap-south-1.amazonaws.com\\nap-southeast-1475088953585.dkr.ecr.ap-\\nsoutheast-1.amazonaws.com\\nap-southeast-2514117268639.dkr.ecr.ap-\\nsoutheast-2.amazonaws.com\\nca-central-1469771592824.dkr.ecr.ca-central-1.amazonaws.com\\neu-north-1669576153137.dkr.ecr.eu-north-1.amazonaws.com\\neu-central-1495149712605.dkr.ecr.eu-central-1.amazonaws.com\\neu-west-1224300973850.dkr.ecr.eu-west-1.amazonaws.com\\neu-west-2644912444149.dkr.ecr.eu-west-2.amazonaws.com\\neu-west-3749696950732.dkr.ecr.eu-west-3.amazonaws.com\\nsa-east-1855470959533.dkr.ecr.sa-east-1.amazonaws.com\\nUse the paths and training input mode as follows:', 'eu-west-3749696950732.dkr.ecr.eu-west-3.amazonaws.com\\nsa-east-1855470959533.dkr.ecr.sa-east-1.amazonaws.com\\nUse the paths and training input mode as follows:\\n•To create a training job (with a request to the CreateTrainingJob (p. 667) API), specify the Docker\\nRegistry path and the training input mode for the training image. You create a training job to train a\\nmodel using a speciﬁc dataset.\\n\\xa0\\n•To create a model (with a CreateModel (p. 648) request), specify the Docker Registry path for the\\ninference image. Amazon SageMaker launches machine learning compute instances that are based on\\nthe endpoint conﬁguration and deploys the model, which includes the artifacts (the result of model\\ntraining).\\nCommon Data Formats for Built-in Algorithms', 'the endpoint conﬁguration and deploys the model, which includes the artifacts (the result of model\\ntraining).\\nCommon Data Formats for Built-in Algorithms\\nThe following topics explain the data formats for the algorithms provided by Amazon SageMaker.\\nTopics\\n•Common Data Formats for Training  (p. 64)\\n•Common Data Formats for Inference  (p. 68)\\nCommon Data Formats for Training\\nTo prepare for training, you can preprocess your data using a variety of AWS services, including AWS\\nGlue, Amazon EMR, Amazon Redshift, Amazon Relational Database Service, and Amazon Athena. After\\npreprocessing, publish the data to an Amazon S3 bucket. For training, the data need to go through a\\nseries of conversions and transformations, including:\\n64Amazon SageMaker Developer Guide\\nCommon Information', 'series of conversions and transformations, including:\\n64Amazon SageMaker Developer Guide\\nCommon Information\\n•Training data serialization (handled by you)\\n•Training data deserialization (handled by the algorithm)\\n•Training model serialization (handled by the algorithm)\\n•Trained model deserialization (optional, handled by you)\\nWhen using Amazon SageMaker in the training portion of the algorithm, make sure to upload all data\\nat once. If more data is added to that location, a new training call would need to be made to construct a\\nbrand new model.\\nThe following table lists supported ContentType values:\\nContent Type Deﬁnition\\ntext/csv; label_size=n Comma-separated values, where n speciﬁes the number of starting\\ncolumns in a row that are labels. The default value for n is 1.', \"Content Type Deﬁnition\\ntext/csv; label_size=n Comma-separated values, where n speciﬁes the number of starting\\ncolumns in a row that are labels. The default value for n is 1.\\napplication/x-recordio-\\nprotobufA protobuf message wrapped in a RecordIO record.\\nTraining Data Formats\\nMany Amazon SageMaker algorithms support training with data in CSV format. To use data in CSV\\nformat for training, in the input data channel speciﬁcation, specify text/csv  as the ContentType.\\nAmazon SageMaker requires that a CSV ﬁle doesn't have a header record and that the target variable is\\nin the ﬁrst column. To run unsupervised learning algorithms that don't have a target, specify the number\\nof label columns in the content type. For example, in this case 'text/csv;label_size=0' .\", \"in the ﬁrst column. To run unsupervised learning algorithms that don't have a target, specify the number\\nof label columns in the content type. For example, in this case 'text/csv;label_size=0' .\\nMost Amazon SageMaker algorithms work best when you use the optimized protobuf recordIO format\\nfor the training data. Using this format allows you to take advantage of Pipe mode  when training\\nthe algorithms that support it. File mode  loads all of your data from Amazon Simple Storage Service\\n(Amazon S3) to the training instance volumes. In Pipe mode , your training job streams data directly\\nfrom Amazon S3. Streaming can provide faster start times for training jobs and better throughput.\\nWith Pipe mode, you also reduce the size of the Amazon Elastic Block Store volumes for your training\", 'from Amazon S3. Streaming can provide faster start times for training jobs and better throughput.\\nWith Pipe mode, you also reduce the size of the Amazon Elastic Block Store volumes for your training\\ninstances. Pipe mode needs only enough disk space to store your ﬁnal model artifacts. File mode\\nneeds disk space to store both your ﬁnal model artifacts and your full training dataset. See the\\nAlgorithmSpeciﬁcation  (p. 863) for additional details on the training input mode. For a summary of the\\ndata formats supported by each algorithm, see the documentation for the individual algorithms or this\\ntable .\\nNote\\nFor an example that shows how to convert the commonly used numPy array into the\\nprotobuf recordIO format, see https://github.com/awslabs/amazon-sagemaker-examples/', 'table .\\nNote\\nFor an example that shows how to convert the commonly used numPy array into the\\nprotobuf recordIO format, see https://github.com/awslabs/amazon-sagemaker-examples/\\nblob/master/introduction_to_amazon_algorithms/factorization_machines_mnist/\\nfactorization_machines_mnist.ipynb. .\\nIn the protobuf recordIO format, Amazon SageMaker converts each observation in the dataset into\\na binary representation as a set of 4-byte ﬂoats and is then loads it to the protobuf values ﬁeld. If\\nyou are using Python for your data preparation, we strongly recommend that you use these existing\\ntransformations. However, if you are using another language, the protobuf deﬁnition ﬁle below provides\\nthe schema that you use to convert your data into Amazon SageMaker protobuf format.\\nsyntax = \"proto2\";', 'the schema that you use to convert your data into Amazon SageMaker protobuf format.\\nsyntax = \"proto2\";\\n \\n package aialgs.data;\\n \\n option java_package = \"com.amazonaws.aialgorithms.proto\";\\n option java_outer_classname = \"RecordProtos\";\\n65Amazon SageMaker Developer Guide\\nCommon Information\\n \\n // A sparse or dense rank-R tensor that stores data as doubles (float64).\\n message Float32Tensor   {\\n     // Each value in the vector. If keys is empty, this is treated as a\\n     // dense vector.\\n     repeated float values = 1 [packed = true];\\n \\n     // If key is not empty, the vector is treated as sparse, with\\n     // each key specifying the location of the value in the sparse vector.\\n     repeated uint64 keys = 2 [packed = true];', '// If key is not empty, the vector is treated as sparse, with\\n     // each key specifying the location of the value in the sparse vector.\\n     repeated uint64 keys = 2 [packed = true];\\n \\n     // An optional shape that allows the vector to represent a matrix.\\n     // For example, if shape = [ 10, 20 ], floor(keys[i] / 10) gives the row,\\n     // and keys[i] % 20 gives the column.\\n     // This also supports n-dimensonal tensors.\\n     // Note: If the tensor is sparse, you must specify this value.\\n     repeated uint64 shape = 3 [packed = true];\\n }\\n \\n // A sparse or dense rank-R tensor that stores data as doubles (float64).\\n message Float64Tensor {\\n     // Each value in the vector. If keys is empty, this is treated as a\\n     // dense vector.'], 'uris': None, 'data': None, 'metadatas': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'included': [<IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from int_host_emd import ollama_emb\n",
        "import json\n",
        "\n",
        "games_db = Chroma(persist_directory=\"./chroma_db/sagemaker\", embedding_function=ollama_emb)\n",
        "coll = games_db.get() # Gets all the data it will not show the embeddings\n",
        "print(coll)\n",
        "\n",
        "# the json file where the output must be stored\n",
        "out_file = open(\"./json/test.json\", \"w\")\n",
        "\n",
        "json.dump(coll, out_file)\n",
        "\n",
        "out_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.00187452 -0.00159323  0.059373   ...  0.00077881 -0.00433228\n",
            "  0.00565044]\n"
          ]
        }
      ],
      "source": [
        "# To view the stored embeddings as well we need to call the get function below shown method\n",
        "data_with_emd = games_db._collection.get(include=['embeddings'])\n",
        "print(data_with_emd[\"embeddings\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300\n",
            "vAmazon SageMaker Developer Guide\n",
            "Get Information for a Script ............................................................................................395\n",
            "Get Started with Containers....................................................................................................396\n",
            "Pre-built Docker Images - Deep Learning...................................................................................398\n",
            "Pre-built Docker Images - Scikit-learn and Spark ML...................................................................401\n",
            "Example Notebooks ................................................................................................................402\n",
            "Use Your Own Training Algorithms...........................................................................................404\n"
          ]
        }
      ],
      "source": [
        "print(len(coll[\"documents\"]))\n",
        "print(coll[\"documents\"][35])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "107\n"
          ]
        }
      ],
      "source": [
        "overlap_text = \"ways to strengthen phonemic awareness skills, drill phonograms, build reading fl  uency, practice spelling,\"\n",
        "print(len(overlap_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "room.  \n",
            " \n",
            " \n",
            " The student picks up one card and reads the word \n",
            "out loud. He walks around the room searching for a \n",
            "match. When he finds the matching card, he picks \n",
            "it up and reads the word out loud. If he reads the \n",
            "word correctly, he may go and find another word \n",
            "to match. If he does not read the word correctly, he \n",
            "tries again, with help from the teacher as needed. \n",
            "When he finds and reads all the matches, he wins!\n",
            "Group\n",
            "Choose high-frequency words for the students \n",
            "to practice and write each word on two index \n",
            "cards. Make at least five pairs per student. Tell the \n",
            "students how many matches they should each find, \n",
            "based on the number of cards you use. Scatter the \n",
            "cards around the room.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " Each student picks up one card and reads the word\n"
          ]
        }
      ],
      "source": [
        "# Query the data from stored chroma db using embeddings\n",
        "# This is a better approach to do so\n",
        "query = \"How to play reading robot\"\n",
        "emd_query = ollama_emb.embed_query(query)\n",
        "docs = games_db.similarity_search_by_vector(emd_query)\n",
        "\n",
        "print(len(docs))\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing chroma database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ids': ['129fcd36-3e5f-4c9f-a50c-4c11bf406401', '2263f44f-1894-4831-ad02-90b9060f5fc6', '2f047ab4-5cf2-4337-9eac-9a6ded13d531', 'e9b50aed-6447-46f3-bac2-eb10eb970c39', '1e9407e0-289c-4c86-af51-e1fd1fcc2070', 'c37f405c-be2b-46cc-be02-c0bfef489bd1', 'f6d52f0f-bdf1-4083-a68f-1036b791380d', 'dd342b92-deef-44d1-8005-116572c85ecd', '5bdad790-ef78-4fae-971e-3b00bc300521', '4a8e310e-0578-49f8-8dbe-dfefb9a59259', '59513662-76b2-4fd1-bade-62335c577f55', '5dc02bc5-b7fa-417d-98e3-921ca65ae437', '8159395f-08cb-410c-93ee-fb80107f9bc9', 'a97ce6ad-bc2f-44c0-a70c-95c3eb35a95d', 'bc753395-71fb-4963-8be0-952a596821f0', 'f9801d00-0ba2-43c9-8bac-064849d8290b', '069a6985-3701-4f03-9109-736cddf464f9', 'ec94bbfe-36a5-49e7-87ef-9798b38dce51', '26bcccca-bb44-4906-a81c-fbda17533e6d', 'f2218899-0ddd-4f1c-a516-11c00c16e8ae', 'ca5ebf72-06cf-4713-925c-0bb5fd09aaec', '2344c279-5a89-4a09-b58e-839250c56495', 'ab0b5ab0-1029-4b9e-b4a1-d71c6951310a', '9e1a8b84-7a19-42cd-b7da-ea06ba6a9792', '4fadfa65-5900-4280-8fc1-5f1051ec9b26', '1c73430c-65b1-4711-8a54-a8a07e004613', '0df349ff-1f78-4914-935e-6c07a51b40bc', '52c89644-75a0-4097-a65b-4abb53507b45', '677f2c41-74d3-4da5-8eca-01ef263f1dcd', 'd2f7d460-eecc-4bdb-a9a9-c4a6e9cdb4c0', '6e1cb129-c229-4226-b8b9-d05c6232d9ac', '6ad5c1d5-5a84-473b-b3e3-1e2f976de0f2', 'f0cf344e-ec00-4eea-8ba8-73a2739180da', '38acb8db-dfc4-4f40-be34-10251a2ca503', '17727e09-53b7-4db9-ab18-fdcf351d6847', 'a8388d61-42cb-4184-9776-30973d2756b1', 'de0195b5-3dfc-48c3-bb28-4ceb0886885a', 'd61d7265-0b54-40be-a48d-8db6c84edc5c', '1acaa7d4-a696-4674-b676-f68c2273a8ac', '2aca9630-271c-4302-8020-09cba5564d1f', 'c492ad19-d5e5-41ea-ab26-4d9ab7629a64', 'c0939c47-9cd5-491d-afdc-3a7fa3263599', '0462c0c9-1915-4c00-9b4b-f0c02aa22fbb', '9f30e258-b663-48ba-9b4e-820bda06f8d1', 'dd071575-68bb-49b6-839d-3140a3761f95', 'a25ced2e-08b3-41e3-a471-73d190a3bd4e', '4347e338-b386-4acd-8e8f-9e7f79f2be1f', '39ba8762-df9d-47a1-afc4-36b384d20361', '2a8c4f4a-33cc-4efa-8964-69c37666a814', 'b819f482-8959-42e7-9a19-af260c648581', '0376e6e5-2359-4229-8b42-f93374ac9cd0', '004e3c09-6e40-43e2-b9e6-d9a9dfd4a0c6', '8fc06f6a-d76d-4765-a742-162204f7bf37', '1a7b0c19-1601-42a3-8006-bea1d49ac8b5', 'b451d21e-1205-4ed9-be20-a7c7ca40ef77', '3d84cc11-b3b1-4ac3-b00a-6b9f7bad278d', 'e038bd54-11b6-46c0-bca1-bef572c0f13d', '97692c35-afc9-41f7-99a0-6ac5ccb5185e', 'fabd45ce-3652-46d0-8168-85042239ce4a', 'a388b84d-0bdd-4eb4-863a-3a6b6d13d0d2', 'a879f29a-fae9-4e82-926a-d54c91179454', '2b219e54-bd6e-4623-b0ff-fe9cf91f5922', '1acbe4ad-7cb0-4bce-a49c-e41bbe55ba9a', '1a08c2c0-5334-4a7c-89a0-38a1c6d715e4', 'bbdc7021-443f-4de7-81bd-63a3a1523721', '571abb7e-66d7-4415-b684-6a940e54a71c', 'fa268d31-1ac4-4c50-9251-6a9f04997676', 'f49ff52a-7a17-4a02-87f9-aafbf5190500', '221f9a46-a2cd-4002-a29e-5f12cde57485', '4b4d87ec-515e-4afe-9402-067a4019963e', '6ec5e38b-16fd-4c7e-8b22-e4338aa477a5', '478589c0-3005-46b9-a6c8-1c376dbed0f5', '0794d04d-4bec-45cb-a22f-ac49ac17c38f', 'f3bfd44f-951b-49a0-916b-488a9ee3a603', 'ef555d76-e07e-46d8-8a1d-a5cda335d77f', '86606b5b-f95b-46d3-ac9b-a77a9d22af4a', '364ab632-6250-4740-946d-d0fa0f873a15', 'f4b23357-2e6e-429c-9887-97c524da5b92', 'a7623c98-656f-4311-ac09-6edfbed6b32d', '49814ae6-fb08-41f9-a730-c2ecd82a02f7', '5969bdc4-4454-4fc6-8a15-7f9fbf70099b', '260e0299-bb32-4129-8caf-4af7a83ded50', 'e273d76d-efe8-4eca-9966-b16b491ba6d8', 'f0ab04f0-e78b-4dc1-8776-cc1c252bdb96', '0588882e-7627-4d70-835a-b68d69db18b7', 'b30a52c5-3fbb-4e38-862a-db919d14fe3b', '45c1c374-4b59-41e2-a21d-4bd42d5dd19f', '22445663-78c4-44d5-b77c-399a2128f609', '093a4bdb-2c25-4f62-a5a6-6350cb619ad0', '598bed21-97fb-4521-ba41-aebc7e22792d', 'c90474e0-f42f-4062-a06f-ec881ca3c599', '38d2b28e-d19c-4fe7-98a1-b89f3be0bb60', 'fe53ec2c-469c-45e0-bede-60f011d52bdb', '6d9fdfa3-aef6-4371-9cac-610e58ced3bd', '1031fb52-28f3-4d06-bd57-8699736bdf3d', 'df431d4e-5cc3-49c0-951b-e3cbb9555d7f', 'b6babd05-a235-479c-8f09-714304159696'], 'embeddings': None, 'documents': [\"1Introduction\\nWhy Play Games?\\nFluency in reading and writing requires a complex set of skills that need to be practiced over time. Th  e \\nhundreds of games and activities in this book provide engaging practice ideas to practice key skill sets \\nwhile respecting students' needs for variety, movement, and fun!\\nWho Are Th  ese Games For?\\nTh  ese games are designed for anyone teaching students of any age to read, spell, or write. Th  ey can be \\nused with any language arts curriculum to add multi-sensory practice, fun, and engagement!\\nHow it Works\\nTh  e Logic of English Game Book is full of games that strengthen literacy skills. Th  ere are active and fun \\nways to strengthen phonemic awareness skills, drill phonograms, build reading fl  uency, practice spelling,\", 'ways to strengthen phonemic awareness skills, drill phonograms, build reading fl  uency, practice spelling, \\nand improve comprehension and vocabulary. Th  ese games equip parents and teachers to provide all sorts \\nof multi-sensory and engaging practice, including high-energy active games, creative games, card games, \\ntactile games, and more. Whether you’ve got ten minutes or all day, these games can help solidify skills \\nand deepen mastery at each step of the learning process.\\nMost games in this book have alternative directions for group and individual settings. Some are designed \\nspecifi  cally for one setting or the other. Each game has a summary of the materials needed, the suggested \\nage range, and the approximate time required to play that game.\\nGame Book Expansion Pack', 'specifi  cally for one setting or the other. Each game has a summary of the materials needed, the suggested \\nage range, and the approximate time required to play that game.\\nGame Book Expansion Pack\\nEight full-color game boards with a laminate coating \\ndesigned for dry erase markers so you can choose \\nphonograms or words to practice. Used in games like \\nSilent E Ladders and Slides, Spelling Scramble, and \\nPhonogram Bubble Race. Available for purchase at \\nstore.logicofenglish.com.\\nAdditional Materials\\nMany games in this book call for the use of common \\nhousehold or classroom materials such as pencils, markers,\\npaper, dice, and toys. Many of the games also call for Logic\\nof English reusable materials. Learn more about these\\nand other helpful resources at www.logicofenglish.com.', 'paper, dice, and toys. Many of the games also call for Logic\\nof English reusable materials. Learn more about these\\nand other helpful resources at www.logicofenglish.com.\\nLOE Reusable Materials Used in Th  ese Games\\n• Phonogram Game Tiles\\n• Phonogram Game Cards\\n• Basic Phonogram Flash Cards\\n• Student Whiteboards\\nstore.logicofenglish.com.\\n2 Logic of English Game Book\\nGlossary of Terms\\nPhonograms - written representations of speech sounds, such as a, b, ou, tch, and eigh. Th  e phonogram \\ngames in this book are designed to help students practice the phonograms’ sounds. When you play a \\nphonogram game, refer to the phonograms by the sound(s) they make, rather than by letter names.\\nPhonemic Awareness - the ability to identify individual sounds within spoken words.', 'phonogram game, refer to the phonograms by the sound(s) they make, rather than by letter names.\\nPhonemic Awareness - the ability to identify individual sounds within spoken words. \\nTh  is skill is generally practiced auditorily and verbally without written text. \\nSegmenting  - breaking words into their individual sounds.\\nBlending - combining individual sounds into whole words. \\nMorphemes - units of meaning within a word, including roots, prefi  xes, and suffi   xes.\\nMorphology  - the study of roots, prefi  xes, and suffi   xes and how they work together to form words. \\nTemplates  - reproducible templates used in some of the games. Th  ey can be found in the back of this \\nbook. Th  ese templates may be copied.\\nBoards  - full color game boards found in the Game Book Expansion Pack.', 'book. Th  ese templates may be copied.\\nBoards  - full color game boards found in the Game Book Expansion Pack.\\nLogic of English® creates integrated\\nlanguage arts curriculum that\\nsystematically intertwines the\\ndiﬀ  erent skills students need to \\nbecome strong readers and writers.\\n • Phonemic Awareness\\n • Systematic Phonics\\n • Fluency\\n • Vocabulary\\n • Comprehension\\n • Composition\\n • Spelling\\n • Grammar\\n • Handwriting\\nLearn more about all of our products at www.logicofengish.com.\\nFoundations\\nAges 4-7Essentials\\nAges 8+\\nSounding Out the \\nSight Words\\nAll Ages3\\n Table of Contents\\nPhonemic Awareness Games 7\\nGame Ages Page\\nSound Detective 4+ 8\\nSorting Sounds 4+ 9\\nCompound Blending Baskets 4-12 10\\nCompound Word Blend & Find 4-12 11\\nBlending Animal Names 4-8 12\\nBlend and Do 4+ 13', 'Phonemic Awareness Games 7\\nGame Ages Page\\nSound Detective 4+ 8\\nSorting Sounds 4+ 9\\nCompound Blending Baskets 4-12 10\\nCompound Word Blend & Find 4-12 11\\nBlending Animal Names 4-8 12\\nBlend and Do 4+ 13\\nConsonant Blending Game 4-12 14Game Ages Page\\nBlending I Spy 4+ 15\\nFirst Sound Bingo 4+ 16\\nVowel Stacks 4-12 17\\nChoose the Object 4-8 18\\nSegmenting I Spy 4-12 19\\nTwenty Sound Questions 6+ 20\\nActive Phonogram Games 21\\nGame Ages Page\\nPhonogram Light-Up 4-10 22\\nPhonogram Retriever 4-9 23\\nPhonogram Hop 4-6 24\\nPhonogram Aerobics 4-8 25\\nPhonogram Color Grab 4-8 26\\nPhonogram Journey 4-8 27\\nPhonogram Scatter 4-10 28\\nPhonogram Obstacle Course 4-10 29\\nPhonogram Bounce 4-6 30\\nPhonogram Hopscotch 5-10 31\\nPhonogram Maze 4-8 32\\nPhonogram Mountain 4-8 33\\nPhonogram Tightrope 4-8 34', 'Phonogram Scatter 4-10 28\\nPhonogram Obstacle Course 4-10 29\\nPhonogram Bounce 4-6 30\\nPhonogram Hopscotch 5-10 31\\nPhonogram Maze 4-8 32\\nPhonogram Mountain 4-8 33\\nPhonogram Tightrope 4-8 34\\nPhonogram Stop and Go 4-10 35\\nPhonogram Pyramid 5-9 36\\nPhonogram Hop Along 5-10 37\\nPhonogram Shoot 5-10 38Game Ages Page\\nLive Phonogram Board Game 4-9 39\\nPhonogram Telephone 5-9 40\\nPhonogram Back Writing 4-10 41\\nSnatch the Match! 4-10 42\\nPhonogram Writing Race 5-10 43\\nPhonogram Arcade Race 4-12 44\\nPhonogram Treasure Hunt 4-10 45\\nPhonogram Bowling 4-10 46\\nPhonogram Fishing 4-9 47\\nPhonogram Football 6+ 48\\nPhonogram Soccer 6+ 49\\nPhonogram Baseball 6+ 50\\nPhonogram Basketball 6+ 51\\nPhonogram Marco Polo 5-10 52\\nPhonogram Collection 5-9 53\\nEcholocation 5-10 54\\nPhonogram Airplanes 5-10 55\\nPhonogram Card Games 57', 'Phonogram Baseball 6+ 50\\nPhonogram Basketball 6+ 51\\nPhonogram Marco Polo 5-10 52\\nPhonogram Collection 5-9 53\\nEcholocation 5-10 54\\nPhonogram Airplanes 5-10 55\\nPhonogram Card Games 57\\nGame Ages Page\\nPhonogram Snatch 4-10 58\\nRotten Egg 4-10 59\\nSpeed 8+ 60\\nLast One! 5-10 61\\nPhonogram Memory 4+ 62Game Ages Page\\nSlap It! 5-12 63\\nGo Fish! 4-8 64\\nDragon 4-9 65\\nABC Order Race 6-12 66\\nPhonogram Train 4-7 674\\n Logic of English Game BookPhonogram Board Games 69\\nGame Ages Page\\nPhonogram Bubble Race 4+ 70\\nPhonogram Board Game 4-9 71\\nPhonogram Bingo 4+ 72Game Ages Page\\nPhonogram Tic-Tac-Toe 6+ 73\\nVowel Bingo 4+ 74\\nPhonogram Team-Up 4-10 75\\nPhonogram Tile Games 77\\nGame Ages Page\\nPhonogram Corners 6-12 78\\nPhonogram Sets and Runs 7+ 79Game Ages Page\\nTen in a Row 4+ 80\\nCreative Phonogram Games 81', 'Vowel Bingo 4+ 74\\nPhonogram Team-Up 4-10 75\\nPhonogram Tile Games 77\\nGame Ages Page\\nPhonogram Corners 6-12 78\\nPhonogram Sets and Runs 7+ 79Game Ages Page\\nTen in a Row 4+ 80\\nCreative Phonogram Games 81\\nGame Ages Page\\nPhonogram Collage 4-12 82\\nCreate a Find 5-14 83\\nPhonogram Nature Art 4-10 84Game Ages Page\\nCreate a Book 4-7 85\\nChalk It Up 4-9 86\\nPhonogram Speed Games 87\\nGame Ages Page\\nBeat the Clock 5-12 88\\nSee It - Say It - Write It 4-10 89\\nPhonogram Flip 5-10 90\\nPhonogram Race 5-10 91\\nPhonogram Challenge 4-8 92Game Ages Page\\nWrite and Erase 5-10 93\\nTeacher Trouble 4-6 94\\nLast One Standing 4-8 95\\nPhonogram Read and Write 5-10 96\\nActive Reading Games 97\\nGame Ages Page\\nReading Light-Up 4-10 98\\nWord Retriever 4-7 99\\nReading Journey 4-8 100\\nWord Mountain 4-8 101\\nReading Tightrope 4-7 102', 'Phonogram Read and Write 5-10 96\\nActive Reading Games 97\\nGame Ages Page\\nReading Light-Up 4-10 98\\nWord Retriever 4-7 99\\nReading Journey 4-8 100\\nWord Mountain 4-8 101\\nReading Tightrope 4-7 102\\nReading Stop and Go 4-10 103\\nReading Fluency Sort 6-10 104\\nHigh-Frequency Word Run 6-12 105\\nReading Tower 4-7 106\\nReading Hop Along 5-10 107\\nWord Maze 4-8 108\\nIsland Reading Tour 4-7 109\\nHigh-Frequency Word Scatter 4-9 110\\nSnatch the Match! 5-10 111\\nHigh-Frequency Word Stations 6+ 112\\nWord Arcade Race 4-12 113\\nReading Treasure Hunt 4-10 114\\nWord Hopscotch 5-10 115Game Ages Page\\nWord Bowling 4-10 116\\nHigh-Frequency Word Fishing 4-9 117\\nReading Football 6+ 118\\nReading Soccer 6+ 119\\nReading Baseball 6+ 120\\nReading Basketball 6+ 121\\nSilent E Machine 4-7 122\\nSilent E Hopscotch 5-10 123', 'High-Frequency Word Fishing 4-9 117\\nReading Football 6+ 118\\nReading Soccer 6+ 119\\nReading Baseball 6+ 120\\nReading Basketball 6+ 121\\nSilent E Machine 4-7 122\\nSilent E Hopscotch 5-10 123\\nAirplane Reading 5-10 124\\nReading Charades 4+ 125\\nHigh-Frequency Word Race 4-7 126\\nReading Y Words 5-9 127\\nLong Vowel Hunt 5-8 128\\nSilent E Store 5-9 129\\nMarco Polo Word Game 5-10 130\\nCompound Echolocation 5-10 131\\nSuffix Collection 7-12 1325\\n Reading Card Games 133\\nGame Ages Page\\nSort Those Words 6+ 134\\nFluency Trail 4-9 135\\nReading Trios 8+ 136\\nGo Fish! 6-12 137Game Ages Page\\nLong Vowel Sort 6+ 138\\nFor My Birthday I Want a... 5-10 139\\nPast Tense Memory Game 5+ 140\\nFox in the Hen House 4-7 141\\nReading Board Games 143\\nGame Ages Page\\nReading Bubble Race 4-9 144\\nReading Board Game 4+ 145\\nReading Bingo 4+ 146', 'Past Tense Memory Game 5+ 140\\nFox in the Hen House 4-7 141\\nReading Board Games 143\\nGame Ages Page\\nReading Bubble Race 4-9 144\\nReading Board Game 4+ 145\\nReading Bingo 4+ 146\\nReading Tic-Tac-Toe 5+ 147Game Ages Page\\nVowel Race Track 6-12 148\\nLong Vowel Switchback 5+ 149\\nSilent E Board Game 4-9 150\\nSilent E Ladders and Slides 6-10 151\\nReading Speed Games 153\\nGame Ages Page\\nReading Beat the Clock 6+ 154\\nSentence Builder 7+ 155Game Ages Page\\nEraser Race 6+ 156\\nActive Spelling Games 157\\nGame Ages Page\\nSpelling Treasure Hunt 5-10 158\\nSpelling Obstacle Course 6-10 159\\nSpelling Tiles Relay 4-9 160\\nFly Swatter Spelling 4-9 161\\nSpelling Journey 5-8 162\\nWriting Race 6-10 163\\nSpelling Arcade Race 6-12 164\\nThe Spelling Circuit 6-12 165\\nSpelling Balancing Act 7+ 166Game Ages Page\\nTeam Spelling 7-12 167', 'Spelling Journey 5-8 162\\nWriting Race 6-10 163\\nSpelling Arcade Race 6-12 164\\nThe Spelling Circuit 6-12 165\\nSpelling Balancing Act 7+ 166Game Ages Page\\nTeam Spelling 7-12 167\\nSpelling Football 6+ 168\\nSpelling Soccer 6+ 169\\nSpelling Baseball 6+ 170\\nSpelling Basketball 6+ 171\\nI’m the Teacher 6+ 172\\nSpelling I Spy 6+ 173\\nSpelling Detectives 7+ 174\\nSchwavenger Hunt 6+ 175\\nSpelling Card Games 177\\nGame Ages Page\\nAdd and Take 7+ 178\\nMake a Memory Game 6+ 179Game Ages Page\\nGuess My Word 6+ 180\\nHouse of Cards 7+ 181\\nSpelling Board Games 183\\nGame Ages Page\\nWord Search 7+ 184\\nSink and Spell 7+ 185\\nSpelling Tic-Tac-Toe 6+ 186Game Ages Page\\nCreate a Crossword Puzzle 8+ 187\\nSpelling Scramble 7+ 188\\nSpelling Tile Games 189\\nGame Ages Page\\nSpelling Hide and Go Seek 6-12 190\\nCreating New Words 5+ 191', 'Spelling Tic-Tac-Toe 6+ 186Game Ages Page\\nCreate a Crossword Puzzle 8+ 187\\nSpelling Scramble 7+ 188\\nSpelling Tile Games 189\\nGame Ages Page\\nSpelling Hide and Go Seek 6-12 190\\nCreating New Words 5+ 191\\nSpeedy Spelling Tiles 6+ 192Game Ages Page\\nHow Many Words? 7+ 193\\nSpelling Scavenger Hunt 9+ 1946\\n Logic of English Game BookCreative Spelling Games 195\\nGame Ages Page\\nRainbow Writing 7-12 196\\nSpelling Magician 6-10 197\\nType the Words 6+ 198\\nWord Picture 7-14 199\\nSpelling Collage 7+ 200\\nSpelling Nature Art 5-9 201\\nPipe Cleaner Spelling 7-10 202Game Ages Page\\nY arn Spelling 7-10 203\\nWord Quilt 4-10 204\\nPicture Dictionary 7+ 205\\nGuess My Picture 7+ 206\\nStory Writing 8+ 207\\nIllustrate the Equation 6+ 208\\nSpelling Speed Games 209\\nGame Ages Page\\nRecord the Words 7-12 210', 'Word Quilt 4-10 204\\nPicture Dictionary 7+ 205\\nGuess My Picture 7+ 206\\nStory Writing 8+ 207\\nIllustrate the Equation 6+ 208\\nSpelling Speed Games 209\\nGame Ages Page\\nRecord the Words 7-12 210\\nOther Handed Spelling 6-12 211\\nSpeed Writing 6-12 212Game Ages Page\\nTiny Spelling 7-12 213\\nSpelling Graph Paper 6-9 214\\nSpell It Loud 6-12 215\\nTactile Spelling Activities 217\\nGame Ages Page\\nSalt Box Race 4-7 218\\nPlaydough Carving 5-12 219\\nWord Painting 6-12 220\\nCotton Swab Erasing 6-12 221Game Ages Page\\nBlind Spelling 6-12 222\\nGlitter Glue 6-12 223\\nSpelling Actions 4-12 224\\nSet It To Music 7-12 225\\nOther Spelling Games 227\\nGame Ages Page\\nCorrect the Teacher 7+ 228\\nCompound Word Brainstorm 6+ 229Game Ages Page\\nDictation Bookmark 6-12 230\\nComprehension Activities 231\\nGame Ages Page\\nRead and Do 4-8 232', 'Game Ages Page\\nCorrect the Teacher 7+ 228\\nCompound Word Brainstorm 6+ 229Game Ages Page\\nDictation Bookmark 6-12 230\\nComprehension Activities 231\\nGame Ages Page\\nRead and Do 4-8 232\\nWhat Are Y ou Do-ING? 5-12 233\\nReading Robot 5-10 234\\nFive W’s 7+ 235Game Ages Page\\nCreate a Zoo! 6+ 236\\nTravel Guide 6+ 237\\nAdjective-Noun Corners 8-12 238\\nWhat’s That Emoji? 7+ 239\\nMorpheme Activities 241\\nGame Ages Page\\nCon- or Com- Match-Up 8+ 242\\nDefinition Match-Up 8+ 243\\nMorpheme Brainstorm 12+ 244\\nIllustrate It! 9+ 245Game Ages Page\\nMorpheme Collage 8+ 246\\nMorpheme Race 8+ 247\\nNewspaper Highlight 7+ 248\\nMorpheme Puzzle 7+ 249\\nAppendix 251\\nAppendix A: Word Lists 251\\nAppendix B: Master Templates 259\\nAppendix C: Game Lists 287Phonemic Awareness Games  Logic of English Game Book\\n12', 'Morpheme Puzzle 7+ 249\\nAppendix 251\\nAppendix A: Word Lists 251\\nAppendix B: Master Templates 259\\nAppendix C: Game Lists 287Phonemic Awareness Games  Logic of English Game Book\\n12\\nBlending Animal Names Ages 4-8\\nSetting:  Individual & Group\\nTime:  1-3 minutes\\nSupplies:  Animal pictures or toys\\nSet Up  How to Play\\nIndividual\\nChoose four to ten animals whose names are just \\none syllable. Set out pictures or toys that represent \\nthose animals. For an extra challenge, choose some \\nmulti-syllable animal names.  The teacher segments the name of an animal, \\nsaying the individual sounds with a pause between \\nthem (example: /d-o-g/). The student must blend \\nthe sounds back together into a word and hold up \\nthe correct animal.\\nGroup\\nChoose animals whose names are just one syllable.', 'them (example: /d-o-g/). The student must blend \\nthe sounds back together into a word and hold up \\nthe correct animal.\\nGroup\\nChoose animals whose names are just one syllable. \\nFor an extra challenge, choose some multi-syllable \\nanimal names. Set out pictures or toys that \\nrepresent those animals.  \\n \\n \\n The teacher segments the name of an animal, \\nsaying the individual sounds with a pause between \\nthem (example: /d-o-g/). The first player must \\nblend the sounds back together into a word and \\nhold up the correct animal. The rest of the players \\ngive thumbs up if they agree with his answer or \\nthumbs down if they disagree. If he is incorrect, he \\nmay try again. Then another student takes a turn.\\nSample Words\\nOne-Syllable Words:\\ndog, cat, fish, fly, goat, cow, mouse, deer, horse, pig,', 'thumbs down if they disagree. If he is incorrect, he \\nmay try again. Then another student takes a turn.\\nSample Words\\nOne-Syllable Words:\\ndog, cat, fish, fly, goat, cow, mouse, deer, horse, pig, \\nbird, owl, hen, ant, sheep, duck, mole, goose, bearMulti-Syllable Words:\\nturtle, lion, rabbit, tiger, pony, squirrel, llama, panda, \\nmonkey, turkey, gerbil, chicken, elephant, dinosaur\\nVariations\\nAnimal Actors\\nSegment animal names and ask the student to \\nblend the word together and act like the animal.\\nDress-Up Blending\\nSet out a pile of dress-up clothes. Segment a word \\n(h-a-t) and ask the student to pick out that piece of \\nclothing and put it on.Student Pairs\\nGroup the students into pairs. Player A chooses \\nthe name of one of the animals and says it with all', '(h-a-t) and ask the student to pick out that piece of \\nclothing and put it on.Student Pairs\\nGroup the students into pairs. Player A chooses \\nthe name of one of the animals and says it with all \\nthe sounds “un-glued” or segmented. Player B must \\n“glue” or blend the sounds back together and find \\nthe correct animal. Active Phonogram Games\\n29\\nPhonogram Obstacle Course Ages 4-10\\nSetting:  Individual & Group\\nTime:  7-15 minutes\\nSupplies:  Whiteboards and dry erase markers or clipboards with paper and pencils, Phonogram Game \\nCards, obstacles\\nSet Up  How to Play\\nIndividual\\nSet up nine stations with a Phonogram Game Card \\nand a dry erase marker or pencil at each station. Put \\nobstacles between the stations to run around, crawl \\nunder, balance on, or climb over. Give the student a', 'and a dry erase marker or pencil at each station. Put \\nobstacles between the stations to run around, crawl \\nunder, balance on, or climb over. Give the student a \\nwhiteboard or a clipboard with paper.The student follows the obstacle course, stopping \\nat each station to read a phonogram, write it on \\nthe whiteboard or clipboard, and show it to the \\nteacher. When the teacher nods “yes,” the student \\nmay go on to the next obstacle.\\nGroup\\nSet up nine stations around the room with a \\nPhonogram Game Card and a dry erase marker or \\npencil at each station. Put obstacles between the \\nstations to run around, crawl under, balance on, or \\nclimb over. Give each student a whiteboard or a \\nclipboard with paper.  \\n \\n \\n Assign a student referee to each station. The referee', 'stations to run around, crawl under, balance on, or \\nclimb over. Give each student a whiteboard or a \\nclipboard with paper.  \\n \\n \\n Assign a student referee to each station. The referee  \\nmakes sure the phonogram is read and written \\ncorrectly. One after another, the students follow the  \\ncourse, stop at each station to read a phonogram, \\nwrite it on the whiteboard or clipboard, and show \\nit to the referee. When the referee nods “yes,” the \\nstudent may go on to the next obstacle. When \\na student finishes the course, he moves into the \\nposition of a referee, freeing the referee to move \\ninto the line to complete the obstacle course.\\nVariations\\nObstacle Relay Teams\\nDivide the students into three equal teams. Set up \\ntwo short obstacle courses. The members of Team', 'into the line to complete the obstacle course.\\nVariations\\nObstacle Relay Teams\\nDivide the students into three equal teams. Set up \\ntwo short obstacle courses. The members of Team \\nOne referee both courses for the first round. Team \\nTwo forms a relay line at one course and Team \\nThree forms a relay line at the other course. One \\nplayer progresses through the course, reading and \\nwriting the phonograms, then tags the next player. \\nRace to be the fastest relay team. Then rotate the \\nteams so that each team gets one chance to referee \\nand two chances to race.Note: Adjust the setup to accommodate your \\ngroup size. For example, with 24 students you \\ncould have three teams of eight students, and two \\ncourses with four stations. With 20 students you', 'group size. For example, with 24 students you \\ncould have three teams of eight students, and two \\ncourses with four stations. With 20 students you \\ncould have four teams of five students, and two \\ncourses with five stations.Active Reading Games Logic of English Game Book\\n110\\nHigh-Frequency Word Scatter Ages 4-9\\nSetting:  Individual & Group\\nTime:  5-10 minutes\\nSupplies:  High-frequency words to practice, index cards, pen\\nSet Up  How to Play\\nIndividual\\nChoose five to twenty-five high-frequency words \\nfor the student to practice and write each word on \\ntwo index cards. Scatter the index cards around the \\nroom.  \\n \\n \\n The student picks up one card and reads the word \\nout loud. He walks around the room searching for a \\nmatch. When he finds the matching card, he picks', 'room.  \\n \\n \\n The student picks up one card and reads the word \\nout loud. He walks around the room searching for a \\nmatch. When he finds the matching card, he picks \\nit up and reads the word out loud. If he reads the \\nword correctly, he may go and find another word \\nto match. If he does not read the word correctly, he \\ntries again, with help from the teacher as needed. \\nWhen he finds and reads all the matches, he wins!\\nGroup\\nChoose high-frequency words for the students \\nto practice and write each word on two index \\ncards. Make at least five pairs per student. Tell the \\nstudents how many matches they should each find, \\nbased on the number of cards you use. Scatter the \\ncards around the room.  \\n \\n \\n \\n \\n \\n \\n Each student picks up one card and reads the word', 'students how many matches they should each find, \\nbased on the number of cards you use. Scatter the \\ncards around the room.  \\n \\n \\n \\n \\n \\n \\n Each student picks up one card and reads the word \\nout loud. All the students walk around the room \\nsearching for a match. When a student finds the \\nmatching card, he picks it up and reads the word to \\nthe teacher. If he reads the word correctly, he may \\ngo and find another word to match. If he does not \\nread the word correctly, he tries again, with help \\nfrom the teacher as needed. If another student is \\nholding the matching card, they may play a tie-\\nbreaking game to determine who will collect the \\nmatch. Once students find their quota of matches, \\nthey may either sit down or help other students. At \\nthe end of the game, students take turns reading', 'match. Once students find their quota of matches, \\nthey may either sit down or help other students. At \\nthe end of the game, students take turns reading \\nthe words they found out loud to the group.\\nVariations\\nCompetition\\nStudents race to find as many pairs as they can. \\nThey must take each pair to the teacher and read \\nthe word correctly before looking for another pair. \\nThe student with the most pairs at the end wins!Timed Scatter\\nSet a timer and record how long it takes the \\nstudent to find all the pairs. Scatter the cards again \\nand see if the student can beat her record! Active Spelling Games\\n173\\nSpelling I Spy Ages 6+\\nSetting:  Individual & Group\\nTime:  1-5 minutes\\nSupplies:  Words to practice, index cards, pen, whiteboards and dry erase markers or pencils and notepads', '173\\nSpelling I Spy Ages 6+\\nSetting:  Individual & Group\\nTime:  1-5 minutes\\nSupplies:  Words to practice, index cards, pen, whiteboards and dry erase markers or pencils and notepads\\nSet Up  How to Play\\nIndividual\\nChoose words to practice spelling and write them \\non index cards. Hang the cards around the room \\nin clear sight of the student. The teacher plays the \\ngame with the student. The teacher and student \\neach hold a whiteboard and dry erase marker, or a \\npencil and notepad.  \\n \\n One player chooses a spelling word. He provides \\na clue to which word he is thinking of by saying, “I \\nspy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants. “ “I spy a word that is \\nan antonym of ____.” The other player guesses', 'spy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants. “ “I spy a word that is \\nan antonym of ____.” The other player guesses \\nwhich word he spies by walking to where that word \\nis hanging. When he finds the right word, both \\nplayers write it.\\nGroup\\nChoose words to practice spelling and write them \\non index cards. Hang the cards around the room \\nin clear sight of all players. Give each student a \\nwhiteboard and dry erase marker.  \\n \\n \\n \\n One player chooses a spelling word. He provides \\na clue to which word he is thinking of by saying, “I \\nspy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants.” “I spy a word that is an', 'spy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants.” “I spy a word that is an \\nantonym of ____.” Other players guess which word \\nhe spies by walking to where that word is hanging. \\nWhen they have found the right word, all the \\nplayers write it.\\nVariations\\nChallenge\\nInstead of hanging word cards around the room, \\nchallenge students to describe the spelling of \\nobjects they see in the room.Comprehension Activities Logic of English Game Book\\n234\\nReading Robot Ages 5-10\\nSetting:  Individual & Group\\nTime:  5-15 minutes\\nSupplies:  Slips of paper, pen, objects or pictures of objects mentioned in the phrases\\nSet Up  How to Play\\nIndividual & Group\\nWrite phrases from the list below on slips of paper', 'Time:  5-15 minutes\\nSupplies:  Slips of paper, pen, objects or pictures of objects mentioned in the phrases\\nSet Up  How to Play\\nIndividual & Group\\nWrite phrases from the list below on slips of paper \\nfor the student(s) to read, one phrase on each slip. \\nCollect the items mentioned in the phrases or \\nprovide pictures of the items.The students are robots. Each student draws a slip, \\nreads the directions, and does what the directions \\nsay. Multiple players take turns.  \\nSample Phrases\\nPut the dog next to the cow.\\nPut the cat by the dog.\\nPut the fish by the cat.\\nPut the goat next to the cow.\\nPut the frog on top of the goat.\\nPut the duck on top of the fish.\\nPut the hen by the cat.\\nPut the pig by the frog.\\nPut the cat next to the dog.\\nPut the frog by the cat.\\nPut the goat by the frog.', 'Put the frog on top of the goat.\\nPut the duck on top of the fish.\\nPut the hen by the cat.\\nPut the pig by the frog.\\nPut the cat next to the dog.\\nPut the frog by the cat.\\nPut the goat by the frog.\\nPut the pig on top of the frog.\\nPut the hen by the fish.\\nPut the cow next to the hen.Put the duck on top of the cow.\\nPut the rooster on top of the barn.\\nPut the horse by the tree.\\nPut the cow by the horse.\\nPut the sheep in the barn.\\nPut the duck in front of the barn.\\nPut the pig on the path.\\nPut the dresser next to the bed.\\nPut the rug by the bed and the \\ndresser.\\nPut the pillow on the bed.\\nPut the blanket on the bed.\\nPut the doll under the blanket.\\nPut the bear on top of the blanket.Drive the train on the tracks.\\nStop the train.\\nDrive the train through the cave.\\nDrive the train fast.', 'Put the blanket on the bed.\\nPut the doll under the blanket.\\nPut the bear on top of the blanket.Drive the train on the tracks.\\nStop the train.\\nDrive the train through the cave.\\nDrive the train fast.\\nSwitch tracks.\\nDrive the train slow.\\nDrive the train up the hill.\\nDrive the train down the hill.\\nPark the train.\\nPark the car by the train.\\nMake the train go fast on the tracks.\\nDrive the car on the road.\\nMake the car stop.\\nMake the car drive slow on the road.\\nVariations\\nRobotic Voices\\nStudents may read the phrases in different voices.Challenge\\nAsk students to write directions for other robots to \\nfollow.Morpheme Activities Logic of English Game Book\\n248\\nNewspaper Highlight Ages 7+\\nSetting:  Individual & Group\\nTime:  5-10 minutes\\nSupplies:  Newspapers, highlighters\\nSet Up  How to Play', 'follow.Morpheme Activities Logic of English Game Book\\n248\\nNewspaper Highlight Ages 7+\\nSetting:  Individual & Group\\nTime:  5-10 minutes\\nSupplies:  Newspapers, highlighters\\nSet Up  How to Play\\nIndividual & Group\\nProvide each student with a section of the \\nnewspaper or have students find an article that \\nthey are interested in. Provide each student with a \\nhighlighter.  \\n \\n Each student reads their newspaper article and \\nsearches for morphemes they have learned. When \\na student finds one of the morphemes, he marks \\nit with the highlighter. Once all the students finish \\ntheir articles, they share each word they found, the \\nmeaning of the morpheme, and the meaning of the \\nword.\\nVariations\\nCompetition\\nThe player who can find and define the most \\nmorphemes wins!Composition Challenge', 'meaning of the morpheme, and the meaning of the \\nword.\\nVariations\\nCompetition\\nThe player who can find and define the most \\nmorphemes wins!Composition Challenge\\nStudents create their own sentences using the \\nwords that contain the selected morphemes.', \"1Introduction\\nWhy Play Games?\\nFluency in reading and writing requires a complex set of skills that need to be practiced over time. Th  e \\nhundreds of games and activities in this book provide engaging practice ideas to practice key skill sets \\nwhile respecting students' needs for variety, movement, and fun!\\nWho Are Th  ese Games For?\\nTh  ese games are designed for anyone teaching students of any age to read, spell, or write. Th  ey can be \\nused with any language arts curriculum to add multi-sensory practice, fun, and engagement!\\nHow it Works\\nTh  e Logic of English Game Book is full of games that strengthen literacy skills. Th  ere are active and fun \\nways to strengthen phonemic awareness skills, drill phonograms, build reading fl  uency, practice spelling,\", 'ways to strengthen phonemic awareness skills, drill phonograms, build reading fl  uency, practice spelling, \\nand improve comprehension and vocabulary. Th  ese games equip parents and teachers to provide all sorts \\nof multi-sensory and engaging practice, including high-energy active games, creative games, card games, \\ntactile games, and more. Whether you’ve got ten minutes or all day, these games can help solidify skills \\nand deepen mastery at each step of the learning process.\\nMost games in this book have alternative directions for group and individual settings. Some are designed \\nspecifi  cally for one setting or the other. Each game has a summary of the materials needed, the suggested \\nage range, and the approximate time required to play that game.\\nGame Book Expansion Pack', 'specifi  cally for one setting or the other. Each game has a summary of the materials needed, the suggested \\nage range, and the approximate time required to play that game.\\nGame Book Expansion Pack\\nEight full-color game boards with a laminate coating \\ndesigned for dry erase markers so you can choose \\nphonograms or words to practice. Used in games like \\nSilent E Ladders and Slides, Spelling Scramble, and \\nPhonogram Bubble Race. Available for purchase at \\nstore.logicofenglish.com.\\nAdditional Materials\\nMany games in this book call for the use of common \\nhousehold or classroom materials such as pencils, markers,\\npaper, dice, and toys. Many of the games also call for Logic\\nof English reusable materials. Learn more about these\\nand other helpful resources at www.logicofenglish.com.', 'paper, dice, and toys. Many of the games also call for Logic\\nof English reusable materials. Learn more about these\\nand other helpful resources at www.logicofenglish.com.\\nLOE Reusable Materials Used in Th  ese Games\\n• Phonogram Game Tiles\\n• Phonogram Game Cards\\n• Basic Phonogram Flash Cards\\n• Student Whiteboards\\nstore.logicofenglish.com.\\n2 Logic of English Game Book\\nGlossary of Terms\\nPhonograms - written representations of speech sounds, such as a, b, ou, tch, and eigh. Th  e phonogram \\ngames in this book are designed to help students practice the phonograms’ sounds. When you play a \\nphonogram game, refer to the phonograms by the sound(s) they make, rather than by letter names.\\nPhonemic Awareness - the ability to identify individual sounds within spoken words.', 'phonogram game, refer to the phonograms by the sound(s) they make, rather than by letter names.\\nPhonemic Awareness - the ability to identify individual sounds within spoken words. \\nTh  is skill is generally practiced auditorily and verbally without written text. \\nSegmenting  - breaking words into their individual sounds.\\nBlending - combining individual sounds into whole words. \\nMorphemes - units of meaning within a word, including roots, prefi  xes, and suffi   xes.\\nMorphology  - the study of roots, prefi  xes, and suffi   xes and how they work together to form words. \\nTemplates  - reproducible templates used in some of the games. Th  ey can be found in the back of this \\nbook. Th  ese templates may be copied.\\nBoards  - full color game boards found in the Game Book Expansion Pack.', 'book. Th  ese templates may be copied.\\nBoards  - full color game boards found in the Game Book Expansion Pack.\\nLogic of English® creates integrated\\nlanguage arts curriculum that\\nsystematically intertwines the\\ndiﬀ  erent skills students need to \\nbecome strong readers and writers.\\n • Phonemic Awareness\\n • Systematic Phonics\\n • Fluency\\n • Vocabulary\\n • Comprehension\\n • Composition\\n • Spelling\\n • Grammar\\n • Handwriting\\nLearn more about all of our products at www.logicofengish.com.\\nFoundations\\nAges 4-7Essentials\\nAges 8+\\nSounding Out the \\nSight Words\\nAll Ages3\\n Table of Contents\\nPhonemic Awareness Games 7\\nGame Ages Page\\nSound Detective 4+ 8\\nSorting Sounds 4+ 9\\nCompound Blending Baskets 4-12 10\\nCompound Word Blend & Find 4-12 11\\nBlending Animal Names 4-8 12\\nBlend and Do 4+ 13', 'Phonemic Awareness Games 7\\nGame Ages Page\\nSound Detective 4+ 8\\nSorting Sounds 4+ 9\\nCompound Blending Baskets 4-12 10\\nCompound Word Blend & Find 4-12 11\\nBlending Animal Names 4-8 12\\nBlend and Do 4+ 13\\nConsonant Blending Game 4-12 14Game Ages Page\\nBlending I Spy 4+ 15\\nFirst Sound Bingo 4+ 16\\nVowel Stacks 4-12 17\\nChoose the Object 4-8 18\\nSegmenting I Spy 4-12 19\\nTwenty Sound Questions 6+ 20\\nActive Phonogram Games 21\\nGame Ages Page\\nPhonogram Light-Up 4-10 22\\nPhonogram Retriever 4-9 23\\nPhonogram Hop 4-6 24\\nPhonogram Aerobics 4-8 25\\nPhonogram Color Grab 4-8 26\\nPhonogram Journey 4-8 27\\nPhonogram Scatter 4-10 28\\nPhonogram Obstacle Course 4-10 29\\nPhonogram Bounce 4-6 30\\nPhonogram Hopscotch 5-10 31\\nPhonogram Maze 4-8 32\\nPhonogram Mountain 4-8 33\\nPhonogram Tightrope 4-8 34', 'Phonogram Scatter 4-10 28\\nPhonogram Obstacle Course 4-10 29\\nPhonogram Bounce 4-6 30\\nPhonogram Hopscotch 5-10 31\\nPhonogram Maze 4-8 32\\nPhonogram Mountain 4-8 33\\nPhonogram Tightrope 4-8 34\\nPhonogram Stop and Go 4-10 35\\nPhonogram Pyramid 5-9 36\\nPhonogram Hop Along 5-10 37\\nPhonogram Shoot 5-10 38Game Ages Page\\nLive Phonogram Board Game 4-9 39\\nPhonogram Telephone 5-9 40\\nPhonogram Back Writing 4-10 41\\nSnatch the Match! 4-10 42\\nPhonogram Writing Race 5-10 43\\nPhonogram Arcade Race 4-12 44\\nPhonogram Treasure Hunt 4-10 45\\nPhonogram Bowling 4-10 46\\nPhonogram Fishing 4-9 47\\nPhonogram Football 6+ 48\\nPhonogram Soccer 6+ 49\\nPhonogram Baseball 6+ 50\\nPhonogram Basketball 6+ 51\\nPhonogram Marco Polo 5-10 52\\nPhonogram Collection 5-9 53\\nEcholocation 5-10 54\\nPhonogram Airplanes 5-10 55\\nPhonogram Card Games 57', 'Phonogram Baseball 6+ 50\\nPhonogram Basketball 6+ 51\\nPhonogram Marco Polo 5-10 52\\nPhonogram Collection 5-9 53\\nEcholocation 5-10 54\\nPhonogram Airplanes 5-10 55\\nPhonogram Card Games 57\\nGame Ages Page\\nPhonogram Snatch 4-10 58\\nRotten Egg 4-10 59\\nSpeed 8+ 60\\nLast One! 5-10 61\\nPhonogram Memory 4+ 62Game Ages Page\\nSlap It! 5-12 63\\nGo Fish! 4-8 64\\nDragon 4-9 65\\nABC Order Race 6-12 66\\nPhonogram Train 4-7 674\\n Logic of English Game BookPhonogram Board Games 69\\nGame Ages Page\\nPhonogram Bubble Race 4+ 70\\nPhonogram Board Game 4-9 71\\nPhonogram Bingo 4+ 72Game Ages Page\\nPhonogram Tic-Tac-Toe 6+ 73\\nVowel Bingo 4+ 74\\nPhonogram Team-Up 4-10 75\\nPhonogram Tile Games 77\\nGame Ages Page\\nPhonogram Corners 6-12 78\\nPhonogram Sets and Runs 7+ 79Game Ages Page\\nTen in a Row 4+ 80\\nCreative Phonogram Games 81', 'Vowel Bingo 4+ 74\\nPhonogram Team-Up 4-10 75\\nPhonogram Tile Games 77\\nGame Ages Page\\nPhonogram Corners 6-12 78\\nPhonogram Sets and Runs 7+ 79Game Ages Page\\nTen in a Row 4+ 80\\nCreative Phonogram Games 81\\nGame Ages Page\\nPhonogram Collage 4-12 82\\nCreate a Find 5-14 83\\nPhonogram Nature Art 4-10 84Game Ages Page\\nCreate a Book 4-7 85\\nChalk It Up 4-9 86\\nPhonogram Speed Games 87\\nGame Ages Page\\nBeat the Clock 5-12 88\\nSee It - Say It - Write It 4-10 89\\nPhonogram Flip 5-10 90\\nPhonogram Race 5-10 91\\nPhonogram Challenge 4-8 92Game Ages Page\\nWrite and Erase 5-10 93\\nTeacher Trouble 4-6 94\\nLast One Standing 4-8 95\\nPhonogram Read and Write 5-10 96\\nActive Reading Games 97\\nGame Ages Page\\nReading Light-Up 4-10 98\\nWord Retriever 4-7 99\\nReading Journey 4-8 100\\nWord Mountain 4-8 101\\nReading Tightrope 4-7 102', 'Phonogram Read and Write 5-10 96\\nActive Reading Games 97\\nGame Ages Page\\nReading Light-Up 4-10 98\\nWord Retriever 4-7 99\\nReading Journey 4-8 100\\nWord Mountain 4-8 101\\nReading Tightrope 4-7 102\\nReading Stop and Go 4-10 103\\nReading Fluency Sort 6-10 104\\nHigh-Frequency Word Run 6-12 105\\nReading Tower 4-7 106\\nReading Hop Along 5-10 107\\nWord Maze 4-8 108\\nIsland Reading Tour 4-7 109\\nHigh-Frequency Word Scatter 4-9 110\\nSnatch the Match! 5-10 111\\nHigh-Frequency Word Stations 6+ 112\\nWord Arcade Race 4-12 113\\nReading Treasure Hunt 4-10 114\\nWord Hopscotch 5-10 115Game Ages Page\\nWord Bowling 4-10 116\\nHigh-Frequency Word Fishing 4-9 117\\nReading Football 6+ 118\\nReading Soccer 6+ 119\\nReading Baseball 6+ 120\\nReading Basketball 6+ 121\\nSilent E Machine 4-7 122\\nSilent E Hopscotch 5-10 123', 'High-Frequency Word Fishing 4-9 117\\nReading Football 6+ 118\\nReading Soccer 6+ 119\\nReading Baseball 6+ 120\\nReading Basketball 6+ 121\\nSilent E Machine 4-7 122\\nSilent E Hopscotch 5-10 123\\nAirplane Reading 5-10 124\\nReading Charades 4+ 125\\nHigh-Frequency Word Race 4-7 126\\nReading Y Words 5-9 127\\nLong Vowel Hunt 5-8 128\\nSilent E Store 5-9 129\\nMarco Polo Word Game 5-10 130\\nCompound Echolocation 5-10 131\\nSuffix Collection 7-12 1325\\n Reading Card Games 133\\nGame Ages Page\\nSort Those Words 6+ 134\\nFluency Trail 4-9 135\\nReading Trios 8+ 136\\nGo Fish! 6-12 137Game Ages Page\\nLong Vowel Sort 6+ 138\\nFor My Birthday I Want a... 5-10 139\\nPast Tense Memory Game 5+ 140\\nFox in the Hen House 4-7 141\\nReading Board Games 143\\nGame Ages Page\\nReading Bubble Race 4-9 144\\nReading Board Game 4+ 145\\nReading Bingo 4+ 146', 'Past Tense Memory Game 5+ 140\\nFox in the Hen House 4-7 141\\nReading Board Games 143\\nGame Ages Page\\nReading Bubble Race 4-9 144\\nReading Board Game 4+ 145\\nReading Bingo 4+ 146\\nReading Tic-Tac-Toe 5+ 147Game Ages Page\\nVowel Race Track 6-12 148\\nLong Vowel Switchback 5+ 149\\nSilent E Board Game 4-9 150\\nSilent E Ladders and Slides 6-10 151\\nReading Speed Games 153\\nGame Ages Page\\nReading Beat the Clock 6+ 154\\nSentence Builder 7+ 155Game Ages Page\\nEraser Race 6+ 156\\nActive Spelling Games 157\\nGame Ages Page\\nSpelling Treasure Hunt 5-10 158\\nSpelling Obstacle Course 6-10 159\\nSpelling Tiles Relay 4-9 160\\nFly Swatter Spelling 4-9 161\\nSpelling Journey 5-8 162\\nWriting Race 6-10 163\\nSpelling Arcade Race 6-12 164\\nThe Spelling Circuit 6-12 165\\nSpelling Balancing Act 7+ 166Game Ages Page\\nTeam Spelling 7-12 167', 'Spelling Journey 5-8 162\\nWriting Race 6-10 163\\nSpelling Arcade Race 6-12 164\\nThe Spelling Circuit 6-12 165\\nSpelling Balancing Act 7+ 166Game Ages Page\\nTeam Spelling 7-12 167\\nSpelling Football 6+ 168\\nSpelling Soccer 6+ 169\\nSpelling Baseball 6+ 170\\nSpelling Basketball 6+ 171\\nI’m the Teacher 6+ 172\\nSpelling I Spy 6+ 173\\nSpelling Detectives 7+ 174\\nSchwavenger Hunt 6+ 175\\nSpelling Card Games 177\\nGame Ages Page\\nAdd and Take 7+ 178\\nMake a Memory Game 6+ 179Game Ages Page\\nGuess My Word 6+ 180\\nHouse of Cards 7+ 181\\nSpelling Board Games 183\\nGame Ages Page\\nWord Search 7+ 184\\nSink and Spell 7+ 185\\nSpelling Tic-Tac-Toe 6+ 186Game Ages Page\\nCreate a Crossword Puzzle 8+ 187\\nSpelling Scramble 7+ 188\\nSpelling Tile Games 189\\nGame Ages Page\\nSpelling Hide and Go Seek 6-12 190\\nCreating New Words 5+ 191', 'Spelling Tic-Tac-Toe 6+ 186Game Ages Page\\nCreate a Crossword Puzzle 8+ 187\\nSpelling Scramble 7+ 188\\nSpelling Tile Games 189\\nGame Ages Page\\nSpelling Hide and Go Seek 6-12 190\\nCreating New Words 5+ 191\\nSpeedy Spelling Tiles 6+ 192Game Ages Page\\nHow Many Words? 7+ 193\\nSpelling Scavenger Hunt 9+ 1946\\n Logic of English Game BookCreative Spelling Games 195\\nGame Ages Page\\nRainbow Writing 7-12 196\\nSpelling Magician 6-10 197\\nType the Words 6+ 198\\nWord Picture 7-14 199\\nSpelling Collage 7+ 200\\nSpelling Nature Art 5-9 201\\nPipe Cleaner Spelling 7-10 202Game Ages Page\\nY arn Spelling 7-10 203\\nWord Quilt 4-10 204\\nPicture Dictionary 7+ 205\\nGuess My Picture 7+ 206\\nStory Writing 8+ 207\\nIllustrate the Equation 6+ 208\\nSpelling Speed Games 209\\nGame Ages Page\\nRecord the Words 7-12 210', 'Word Quilt 4-10 204\\nPicture Dictionary 7+ 205\\nGuess My Picture 7+ 206\\nStory Writing 8+ 207\\nIllustrate the Equation 6+ 208\\nSpelling Speed Games 209\\nGame Ages Page\\nRecord the Words 7-12 210\\nOther Handed Spelling 6-12 211\\nSpeed Writing 6-12 212Game Ages Page\\nTiny Spelling 7-12 213\\nSpelling Graph Paper 6-9 214\\nSpell It Loud 6-12 215\\nTactile Spelling Activities 217\\nGame Ages Page\\nSalt Box Race 4-7 218\\nPlaydough Carving 5-12 219\\nWord Painting 6-12 220\\nCotton Swab Erasing 6-12 221Game Ages Page\\nBlind Spelling 6-12 222\\nGlitter Glue 6-12 223\\nSpelling Actions 4-12 224\\nSet It To Music 7-12 225\\nOther Spelling Games 227\\nGame Ages Page\\nCorrect the Teacher 7+ 228\\nCompound Word Brainstorm 6+ 229Game Ages Page\\nDictation Bookmark 6-12 230\\nComprehension Activities 231\\nGame Ages Page\\nRead and Do 4-8 232', 'Game Ages Page\\nCorrect the Teacher 7+ 228\\nCompound Word Brainstorm 6+ 229Game Ages Page\\nDictation Bookmark 6-12 230\\nComprehension Activities 231\\nGame Ages Page\\nRead and Do 4-8 232\\nWhat Are Y ou Do-ING? 5-12 233\\nReading Robot 5-10 234\\nFive W’s 7+ 235Game Ages Page\\nCreate a Zoo! 6+ 236\\nTravel Guide 6+ 237\\nAdjective-Noun Corners 8-12 238\\nWhat’s That Emoji? 7+ 239\\nMorpheme Activities 241\\nGame Ages Page\\nCon- or Com- Match-Up 8+ 242\\nDefinition Match-Up 8+ 243\\nMorpheme Brainstorm 12+ 244\\nIllustrate It! 9+ 245Game Ages Page\\nMorpheme Collage 8+ 246\\nMorpheme Race 8+ 247\\nNewspaper Highlight 7+ 248\\nMorpheme Puzzle 7+ 249\\nAppendix 251\\nAppendix A: Word Lists 251\\nAppendix B: Master Templates 259\\nAppendix C: Game Lists 287Phonemic Awareness Games  Logic of English Game Book\\n12', 'Morpheme Puzzle 7+ 249\\nAppendix 251\\nAppendix A: Word Lists 251\\nAppendix B: Master Templates 259\\nAppendix C: Game Lists 287Phonemic Awareness Games  Logic of English Game Book\\n12\\nBlending Animal Names Ages 4-8\\nSetting:  Individual & Group\\nTime:  1-3 minutes\\nSupplies:  Animal pictures or toys\\nSet Up  How to Play\\nIndividual\\nChoose four to ten animals whose names are just \\none syllable. Set out pictures or toys that represent \\nthose animals. For an extra challenge, choose some \\nmulti-syllable animal names.  The teacher segments the name of an animal, \\nsaying the individual sounds with a pause between \\nthem (example: /d-o-g/). The student must blend \\nthe sounds back together into a word and hold up \\nthe correct animal.\\nGroup\\nChoose animals whose names are just one syllable.', 'them (example: /d-o-g/). The student must blend \\nthe sounds back together into a word and hold up \\nthe correct animal.\\nGroup\\nChoose animals whose names are just one syllable. \\nFor an extra challenge, choose some multi-syllable \\nanimal names. Set out pictures or toys that \\nrepresent those animals.  \\n \\n \\n The teacher segments the name of an animal, \\nsaying the individual sounds with a pause between \\nthem (example: /d-o-g/). The first player must \\nblend the sounds back together into a word and \\nhold up the correct animal. The rest of the players \\ngive thumbs up if they agree with his answer or \\nthumbs down if they disagree. If he is incorrect, he \\nmay try again. Then another student takes a turn.\\nSample Words\\nOne-Syllable Words:\\ndog, cat, fish, fly, goat, cow, mouse, deer, horse, pig,', 'thumbs down if they disagree. If he is incorrect, he \\nmay try again. Then another student takes a turn.\\nSample Words\\nOne-Syllable Words:\\ndog, cat, fish, fly, goat, cow, mouse, deer, horse, pig, \\nbird, owl, hen, ant, sheep, duck, mole, goose, bearMulti-Syllable Words:\\nturtle, lion, rabbit, tiger, pony, squirrel, llama, panda, \\nmonkey, turkey, gerbil, chicken, elephant, dinosaur\\nVariations\\nAnimal Actors\\nSegment animal names and ask the student to \\nblend the word together and act like the animal.\\nDress-Up Blending\\nSet out a pile of dress-up clothes. Segment a word \\n(h-a-t) and ask the student to pick out that piece of \\nclothing and put it on.Student Pairs\\nGroup the students into pairs. Player A chooses \\nthe name of one of the animals and says it with all', '(h-a-t) and ask the student to pick out that piece of \\nclothing and put it on.Student Pairs\\nGroup the students into pairs. Player A chooses \\nthe name of one of the animals and says it with all \\nthe sounds “un-glued” or segmented. Player B must \\n“glue” or blend the sounds back together and find \\nthe correct animal. Active Phonogram Games\\n29\\nPhonogram Obstacle Course Ages 4-10\\nSetting:  Individual & Group\\nTime:  7-15 minutes\\nSupplies:  Whiteboards and dry erase markers or clipboards with paper and pencils, Phonogram Game \\nCards, obstacles\\nSet Up  How to Play\\nIndividual\\nSet up nine stations with a Phonogram Game Card \\nand a dry erase marker or pencil at each station. Put \\nobstacles between the stations to run around, crawl \\nunder, balance on, or climb over. Give the student a', 'and a dry erase marker or pencil at each station. Put \\nobstacles between the stations to run around, crawl \\nunder, balance on, or climb over. Give the student a \\nwhiteboard or a clipboard with paper.The student follows the obstacle course, stopping \\nat each station to read a phonogram, write it on \\nthe whiteboard or clipboard, and show it to the \\nteacher. When the teacher nods “yes,” the student \\nmay go on to the next obstacle.\\nGroup\\nSet up nine stations around the room with a \\nPhonogram Game Card and a dry erase marker or \\npencil at each station. Put obstacles between the \\nstations to run around, crawl under, balance on, or \\nclimb over. Give each student a whiteboard or a \\nclipboard with paper.  \\n \\n \\n Assign a student referee to each station. The referee', 'stations to run around, crawl under, balance on, or \\nclimb over. Give each student a whiteboard or a \\nclipboard with paper.  \\n \\n \\n Assign a student referee to each station. The referee  \\nmakes sure the phonogram is read and written \\ncorrectly. One after another, the students follow the  \\ncourse, stop at each station to read a phonogram, \\nwrite it on the whiteboard or clipboard, and show \\nit to the referee. When the referee nods “yes,” the \\nstudent may go on to the next obstacle. When \\na student finishes the course, he moves into the \\nposition of a referee, freeing the referee to move \\ninto the line to complete the obstacle course.\\nVariations\\nObstacle Relay Teams\\nDivide the students into three equal teams. Set up \\ntwo short obstacle courses. The members of Team', 'into the line to complete the obstacle course.\\nVariations\\nObstacle Relay Teams\\nDivide the students into three equal teams. Set up \\ntwo short obstacle courses. The members of Team \\nOne referee both courses for the first round. Team \\nTwo forms a relay line at one course and Team \\nThree forms a relay line at the other course. One \\nplayer progresses through the course, reading and \\nwriting the phonograms, then tags the next player. \\nRace to be the fastest relay team. Then rotate the \\nteams so that each team gets one chance to referee \\nand two chances to race.Note: Adjust the setup to accommodate your \\ngroup size. For example, with 24 students you \\ncould have three teams of eight students, and two \\ncourses with four stations. With 20 students you', 'group size. For example, with 24 students you \\ncould have three teams of eight students, and two \\ncourses with four stations. With 20 students you \\ncould have four teams of five students, and two \\ncourses with five stations.Active Reading Games Logic of English Game Book\\n110\\nHigh-Frequency Word Scatter Ages 4-9\\nSetting:  Individual & Group\\nTime:  5-10 minutes\\nSupplies:  High-frequency words to practice, index cards, pen\\nSet Up  How to Play\\nIndividual\\nChoose five to twenty-five high-frequency words \\nfor the student to practice and write each word on \\ntwo index cards. Scatter the index cards around the \\nroom.  \\n \\n \\n The student picks up one card and reads the word \\nout loud. He walks around the room searching for a \\nmatch. When he finds the matching card, he picks', \"1Introduction\\nWhy Play Games?\\nFluency in reading and writing requires a complex set of skills that need to be practiced over time. Th  e \\nhundreds of games and activities in this book provide engaging practice ideas to practice key skill sets \\nwhile respecting students' needs for variety, movement, and fun!\\nWho Are Th  ese Games For?\\nTh  ese games are designed for anyone teaching students of any age to read, spell, or write. Th  ey can be \\nused with any language arts curriculum to add multi-sensory practice, fun, and engagement!\\nHow it Works\\nTh  e Logic of English Game Book is full of games that strengthen literacy skills. Th  ere are active and fun \\nways to strengthen phonemic awareness skills, drill phonograms, build reading fl  uency, practice spelling,\", 'ways to strengthen phonemic awareness skills, drill phonograms, build reading fl  uency, practice spelling, \\nand improve comprehension and vocabulary. Th  ese games equip parents and teachers to provide all sorts \\nof multi-sensory and engaging practice, including high-energy active games, creative games, card games, \\ntactile games, and more. Whether you’ve got ten minutes or all day, these games can help solidify skills \\nand deepen mastery at each step of the learning process.\\nMost games in this book have alternative directions for group and individual settings. Some are designed \\nspecifi  cally for one setting or the other. Each game has a summary of the materials needed, the suggested \\nage range, and the approximate time required to play that game.\\nGame Book Expansion Pack', 'specifi  cally for one setting or the other. Each game has a summary of the materials needed, the suggested \\nage range, and the approximate time required to play that game.\\nGame Book Expansion Pack\\nEight full-color game boards with a laminate coating \\ndesigned for dry erase markers so you can choose \\nphonograms or words to practice. Used in games like \\nSilent E Ladders and Slides, Spelling Scramble, and \\nPhonogram Bubble Race. Available for purchase at \\nstore.logicofenglish.com.\\nAdditional Materials\\nMany games in this book call for the use of common \\nhousehold or classroom materials such as pencils, markers,\\npaper, dice, and toys. Many of the games also call for Logic\\nof English reusable materials. Learn more about these\\nand other helpful resources at www.logicofenglish.com.', 'paper, dice, and toys. Many of the games also call for Logic\\nof English reusable materials. Learn more about these\\nand other helpful resources at www.logicofenglish.com.\\nLOE Reusable Materials Used in Th  ese Games\\n• Phonogram Game Tiles\\n• Phonogram Game Cards\\n• Basic Phonogram Flash Cards\\n• Student Whiteboards\\nstore.logicofenglish.com.\\n2 Logic of English Game Book\\nGlossary of Terms\\nPhonograms - written representations of speech sounds, such as a, b, ou, tch, and eigh. Th  e phonogram \\ngames in this book are designed to help students practice the phonograms’ sounds. When you play a \\nphonogram game, refer to the phonograms by the sound(s) they make, rather than by letter names.\\nPhonemic Awareness - the ability to identify individual sounds within spoken words.', 'phonogram game, refer to the phonograms by the sound(s) they make, rather than by letter names.\\nPhonemic Awareness - the ability to identify individual sounds within spoken words. \\nTh  is skill is generally practiced auditorily and verbally without written text. \\nSegmenting  - breaking words into their individual sounds.\\nBlending - combining individual sounds into whole words. \\nMorphemes - units of meaning within a word, including roots, prefi  xes, and suffi   xes.\\nMorphology  - the study of roots, prefi  xes, and suffi   xes and how they work together to form words. \\nTemplates  - reproducible templates used in some of the games. Th  ey can be found in the back of this \\nbook. Th  ese templates may be copied.\\nBoards  - full color game boards found in the Game Book Expansion Pack.', 'book. Th  ese templates may be copied.\\nBoards  - full color game boards found in the Game Book Expansion Pack.\\nLogic of English® creates integrated\\nlanguage arts curriculum that\\nsystematically intertwines the\\ndiﬀ  erent skills students need to \\nbecome strong readers and writers.\\n • Phonemic Awareness\\n • Systematic Phonics\\n • Fluency\\n • Vocabulary\\n • Comprehension\\n • Composition\\n • Spelling\\n • Grammar\\n • Handwriting\\nLearn more about all of our products at www.logicofengish.com.\\nFoundations\\nAges 4-7Essentials\\nAges 8+\\nSounding Out the \\nSight Words\\nAll Ages3\\n Table of Contents\\nPhonemic Awareness Games 7\\nGame Ages Page\\nSound Detective 4+ 8\\nSorting Sounds 4+ 9\\nCompound Blending Baskets 4-12 10\\nCompound Word Blend & Find 4-12 11\\nBlending Animal Names 4-8 12\\nBlend and Do 4+ 13', 'Phonemic Awareness Games 7\\nGame Ages Page\\nSound Detective 4+ 8\\nSorting Sounds 4+ 9\\nCompound Blending Baskets 4-12 10\\nCompound Word Blend & Find 4-12 11\\nBlending Animal Names 4-8 12\\nBlend and Do 4+ 13\\nConsonant Blending Game 4-12 14Game Ages Page\\nBlending I Spy 4+ 15\\nFirst Sound Bingo 4+ 16\\nVowel Stacks 4-12 17\\nChoose the Object 4-8 18\\nSegmenting I Spy 4-12 19\\nTwenty Sound Questions 6+ 20\\nActive Phonogram Games 21\\nGame Ages Page\\nPhonogram Light-Up 4-10 22\\nPhonogram Retriever 4-9 23\\nPhonogram Hop 4-6 24\\nPhonogram Aerobics 4-8 25\\nPhonogram Color Grab 4-8 26\\nPhonogram Journey 4-8 27\\nPhonogram Scatter 4-10 28\\nPhonogram Obstacle Course 4-10 29\\nPhonogram Bounce 4-6 30\\nPhonogram Hopscotch 5-10 31\\nPhonogram Maze 4-8 32\\nPhonogram Mountain 4-8 33\\nPhonogram Tightrope 4-8 34', 'Phonogram Scatter 4-10 28\\nPhonogram Obstacle Course 4-10 29\\nPhonogram Bounce 4-6 30\\nPhonogram Hopscotch 5-10 31\\nPhonogram Maze 4-8 32\\nPhonogram Mountain 4-8 33\\nPhonogram Tightrope 4-8 34\\nPhonogram Stop and Go 4-10 35\\nPhonogram Pyramid 5-9 36\\nPhonogram Hop Along 5-10 37\\nPhonogram Shoot 5-10 38Game Ages Page\\nLive Phonogram Board Game 4-9 39\\nPhonogram Telephone 5-9 40\\nPhonogram Back Writing 4-10 41\\nSnatch the Match! 4-10 42\\nPhonogram Writing Race 5-10 43\\nPhonogram Arcade Race 4-12 44\\nPhonogram Treasure Hunt 4-10 45\\nPhonogram Bowling 4-10 46\\nPhonogram Fishing 4-9 47\\nPhonogram Football 6+ 48\\nPhonogram Soccer 6+ 49\\nPhonogram Baseball 6+ 50\\nPhonogram Basketball 6+ 51\\nPhonogram Marco Polo 5-10 52\\nPhonogram Collection 5-9 53\\nEcholocation 5-10 54\\nPhonogram Airplanes 5-10 55\\nPhonogram Card Games 57', 'Phonogram Baseball 6+ 50\\nPhonogram Basketball 6+ 51\\nPhonogram Marco Polo 5-10 52\\nPhonogram Collection 5-9 53\\nEcholocation 5-10 54\\nPhonogram Airplanes 5-10 55\\nPhonogram Card Games 57\\nGame Ages Page\\nPhonogram Snatch 4-10 58\\nRotten Egg 4-10 59\\nSpeed 8+ 60\\nLast One! 5-10 61\\nPhonogram Memory 4+ 62Game Ages Page\\nSlap It! 5-12 63\\nGo Fish! 4-8 64\\nDragon 4-9 65\\nABC Order Race 6-12 66\\nPhonogram Train 4-7 674\\n Logic of English Game BookPhonogram Board Games 69\\nGame Ages Page\\nPhonogram Bubble Race 4+ 70\\nPhonogram Board Game 4-9 71\\nPhonogram Bingo 4+ 72Game Ages Page\\nPhonogram Tic-Tac-Toe 6+ 73\\nVowel Bingo 4+ 74\\nPhonogram Team-Up 4-10 75\\nPhonogram Tile Games 77\\nGame Ages Page\\nPhonogram Corners 6-12 78\\nPhonogram Sets and Runs 7+ 79Game Ages Page\\nTen in a Row 4+ 80\\nCreative Phonogram Games 81', 'Vowel Bingo 4+ 74\\nPhonogram Team-Up 4-10 75\\nPhonogram Tile Games 77\\nGame Ages Page\\nPhonogram Corners 6-12 78\\nPhonogram Sets and Runs 7+ 79Game Ages Page\\nTen in a Row 4+ 80\\nCreative Phonogram Games 81\\nGame Ages Page\\nPhonogram Collage 4-12 82\\nCreate a Find 5-14 83\\nPhonogram Nature Art 4-10 84Game Ages Page\\nCreate a Book 4-7 85\\nChalk It Up 4-9 86\\nPhonogram Speed Games 87\\nGame Ages Page\\nBeat the Clock 5-12 88\\nSee It - Say It - Write It 4-10 89\\nPhonogram Flip 5-10 90\\nPhonogram Race 5-10 91\\nPhonogram Challenge 4-8 92Game Ages Page\\nWrite and Erase 5-10 93\\nTeacher Trouble 4-6 94\\nLast One Standing 4-8 95\\nPhonogram Read and Write 5-10 96\\nActive Reading Games 97\\nGame Ages Page\\nReading Light-Up 4-10 98\\nWord Retriever 4-7 99\\nReading Journey 4-8 100\\nWord Mountain 4-8 101\\nReading Tightrope 4-7 102', 'Phonogram Read and Write 5-10 96\\nActive Reading Games 97\\nGame Ages Page\\nReading Light-Up 4-10 98\\nWord Retriever 4-7 99\\nReading Journey 4-8 100\\nWord Mountain 4-8 101\\nReading Tightrope 4-7 102\\nReading Stop and Go 4-10 103\\nReading Fluency Sort 6-10 104\\nHigh-Frequency Word Run 6-12 105\\nReading Tower 4-7 106\\nReading Hop Along 5-10 107\\nWord Maze 4-8 108\\nIsland Reading Tour 4-7 109\\nHigh-Frequency Word Scatter 4-9 110\\nSnatch the Match! 5-10 111\\nHigh-Frequency Word Stations 6+ 112\\nWord Arcade Race 4-12 113\\nReading Treasure Hunt 4-10 114\\nWord Hopscotch 5-10 115Game Ages Page\\nWord Bowling 4-10 116\\nHigh-Frequency Word Fishing 4-9 117\\nReading Football 6+ 118\\nReading Soccer 6+ 119\\nReading Baseball 6+ 120\\nReading Basketball 6+ 121\\nSilent E Machine 4-7 122\\nSilent E Hopscotch 5-10 123', 'High-Frequency Word Fishing 4-9 117\\nReading Football 6+ 118\\nReading Soccer 6+ 119\\nReading Baseball 6+ 120\\nReading Basketball 6+ 121\\nSilent E Machine 4-7 122\\nSilent E Hopscotch 5-10 123\\nAirplane Reading 5-10 124\\nReading Charades 4+ 125\\nHigh-Frequency Word Race 4-7 126\\nReading Y Words 5-9 127\\nLong Vowel Hunt 5-8 128\\nSilent E Store 5-9 129\\nMarco Polo Word Game 5-10 130\\nCompound Echolocation 5-10 131\\nSuffix Collection 7-12 1325\\n Reading Card Games 133\\nGame Ages Page\\nSort Those Words 6+ 134\\nFluency Trail 4-9 135\\nReading Trios 8+ 136\\nGo Fish! 6-12 137Game Ages Page\\nLong Vowel Sort 6+ 138\\nFor My Birthday I Want a... 5-10 139\\nPast Tense Memory Game 5+ 140\\nFox in the Hen House 4-7 141\\nReading Board Games 143\\nGame Ages Page\\nReading Bubble Race 4-9 144\\nReading Board Game 4+ 145\\nReading Bingo 4+ 146', 'Past Tense Memory Game 5+ 140\\nFox in the Hen House 4-7 141\\nReading Board Games 143\\nGame Ages Page\\nReading Bubble Race 4-9 144\\nReading Board Game 4+ 145\\nReading Bingo 4+ 146\\nReading Tic-Tac-Toe 5+ 147Game Ages Page\\nVowel Race Track 6-12 148\\nLong Vowel Switchback 5+ 149\\nSilent E Board Game 4-9 150\\nSilent E Ladders and Slides 6-10 151\\nReading Speed Games 153\\nGame Ages Page\\nReading Beat the Clock 6+ 154\\nSentence Builder 7+ 155Game Ages Page\\nEraser Race 6+ 156\\nActive Spelling Games 157\\nGame Ages Page\\nSpelling Treasure Hunt 5-10 158\\nSpelling Obstacle Course 6-10 159\\nSpelling Tiles Relay 4-9 160\\nFly Swatter Spelling 4-9 161\\nSpelling Journey 5-8 162\\nWriting Race 6-10 163\\nSpelling Arcade Race 6-12 164\\nThe Spelling Circuit 6-12 165\\nSpelling Balancing Act 7+ 166Game Ages Page\\nTeam Spelling 7-12 167', 'Spelling Journey 5-8 162\\nWriting Race 6-10 163\\nSpelling Arcade Race 6-12 164\\nThe Spelling Circuit 6-12 165\\nSpelling Balancing Act 7+ 166Game Ages Page\\nTeam Spelling 7-12 167\\nSpelling Football 6+ 168\\nSpelling Soccer 6+ 169\\nSpelling Baseball 6+ 170\\nSpelling Basketball 6+ 171\\nI’m the Teacher 6+ 172\\nSpelling I Spy 6+ 173\\nSpelling Detectives 7+ 174\\nSchwavenger Hunt 6+ 175\\nSpelling Card Games 177\\nGame Ages Page\\nAdd and Take 7+ 178\\nMake a Memory Game 6+ 179Game Ages Page\\nGuess My Word 6+ 180\\nHouse of Cards 7+ 181\\nSpelling Board Games 183\\nGame Ages Page\\nWord Search 7+ 184\\nSink and Spell 7+ 185\\nSpelling Tic-Tac-Toe 6+ 186Game Ages Page\\nCreate a Crossword Puzzle 8+ 187\\nSpelling Scramble 7+ 188\\nSpelling Tile Games 189\\nGame Ages Page\\nSpelling Hide and Go Seek 6-12 190\\nCreating New Words 5+ 191', 'Spelling Tic-Tac-Toe 6+ 186Game Ages Page\\nCreate a Crossword Puzzle 8+ 187\\nSpelling Scramble 7+ 188\\nSpelling Tile Games 189\\nGame Ages Page\\nSpelling Hide and Go Seek 6-12 190\\nCreating New Words 5+ 191\\nSpeedy Spelling Tiles 6+ 192Game Ages Page\\nHow Many Words? 7+ 193\\nSpelling Scavenger Hunt 9+ 1946\\n Logic of English Game BookCreative Spelling Games 195\\nGame Ages Page\\nRainbow Writing 7-12 196\\nSpelling Magician 6-10 197\\nType the Words 6+ 198\\nWord Picture 7-14 199\\nSpelling Collage 7+ 200\\nSpelling Nature Art 5-9 201\\nPipe Cleaner Spelling 7-10 202Game Ages Page\\nY arn Spelling 7-10 203\\nWord Quilt 4-10 204\\nPicture Dictionary 7+ 205\\nGuess My Picture 7+ 206\\nStory Writing 8+ 207\\nIllustrate the Equation 6+ 208\\nSpelling Speed Games 209\\nGame Ages Page\\nRecord the Words 7-12 210', 'Word Quilt 4-10 204\\nPicture Dictionary 7+ 205\\nGuess My Picture 7+ 206\\nStory Writing 8+ 207\\nIllustrate the Equation 6+ 208\\nSpelling Speed Games 209\\nGame Ages Page\\nRecord the Words 7-12 210\\nOther Handed Spelling 6-12 211\\nSpeed Writing 6-12 212Game Ages Page\\nTiny Spelling 7-12 213\\nSpelling Graph Paper 6-9 214\\nSpell It Loud 6-12 215\\nTactile Spelling Activities 217\\nGame Ages Page\\nSalt Box Race 4-7 218\\nPlaydough Carving 5-12 219\\nWord Painting 6-12 220\\nCotton Swab Erasing 6-12 221Game Ages Page\\nBlind Spelling 6-12 222\\nGlitter Glue 6-12 223\\nSpelling Actions 4-12 224\\nSet It To Music 7-12 225\\nOther Spelling Games 227\\nGame Ages Page\\nCorrect the Teacher 7+ 228\\nCompound Word Brainstorm 6+ 229Game Ages Page\\nDictation Bookmark 6-12 230\\nComprehension Activities 231\\nGame Ages Page\\nRead and Do 4-8 232', 'Game Ages Page\\nCorrect the Teacher 7+ 228\\nCompound Word Brainstorm 6+ 229Game Ages Page\\nDictation Bookmark 6-12 230\\nComprehension Activities 231\\nGame Ages Page\\nRead and Do 4-8 232\\nWhat Are Y ou Do-ING? 5-12 233\\nReading Robot 5-10 234\\nFive W’s 7+ 235Game Ages Page\\nCreate a Zoo! 6+ 236\\nTravel Guide 6+ 237\\nAdjective-Noun Corners 8-12 238\\nWhat’s That Emoji? 7+ 239\\nMorpheme Activities 241\\nGame Ages Page\\nCon- or Com- Match-Up 8+ 242\\nDefinition Match-Up 8+ 243\\nMorpheme Brainstorm 12+ 244\\nIllustrate It! 9+ 245Game Ages Page\\nMorpheme Collage 8+ 246\\nMorpheme Race 8+ 247\\nNewspaper Highlight 7+ 248\\nMorpheme Puzzle 7+ 249\\nAppendix 251\\nAppendix A: Word Lists 251\\nAppendix B: Master Templates 259\\nAppendix C: Game Lists 287Phonemic Awareness Games  Logic of English Game Book\\n12', 'Morpheme Puzzle 7+ 249\\nAppendix 251\\nAppendix A: Word Lists 251\\nAppendix B: Master Templates 259\\nAppendix C: Game Lists 287Phonemic Awareness Games  Logic of English Game Book\\n12\\nBlending Animal Names Ages 4-8\\nSetting:  Individual & Group\\nTime:  1-3 minutes\\nSupplies:  Animal pictures or toys\\nSet Up  How to Play\\nIndividual\\nChoose four to ten animals whose names are just \\none syllable. Set out pictures or toys that represent \\nthose animals. For an extra challenge, choose some \\nmulti-syllable animal names.  The teacher segments the name of an animal, \\nsaying the individual sounds with a pause between \\nthem (example: /d-o-g/). The student must blend \\nthe sounds back together into a word and hold up \\nthe correct animal.\\nGroup\\nChoose animals whose names are just one syllable.', 'them (example: /d-o-g/). The student must blend \\nthe sounds back together into a word and hold up \\nthe correct animal.\\nGroup\\nChoose animals whose names are just one syllable. \\nFor an extra challenge, choose some multi-syllable \\nanimal names. Set out pictures or toys that \\nrepresent those animals.  \\n \\n \\n The teacher segments the name of an animal, \\nsaying the individual sounds with a pause between \\nthem (example: /d-o-g/). The first player must \\nblend the sounds back together into a word and \\nhold up the correct animal. The rest of the players \\ngive thumbs up if they agree with his answer or \\nthumbs down if they disagree. If he is incorrect, he \\nmay try again. Then another student takes a turn.\\nSample Words\\nOne-Syllable Words:\\ndog, cat, fish, fly, goat, cow, mouse, deer, horse, pig,', 'thumbs down if they disagree. If he is incorrect, he \\nmay try again. Then another student takes a turn.\\nSample Words\\nOne-Syllable Words:\\ndog, cat, fish, fly, goat, cow, mouse, deer, horse, pig, \\nbird, owl, hen, ant, sheep, duck, mole, goose, bearMulti-Syllable Words:\\nturtle, lion, rabbit, tiger, pony, squirrel, llama, panda, \\nmonkey, turkey, gerbil, chicken, elephant, dinosaur\\nVariations\\nAnimal Actors\\nSegment animal names and ask the student to \\nblend the word together and act like the animal.\\nDress-Up Blending\\nSet out a pile of dress-up clothes. Segment a word \\n(h-a-t) and ask the student to pick out that piece of \\nclothing and put it on.Student Pairs\\nGroup the students into pairs. Player A chooses \\nthe name of one of the animals and says it with all', '(h-a-t) and ask the student to pick out that piece of \\nclothing and put it on.Student Pairs\\nGroup the students into pairs. Player A chooses \\nthe name of one of the animals and says it with all \\nthe sounds “un-glued” or segmented. Player B must \\n“glue” or blend the sounds back together and find \\nthe correct animal. Active Phonogram Games\\n29\\nPhonogram Obstacle Course Ages 4-10\\nSetting:  Individual & Group\\nTime:  7-15 minutes\\nSupplies:  Whiteboards and dry erase markers or clipboards with paper and pencils, Phonogram Game \\nCards, obstacles\\nSet Up  How to Play\\nIndividual\\nSet up nine stations with a Phonogram Game Card \\nand a dry erase marker or pencil at each station. Put \\nobstacles between the stations to run around, crawl \\nunder, balance on, or climb over. Give the student a', 'and a dry erase marker or pencil at each station. Put \\nobstacles between the stations to run around, crawl \\nunder, balance on, or climb over. Give the student a \\nwhiteboard or a clipboard with paper.The student follows the obstacle course, stopping \\nat each station to read a phonogram, write it on \\nthe whiteboard or clipboard, and show it to the \\nteacher. When the teacher nods “yes,” the student \\nmay go on to the next obstacle.\\nGroup\\nSet up nine stations around the room with a \\nPhonogram Game Card and a dry erase marker or \\npencil at each station. Put obstacles between the \\nstations to run around, crawl under, balance on, or \\nclimb over. Give each student a whiteboard or a \\nclipboard with paper.  \\n \\n \\n Assign a student referee to each station. The referee', 'stations to run around, crawl under, balance on, or \\nclimb over. Give each student a whiteboard or a \\nclipboard with paper.  \\n \\n \\n Assign a student referee to each station. The referee  \\nmakes sure the phonogram is read and written \\ncorrectly. One after another, the students follow the  \\ncourse, stop at each station to read a phonogram, \\nwrite it on the whiteboard or clipboard, and show \\nit to the referee. When the referee nods “yes,” the \\nstudent may go on to the next obstacle. When \\na student finishes the course, he moves into the \\nposition of a referee, freeing the referee to move \\ninto the line to complete the obstacle course.\\nVariations\\nObstacle Relay Teams\\nDivide the students into three equal teams. Set up \\ntwo short obstacle courses. The members of Team', 'into the line to complete the obstacle course.\\nVariations\\nObstacle Relay Teams\\nDivide the students into three equal teams. Set up \\ntwo short obstacle courses. The members of Team \\nOne referee both courses for the first round. Team \\nTwo forms a relay line at one course and Team \\nThree forms a relay line at the other course. One \\nplayer progresses through the course, reading and \\nwriting the phonograms, then tags the next player. \\nRace to be the fastest relay team. Then rotate the \\nteams so that each team gets one chance to referee \\nand two chances to race.Note: Adjust the setup to accommodate your \\ngroup size. For example, with 24 students you \\ncould have three teams of eight students, and two \\ncourses with four stations. With 20 students you', 'group size. For example, with 24 students you \\ncould have three teams of eight students, and two \\ncourses with four stations. With 20 students you \\ncould have four teams of five students, and two \\ncourses with five stations.Active Reading Games Logic of English Game Book\\n110\\nHigh-Frequency Word Scatter Ages 4-9\\nSetting:  Individual & Group\\nTime:  5-10 minutes\\nSupplies:  High-frequency words to practice, index cards, pen\\nSet Up  How to Play\\nIndividual\\nChoose five to twenty-five high-frequency words \\nfor the student to practice and write each word on \\ntwo index cards. Scatter the index cards around the \\nroom.  \\n \\n \\n The student picks up one card and reads the word \\nout loud. He walks around the room searching for a \\nmatch. When he finds the matching card, he picks', 'room.  \\n \\n \\n The student picks up one card and reads the word \\nout loud. He walks around the room searching for a \\nmatch. When he finds the matching card, he picks \\nit up and reads the word out loud. If he reads the \\nword correctly, he may go and find another word \\nto match. If he does not read the word correctly, he \\ntries again, with help from the teacher as needed. \\nWhen he finds and reads all the matches, he wins!\\nGroup\\nChoose high-frequency words for the students \\nto practice and write each word on two index \\ncards. Make at least five pairs per student. Tell the \\nstudents how many matches they should each find, \\nbased on the number of cards you use. Scatter the \\ncards around the room.  \\n \\n \\n \\n \\n \\n \\n Each student picks up one card and reads the word', 'students how many matches they should each find, \\nbased on the number of cards you use. Scatter the \\ncards around the room.  \\n \\n \\n \\n \\n \\n \\n Each student picks up one card and reads the word \\nout loud. All the students walk around the room \\nsearching for a match. When a student finds the \\nmatching card, he picks it up and reads the word to \\nthe teacher. If he reads the word correctly, he may \\ngo and find another word to match. If he does not \\nread the word correctly, he tries again, with help \\nfrom the teacher as needed. If another student is \\nholding the matching card, they may play a tie-\\nbreaking game to determine who will collect the \\nmatch. Once students find their quota of matches, \\nthey may either sit down or help other students. At \\nthe end of the game, students take turns reading', 'match. Once students find their quota of matches, \\nthey may either sit down or help other students. At \\nthe end of the game, students take turns reading \\nthe words they found out loud to the group.\\nVariations\\nCompetition\\nStudents race to find as many pairs as they can. \\nThey must take each pair to the teacher and read \\nthe word correctly before looking for another pair. \\nThe student with the most pairs at the end wins!Timed Scatter\\nSet a timer and record how long it takes the \\nstudent to find all the pairs. Scatter the cards again \\nand see if the student can beat her record! Active Spelling Games\\n173\\nSpelling I Spy Ages 6+\\nSetting:  Individual & Group\\nTime:  1-5 minutes\\nSupplies:  Words to practice, index cards, pen, whiteboards and dry erase markers or pencils and notepads', '173\\nSpelling I Spy Ages 6+\\nSetting:  Individual & Group\\nTime:  1-5 minutes\\nSupplies:  Words to practice, index cards, pen, whiteboards and dry erase markers or pencils and notepads\\nSet Up  How to Play\\nIndividual\\nChoose words to practice spelling and write them \\non index cards. Hang the cards around the room \\nin clear sight of the student. The teacher plays the \\ngame with the student. The teacher and student \\neach hold a whiteboard and dry erase marker, or a \\npencil and notepad.  \\n \\n One player chooses a spelling word. He provides \\na clue to which word he is thinking of by saying, “I \\nspy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants. “ “I spy a word that is \\nan antonym of ____.” The other player guesses', 'spy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants. “ “I spy a word that is \\nan antonym of ____.” The other player guesses \\nwhich word he spies by walking to where that word \\nis hanging. When he finds the right word, both \\nplayers write it.\\nGroup\\nChoose words to practice spelling and write them \\non index cards. Hang the cards around the room \\nin clear sight of all players. Give each student a \\nwhiteboard and dry erase marker.  \\n \\n \\n \\n One player chooses a spelling word. He provides \\na clue to which word he is thinking of by saying, “I \\nspy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants.” “I spy a word that is an', 'spy a word that ____.” For example: “I spy a word \\nthat has two single-letter vowels.” “I spy a word \\nthat has four consonants.” “I spy a word that is an \\nantonym of ____.” Other players guess which word \\nhe spies by walking to where that word is hanging. \\nWhen they have found the right word, all the \\nplayers write it.\\nVariations\\nChallenge\\nInstead of hanging word cards around the room, \\nchallenge students to describe the spelling of \\nobjects they see in the room.Comprehension Activities Logic of English Game Book\\n234\\nReading Robot Ages 5-10\\nSetting:  Individual & Group\\nTime:  5-15 minutes\\nSupplies:  Slips of paper, pen, objects or pictures of objects mentioned in the phrases\\nSet Up  How to Play\\nIndividual & Group\\nWrite phrases from the list below on slips of paper', 'Time:  5-15 minutes\\nSupplies:  Slips of paper, pen, objects or pictures of objects mentioned in the phrases\\nSet Up  How to Play\\nIndividual & Group\\nWrite phrases from the list below on slips of paper \\nfor the student(s) to read, one phrase on each slip. \\nCollect the items mentioned in the phrases or \\nprovide pictures of the items.The students are robots. Each student draws a slip, \\nreads the directions, and does what the directions \\nsay. Multiple players take turns.  \\nSample Phrases\\nPut the dog next to the cow.\\nPut the cat by the dog.\\nPut the fish by the cat.\\nPut the goat next to the cow.\\nPut the frog on top of the goat.\\nPut the duck on top of the fish.\\nPut the hen by the cat.\\nPut the pig by the frog.\\nPut the cat next to the dog.\\nPut the frog by the cat.\\nPut the goat by the frog.', 'Put the frog on top of the goat.\\nPut the duck on top of the fish.\\nPut the hen by the cat.\\nPut the pig by the frog.\\nPut the cat next to the dog.\\nPut the frog by the cat.\\nPut the goat by the frog.\\nPut the pig on top of the frog.\\nPut the hen by the fish.\\nPut the cow next to the hen.Put the duck on top of the cow.\\nPut the rooster on top of the barn.\\nPut the horse by the tree.\\nPut the cow by the horse.\\nPut the sheep in the barn.\\nPut the duck in front of the barn.\\nPut the pig on the path.\\nPut the dresser next to the bed.\\nPut the rug by the bed and the \\ndresser.\\nPut the pillow on the bed.\\nPut the blanket on the bed.\\nPut the doll under the blanket.\\nPut the bear on top of the blanket.Drive the train on the tracks.\\nStop the train.\\nDrive the train through the cave.\\nDrive the train fast.', 'Put the blanket on the bed.\\nPut the doll under the blanket.\\nPut the bear on top of the blanket.Drive the train on the tracks.\\nStop the train.\\nDrive the train through the cave.\\nDrive the train fast.\\nSwitch tracks.\\nDrive the train slow.\\nDrive the train up the hill.\\nDrive the train down the hill.\\nPark the train.\\nPark the car by the train.\\nMake the train go fast on the tracks.\\nDrive the car on the road.\\nMake the car stop.\\nMake the car drive slow on the road.\\nVariations\\nRobotic Voices\\nStudents may read the phrases in different voices.Challenge\\nAsk students to write directions for other robots to \\nfollow.Morpheme Activities Logic of English Game Book\\n248\\nNewspaper Highlight Ages 7+\\nSetting:  Individual & Group\\nTime:  5-10 minutes\\nSupplies:  Newspapers, highlighters\\nSet Up  How to Play', 'follow.Morpheme Activities Logic of English Game Book\\n248\\nNewspaper Highlight Ages 7+\\nSetting:  Individual & Group\\nTime:  5-10 minutes\\nSupplies:  Newspapers, highlighters\\nSet Up  How to Play\\nIndividual & Group\\nProvide each student with a section of the \\nnewspaper or have students find an article that \\nthey are interested in. Provide each student with a \\nhighlighter.  \\n \\n Each student reads their newspaper article and \\nsearches for morphemes they have learned. When \\na student finds one of the morphemes, he marks \\nit with the highlighter. Once all the students finish \\ntheir articles, they share each word they found, the \\nmeaning of the morpheme, and the meaning of the \\nword.\\nVariations\\nCompetition\\nThe player who can find and define the most \\nmorphemes wins!Composition Challenge', 'meaning of the morpheme, and the meaning of the \\nword.\\nVariations\\nCompetition\\nThe player who can find and define the most \\nmorphemes wins!Composition Challenge\\nStudents create their own sentences using the \\nwords that contain the selected morphemes.'], 'uris': None, 'data': None, 'metadatas': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'included': [<IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from int_host_emd import ollama_emb\n",
        "import json\n",
        "\n",
        "games_db = Chroma(persist_directory=\"./chroma_db/games\", embedding_function=ollama_emb)\n",
        "test_coll = games_db.get() # Gets all the data\n",
        "print(test_coll)\n",
        "\n",
        "# the json file where the output must be stored\n",
        "out_file = open(\"./json/games.json\", \"w\")\n",
        "\n",
        "json.dump(test_coll, out_file)\n",
        "\n",
        "out_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.0007629191, -0.016017204, 0.05964438, -0.0065586194, -0.00035870256, -0.0204869, 0.008895703, -0.0019428431, -0.006383767, -0.016018713, -0.011643511, 0.01574233, 0.037187207, 0.02299433, -0.003175757, -0.003256909, -0.01675641, 0.01246609, -0.024588313, -0.022870384, -0.02053404, -0.0028706589, -0.012288395, -0.011708509, 0.020974858, -0.006391835, 0.01123614, -0.007962558, 0.015125625, 0.009852555, 0.020684754, 0.009297284, -0.025251498, 0.0070965444, 0.005013573, -0.018504115, -0.0024167579, 0.016246982, -0.023136893, 0.0068406775, -0.009552687, -0.015694855, 0.006966711, -0.005763419, -0.009104773, -0.0043458934, 0.018754415, 0.023180911, -0.019471468, -0.008306125, 0.009184352, 0.008329004, -0.01756199, 0.008185108, -0.0029403109, -0.010061228, -0.00029907192, -0.004764069, -0.014502829, 0.009481308, 0.00090500846, -0.012083625, -0.018142853, 0.010146915, 0.06498779, -0.05209598, -0.006573271, -0.005743219, -0.0018883348, -0.015776059, 0.003977813, 0.029212011, 0.013312281, -0.0062636393, 0.0056519792, 0.0050817514, 0.0010404541, -0.00803716, 0.005287218, -0.0261308, -0.00812587, -0.01640723, -0.018957015, 0.011924892, -0.012202042, 0.010945124, -0.018903097, -0.00861535, 0.013540537, -0.015925663, 0.0006992691, -0.004295108, 0.006271584, 0.04825593, -0.0021592241, 0.015220536, -0.0033887355, 0.007880339, 0.017490927, 0.021661047, -0.006808907, 0.020423451, 0.0007498479, 0.020093778, -0.0033845617, -0.026667323, 0.008638068, -0.012449026, 0.010293774, -0.00028562342, 0.0070454474, 0.01606816, 0.020578008, -0.014158992, -0.012602376, -0.0077967164, 0.021988275, 0.00094561384, -0.02418847, -0.016775874, -0.02355697, -0.023577051, 0.0038996052, -0.011194761, -0.011473617, 0.029238736, 0.0023889225, -0.008477758, 0.0016999512, -0.015118031, -0.011902431, 0.010952351, 0.01177976, 0.011094175, -0.00709787, 0.015142859, -0.0017825745, -0.004628114, 0.029978676, -0.013765236, 0.0016444732, 0.0010664724, 0.01303478, 0.010521721, -0.01963251, -0.0005250423, 0.018013049, -0.00253788, 0.012755794, 0.0024016337, 0.0045682034, -0.037665404, 0.015013763, -0.002812873, -0.0067745787, -0.004944122, 0.0119534675, -0.022969944, -0.0060639256, -0.005467969, 0.0020732041, 0.015846888, -0.0062159672, 0.012511274, 0.023359062, -0.0013645804, -0.005175081, 0.016393717, -0.009008117, -0.028146548, 0.0008742411, -0.008226774, 0.016202077, -0.02156403, -0.002616035, -0.014995564, 0.02157061, 0.017431537, 0.006377068, -0.0019166509, 0.003994527, -0.010149174, -0.014765353, -0.002375737, -0.009411665, 0.008499292, -0.0012878478, 0.012347609, -0.0029323911, -0.004715833, 0.0063572573, 0.0051384484, -0.022307767, 0.012849814, 0.0021937669, -0.02031111, -0.016498936, 0.016689075, 0.0047132596, 0.009109164, -0.002101827, -0.0022564128, -0.0029840646, -0.006277067, -0.020569844, -0.0082491925, 0.015022286, 0.0065487935, 0.0150411595, 0.0022429435, -0.020274876, -0.019077174, -0.019914761, 0.015856152, -0.004494426, -0.04231704, 0.006592696, 0.021760644, 0.002961559, -0.003461528, 0.005757128, 0.033212095, 0.023049228, -0.010045515, 0.004328432, -0.018302144, 0.006197529, -0.007884958, -0.0063826754, -0.0018633866, 0.012177434, 0.0017277823, -0.00849088, -0.0047509028, -0.029848611, -0.015868274, 0.0069349096, -0.008350609, 0.011463403, -0.003943411, -0.01651919, 0.0098669715, -0.0034536547, -0.0031241304, -0.004083245, 0.025370756, -0.0041207965, 0.006795177, 0.0095887855, 0.0151149845, 0.010389511, 0.012096414, 0.0022248006, -0.0030060129, -0.00918582, 0.007061538, -0.0008261198, -0.00070792204, 0.023677599, 0.023241697, -0.008721657, 0.01552284, -0.0068994123, -0.016317086, 0.0149950525, -0.014399712, -0.0039831577, -0.012912717, -0.0071593076, 0.009618987, -0.015008426, 0.0068256874, -0.014405837, 0.008726362, 0.021850519, -0.006440484, 0.0011577595, 0.0007855575, -0.01778683, 0.022594934, 0.014863592, -0.010315651, -0.03691771, 0.003949522, -0.017577844, -0.0013137251, 0.009433028, 0.004572642, 0.0020802992, 0.0017277262, 0.009384468, 0.0025898528, 0.017768927, -0.02043548, -0.013851511, -0.018233156, -0.040971924, -0.022901433, 0.008291265, -0.012685964, -0.004293061, -0.0031877975, 0.014128813, 0.028258028, 0.009133032, 0.007584811, 0.009564288, -0.031244606, 0.017650481, 0.0037808628, 0.0068792584, -0.0056260726, 0.0048745824, -0.007498363, 0.02002845, -0.005496012, -0.0026289797, 0.0001738692, -0.0029345292, 0.015509128, 0.008223062, 0.0037833625, 0.023323357, -0.0033826109, 0.00480652, -0.006883622, 0.026456146, -0.0073279217, -0.009280964, 0.035435863, 0.0015544052, 0.019697208, 0.021932084, 0.011154587, -0.01647336, 0.0060337796, 0.0013341211, 0.005327445, 0.016209409, 0.014231442, -0.016542759, -0.012423888, 0.003014774, -0.008577387, -0.0056168307, -0.0020783017, -0.009615509, -0.015521694, 0.0038371212, 0.009406307, 0.03431167, -0.003433697, -0.02008267, 0.008495954, -0.027496047, -0.006727699, -0.0099166725, -0.0068231337, 0.029127117, 0.018806918, -0.032542586, -0.012093741, 0.019151874, -0.0075152656, 0.005505055, -0.0021671976, 0.029894564, 0.018577913, 0.035365522, -0.002683945, 0.061736394, 0.009172802, 0.0029885643, -0.009194757, -0.009859072, -0.006655773, 0.015819145, 0.013409493, -0.009417104, -0.0013636817, 0.013836179, 0.01207936, -0.005587161, -0.009016254, -0.0032373604, 0.019329438, -0.026029555, -0.001890634, -0.010664073, 0.012516007, 0.025003133, -0.010372235, -0.015802888, -0.015711779, 0.008980305, -0.011588248, 0.0068258005, 0.0021526807, -0.00623762, 0.018961532, 0.007836603, 0.030742507, 0.0038159029, 0.011987498, 0.012485157, 0.019718017, -0.006467678, 0.011174059, -0.0028646986, -0.0047977767, 0.0059959814, -0.020338794, -0.0051651984, 0.0037626289, 0.016733995, 0.026604023, 0.0023658653, 0.0058750156, 0.012063994, 0.0057868017, 0.0031001328, -0.010167189, -0.004962458, 0.03217847, 0.024116263, 0.028118242, 0.03505634, 0.08980762, -0.015007855, 0.0028623848, -0.010647863, -0.027051518, -0.0008557611, -0.015233686, -0.015030436, 0.01980923, -0.012994407, 0.009908703, -0.0035675904, 0.00016900837, 0.008493796, 0.036224682, -0.026679682, 0.043258198, 0.010303441, 0.009503358, -0.008597301, -0.008507346, -0.032644894, -0.008776634, 0.014573153, 0.043873087, -0.0017538967, 0.017920414, 0.010014953, 0.015238952, 0.020933319, -0.022708949, 0.045794345, 0.025076337, 0.016790453, -0.0036323783, 0.025052827, -0.0014242479, -0.013831162, -0.016394516, -0.011674397, -0.028635744, -0.010687984, -0.0042013787, -0.0030954622, -0.009078709, 0.011207706, -0.0064922296, -0.02377718, -0.020840315, -0.0041880836, -0.020638261, -0.02616354, 0.004933136, 0.017084906, 0.03729609, -0.021155784, 0.028230216, 0.012407181, 0.0015795437, -0.0070194146, -0.017485704, 0.0026920761, 0.02081889, -0.01132574, -0.005905829, -0.003997378, -0.0042545903, 0.0020430523, 0.008937747, 0.004213074, 0.017309085, -0.020555122, -0.011973166, 0.018076204, -0.025267396, 0.027256534, -0.0007451017, 0.014033988, 0.00828349, 0.026769985, 0.023531854, 0.0054650404, 0.0110025285, 0.0174768, 0.016223773, -0.015955424, -0.009260846, -0.003933438, -0.004246964, 0.0021912425, 0.008598407, 0.01986323, -0.032146513, 0.028462043, -0.011225104, -0.044811767, -0.018804863, 0.03826198, -0.009589064, 0.0005047363, 0.031699225, 0.0089825215, -0.013845465, -0.009844374, -0.0057521635, -0.0043752976, -0.015965173, -0.010527908, 0.018753532, -0.017337738, -0.008491768, 0.008523853, 0.026463747, 0.04885792, -0.004797713, 0.025438052, 0.0076735932, 0.001227199, -0.016086338, -0.009282287, -0.0067809443, 0.0011113621, -0.009747252, 0.0060891896, 0.007099576, 0.007560985, -0.02849492, -0.025255002, 0.0076733343, -0.0023748484, -0.003685427, 0.028942369, -0.016835105, -0.003116122, -0.0013774303, -0.011623198, 0.008143032, 0.002960574, 0.016161144, 0.010154227, 0.024150666, -0.0054666335, 0.024114689, -0.0010274659, 0.0030190824, -0.0036305003, 0.0071011037, 0.013850558, 0.011086493, 0.0031617526, 0.026891809, 0.006395293, 1.1912768e-05, -0.014004686, 0.0057992833, -0.004701156, -0.0003175319, 0.02297607, -0.0077439453, -0.008844595, -0.0027823565, 0.025709243, 0.009620182, 0.020880368, -0.0047282954, 0.00028926763, -0.022549428, 0.00917865, 0.0010146268, -0.010916474, -0.0009841537, 0.0043863356, 0.008920238, -0.024869233, 0.0022463747, -0.004846886, -0.012064974, -0.010594982, 0.016030462, 0.0063498244, -0.0037639006, 0.031102678, 0.012908676, 0.008329142, 0.005909157, -0.021617845, -0.015442623, -0.012700716, 0.014959473, 0.014441661, -0.007180219, -0.02343431, 0.011505552, -0.022715807, 0.022908665, 0.00015206289, -0.0047355974, -0.016944787, 0.011291089, 0.01227262, -0.0034783569, -0.017961383, -0.019357258, 0.0032318267, 0.016261522, -0.015897332, -0.017651062, 0.023126718, -0.0031127126, -0.0093657365, 0.0010600894, -0.0010346003, 0.009730405, -0.014317218, 0.017271452, -0.05338878, -0.0037918303, 0.0058751814, -0.0091796825, 0.0052225688, 0.012988217, 0.011561788, 0.013080754, 0.00668739, 0.015810197, 0.0024191998, -0.028364368, -0.0050937785, 0.00266976, 0.005297329, 0.002137206, -0.015787266, -0.023020497, -0.0002480874, 0.049287457, 0.009807522, 0.025045615, -0.012303485, -0.005350533, 0.012854804, -0.001974994, -0.045812815, -0.012601624, 0.018147966, -0.0047782334, -0.0041230163, -0.011475821, -0.017680174, -0.0043974225, 0.052115455, 0.01012505, -0.025473053, -0.0103797475, -0.017879639, -0.007018625, 0.015239289, -0.01412651, -0.010343205, -0.024125678, -0.01477611, 0.022461232, 0.026954275, 0.006389134, 0.013926934, 0.009774258, -0.015623737, 0.004994338, 0.003950083, 0.005976195, -0.035721377, 0.009003666, 0.010741662, -0.019435313, 0.004794457, -0.018943228, 0.040516574, -0.030630345, -0.012845192, 0.01329865, 0.011149427, 0.003922727, 0.0054857107, -0.0069582076, -0.00015347826, 0.00132462, 0.020287218, 0.004947133, 0.010958696, -0.0012444702, -0.019559925, -0.0046909223, 0.010753008, 0.0068277516, 0.0053047733, 0.008337449, -0.0027287013, -0.0031761192, 0.013756085, -0.0127612585, -0.02452134, 0.002765326, 0.011480466, -0.014283214, 0.019095588, 0.013885716, -0.009167785, -0.0076651457, 0.0031083089, -0.0012953379, -0.03384705, 0.029441908, 0.006900772, -0.0284955, 0.0018470831, 0.02351393, -0.01702875, -0.0322336, 0.017487936, -0.004997621, 0.03754063, -0.010128573, -0.010043516, -0.034258746, 0.003550379, 0.03723707, -0.013579987, 0.0075214766, -0.0002043368, -0.006313173, 0.0010929698, -0.002561593, 0.010450363, 0.00972062, 0.0043834597, -0.0017187231, 0.002483906, 0.007507882, 0.029643144, -0.01811916, -0.013758002, 0.025051909, -0.013128336, 0.0047586737, -0.039816216, 0.022576904, 0.021926438, -0.011173565, 0.00068772165, 0.007246317, -0.017059855, -0.015679168, 0.024066785, 0.004693178, -0.014290957, -0.011648835, -0.0076386537, 0.01628392, 0.000804095, -0.0149133345, 0.022395328, 0.023331841, -0.0020771865, 0.016912023, 0.0032286278, -0.01544937, -0.00053359545, 0.0029856511, -0.031769007, 0.014356574, 0.013644213, 0.0013815913, -0.0053791315, 0.015293558, -0.0050191064, -0.019888896, -0.0047102226, -0.025049541, -0.013507054, -0.013533311, -0.013691626, 0.0008181229, -0.01214743, 0.008922223, 0.017817708, 0.018429639, -0.006677476, -0.005344847, -0.0044792355, -0.013781306, -0.01793099, -0.012329684, -0.006827839, 0.0030031002, 0.028269764, 0.017888162, -0.021899134, 7.875091e-05, -0.028608805, 0.04070388, -0.0142277945, -0.013544638, 0.0012038455, 0.007939842, -0.0019626082, -0.026578723, 0.004190644, -0.017093822, -0.004238261, -0.028408116, -0.0009851197, 0.0009894139, 0.007486386, -0.03971997, -0.008629716, -0.00023912461, -0.0018284051, 0.009546756, 0.0053981454, 0.025536608, 0.02015858, -0.0010103174, -0.010251365, 0.012381466, -0.00032998816, -0.018421168, -0.015956242, -0.0036311327, 0.008255972, 0.019463165, -0.0022670918, -0.004217626, 0.0011058828, 0.021095593, -0.002529213, -0.01727858, 0.009256619, -0.009714898, -5.129083e-05, -0.00025332184, -0.017938286, -0.0018981626, -0.022760367, 0.033338923, -0.012894249, 0.023558255, -0.018511621, -0.009503899, -0.0024640127, -0.014613202, -0.012568083, 0.0144449705, -0.012685683, -0.0035989818, -0.005256367, -0.0627358, 0.008737296, 0.023693923, -0.0034698797, -0.0061022257, 0.017117683, -0.0058781602, -0.007818213, -0.011814849, -0.015992504, 0.012562473, -0.00012805944, -0.007271331, -0.0038700094, -0.01292747, 0.026888216, 0.0013203308, 0.027569968, -0.0042428887, -0.019565517, 0.0118670175, -0.0014476742, -0.030962126, 0.026514042, 0.006220762, 0.022068001, 0.013482954, 0.00074546196, 0.001523118, -0.020871181, 0.02546171, 0.023150843, 0.0010514224, 0.0012244649, 0.023800056, 0.015279201, -0.0051439432, 0.0059345197, -0.0028388174, 0.0105716605, 0.015986871, 0.0019482084, 0.0076436414, -0.008871336, -0.0087760445, -0.016823806, -0.028465219, 0.009540726, 0.039351657, -0.0043016323, 0.042934246, -0.020922408, -0.002496803, 0.011892812, -0.02167276, -0.0065140342, -0.0010794419, -0.031428006, 0.009123587, 0.005284508, -0.017008606, -0.0057085515, -0.006513347, -0.004168474, 0.031854372, 0.029165348, -0.001231857, -0.004225318, -0.0025842837, 0.00893857, -0.015436361, -0.00310804, -0.002437886, -0.021760706, 0.01676061, 0.010667935, -0.037132215, 0.008784419, -0.0146061415, 0.028987566, -0.017704679, 0.020181376, -0.012971962, 0.0159962, -0.010921796, -0.005527202, 0.022383539, -0.011594269, -0.007702216, -0.0049753096, 0.011405659, -0.020215318, -0.00023601405, 0.007658857, -0.005853718, -0.0028548476, 0.012700114, 0.011770941, -0.0059668245, -0.014468408, 0.02056482, 0.00019221424, -0.011497335, 0.007960702, -0.016475232, 0.0044991793, -0.007089141, -0.004301563, 0.001075206, -0.00018074579, 0.0076138447, -0.004264358, 0.009536533, -0.003861357, 0.003476608, 0.031179002, -0.012907087, 0.008690134, -0.004507552, 0.015835617, 0.0046610595, -0.018891674, -0.00028136733, -0.011816296, 0.008964602, 0.0031247493, -0.0093042385, 0.049489956, -0.013244147, 0.01830577, 0.015666991, 0.018120574, 0.02197044, -0.005499828, 0.0033907269, 0.0043655266, 0.0020689566, 0.0094715785, -0.0052671214, 0.009330276, 0.009982305, -0.0051290705, 0.011492722, 0.012655524, -0.024505936, 0.012720748, 0.003518098, 0.010670944, 0.009825071, 0.018256882, 0.009528268, 0.00789686, 0.012601229, 0.009102815, 0.008568867, -0.0025324149, -0.0216995, -0.0014174789, 0.0003623741, -0.023360427, -0.0009703093, -0.009342597, 0.0022124804, 0.0005453384, -0.011515856, 0.010002006, 0.012668503, 0.02680853, 0.008021538, 0.008674335, -0.0076437807, 0.03058305, 6.8591808e-06, 0.0009982692, 0.006039451, 0.030958885, -0.007628423, 0.00058972737, 0.004620425, -0.0056298357, 2.7512779e-05, -0.00615028, -0.014210062, 0.008287251, 0.00282216, -0.009227354, -0.003137603, -0.021746758, 0.0048975176, 0.00725025, -0.021180212, 0.04103019, -0.020530932, 0.021090979, 0.010181016, -0.03795284, -0.011096758, 0.0048800143, 0.008443998, -0.004990336, 0.0072756265, 0.0026105992, 0.01990886, -0.0022899765, 0.0039002856, 0.015616418, 0.006367939, 0.035926912, 0.0046841237, 0.004364125, 0.031065917, -0.021553451, 0.0038508363, -0.0006407732, -0.009890372, 0.021460671, -0.00448057, 0.0006768751, 0.005232883, -0.00060858426, 0.0013734276, 0.0180095, 0.0018829728, -0.005292909, -0.010770671, -0.02113241, 0.0087542515, 0.0057163616, 0.012453427, 0.012740309, 0.04643084, -0.0030626908, -0.005409724, 0.0035856476, -0.011707983, -0.0060044336, 0.027688112, 0.0013169643, -0.013876257, 0.0068143257, 0.008529466, 0.002526669, 0.00022301343, -0.0100938715, -0.0016753891, -0.010984111, -0.0027223097, 0.009142818, 0.016051706, 0.0065765604, -0.01930802, -0.0197582, -0.0068086907, -0.010005926, -0.02197295, 0.010390449, 0.022040553, 0.025348123, 0.014903335, -0.009748458, 0.0066105668, -0.018992808, 0.013939347, 0.014706712, -0.027470326, -0.013555496, 0.0058438336, 0.006634095, -0.017480042, -0.007213111, 0.013307905, 0.0015823978, -0.010701688, -0.023497606, -0.0016507515, -0.0028443064, 0.0026735778, 0.005249164, 0.00017020432, 0.019903656, -0.018635789, 0.0015696058, -0.0007096593, 0.010030262, 0.0057453155, 0.01037038, 0.0027756565, 0.0116376905, -0.0070645716, 0.0045466903, -0.018590672, 0.020883685, 0.024460029, -0.0091989115, -0.0060893693, -0.0043859608, -0.020036248, 0.00921339, -0.0067126337, 0.00038755118, 0.012716947, -0.022697676, 0.00416402, 0.019078717, 0.017607596, -0.0010562808, 0.011197688, -0.011242882, -0.008878697, -0.0021112533, -0.005063927, -0.017255483, 0.004008315, 0.013544231, 0.010234845, -0.026981624, 0.008971144, 0.01255257, -0.019942943, 0.01690395, -0.01111178, -0.0028151872, -0.03240999, -0.0020847088, 0.030163474, 0.014342719, -0.026873652, 0.002845379, 0.0029061844, 0.010180341, 0.01345327, -0.004860207, -0.004788998, -0.00018714255, 0.0076995348, -0.0013473331, 0.003067296, -0.013092602, 0.0052193194, 0.0012224707, 0.0029554677, 0.012265762, 0.025820727, -0.014811236, -0.013614136, 0.0016265803, -0.023880085, -0.0064487923, -0.014620114, -0.014520745, 0.018983329, -0.003494348, 0.006687331, -0.013161637, 0.0080803605, -0.0016684433, -0.0071034557, 0.06548534, -0.019984307, -0.009398742, 0.008026008, 0.021253897, 0.003276022, 0.010490892, 0.0083350325, -0.0029314423, 0.007193817, -0.010984545, 0.0045631356, 0.0035548324, -0.0146895405, -0.011618313, 0.005882192, 0.027675293, 0.022676567, 0.0073788716, -0.0060190517, -0.002697516, 0.007953813, -0.005629049, -0.00932047, -0.0046797143, 0.005040697, 0.0020862333, -0.010657537, 0.014042027, 0.024162548, 0.0072772168, -0.0127435895, -0.0025572204, 0.0151401935, 0.0040779174, 0.0058517093, 0.0035615326, 0.007843926, 0.0026289762, -0.0035215768, -0.01185439, -0.010103693, 0.017167317, 0.0053443247, 0.002493366, -0.003977894, -0.018363405, -0.010497737, 0.0017942223, 0.0065926285, 0.009068426, -0.007815493, -0.0012644209, 0.011068229, -0.028113749, -0.01656044, 0.024259422, -0.0041977805, -0.0031024087, 0.014405603, 0.01660146, 0.02050375, -0.0058057, -0.007991199, -0.039065685, -0.0012146662, -0.014782594, 0.009514139, -0.009975642, 0.0023159434, 0.024905415, 0.0030072702, 0.0041107545, -0.016142044, 0.016417539, -0.004562812, 0.028902391, 0.0052250884, -0.012482714, -0.014605327, -0.01279441, 0.0027265053, -0.014584262, -0.007076889, -0.007773672, 0.039712936, 0.016875347, 0.0034097878, 0.022251643, 0.0061405017, 0.02143254, 0.013077203, 0.006581478, 0.006645628, 0.025082948, 0.05323865, 0.016608994, 0.021752562, -0.0019511754, -0.0071883607, -0.0038140558, -0.01299518, 0.015126145, -0.0043258998, 0.006958913, -0.005653692, 0.0038778796, -0.026471829, 0.011600103, 0.0113016125, 0.03326703, 0.0034899502, 0.012159334, 0.008866327, -0.008026103, -0.0055051846, -0.0008525838, 0.0074782195, -0.005287095, 0.009821009, -0.020676253, 0.0055279983, -0.0341843, -0.027676845, 0.02126834, 0.23135717, 0.0037142267, 0.02461753, 0.00045080564, -0.0044106473, -0.01205518, -0.09955255, -0.005384129, 0.0053668437, 0.00018947912, 0.013571825, -0.0022701584, 0.0046711913, 0.0028491286, -0.0123016955, -0.0039551146, -0.03449754, -0.013260459, -0.013725823, -0.008232205, -0.010314785, -0.0018456714, 0.00680202, 0.015797615, -0.02357247, -0.0013122419, -0.00058588164, -0.009248229, 0.03545469, -0.017791923, -0.030963995, 0.010160649, 0.008276266, 0.013012949, -0.008048289, 0.0070600756, -0.0013910461, 0.008180178, 0.023442835, -0.020384364, 0.005095539, -0.031458877, -0.00093931804, 0.0002555697, -0.058484275, -0.020216234, -0.04871095, -0.028041827, -0.016339557, -0.01981345, -0.010225899, -0.008069679, -0.00079247006, -0.06312447, -0.0052154753, 0.027087027, 0.00913219, -0.010811564, 0.0048970846, -0.0023776938, 0.015465416, -0.009661084, -0.011605563, 0.031441197, 0.005956315, 0.012102272, -0.024032183, 0.002329211, -0.008875172, 0.0033109973, 0.02094204, 0.0018056894, -0.02323661, -0.0032838662, -0.021000452, 0.0031476123, 0.010220449, 0.03990525, 0.0016121311, -0.004852862, -0.026121128, -0.0065175495, -0.0032506085, -0.00024818032, 0.011349982, 0.012984001, -0.013371796, -0.02159552, 0.011394136, 0.00021547203, 0.0045242608, 0.013117343, 0.0001770497, 0.019203704, 0.040241767, 0.020190543, 0.018609961, 0.0056582727, -0.018295106, -0.002309664, -0.001195745, 0.0064529553, -0.01282734, 0.0048194467, -0.0069832834, 0.019625792, 0.014509707, 0.008666983, 0.020634769, -0.004211229, 0.010508677, -0.02380764, 0.004427748, 0.0162881, 0.006734565, -0.0018971008, 0.0078030345, -0.011660065, -0.014917049, 0.020576159, 0.00033250268, -0.016491879, 0.022357514, -0.005630105, 0.013107969, 0.008171718, -0.007740812, -0.004800203, -0.015815275, 0.003861444, 0.014681238, 0.015145856, -0.0017049792, 0.012471447, 0.0021962314, -0.0039778776, 0.0024863996, -0.0015044195, 0.023876581, 0.0018511855, 0.006998293, 0.010496111, -0.02227563, 0.025207385, 0.0052745775, 0.045009997, -0.00044843627, 0.009593384, -0.026431626, -0.007828871, -0.014983302, 0.002401605, -0.0042002187, 0.018008899, 0.010067672, -0.015690895, 0.040577434, 0.01876871, -0.013104319, 0.019993622, 0.01493756, 0.029419223, -0.0035759122, -0.01875112, -0.04670499, 0.002028034, -0.026327841, -0.0020733539, 0.002343579, -0.001229684, -0.020152796, 0.03325761, 0.005506168, -0.016104072, -0.0011124103, 0.010566069, -0.00014292101, -0.009350391, -0.010074633, 0.007260334, -0.032604203, 0.011707486, 6.662034e-05, -0.019590788, -0.02170784, 0.012561746, -0.013139549, -0.020080624, 0.0047688396, -0.036262162, 0.024521103, -0.0061221146, 0.018426051, 0.01692795, 0.024662435, -0.008987785, 0.016644504, -0.020633528, -0.02657632, 0.053234838, 0.01234854, 0.008945573, 0.004933557, 0.004184891, 0.00032164907, 0.023267785, 0.0010047157, -0.0074146977, -0.017265968, -0.028153924, 0.0066971546, 0.013845286, 0.018861346, 0.0023329176, 0.0033349507, 0.007919126, 0.030300828, 0.001233497, -0.011423305, 0.01260459, -0.038989577, 0.004478805, 0.03841469, -0.01712759, 0.014358586, 0.016208103, -0.00736089, -0.01280622, 0.032286167, -0.015229908, 0.012157732, 0.004463604, 0.0009498036, 0.016517894, -0.023092464, -0.011129969, -0.01177826, 0.025526067, 0.03039956, -0.015424114, -0.029676901, 0.002158253, -0.03024402, -0.0011154136, -0.01282273, -0.0075401575, 0.007271621, -0.018462608, -0.005184922, -0.014400539, 0.016940985, -0.0051455423, -0.018064551, 0.0072621233, -0.016302494, -0.024664914, -0.01289321, -0.0018969956, -0.025061358, 0.020997241, -0.020645812, -0.019032048, -0.013324751, -0.006699796, 0.024726067, -0.0152986115, 0.0032129558, 0.024671981, 0.0121181235, -0.0013679032, 0.011526605, -0.005318725, 0.0007498566, -0.0039948407, 0.016956063, -0.010256449, 0.016603125, -0.0005874673, -0.026480045, -0.0037878654, -0.012148276, 0.023129271, -0.0127091715, -0.02110924, -0.025891464, -0.0207376, -0.020451335, -0.026445484, 0.008621527, 0.016466115, 0.019174637, 0.012719892, -0.014783084, -0.011885359, 0.014054049, 0.0023605044, 0.006851372, -0.010265396, -0.0114856, -0.0045150463, -0.0012589244, -0.022783183, 0.00047670864, -0.016999634, -0.005080354, 0.0117427595, -0.0050546024, -0.004282933, -0.016436724, -0.0036771588, -0.028445479, 0.0018652857, 0.0018084184, -0.0074210237, 0.0354411, -0.025072552, 0.00063978584, -0.0057878634, 0.0026959402, -0.00020127137, -0.012333944, 0.015230951, -0.001684776, 0.08265515, -0.0136349425, 0.009895885, -0.009146257, -0.037500326, 0.019744249, -0.0008068369, 0.020395601, 0.024036625, -0.0065006344, 0.008621499, 0.0014381085, 0.013828278, 0.00808612, -0.0028574006, -0.013950044, -0.0089206, 0.0023335784, -0.023302795, 0.009562303, 0.018474685, 0.021578297, 0.019971179, -0.013342103, -0.01870033, -0.014937186, 0.011057291, 0.0154288, -0.0034067738, -0.0074753193, 0.007950718, 0.00077316124, -0.013343574, 0.001507764, 0.03037351, 0.012595449, -0.014904777, -0.024606677, 0.00286534, 0.011044387, -0.01363167, 0.023145957, -0.007506394, 0.0022592586, 0.014217326, 0.012594987, -0.008472912, -0.014217072, -0.024370838, 0.02242988, -0.0077330074, 0.0035153197, -0.007319003, 0.0232463, -4.4884415e-05, -0.0015547096, 0.013488847, -0.0014992229, -0.027458383, 0.015610622, 0.009447425, -0.007414625, 0.0023520552, 0.028426697, 0.0047401944, 0.0032137278, -0.013566948, 0.0006289911, -0.02911896, 0.0064817015, -0.04364264, -0.01532436, 0.0012867709, -0.01921715, 0.018663006, 0.03671656, 0.017335419, 0.0028111695, -0.018864596, -0.0256229, -0.014640707, -0.0058821207, -0.00035340447, -0.007610981, -0.011387289, -0.0009404173, 0.006314355, -0.01313847, -0.003853354, 0.0066968775, 0.007028986, 0.018112915, -0.011772258, 0.0001537764, 0.0028436282, -0.020449052, 0.0019329773, -0.006036169, -0.007889665, -0.0001543336, -0.030772835, -0.023832485, 0.0117046265, -0.045661155, -0.004040219, 0.014874013, 0.031343125, 0.015689705, 0.02933353, -0.02135199, 0.0035191744, -0.0024254974, 0.013974126, -0.0061785253, -0.010225564, 0.0049534147, -0.0016995491, 0.00200397, -0.025048021, 0.020165993, 0.00019191977, 0.009792554, 0.011556219, -0.012133887, 0.020887488, 0.008253623, 0.0013091329, -0.0073306924, 0.00042463635, -0.012260057, -0.010355311, 0.007157393, 0.017272849, -0.02072866, 0.019522214, 0.00012562053, -0.00805199, -0.0009753741, -0.009556811, -0.0119356485, 0.03543846, 0.018140446, -0.007019762, 0.0077010863, 0.009409453, -0.02081084, -0.0061536506, 0.014324393, 0.009511336, 0.007373431, 0.002650009, -0.011621783, 0.0058220723, -0.017542683, 0.010593112, -0.00041978553, 0.019803297, -0.012827632, -0.0053399084, 0.004384038, 0.011022811, 0.019283818, 0.02582357, -0.004280071, 0.015029163, 0.020027539, -0.021949748, 0.013166187, -0.0044554356, 0.012811759, 0.0066878865, -0.0029046729, 0.021165632, -0.0036044505, 0.0065206266, 0.0026569911, 0.0063098404, -0.0231158, -0.008001705, -4.3180367e-05, -0.015127372, 0.004953265, 0.0006693105, 0.011951478, 0.019176688, -0.0048408746, 0.0044473084, 0.013354016, 0.0033439319, -0.020473873, 0.0087699955, 0.02015448, -0.019687282, 0.047851972, 0.00021732076, -0.0012051383, -0.016373811, 0.004117366, 0.0033859124, -0.0015911865, 0.018014453, 0.0055143284, 0.012601517, -0.000873502, -0.003553271, 0.017053941, -0.013483761, -0.01650988, -0.0038143012, -0.34528455, 0.012096471, 0.019559937, -0.018358182, -0.023608275, 0.006854606, 0.014704633, 0.04096271, 0.013230509, 0.009156086, -0.006249299, -0.008856024, 0.004340652, 0.00651453, 3.039628e-06, -0.007596386, -0.00093691226, 0.0065426133, 0.016744127, 0.0087019885, 0.0049054716, 0.022704022, -0.0022428208, -0.001144838, 0.0032270919, 0.0059543587, -0.010685226, 0.021593014, -0.007670894, 0.009152322, -0.003995279, 0.008620685, 0.019285554, -0.020681756, -0.007460784, -0.01792808, 4.66266e-06, -0.00087681203, 0.007887236, 0.012072171, -0.013246154, 0.01765655, -0.02433263, 0.02066704, 0.008101652, -0.013351838, 0.024692114, -0.004115644, 0.022211649, -0.015156004, -0.02412219, 0.009101198, -0.0046512247, 0.0062458147, -0.01735414, -0.006876947, -0.00059456634, -0.006543041, -0.009221733, 0.004431872, -0.002010088, 0.006596434, 0.007934264, -0.011716823, -0.0044413228, -0.016245019, 0.006935728, -0.020932458, 0.0046365242, -0.009063915, -0.008776479, 0.023438646, 0.004806878, 0.0076011536, 0.015870463, 0.017120952, 0.0009811906, -0.038725402, -0.020644855, 0.02730371, -0.0033337146, -0.0043965047, 0.01609096, 0.01388499, -0.006233858, -0.014596023, -0.0017544007, 0.0069008092, -0.015519717, 0.015979653, -0.012797616, -0.0040395544, -0.02666407, -0.0149561, 0.015498235, 0.011692348, 0.0027486822, 0.044379234, -0.011515449, 0.01398297, 0.0075712847, 0.017370157, 0.008987692, -0.017465128, -0.13352047, 0.019649155, 0.032001052, -0.01286198, -0.010315427, 0.01135965, -0.014107921, 0.0040267254, 0.014372226, 0.00096142443, -0.056672335, 0.016279705, 0.016340826, 0.015908174, -0.01685941, 0.002781622, -0.017013742, 0.022681238, -0.0035326302, -0.0119471345, 0.0074769277, 0.0007757597, 0.002266849, 0.01421344, -0.011126679, 0.0031090167, -0.0046305596, 0.029332483, 0.011632596, -0.0021361818, -0.012895452, 0.011178259, 0.025625696, -0.011572757, -0.043141715, -0.0008454071, 0.026207112, -0.010396991, 0.0027577048, -0.0076076766, -0.010220209, -0.005812129, -0.009282685, -0.0087557295, 0.007859969, -0.010398977, -0.018105488, -0.007756995, 0.019889766, -0.020514226, -0.01121573, -0.012728071, 0.0009619432, -0.00091585825, 0.019530652, -0.008161599, 0.007642034, -0.018649727, 0.0007350967, -0.009432948, -0.0035548732, -0.0011421012, 0.021072704, 0.0059313076, -0.0024097215, 0.019052517, -0.008039279, -0.0047259084, 0.019635772, -0.0112422565, 0.003029594, -0.017065471, 0.024250688, -0.010143331, 0.033084214, -0.0043206825, -0.0044066343, -0.020969743, -0.011057446, -0.024633598, -0.013636416, 0.018895281, 0.019601468, 0.003901519, -0.01280906, -0.00065814034, 0.015046943, 0.026990304, 0.008701849, -0.01050338, -0.008442367, 0.009094272, -0.00014669193, 0.038839977, 0.013898209, -0.004450854, 0.0038790368, 0.0064196875, -0.016727718, 0.025202537, -0.004896916, -0.025862865, -0.002381415, -0.004008949, -0.010287105, 0.01835513, 0.009539962, -0.009712049, 0.024034202, -0.0077092675, 0.016877882, -0.004360385, -0.013845404, 0.010975774, -0.031250466, -0.014548652, -0.008841636, 0.010963715, -0.0007996773, 0.018588446, -0.0043338244, -0.017878566, -0.00085987325, 0.0056489264, -0.0134313945, -0.0031682714, 0.018904649, 0.031786572, 0.012788314, -0.023844399, 0.006288093, -0.0005422896, 0.0009799869, -0.0032175712, 0.03439507, 0.0018981631, 0.009506049, 0.012295712, 0.0017126314, -0.0020570625, 0.017020361, -0.009769511, -0.006872954, 0.010923705, -0.017461272, -0.010106099, -0.0049935402, 0.0142214745, 0.0027438551, 0.016913254, 0.020140028, 0.0116037065, 0.0021952775, -0.010520015, 0.005157174, 0.038098108, 0.009906747, 0.018770617, 0.009092015, 0.0070503517, -0.024387458, -0.006544972, -0.0019070184, -0.008072496, -0.0026090455, 0.011844649, -0.016830966, 0.012330384, -0.007960494, -0.006564924, 0.014223008, -0.010979325, -0.01030943, 0.050869133, -0.010787726, -0.0033290477, 0.007599524, 0.00015039483, -0.0040447195, 0.0033471857, 0.0010526956, 0.0013813195, 0.008081001, -0.0068200775, -0.03576583, -0.0020754382, -0.02297215, 0.004243421, -0.013223776, -0.01702888, 0.04895642, 0.0037621267, 0.012438935, -0.022928627, 0.013426322, -0.008561838, 0.009839811, -0.0024875752, 0.013828914, 0.004886902, -0.026947118, 0.015775485, -0.0010176438, -0.00013702556, 0.02602608, -0.0026797596, 0.013322222, -0.0124095995, 0.029655669, -0.0009783764, -0.0024930774, 0.023608003, 0.020332325, -0.023948632, -0.009824676, -0.005847278, 0.0075714192, -0.0041707368, 0.030605381, 0.027680814, 0.010881209, -0.015771326, 0.01302982, -0.010170441, -0.008416044, 0.037546758, 1.6939714e-06, 0.019926826, -0.024442688, -0.012237367, 0.0010406751, 0.0054041413, -0.0044891504, 0.004105359, 0.0064509152, -0.0051592966, 0.01241131, 0.0020474116, 0.0025568826, -0.0039189165, 0.017926237, 0.024622213, 0.0011846763, 0.020225361, 0.012181062, -0.012087826, -0.00625644, -0.0060663777, -0.013752547, -0.01365787, -0.0058339476, -0.0041456986, 0.018087527, 0.020821, -0.0075613232, 0.00034863927, 0.015164449, -0.0016886864, 0.009280297, 0.015550462, -0.0013671026, 0.037305914, 0.01133019, 0.03425228, -0.0038729408, -0.012860451, 0.005344581, -0.011185488, -0.010418979, -0.010953906, 0.0009114016, -0.005445326, 0.017257059, -0.006894444, 0.0041309106, 0.0008971725, -0.017405422, -0.008250779, 0.0029720624, 0.0013493508, 0.015338052, 0.0074633583, -0.016347347, 0.00027732074, -0.00086635485, 0.020603582, -0.011923325, 0.008034226, -0.0077885296, 0.0071304054, -0.016151432, 0.0056830333, -0.011736881, -0.00025534903, -0.017150994, 0.0016339628, 0.0075133303, -0.008022205, -0.013717681, 0.010054562, 0.001469837, 0.0018289983, 0.0022525927, 0.013174655, 0.017684918, 0.009650965, 0.014942652, 0.003882176, 0.0025756706, -0.0005255127, 0.0050588665, 0.0008107694, 0.0152976755, -0.015453191, 0.0046309805, 0.014653214, 0.02882623, 0.00738608, -0.022213591, -0.015605565, -0.024637269, 0.017594473, 0.009890059, -0.004747829, 0.012931713, 0.0013484468, -0.02114325, -0.009479791, -0.0017791938, 0.0072104945, -0.0007580818, 0.07339828, -0.0065016127, -0.0017717611, 0.009932847, 0.0038898357, 0.0023235122, -0.005461565, -0.0025427365, 0.004976659, 0.009944303, 0.010017591, 0.012837728, -0.0037058755, -0.004236393, 0.00238595, 0.016929816, -0.018643776, 0.011209067, 0.006066262, 0.008125355, 0.0044083633, 0.0071065454, 0.020888675, -0.022999898, -0.00911895, -0.01671077, 0.010619374, -0.017901523, -0.0033663153, -0.030861989, -0.012221017, -0.002551142, -0.008526364, -0.0050873235, -0.0072954926, -0.0015430121, 0.00662726, 0.008432235, 0.013405561, 0.013781695, -0.019184738, -0.008547475, -0.025922818, 0.004791797, -0.0459306, 0.01694801, 0.016373022, -0.007843821, 0.017740298, -0.01459796, 0.02463145, 1.142312e-05, -0.012745355, 0.007252108, -0.00667663, 0.009338155, -0.015502926, -0.0154864425, 0.018659975, 0.0017840749, 0.0032334386, -0.02452362, -0.005211578, 0.0018633506, 0.0072694495, 0.0041270345, -0.0031338823, -0.015719261, 0.0068361387, 0.011246554, -0.010782746, -0.01432625, 1.3958617e-05, 0.00608323, -0.00014068239, -0.01301804, -0.02638058, -0.0060473992, 0.013577765, 0.015768768, -0.002575424, 0.03450404, 0.0037418087, -0.023439586, -0.0006294945, -0.003200697, 0.00384574, -0.00057771127, -0.002414922, 0.0090240035, -0.018903352, -0.006287488, -0.013349261, 0.0073817563, -0.005472866, -0.00037445212, -0.02579778, 0.0036009895, 0.009942862, -0.007865657, 0.020500772, -0.02329794, 0.008251072, 0.01565918, -0.024988502, -0.010610678, 0.023777904, 0.014004385, 0.003867763, 0.015945945, -0.00057860924, 0.022805806, 0.0084545, 0.009972694, -0.0047343792, 0.0013414687, 0.003582152, -0.0028233966, -0.0022895597, -0.0010372935, -0.0011946094, -0.017361887, 0.0073276125, -0.021572111, 0.05206673, 0.0027460281, -0.018593192, 0.002737815, 0.022643091, 0.014826801, 0.0018698114, 0.011512754, 0.017917212, 0.008958446, 0.00912022, 0.035769384, 0.0041847783, 0.0044506616, 0.0029006694, -0.0012050244, -0.015926536, 0.007524076, 0.029384363, -0.012451179, 0.01242174, -0.0026445368, -0.011532889, 0.013897164, -0.016934777, -0.012298569, 0.012261331, -0.008858196, -0.00381806, -0.00797536, 0.014358624, 0.002997594, 0.025134673, 0.00998219, -0.0050330507, 0.01947254, -0.012591505, 0.013968313, -0.00998667, -0.022316264, -0.014387741, -0.008928091, -0.0012362837, 0.015643185, 0.000124623, -0.0069125295, 0.012300611, 0.023062803, -0.007860019, 0.010112769, -0.0037127875, -0.010581703, -0.001724675, 0.016028138, -0.005473887, 0.006266024, -0.010387749, -0.00370764, 0.021858053, 0.03283125, -0.017475042, -0.03296426, 0.008058834, 0.00022010028, -0.013255896, 0.02070842, -0.012980956, -0.029056551, -0.003706147, -0.011408273, 0.005960004, 0.0100124525, 0.030398771, 0.017001968, 0.013109322, 0.020751532, 0.0036833382, -0.0067858966, -0.007043994, -0.016628942, 0.0034051538, 0.0024045403, -0.011755984, -0.0007499928, 0.0048929644, 0.011083518, 0.011516152, 0.005610802, -0.010378016, 0.0048532463, -0.00053419144, -0.015202871, 0.0013088536, -0.00033775583, -0.010738303, -0.024029056, 0.0060839467, 0.0014363002, 0.017986827, 0.006626206, 0.0025995523, 0.018825302, 0.028323801, -0.0034772602, -0.011856796, -0.002186719, -0.0015161554, -0.0077323685, -0.023256911, 0.021009527, -0.004461219, -0.026123574, -0.017735302, 0.01648881, 0.003517403, 0.006509749, -0.006124865, 0.027165279, -0.0017132538, 0.013971788, -0.019199405, 0.0022409463, -0.007248599, 0.022092935, -0.0032348423, 0.0053824047, -0.0011288008, 0.011179783, -0.0014079373, -0.012437233, -0.0061539263, -0.017931826, 0.0010839208, 0.12596056, -0.0043754163, -0.012584402, 0.011662548, 0.014547382, -0.0039902735, 0.020902118, 0.0045894766, 0.023188267, 0.0028276527, 0.006786336, -0.023699773, -0.0011922448, 0.0033776492, -0.002667448, 0.0155432, 0.008696944, 0.016041208, -0.0037538307, 0.009784884, 0.000941309, 0.0156453, -0.029085476, 0.053731903, -0.024527665, -0.023767136, 0.042071007, -0.0121483775, 0.009934062, -0.001988003, 0.018129684, -0.020121135, 0.008486518, -0.0036017937, -0.008957714, -0.028301407, 0.032907728, -0.009941434, 0.0012635967, -0.038927305, 0.024741184, -0.0021963997, -0.0033553757, 0.00071848516, 0.016102117, 0.0051329625, -0.0062351697, -0.01581742, -0.012719831, 0.018839939, 0.017576164, -0.020660887, -0.03407722, -0.016831143, 0.003190292, -0.011772709, 0.012566248, -0.018753292, 0.015065477, 0.01649277, 0.012825472, 0.013474297, 0.013395974, 0.0022912233, -0.01064499, -0.00987973, -0.013723485, -0.015434682, -0.014905923, -0.005661279, 0.032697927, 0.0077460557, -0.0069308206, -0.0002555745, -0.006179166, 0.03847436, -0.006971199, 0.02543802, -0.020226505, -0.015090738, -0.008460398, -0.022237688, 0.014388606, -0.017027203, 0.001729762, 0.021354213, -0.018750478, -0.0039047017, -0.007062402, -0.025367228, 0.021880971, -0.0008838537, 0.028265689, 0.0136641245, -0.018141873, -0.018725317, 0.008546301, 0.004908889, -0.00053435034, -0.015801733, -0.017396823, -0.008527431, 0.012952873, -0.0012294883, -0.009052781, -0.013499563, 0.0093388865, -0.0010335862, -0.007849282, 0.004280752, 0.009011472, 0.003103392, -0.007421028, 0.015190348, 0.00639878, 0.0014138109, -0.009378165, 0.013070928, 0.0043502375, -0.0057331477, -0.010879845, -0.0061761485, 0.01829533, 0.0015384911, 0.010705732, 0.03269906, -0.03202522, 0.020045107, -0.001962585, 0.026835505, 0.022476003, -0.0048059705, 0.0038555635, 0.008370777, -0.0074920706, -0.025328852, 0.015869424, 0.011336184, 0.027824076, 0.0076404, -0.009313456, -0.0016841682, -0.009202854, 0.01673587, -0.026484929, -0.013295533, 0.005175888, -0.028758068, -0.007737794, 0.0065882523, -0.0016786201, 0.007118303, -0.012529956, 0.01565017, -0.021756392, -0.0061762854, -0.02454715, 0.014986139, -0.016547667, -0.028318051, 0.004008455, -0.03026315, 0.015526746, -0.021414593, -0.00023139847, 0.02300424, 0.018007647, 0.013955537, 0.0031909498, -0.029802473, -0.018549357, -0.0013945618, 0.021752305, -0.004867579, -0.0017157081, 0.016254364, 0.033928104, 0.026060157, -0.01763558, -0.017888298, 0.005076967, -0.01292504, -0.02543524, 0.015651984, 0.016865794, 0.009971961, -0.017411532, 0.0122600105, 0.010350139, 0.026311196, -0.018615171, 0.008555369, 0.00048411835, 0.03017755, -0.0012482204, 0.0021429316, -0.017191295, 0.028896382, -0.019779852, -0.015545295, 0.015633373, -0.007326923, 0.031561226, -0.029388808, -0.018375298, -0.012149829, 0.010514424, 0.011358417, 0.0021155514, -0.020052752, 0.0102549605, 0.009286154, -0.0054698884, -0.0013541905, -0.011922334, 0.021783255, -0.0405333, 0.0130008785, 0.009013533, -0.009390326, 0.0026482483, -0.05311335, -0.010654637, -0.022670312, 0.0032420366, -0.0030093708, -0.012686964, 0.02468648, -0.0034257574, 0.010372902, -0.012901446, 0.014292662, -0.0044377497, 0.008316587, 0.0056517865, -0.00927046, 0.019590143, -0.006296356, -0.023750585, 0.010948904, 0.030541524, 0.011613617, -0.0064697573, -0.009321682, -0.011700776, -0.017147798, -0.002529836, -0.008311609, -0.006612544, -0.031507663, -0.027000582, 0.0051194113, 0.0067472383, -0.010580134, -0.013532823, -0.008312468, 0.0010431745, -0.0010390797, 0.02112689, 0.009763095, 0.0038078774, -0.003443539, 0.034117155, 0.027858745, 0.0024957757, -0.011071666, -0.019328184, -0.018067062, 0.0139775695, 0.00818111, -0.0025751092, 0.020003831, -0.0034736753, 0.005178686, -0.005453986, 0.0025936654, 2.0176314e-05, 0.011700007, -0.020943442, 0.0026799536, 0.0075005936, -0.024215875, 0.013570581, -0.0060930424, 0.003712114, -0.00087756943, 0.0027639947, 0.007955702, -0.010549472, -0.0070300475, -0.0013726965, 0.013340784, -0.017090363, -0.015113781, 0.007166193, 0.008803398, 0.013708775, -0.02957718, 0.011840251, 0.0022210348, -0.0058757225, -0.0134022245, 0.027983498, 0.0145854885, -0.0037356953, -0.01963278, -0.0008696497, 0.0063147866, -0.02124266, 0.027395027, 0.0049963538, -0.00214915, -0.0073022577, -0.004514058, -0.00880237, -0.01221709, 0.004896953, 0.018879807, 0.019884724, -0.0042564757, 0.012879886, -0.020387758, 0.010609256, -0.008661287, 0.005432474, 0.016541544, 0.001208443, -0.004812699, 0.00028560526, -0.017943075, 0.0024244913, 0.0022532893, 0.006663542, 0.0017322599, 0.013649864, -0.027771417, -0.009394151, 0.07339783, -0.006706842, 0.013247485, -0.012976396, -0.017002968, -0.02066124, -0.0038462689, 0.021527989, -0.010611979, 0.017553365, -0.004034557, 0.008094072, -0.00053934817, 0.009675207, -0.020422656, 0.0073363944, 0.020708846, -0.035338853, 0.010490304, 0.050919402, 0.005205955, -0.0039200042, 0.014621562, 0.00039922763, -0.003343401, -0.09897954, -0.01530008, -0.029473381, 0.033534553, 0.006115913, -0.022340145, 0.028184421, -0.03494393, -0.015756, 0.016732752, -0.009004838, -0.01321403, -0.031058792, 0.003850698, -0.0005753141, 0.0013106217, -0.02378275, -0.013370536, -0.017804967, -0.000926321, -0.022081716, -0.02200029, 0.0024314285, -0.011429327, -0.0024340884, 0.0054756603, 0.0031352532, 0.001632668, -0.017948998, 0.0073211836, -0.021302843, 0.00048398596, 0.014268944, -0.00023405567, 0.011742223, 0.0050383066, -0.0013446246, 0.023280445, 0.00094215776, -0.021762546, -0.0039989324, 0.019068627, -0.002328079, 0.005726496, 0.0049179844, 0.01274915, 0.015963094, -0.007669303, 0.02108023, -0.002618981, -0.022273676, -0.0032670463, 0.0044710794, 0.0014580105, -0.0013648729, 0.0075966083, 0.0111568365, -0.01070177, -0.014077799, 0.013968356, 0.0022325453, -0.007556292, -0.0035632823, -0.021184353, -0.027141133, -0.00328775, -0.0133053465, -0.006373188, 0.018078256, -0.020271534, 0.014405729, 0.0022055549, 0.019431153, -0.0017380731, 0.010894331, -0.011621972, 0.0113894185, 0.011657341, -0.0067655346, -0.0030468921, 0.013067476, -0.0053992094, 0.012923909, -0.017261084, -0.0062329555, 0.007772872, 0.009044655, -0.008540212, -0.016647955, 0.028278705, -0.02413084, -0.008681952, 0.023554444, -0.014706189, -0.0022821487, -0.005316722, -0.0007917266, 0.030470833, -0.017893918, -0.0107629355, -0.0056153466, -0.009875931, -0.00091122056, -0.026375096, 0.01272111, -0.0069236564, -0.009866334, 0.020465452, -0.030847933, 0.011015894, -0.014325651, -0.015615064, 0.01834988, 0.00097411283, 0.0069531156, 0.01328959, 0.002945256, 0.005230547, -0.03732641, 0.021564504, -0.010188784, -0.0008496048, 0.004478718]\n"
          ]
        }
      ],
      "source": [
        "print(ollama_emb.embed_query(\"Test input\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLJp8yPF4Rpt"
      },
      "source": [
        "### Run the QA cycle\n",
        "\n",
        "Simply run the cells and ask a question -- or `quit` to stop. (you can also stop execution with the \"▪\" button on the top toolbar)\n",
        "\n",
        "Here are some suggested questions:\n",
        "- _What is the current GDP?_\n",
        "- _How much the agriculture target will be increased to and what the focus will be_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbJugrh7SX3C",
        "outputId": "10e8f954-a113-47a2-a84c-615a9f6e5dc6"
      },
      "outputs": [],
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = vectordb_index.query(query_text, llm=ollama_emb).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in vectordb_index.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a chat_model - Ollama object for internal hosted Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langchain_ollama.chat_models.ChatOllama'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Je dois le code.', additional_kwargs={}, response_metadata={'model': 'llama3.2:3b', 'created_at': '2024-12-04T10:43:27.845045486Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1752585886, 'load_duration': 1579390556, 'prompt_eval_count': 42, 'prompt_eval_duration': 24104000, 'eval_count': 6, 'eval_duration': 59782000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f33e9d61-699d-4ffc-91bc-759d4509dff4-0', usage_metadata={'input_tokens': 42, 'output_tokens': 6, 'total_tokens': 48})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "llm = ChatOllama(base_url='https://ollama.aes.zdidata.com',\n",
        "    model = \"llama3.2:3b\",\n",
        "    temperature = 0.8,\n",
        "    client_kwargs={\"verify\": False},\n",
        ")\n",
        "# print(type(llm))\n",
        "\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "llm.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Je suis passionné de programmation. (Note: This translation is quite literal, but in everyday conversation, you might say \"J\\'adore la programmation\" or \"Programmer me passionne\") \\n\\nIf you\\'d like a more natural-sounding French sentence, here\\'s an alternative:\\n\\n J\\'aime vraiment programmer.\\n\\nOr\\n\\n Je suis fou de l\\'informatique (this one is more general and includes programming).'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "review_chain = llm | output_parser\n",
        "review_chain.invoke(messages)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag_poc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
